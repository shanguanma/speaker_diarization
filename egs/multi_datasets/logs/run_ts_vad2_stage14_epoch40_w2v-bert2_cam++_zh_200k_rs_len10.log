2025-02-06 12:08:36,684 (train_accelerate_ddp:857) INFO: params: {'best_train_loss': inf, 'best_valid_loss': inf, 'best_train_der': inf, 'best_valid_der': inf, 'best_train_epoch': -1, 'best_valid_epoch': -1, 'batch_idx_train': 0, 'log_interval': 500, 'reset_interval': 200, 'valid_interval': 500, 'batch_size': 64, 'verbose': 1, 'world_size': 2, 'tensorboard': True, 'num_epochs': 40, 'max_updates': 40000, 'warmup_updates': 4000, 'freeze_updates': 4000, 'start_batch': 0, 'start_epoch': 1, 'seed': 1337, 'exp_dir': PosixPath('/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10'), 'save_every_n': 1500, 'keep_last_k': 1, 'keep_last_epoch': 1, 'grad_clip': True, 'feature_grad_mult': 0.1, 'lr': 2e-05, 'average_period': 200, 'train_on_average': False, 'musan_path': '/mntcephfs/lee_dataset/asr/musan', 'rir_path': '/mntcephfs/lee_dataset/asr/RIRS_NOISES', 'spk_path': '/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4', 'speaker_embedding_name_dir': 'cam++_zh-cn_200k_feature_dir', 'data_dir': '/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4', 'dataset_name': 'alimeeting_ami_aishell_4', 'max_num_speaker': 7, 'speech_encoder_path': '/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/w2v-bert2.0/model.safetensors', 'select_encoder_layer_nums': 6, 'wavlm_fuse_feat_post_norm': False, 'speech_encoder_config': '/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/w2v-bert2.0/config.json', 'num_transformer_layer': 2, 'd_state': 256, 'expand': 4, 'speech_encoder_type': 'w2v-bert2', 'speaker_embed_dim': 192, 'rs_len': 10, 'segment_shift': 2, 'single_backend_type': 'mamba2', 'multi_backend_type': 'transformer', 'do_finetune': False, 'init_modules': None, 'finetune_ckpt': None}
2025-02-06 12:08:36,684 (train_accelerate_ddp:857) INFO: params: {'best_train_loss': inf, 'best_valid_loss': inf, 'best_train_der': inf, 'best_valid_der': inf, 'best_train_epoch': -1, 'best_valid_epoch': -1, 'batch_idx_train': 0, 'log_interval': 500, 'reset_interval': 200, 'valid_interval': 500, 'batch_size': 64, 'verbose': 1, 'world_size': 2, 'tensorboard': True, 'num_epochs': 40, 'max_updates': 40000, 'warmup_updates': 4000, 'freeze_updates': 4000, 'start_batch': 0, 'start_epoch': 1, 'seed': 1337, 'exp_dir': PosixPath('/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10'), 'save_every_n': 1500, 'keep_last_k': 1, 'keep_last_epoch': 1, 'grad_clip': True, 'feature_grad_mult': 0.1, 'lr': 2e-05, 'average_period': 200, 'train_on_average': False, 'musan_path': '/mntcephfs/lee_dataset/asr/musan', 'rir_path': '/mntcephfs/lee_dataset/asr/RIRS_NOISES', 'spk_path': '/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4', 'speaker_embedding_name_dir': 'cam++_zh-cn_200k_feature_dir', 'data_dir': '/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4', 'dataset_name': 'alimeeting_ami_aishell_4', 'max_num_speaker': 7, 'speech_encoder_path': '/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/w2v-bert2.0/model.safetensors', 'select_encoder_layer_nums': 6, 'wavlm_fuse_feat_post_norm': False, 'speech_encoder_config': '/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/w2v-bert2.0/config.json', 'num_transformer_layer': 2, 'd_state': 256, 'expand': 4, 'speech_encoder_type': 'w2v-bert2', 'speaker_embed_dim': 192, 'rs_len': 10, 'segment_shift': 2, 'single_backend_type': 'mamba2', 'multi_backend_type': 'transformer', 'do_finetune': False, 'init_modules': None, 'finetune_ckpt': None}
2025-02-06 12:08:36,688 (train_accelerate_ddp:873) INFO: data_cfg: TSVADDataConfig(data_dir='/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4', ts_len=6000, rs_len=10, segment_shift=2, spk_path='/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4', speech_encoder_type='w2v-bert2', speaker_embedding_name_dir='cam++_zh-cn_200k_feature_dir', speaker_embed_dim=192, noise_ratio=0.8, zero_ratio=0.3, sample_rate=16000, max_num_speaker=7, dataset_name='alimeeting', embed_input=False, embed_len=1, embed_shift=0.4, label_rate=25, random_channel=False, random_mask_speaker_prob=0.0, random_mask_speaker_step=0, musan_path='/mntcephfs/lee_dataset/asr/musan', rir_path='/mntcephfs/lee_dataset/asr/RIRS_NOISES')
2025-02-06 12:08:36,688 (train_accelerate_ddp:873) INFO: data_cfg: TSVADDataConfig(data_dir='/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4', ts_len=6000, rs_len=10, segment_shift=2, spk_path='/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4', speech_encoder_type='w2v-bert2', speaker_embedding_name_dir='cam++_zh-cn_200k_feature_dir', speaker_embed_dim=192, noise_ratio=0.8, zero_ratio=0.3, sample_rate=16000, max_num_speaker=7, dataset_name='alimeeting', embed_input=False, embed_len=1, embed_shift=0.4, label_rate=25, random_channel=False, random_mask_speaker_prob=0.0, random_mask_speaker_step=0, musan_path='/mntcephfs/lee_dataset/asr/musan', rir_path='/mntcephfs/lee_dataset/asr/RIRS_NOISES')
  0%|          | 0/145 [00:00<?, ?it/s]  0%|          | 0/145 [00:00<?, ?it/s] 29%|██▉       | 42/145 [00:00<00:00, 419.39it/s] 30%|██▉       | 43/145 [00:00<00:00, 421.02it/s] 60%|██████    | 87/145 [00:00<00:00, 435.85it/s] 61%|██████▏   | 89/145 [00:00<00:00, 441.50it/s] 96%|█████████▌| 139/145 [00:00<00:00, 473.28it/s] 97%|█████████▋| 141/145 [00:00<00:00, 473.87it/s]100%|██████████| 145/145 [00:00<00:00, 462.11it/s]
2025-02-06 12:08:37,030 (ts_vad_dataset:152) INFO: model expect fbank as input , fbank_input should be True !!!
2025-02-06 12:08:37,031 (ts_vad_dataset:160) INFO: loaded sentence=35332, shortest sent=640.0, longest sent=160000.0, rs_len=10, segment_shift=2,  rir=False, musan=False, noise_ratio=0.8, zero_ratio=0.3 
100%|██████████| 145/145 [00:00<00:00, 463.83it/s]
2025-02-06 12:08:37,032 (ts_vad_dataset:152) INFO: model expect fbank as input , fbank_input should be True !!!
2025-02-06 12:08:37,033 (ts_vad_dataset:160) INFO: loaded sentence=35332, shortest sent=640.0, longest sent=160000.0, rs_len=10, segment_shift=2,  rir=False, musan=False, noise_ratio=0.8, zero_ratio=0.3 
  0%|          | 0/2080 [00:00<?, ?it/s]  0%|          | 0/2080 [00:00<?, ?it/s]  1%|▏         | 28/2080 [00:00<00:16, 125.41it/s]  1%|▏         | 28/2080 [00:00<00:15, 128.49it/s]  3%|▎         | 64/2080 [00:00<00:09, 216.85it/s]  3%|▎         | 66/2080 [00:00<00:08, 226.95it/s]  5%|▍         | 101/2080 [00:00<00:07, 270.18it/s]  5%|▍         | 103/2080 [00:00<00:07, 276.48it/s]  7%|▋         | 138/2080 [00:00<00:09, 201.28it/s]  7%|▋         | 138/2080 [00:00<00:09, 201.99it/s]  8%|▊         | 173/2080 [00:00<00:08, 237.19it/s]  8%|▊         | 174/2080 [00:00<00:07, 239.87it/s] 10%|█         | 209/2080 [00:00<00:07, 267.12it/s] 10%|█         | 210/2080 [00:00<00:06, 270.52it/s] 12%|█▏        | 246/2080 [00:00<00:06, 294.37it/s] 12%|█▏        | 247/2080 [00:00<00:06, 296.54it/s] 14%|█▎        | 283/2080 [00:01<00:05, 310.34it/s] 14%|█▎        | 284/2080 [00:01<00:05, 316.11it/s] 15%|█▌        | 317/2080 [00:01<00:08, 198.96it/s] 15%|█▌        | 319/2080 [00:01<00:08, 203.18it/s] 17%|█▋        | 355/2080 [00:01<00:07, 233.61it/s] 17%|█▋        | 357/2080 [00:01<00:07, 238.58it/s] 19%|█▉        | 390/2080 [00:01<00:06, 259.19it/s] 19%|█▉        | 392/2080 [00:01<00:06, 262.21it/s] 21%|██        | 431/2080 [00:01<00:05, 294.85it/s] 21%|██        | 433/2080 [00:01<00:05, 297.83it/s] 23%|██▎       | 471/2080 [00:01<00:05, 320.87it/s] 23%|██▎       | 474/2080 [00:01<00:04, 325.64it/s] 25%|██▍       | 512/2080 [00:01<00:04, 344.09it/s] 25%|██▍       | 515/2080 [00:01<00:04, 346.37it/s] 26%|██▋       | 550/2080 [00:02<00:04, 352.28it/s] 27%|██▋       | 553/2080 [00:01<00:04, 353.96it/s] 28%|██▊       | 588/2080 [00:02<00:07, 209.41it/s] 28%|██▊       | 591/2080 [00:02<00:07, 210.55it/s] 30%|███       | 630/2080 [00:02<00:05, 249.27it/s] 30%|███       | 634/2080 [00:02<00:05, 251.23it/s] 32%|███▏      | 670/2080 [00:02<00:05, 280.95it/s] 32%|███▏      | 675/2080 [00:02<00:04, 284.15it/s] 34%|███▍      | 712/2080 [00:02<00:04, 312.07it/s] 34%|███▍      | 716/2080 [00:02<00:04, 312.98it/s] 36%|███▌      | 753/2080 [00:02<00:03, 336.09it/s] 36%|███▋      | 758/2080 [00:02<00:03, 338.59it/s] 38%|███▊      | 797/2080 [00:02<00:03, 362.83it/s] 39%|███▊      | 801/2080 [00:02<00:03, 355.02it/s] 40%|████      | 837/2080 [00:02<00:03, 370.26it/s] 41%|████      | 843/2080 [00:02<00:03, 370.62it/s] 42%|████▏     | 878/2080 [00:03<00:03, 380.11it/s] 43%|████▎     | 886/2080 [00:03<00:03, 384.56it/s] 44%|████▍     | 918/2080 [00:03<00:03, 382.40it/s] 45%|████▍     | 927/2080 [00:03<00:02, 389.28it/s] 46%|████▌     | 961/2080 [00:03<00:02, 395.65it/s] 47%|████▋     | 970/2080 [00:03<00:02, 400.86it/s] 48%|████▊     | 1003/2080 [00:03<00:02, 402.01it/s] 49%|████▊     | 1013/2080 [00:03<00:02, 408.90it/s] 50%|█████     | 1044/2080 [00:03<00:02, 398.41it/s] 51%|█████     | 1055/2080 [00:03<00:02, 403.64it/s] 52%|█████▏    | 1087/2080 [00:03<00:02, 405.74it/s] 53%|█████▎    | 1096/2080 [00:03<00:02, 405.01it/s] 54%|█████▍    | 1128/2080 [00:03<00:02, 396.60it/s] 55%|█████▍    | 1137/2080 [00:03<00:02, 403.93it/s] 56%|█████▋    | 1171/2080 [00:03<00:02, 405.09it/s] 57%|█████▋    | 1178/2080 [00:03<00:02, 404.85it/s] 59%|█████▊    | 1217/2080 [00:03<00:02, 419.14it/s] 59%|█████▉    | 1225/2080 [00:03<00:02, 422.05it/s] 61%|██████    | 1260/2080 [00:03<00:01, 413.32it/s] 61%|██████    | 1268/2080 [00:03<00:01, 420.39it/s] 63%|██████▎   | 1303/2080 [00:04<00:01, 415.75it/s] 63%|██████▎   | 1311/2080 [00:04<00:01, 422.11it/s] 65%|██████▍   | 1349/2080 [00:04<00:01, 427.62it/s] 65%|██████▌   | 1358/2080 [00:04<00:01, 433.89it/s] 67%|██████▋   | 1394/2080 [00:04<00:01, 433.77it/s] 67%|██████▋   | 1402/2080 [00:04<00:01, 431.80it/s] 69%|██████▉   | 1438/2080 [00:04<00:01, 427.50it/s] 70%|██████▉   | 1446/2080 [00:04<00:01, 400.28it/s] 71%|███████   | 1481/2080 [00:04<00:01, 398.41it/s] 72%|███████▏  | 1490/2080 [00:04<00:01, 410.06it/s] 73%|███████▎  | 1523/2080 [00:04<00:01, 404.43it/s] 74%|███████▎  | 1533/2080 [00:04<00:01, 415.69it/s] 76%|███████▌  | 1571/2080 [00:04<00:01, 425.00it/s] 76%|███████▌  | 1582/2080 [00:04<00:01, 435.48it/s] 78%|███████▊  | 1614/2080 [00:04<00:01, 422.58it/s] 78%|███████▊  | 1626/2080 [00:04<00:01, 427.83it/s] 80%|███████▉  | 1662/2080 [00:04<00:00, 437.03it/s] 80%|████████  | 1674/2080 [00:04<00:00, 442.41it/s] 82%|████████▏ | 1706/2080 [00:05<00:00, 403.68it/s] 83%|████████▎ | 1719/2080 [00:05<00:00, 404.60it/s] 84%|████████▍ | 1755/2080 [00:05<00:00, 425.85it/s] 85%|████████▌ | 1770/2080 [00:05<00:00, 433.00it/s] 86%|████████▋ | 1799/2080 [00:05<00:00, 420.64it/s] 87%|████████▋ | 1815/2080 [00:05<00:00, 424.79it/s] 89%|████████▉ | 1849/2080 [00:05<00:00, 442.38it/s] 89%|████████▉ | 1859/2080 [00:05<00:00, 429.00it/s] 91%|█████████ | 1894/2080 [00:05<00:00, 441.76it/s] 92%|█████████▏| 1908/2080 [00:05<00:00, 443.21it/s] 93%|█████████▎| 1939/2080 [00:05<00:00, 443.71it/s] 94%|█████████▍| 1953/2080 [00:05<00:00, 443.15it/s] 96%|█████████▌| 1987/2080 [00:05<00:00, 453.39it/s] 96%|█████████▋| 2002/2080 [00:05<00:00, 455.81it/s] 98%|█████████▊| 2036/2080 [00:05<00:00, 461.28it/s] 99%|█████████▊| 2051/2080 [00:05<00:00, 464.77it/s]100%|██████████| 2080/2080 [00:05<00:00, 354.17it/s]
2025-02-06 12:08:43,282 (ts_vad_dataset:152) INFO: model expect fbank as input , fbank_input should be True !!!
100%|██████████| 2080/2080 [00:05<00:00, 356.36it/s]
2025-02-06 12:08:43,292 (ts_vad_dataset:152) INFO: model expect fbank as input , fbank_input should be True !!!
2025-02-06 12:08:43,294 (ts_vad_dataset:160) INFO: loaded sentence=526485, shortest sent=48640.0, longest sent=160000.0, rs_len=10, segment_shift=2,  rir=True, musan=True, noise_ratio=0.8, zero_ratio=0.3 
2025-02-06 12:08:43,294 (train_accelerate_ddp:908) INFO: The scale window is set to 8192.
2025-02-06 12:08:43,303 (ts_vad_dataset:160) INFO: loaded sentence=526485, shortest sent=48640.0, longest sent=160000.0, rs_len=10, segment_shift=2,  rir=True, musan=True, noise_ratio=0.8, zero_ratio=0.3 
2025-02-06 12:08:43,303 (train_accelerate_ddp:908) INFO: The scale window is set to 8192.
/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler(**kwargs)
/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler(**kwargs)
2025-02-06 12:08:43,451 (other:349) WARNING: Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-02-06 12:08:43,451 (train_accelerate_ddp:946) INFO: model_cfg: TSVADConfig(speech_encoder_path='/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/w2v-bert2.0/model.safetensors', speech_encoder_type='w2v-bert2', freeze_speech_encoder_updates=4000, num_attention_head=4, num_transformer_layer=2, transformer_embed_dim=384, transformer_ffn_embed_dim=1536, speaker_embed_dim=192, dropout=0.1, use_spk_embed=True, feature_grad_mult=0.1, whisper_n_mels=80, select_encoder_layer_nums=6, wavlm_fuse_feat_post_norm=False, speech_encoder_config='/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/w2v-bert2.0/config.json', single_backend_type='mamba2', multi_backend_type='transformer', d_state=256, expand=4)
2025-02-06 12:08:43,451 (train_accelerate_ddp:946) INFO: model_cfg: TSVADConfig(speech_encoder_path='/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/w2v-bert2.0/model.safetensors', speech_encoder_type='w2v-bert2', freeze_speech_encoder_updates=4000, num_attention_head=4, num_transformer_layer=2, transformer_embed_dim=384, transformer_ffn_embed_dim=1536, speaker_embed_dim=192, dropout=0.1, use_spk_embed=True, feature_grad_mult=0.1, whisper_n_mels=80, select_encoder_layer_nums=6, wavlm_fuse_feat_post_norm=False, speech_encoder_config='/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/w2v-bert2.0/config.json', single_backend_type='mamba2', multi_backend_type='transformer', d_state=256, expand=4)
self.wavlm_fuse_feat_post_norm: False
self.wavlm_fuse_feat_post_norm: False
Some weights of the model checkpoint at /mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/w2v-bert2.0/model.safetensors were not used when initializing Wav2Vec2BertModel: ['encoder.layers.10.conv_module.depthwise_conv.weight', 'encoder.layers.10.conv_module.depthwise_layer_norm.bias', 'encoder.layers.10.conv_module.depthwise_layer_norm.weight', 'encoder.layers.10.conv_module.layer_norm.bias', 'encoder.layers.10.conv_module.layer_norm.weight', 'encoder.layers.10.conv_module.pointwise_conv1.weight', 'encoder.layers.10.conv_module.pointwise_conv2.weight', 'encoder.layers.10.ffn1.intermediate_dense.bias', 'encoder.layers.10.ffn1.intermediate_dense.weight', 'encoder.layers.10.ffn1.output_dense.bias', 'encoder.layers.10.ffn1.output_dense.weight', 'encoder.layers.10.ffn1_layer_norm.bias', 'encoder.layers.10.ffn1_layer_norm.weight', 'encoder.layers.10.ffn2.intermediate_dense.bias', 'encoder.layers.10.ffn2.intermediate_dense.weight', 'encoder.layers.10.ffn2.output_dense.bias', 'encoder.layers.10.ffn2.output_dense.weight', 'encoder.layers.10.ffn2_layer_norm.bias', 'encoder.layers.10.ffn2_layer_norm.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.self_attn.distance_embedding.weight', 'encoder.layers.10.self_attn.linear_k.bias', 'encoder.layers.10.self_attn.linear_k.weight', 'encoder.layers.10.self_attn.linear_out.bias', 'encoder.layers.10.self_attn.linear_out.weight', 'encoder.layers.10.self_attn.linear_q.bias', 'encoder.layers.10.self_attn.linear_q.weight', 'encoder.layers.10.self_attn.linear_v.bias', 'encoder.layers.10.self_attn.linear_v.weight', 'encoder.layers.10.self_attn_layer_norm.bias', 'encoder.layers.10.self_attn_layer_norm.weight', 'encoder.layers.11.conv_module.depthwise_conv.weight', 'encoder.layers.11.conv_module.depthwise_layer_norm.bias', 'encoder.layers.11.conv_module.depthwise_layer_norm.weight', 'encoder.layers.11.conv_module.layer_norm.bias', 'encoder.layers.11.conv_module.layer_norm.weight', 'encoder.layers.11.conv_module.pointwise_conv1.weight', 'encoder.layers.11.conv_module.pointwise_conv2.weight', 'encoder.layers.11.ffn1.intermediate_dense.bias', 'encoder.layers.11.ffn1.intermediate_dense.weight', 'encoder.layers.11.ffn1.output_dense.bias', 'encoder.layers.11.ffn1.output_dense.weight', 'encoder.layers.11.ffn1_layer_norm.bias', 'encoder.layers.11.ffn1_layer_norm.weight', 'encoder.layers.11.ffn2.intermediate_dense.bias', 'encoder.layers.11.ffn2.intermediate_dense.weight', 'encoder.layers.11.ffn2.output_dense.bias', 'encoder.layers.11.ffn2.output_dense.weight', 'encoder.layers.11.ffn2_layer_norm.bias', 'encoder.layers.11.ffn2_layer_norm.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.self_attn.distance_embedding.weight', 'encoder.layers.11.self_attn.linear_k.bias', 'encoder.layers.11.self_attn.linear_k.weight', 'encoder.layers.11.self_attn.linear_out.bias', 'encoder.layers.11.self_attn.linear_out.weight', 'encoder.layers.11.self_attn.linear_q.bias', 'encoder.layers.11.self_attn.linear_q.weight', 'encoder.layers.11.self_attn.linear_v.bias', 'encoder.layers.11.self_attn.linear_v.weight', 'encoder.layers.11.self_attn_layer_norm.bias', 'encoder.layers.11.self_attn_layer_norm.weight', 'encoder.layers.12.conv_module.depthwise_conv.weight', 'encoder.layers.12.conv_module.depthwise_layer_norm.bias', 'encoder.layers.12.conv_module.depthwise_layer_norm.weight', 'encoder.layers.12.conv_module.layer_norm.bias', 'encoder.layers.12.conv_module.layer_norm.weight', 'encoder.layers.12.conv_module.pointwise_conv1.weight', 'encoder.layers.12.conv_module.pointwise_conv2.weight', 'encoder.layers.12.ffn1.intermediate_dense.bias', 'encoder.layers.12.ffn1.intermediate_dense.weight', 'encoder.layers.12.ffn1.output_dense.bias', 'encoder.layers.12.ffn1.output_dense.weight', 'encoder.layers.12.ffn1_layer_norm.bias', 'encoder.layers.12.ffn1_layer_norm.weight', 'encoder.layers.12.ffn2.intermediate_dense.bias', 'encoder.layers.12.ffn2.intermediate_dense.weight', 'encoder.layers.12.ffn2.output_dense.bias', 'encoder.layers.12.ffn2.output_dense.weight', 'encoder.layers.12.ffn2_layer_norm.bias', 'encoder.layers.12.ffn2_layer_norm.weight', 'encoder.layers.12.final_layer_norm.bias', 'encoder.layers.12.final_layer_norm.weight', 'encoder.layers.12.self_attn.distance_embedding.weight', 'encoder.layers.12.self_attn.linear_k.bias', 'encoder.layers.12.self_attn.linear_k.weight', 'encoder.layers.12.self_attn.linear_out.bias', 'encoder.layers.12.self_attn.linear_out.weight', 'encoder.layers.12.self_attn.linear_q.bias', 'encoder.layers.12.self_attn.linear_q.weight', 'encoder.layers.12.self_attn.linear_v.bias', 'encoder.layers.12.self_attn.linear_v.weight', 'encoder.layers.12.self_attn_layer_norm.bias', 'encoder.layers.12.self_attn_layer_norm.weight', 'encoder.layers.13.conv_module.depthwise_conv.weight', 'encoder.layers.13.conv_module.depthwise_layer_norm.bias', 'encoder.layers.13.conv_module.depthwise_layer_norm.weight', 'encoder.layers.13.conv_module.layer_norm.bias', 'encoder.layers.13.conv_module.layer_norm.weight', 'encoder.layers.13.conv_module.pointwise_conv1.weight', 'encoder.layers.13.conv_module.pointwise_conv2.weight', 'encoder.layers.13.ffn1.intermediate_dense.bias', 'encoder.layers.13.ffn1.intermediate_dense.weight', 'encoder.layers.13.ffn1.output_dense.bias', 'encoder.layers.13.ffn1.output_dense.weight', 'encoder.layers.13.ffn1_layer_norm.bias', 'encoder.layers.13.ffn1_layer_norm.weight', 'encoder.layers.13.ffn2.intermediate_dense.bias', 'encoder.layers.13.ffn2.intermediate_dense.weight', 'encoder.layers.13.ffn2.output_dense.bias', 'encoder.layers.13.ffn2.output_dense.weight', 'encoder.layers.13.ffn2_layer_norm.bias', 'encoder.layers.13.ffn2_layer_norm.weight', 'encoder.layers.13.final_layer_norm.bias', 'encoder.layers.13.final_layer_norm.weight', 'encoder.layers.13.self_attn.distance_embedding.weight', 'encoder.layers.13.self_attn.linear_k.bias', 'encoder.layers.13.self_attn.linear_k.weight', 'encoder.layers.13.self_attn.linear_out.bias', 'encoder.layers.13.self_attn.linear_out.weight', 'encoder.layers.13.self_attn.linear_q.bias', 'encoder.layers.13.self_attn.linear_q.weight', 'encoder.layers.13.self_attn.linear_v.bias', 'encoder.layers.13.self_attn.linear_v.weight', 'encoder.layers.13.self_attn_layer_norm.bias', 'encoder.layers.13.self_attn_layer_norm.weight', 'encoder.layers.14.conv_module.depthwise_conv.weight', 'encoder.layers.14.conv_module.depthwise_layer_norm.bias', 'encoder.layers.14.conv_module.depthwise_layer_norm.weight', 'encoder.layers.14.conv_module.layer_norm.bias', 'encoder.layers.14.conv_module.layer_norm.weight', 'encoder.layers.14.conv_module.pointwise_conv1.weight', 'encoder.layers.14.conv_module.pointwise_conv2.weight', 'encoder.layers.14.ffn1.intermediate_dense.bias', 'encoder.layers.14.ffn1.intermediate_dense.weight', 'encoder.layers.14.ffn1.output_dense.bias', 'encoder.layers.14.ffn1.output_dense.weight', 'encoder.layers.14.ffn1_layer_norm.bias', 'encoder.layers.14.ffn1_layer_norm.weight', 'encoder.layers.14.ffn2.intermediate_dense.bias', 'encoder.layers.14.ffn2.intermediate_dense.weight', 'encoder.layers.14.ffn2.output_dense.bias', 'encoder.layers.14.ffn2.output_dense.weight', 'encoder.layers.14.ffn2_layer_norm.bias', 'encoder.layers.14.ffn2_layer_norm.weight', 'encoder.layers.14.final_layer_norm.bias', 'encoder.layers.14.final_layer_norm.weight', 'encoder.layers.14.self_attn.distance_embedding.weight', 'encoder.layers.14.self_attn.linear_k.bias', 'encoder.layers.14.self_attn.linear_k.weight', 'encoder.layers.14.self_attn.linear_out.bias', 'encoder.layers.14.self_attn.linear_out.weight', 'encoder.layers.14.self_attn.linear_q.bias', 'encoder.layers.14.self_attn.linear_q.weight', 'encoder.layers.14.self_attn.linear_v.bias', 'encoder.layers.14.self_attn.linear_v.weight', 'encoder.layers.14.self_attn_layer_norm.bias', 'encoder.layers.14.self_attn_layer_norm.weight', 'encoder.layers.15.conv_module.depthwise_conv.weight', 'encoder.layers.15.conv_module.depthwise_layer_norm.bias', 'encoder.layers.15.conv_module.depthwise_layer_norm.weight', 'encoder.layers.15.conv_module.layer_norm.bias', 'encoder.layers.15.conv_module.layer_norm.weight', 'encoder.layers.15.conv_module.pointwise_conv1.weight', 'encoder.layers.15.conv_module.pointwise_conv2.weight', 'encoder.layers.15.ffn1.intermediate_dense.bias', 'encoder.layers.15.ffn1.intermediate_dense.weight', 'encoder.layers.15.ffn1.output_dense.bias', 'encoder.layers.15.ffn1.output_dense.weight', 'encoder.layers.15.ffn1_layer_norm.bias', 'encoder.layers.15.ffn1_layer_norm.weight', 'encoder.layers.15.ffn2.intermediate_dense.bias', 'encoder.layers.15.ffn2.intermediate_dense.weight', 'encoder.layers.15.ffn2.output_dense.bias', 'encoder.layers.15.ffn2.output_dense.weight', 'encoder.layers.15.ffn2_layer_norm.bias', 'encoder.layers.15.ffn2_layer_norm.weight', 'encoder.layers.15.final_layer_norm.bias', 'encoder.layers.15.final_layer_norm.weight', 'encoder.layers.15.self_attn.distance_embedding.weight', 'encoder.layers.15.self_attn.linear_k.bias', 'encoder.layers.15.self_attn.linear_k.weight', 'encoder.layers.15.self_attn.linear_out.bias', 'encoder.layers.15.self_attn.linear_out.weight', 'encoder.layers.15.self_attn.linear_q.bias', 'encoder.layers.15.self_attn.linear_q.weight', 'encoder.layers.15.self_attn.linear_v.bias', 'encoder.layers.15.self_attn.linear_v.weight', 'encoder.layers.15.self_attn_layer_norm.bias', 'encoder.layers.15.self_attn_layer_norm.weight', 'encoder.layers.16.conv_module.depthwise_conv.weight', 'encoder.layers.16.conv_module.depthwise_layer_norm.bias', 'encoder.layers.16.conv_module.depthwise_layer_norm.weight', 'encoder.layers.16.conv_module.layer_norm.bias', 'encoder.layers.16.conv_module.layer_norm.weight', 'encoder.layers.16.conv_module.pointwise_conv1.weight', 'encoder.layers.16.conv_module.pointwise_conv2.weight', 'encoder.layers.16.ffn1.intermediate_dense.bias', 'encoder.layers.16.ffn1.intermediate_dense.weight', 'encoder.layers.16.ffn1.output_dense.bias', 'encoder.layers.16.ffn1.output_dense.weight', 'encoder.layers.16.ffn1_layer_norm.bias', 'encoder.layers.16.ffn1_layer_norm.weight', 'encoder.layers.16.ffn2.intermediate_dense.bias', 'encoder.layers.16.ffn2.intermediate_dense.weight', 'encoder.layers.16.ffn2.output_dense.bias', 'encoder.layers.16.ffn2.output_dense.weight', 'encoder.layers.16.ffn2_layer_norm.bias', 'encoder.layers.16.ffn2_layer_norm.weight', 'encoder.layers.16.final_layer_norm.bias', 'encoder.layers.16.final_layer_norm.weight', 'encoder.layers.16.self_attn.distance_embedding.weight', 'encoder.layers.16.self_attn.linear_k.bias', 'encoder.layers.16.self_attn.linear_k.weight', 'encoder.layers.16.self_attn.linear_out.bias', 'encoder.layers.16.self_attn.linear_out.weight', 'encoder.layers.16.self_attn.linear_q.bias', 'encoder.layers.16.self_attn.linear_q.weight', 'encoder.layers.16.self_attn.linear_v.bias', 'encoder.layers.16.self_attn.linear_v.weight', 'encoder.layers.16.self_attn_layer_norm.bias', 'encoder.layers.16.self_attn_layer_norm.weight', 'encoder.layers.17.conv_module.depthwise_conv.weight', 'encoder.layers.17.conv_module.depthwise_layer_norm.bias', 'encoder.layers.17.conv_module.depthwise_layer_norm.weight', 'encoder.layers.17.conv_module.layer_norm.bias', 'encoder.layers.17.conv_module.layer_norm.weight', 'encoder.layers.17.conv_module.pointwise_conv1.weight', 'encoder.layers.17.conv_module.pointwise_conv2.weight', 'encoder.layers.17.ffn1.intermediate_dense.bias', 'encoder.layers.17.ffn1.intermediate_dense.weight', 'encoder.layers.17.ffn1.output_dense.bias', 'encoder.layers.17.ffn1.output_dense.weight', 'encoder.layers.17.ffn1_layer_norm.bias', 'encoder.layers.17.ffn1_layer_norm.weight', 'encoder.layers.17.ffn2.intermediate_dense.bias', 'encoder.layers.17.ffn2.intermediate_dense.weight', 'encoder.layers.17.ffn2.output_dense.bias', 'encoder.layers.17.ffn2.output_dense.weight', 'encoder.layers.17.ffn2_layer_norm.bias', 'encoder.layers.17.ffn2_layer_norm.weight', 'encoder.layers.17.final_layer_norm.bias', 'encoder.layers.17.final_layer_norm.weight', 'encoder.layers.17.self_attn.distance_embedding.weight', 'encoder.layers.17.self_attn.linear_k.bias', 'encoder.layers.17.self_attn.linear_k.weight', 'encoder.layers.17.self_attn.linear_out.bias', 'encoder.layers.17.self_attn.linear_out.weight', 'encoder.layers.17.self_attn.linear_q.bias', 'encoder.layers.17.self_attn.linear_q.weight', 'encoder.layers.17.self_attn.linear_v.bias', 'encoder.layers.17.self_attn.linear_v.weight', 'encoder.layers.17.self_attn_layer_norm.bias', 'encoder.layers.17.self_attn_layer_norm.weight', 'encoder.layers.18.conv_module.depthwise_conv.weight', 'encoder.layers.18.conv_module.depthwise_layer_norm.bias', 'encoder.layers.18.conv_module.depthwise_layer_norm.weight', 'encoder.layers.18.conv_module.layer_norm.bias', 'encoder.layers.18.conv_module.layer_norm.weight', 'encoder.layers.18.conv_module.pointwise_conv1.weight', 'encoder.layers.18.conv_module.pointwise_conv2.weight', 'encoder.layers.18.ffn1.intermediate_dense.bias', 'encoder.layers.18.ffn1.intermediate_dense.weight', 'encoder.layers.18.ffn1.output_dense.bias', 'encoder.layers.18.ffn1.output_dense.weight', 'encoder.layers.18.ffn1_layer_norm.bias', 'encoder.layers.18.ffn1_layer_norm.weight', 'encoder.layers.18.ffn2.intermediate_dense.bias', 'encoder.layers.18.ffn2.intermediate_dense.weight', 'encoder.layers.18.ffn2.output_dense.bias', 'encoder.layers.18.ffn2.output_dense.weight', 'encoder.layers.18.ffn2_layer_norm.bias', 'encoder.layers.18.ffn2_layer_norm.weight', 'encoder.layers.18.final_layer_norm.bias', 'encoder.layers.18.final_layer_norm.weight', 'encoder.layers.18.self_attn.distance_embedding.weight', 'encoder.layers.18.self_attn.linear_k.bias', 'encoder.layers.18.self_attn.linear_k.weight', 'encoder.layers.18.self_attn.linear_out.bias', 'encoder.layers.18.self_attn.linear_out.weight', 'encoder.layers.18.self_attn.linear_q.bias', 'encoder.layers.18.self_attn.linear_q.weight', 'encoder.layers.18.self_attn.linear_v.bias', 'encoder.layers.18.self_attn.linear_v.weight', 'encoder.layers.18.self_attn_layer_norm.bias', 'encoder.layers.18.self_attn_layer_norm.weight', 'encoder.layers.19.conv_module.depthwise_conv.weight', 'encoder.layers.19.conv_module.depthwise_layer_norm.bias', 'encoder.layers.19.conv_module.depthwise_layer_norm.weight', 'encoder.layers.19.conv_module.layer_norm.bias', 'encoder.layers.19.conv_module.layer_norm.weight', 'encoder.layers.19.conv_module.pointwise_conv1.weight', 'encoder.layers.19.conv_module.pointwise_conv2.weight', 'encoder.layers.19.ffn1.intermediate_dense.bias', 'encoder.layers.19.ffn1.intermediate_dense.weight', 'encoder.layers.19.ffn1.output_dense.bias', 'encoder.layers.19.ffn1.output_dense.weight', 'encoder.layers.19.ffn1_layer_norm.bias', 'encoder.layers.19.ffn1_layer_norm.weight', 'encoder.layers.19.ffn2.intermediate_dense.bias', 'encoder.layers.19.ffn2.intermediate_dense.weight', 'encoder.layers.19.ffn2.output_dense.bias', 'encoder.layers.19.ffn2.output_dense.weight', 'encoder.layers.19.ffn2_layer_norm.bias', 'encoder.layers.19.ffn2_layer_norm.weight', 'encoder.layers.19.final_layer_norm.bias', 'encoder.layers.19.final_layer_norm.weight', 'encoder.layers.19.self_attn.distance_embedding.weight', 'encoder.layers.19.self_attn.linear_k.bias', 'encoder.layers.19.self_attn.linear_k.weight', 'encoder.layers.19.self_attn.linear_out.bias', 'encoder.layers.19.self_attn.linear_out.weight', 'encoder.layers.19.self_attn.linear_q.bias', 'encoder.layers.19.self_attn.linear_q.weight', 'encoder.layers.19.self_attn.linear_v.bias', 'encoder.layers.19.self_attn.linear_v.weight', 'encoder.layers.19.self_attn_layer_norm.bias', 'encoder.layers.19.self_attn_layer_norm.weight', 'encoder.layers.20.conv_module.depthwise_conv.weight', 'encoder.layers.20.conv_module.depthwise_layer_norm.bias', 'encoder.layers.20.conv_module.depthwise_layer_norm.weight', 'encoder.layers.20.conv_module.layer_norm.bias', 'encoder.layers.20.conv_module.layer_norm.weight', 'encoder.layers.20.conv_module.pointwise_conv1.weight', 'encoder.layers.20.conv_module.pointwise_conv2.weight', 'encoder.layers.20.ffn1.intermediate_dense.bias', 'encoder.layers.20.ffn1.intermediate_dense.weight', 'encoder.layers.20.ffn1.output_dense.bias', 'encoder.layers.20.ffn1.output_dense.weight', 'encoder.layers.20.ffn1_layer_norm.bias', 'encoder.layers.20.ffn1_layer_norm.weight', 'encoder.layers.20.ffn2.intermediate_dense.bias', 'encoder.layers.20.ffn2.intermediate_dense.weight', 'encoder.layers.20.ffn2.output_dense.bias', 'encoder.layers.20.ffn2.output_dense.weight', 'encoder.layers.20.ffn2_layer_norm.bias', 'encoder.layers.20.ffn2_layer_norm.weight', 'encoder.layers.20.final_layer_norm.bias', 'encoder.layers.20.final_layer_norm.weight', 'encoder.layers.20.self_attn.distance_embedding.weight', 'encoder.layers.20.self_attn.linear_k.bias', 'encoder.layers.20.self_attn.linear_k.weight', 'encoder.layers.20.self_attn.linear_out.bias', 'encoder.layers.20.self_attn.linear_out.weight', 'encoder.layers.20.self_attn.linear_q.bias', 'encoder.layers.20.self_attn.linear_q.weight', 'encoder.layers.20.self_attn.linear_v.bias', 'encoder.layers.20.self_attn.linear_v.weight', 'encoder.layers.20.self_attn_layer_norm.bias', 'encoder.layers.20.self_attn_layer_norm.weight', 'encoder.layers.21.conv_module.depthwise_conv.weight', 'encoder.layers.21.conv_module.depthwise_layer_norm.bias', 'encoder.layers.21.conv_module.depthwise_layer_norm.weight', 'encoder.layers.21.conv_module.layer_norm.bias', 'encoder.layers.21.conv_module.layer_norm.weight', 'encoder.layers.21.conv_module.pointwise_conv1.weight', 'encoder.layers.21.conv_module.pointwise_conv2.weight', 'encoder.layers.21.ffn1.intermediate_dense.bias', 'encoder.layers.21.ffn1.intermediate_dense.weight', 'encoder.layers.21.ffn1.output_dense.bias', 'encoder.layers.21.ffn1.output_dense.weight', 'encoder.layers.21.ffn1_layer_norm.bias', 'encoder.layers.21.ffn1_layer_norm.weight', 'encoder.layers.21.ffn2.intermediate_dense.bias', 'encoder.layers.21.ffn2.intermediate_dense.weight', 'encoder.layers.21.ffn2.output_dense.bias', 'encoder.layers.21.ffn2.output_dense.weight', 'encoder.layers.21.ffn2_layer_norm.bias', 'encoder.layers.21.ffn2_layer_norm.weight', 'encoder.layers.21.final_layer_norm.bias', 'encoder.layers.21.final_layer_norm.weight', 'encoder.layers.21.self_attn.distance_embedding.weight', 'encoder.layers.21.self_attn.linear_k.bias', 'encoder.layers.21.self_attn.linear_k.weight', 'encoder.layers.21.self_attn.linear_out.bias', 'encoder.layers.21.self_attn.linear_out.weight', 'encoder.layers.21.self_attn.linear_q.bias', 'encoder.layers.21.self_attn.linear_q.weight', 'encoder.layers.21.self_attn.linear_v.bias', 'encoder.layers.21.self_attn.linear_v.weight', 'encoder.layers.21.self_attn_layer_norm.bias', 'encoder.layers.21.self_attn_layer_norm.weight', 'encoder.layers.22.conv_module.depthwise_conv.weight', 'encoder.layers.22.conv_module.depthwise_layer_norm.bias', 'encoder.layers.22.conv_module.depthwise_layer_norm.weight', 'encoder.layers.22.conv_module.layer_norm.bias', 'encoder.layers.22.conv_module.layer_norm.weight', 'encoder.layers.22.conv_module.pointwise_conv1.weight', 'encoder.layers.22.conv_module.pointwise_conv2.weight', 'encoder.layers.22.ffn1.intermediate_dense.bias', 'encoder.layers.22.ffn1.intermediate_dense.weight', 'encoder.layers.22.ffn1.output_dense.bias', 'encoder.layers.22.ffn1.output_dense.weight', 'encoder.layers.22.ffn1_layer_norm.bias', 'encoder.layers.22.ffn1_layer_norm.weight', 'encoder.layers.22.ffn2.intermediate_dense.bias', 'encoder.layers.22.ffn2.intermediate_dense.weight', 'encoder.layers.22.ffn2.output_dense.bias', 'encoder.layers.22.ffn2.output_dense.weight', 'encoder.layers.22.ffn2_layer_norm.bias', 'encoder.layers.22.ffn2_layer_norm.weight', 'encoder.layers.22.final_layer_norm.bias', 'encoder.layers.22.final_layer_norm.weight', 'encoder.layers.22.self_attn.distance_embedding.weight', 'encoder.layers.22.self_attn.linear_k.bias', 'encoder.layers.22.self_attn.linear_k.weight', 'encoder.layers.22.self_attn.linear_out.bias', 'encoder.layers.22.self_attn.linear_out.weight', 'encoder.layers.22.self_attn.linear_q.bias', 'encoder.layers.22.self_attn.linear_q.weight', 'encoder.layers.22.self_attn.linear_v.bias', 'encoder.layers.22.self_attn.linear_v.weight', 'encoder.layers.22.self_attn_layer_norm.bias', 'encoder.layers.22.self_attn_layer_norm.weight', 'encoder.layers.23.conv_module.depthwise_conv.weight', 'encoder.layers.23.conv_module.depthwise_layer_norm.bias', 'encoder.layers.23.conv_module.depthwise_layer_norm.weight', 'encoder.layers.23.conv_module.layer_norm.bias', 'encoder.layers.23.conv_module.layer_norm.weight', 'encoder.layers.23.conv_module.pointwise_conv1.weight', 'encoder.layers.23.conv_module.pointwise_conv2.weight', 'encoder.layers.23.ffn1.intermediate_dense.bias', 'encoder.layers.23.ffn1.intermediate_dense.weight', 'encoder.layers.23.ffn1.output_dense.bias', 'encoder.layers.23.ffn1.output_dense.weight', 'encoder.layers.23.ffn1_layer_norm.bias', 'encoder.layers.23.ffn1_layer_norm.weight', 'encoder.layers.23.ffn2.intermediate_dense.bias', 'encoder.layers.23.ffn2.intermediate_dense.weight', 'encoder.layers.23.ffn2.output_dense.bias', 'encoder.layers.23.ffn2.output_dense.weight', 'encoder.layers.23.ffn2_layer_norm.bias', 'encoder.layers.23.ffn2_layer_norm.weight', 'encoder.layers.23.final_layer_norm.bias', 'encoder.layers.23.final_layer_norm.weight', 'encoder.layers.23.self_attn.distance_embedding.weight', 'encoder.layers.23.self_attn.linear_k.bias', 'encoder.layers.23.self_attn.linear_k.weight', 'encoder.layers.23.self_attn.linear_out.bias', 'encoder.layers.23.self_attn.linear_out.weight', 'encoder.layers.23.self_attn.linear_q.bias', 'encoder.layers.23.self_attn.linear_q.weight', 'encoder.layers.23.self_attn.linear_v.bias', 'encoder.layers.23.self_attn.linear_v.weight', 'encoder.layers.23.self_attn_layer_norm.bias', 'encoder.layers.23.self_attn_layer_norm.weight', 'encoder.layers.6.conv_module.depthwise_conv.weight', 'encoder.layers.6.conv_module.depthwise_layer_norm.bias', 'encoder.layers.6.conv_module.depthwise_layer_norm.weight', 'encoder.layers.6.conv_module.layer_norm.bias', 'encoder.layers.6.conv_module.layer_norm.weight', 'encoder.layers.6.conv_module.pointwise_conv1.weight', 'encoder.layers.6.conv_module.pointwise_conv2.weight', 'encoder.layers.6.ffn1.intermediate_dense.bias', 'encoder.layers.6.ffn1.intermediate_dense.weight', 'encoder.layers.6.ffn1.output_dense.bias', 'encoder.layers.6.ffn1.output_dense.weight', 'encoder.layers.6.ffn1_layer_norm.bias', 'encoder.layers.6.ffn1_layer_norm.weight', 'encoder.layers.6.ffn2.intermediate_dense.bias', 'encoder.layers.6.ffn2.intermediate_dense.weight', 'encoder.layers.6.ffn2.output_dense.bias', 'encoder.layers.6.ffn2.output_dense.weight', 'encoder.layers.6.ffn2_layer_norm.bias', 'encoder.layers.6.ffn2_layer_norm.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.self_attn.distance_embedding.weight', 'encoder.layers.6.self_attn.linear_k.bias', 'encoder.layers.6.self_attn.linear_k.weight', 'encoder.layers.6.self_attn.linear_out.bias', 'encoder.layers.6.self_attn.linear_out.weight', 'encoder.layers.6.self_attn.linear_q.bias', 'encoder.layers.6.self_attn.linear_q.weight', 'encoder.layers.6.self_attn.linear_v.bias', 'encoder.layers.6.self_attn.linear_v.weight', 'encoder.layers.6.self_attn_layer_norm.bias', 'encoder.layers.6.self_attn_layer_norm.weight', 'encoder.layers.7.conv_module.depthwise_conv.weight', 'encoder.layers.7.conv_module.depthwise_layer_norm.bias', 'encoder.layers.7.conv_module.depthwise_layer_norm.weight', 'encoder.layers.7.conv_module.layer_norm.bias', 'encoder.layers.7.conv_module.layer_norm.weight', 'encoder.layers.7.conv_module.pointwise_conv1.weight', 'encoder.layers.7.conv_module.pointwise_conv2.weight', 'encoder.layers.7.ffn1.intermediate_dense.bias', 'encoder.layers.7.ffn1.intermediate_dense.weight', 'encoder.layers.7.ffn1.output_dense.bias', 'encoder.layers.7.ffn1.output_dense.weight', 'encoder.layers.7.ffn1_layer_norm.bias', 'encoder.layers.7.ffn1_layer_norm.weight', 'encoder.layers.7.ffn2.intermediate_dense.bias', 'encoder.layers.7.ffn2.intermediate_dense.weight', 'encoder.layers.7.ffn2.output_dense.bias', 'encoder.layers.7.ffn2.output_dense.weight', 'encoder.layers.7.ffn2_layer_norm.bias', 'encoder.layers.7.ffn2_layer_norm.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.self_attn.distance_embedding.weight', 'encoder.layers.7.self_attn.linear_k.bias', 'encoder.layers.7.self_attn.linear_k.weight', 'encoder.layers.7.self_attn.linear_out.bias', 'encoder.layers.7.self_attn.linear_out.weight', 'encoder.layers.7.self_attn.linear_q.bias', 'encoder.layers.7.self_attn.linear_q.weight', 'encoder.layers.7.self_attn.linear_v.bias', 'encoder.layers.7.self_attn.linear_v.weight', 'encoder.layers.7.self_attn_layer_norm.bias', 'encoder.layers.7.self_attn_layer_norm.weight', 'encoder.layers.8.conv_module.depthwise_conv.weight', 'encoder.layers.8.conv_module.depthwise_layer_norm.bias', 'encoder.layers.8.conv_module.depthwise_layer_norm.weight', 'encoder.layers.8.conv_module.layer_norm.bias', 'encoder.layers.8.conv_module.layer_norm.weight', 'encoder.layers.8.conv_module.pointwise_conv1.weight', 'encoder.layers.8.conv_module.pointwise_conv2.weight', 'encoder.layers.8.ffn1.intermediate_dense.bias', 'encoder.layers.8.ffn1.intermediate_dense.weight', 'encoder.layers.8.ffn1.output_dense.bias', 'encoder.layers.8.ffn1.output_dense.weight', 'encoder.layers.8.ffn1_layer_norm.bias', 'encoder.layers.8.ffn1_layer_norm.weight', 'encoder.layers.8.ffn2.intermediate_dense.bias', 'encoder.layers.8.ffn2.intermediate_dense.weight', 'encoder.layers.8.ffn2.output_dense.bias', 'encoder.layers.8.ffn2.output_dense.weight', 'encoder.layers.8.ffn2_layer_norm.bias', 'encoder.layers.8.ffn2_layer_norm.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.self_attn.distance_embedding.weight', 'encoder.layers.8.self_attn.linear_k.bias', 'encoder.layers.8.self_attn.linear_k.weight', 'encoder.layers.8.self_attn.linear_out.bias', 'encoder.layers.8.self_attn.linear_out.weight', 'encoder.layers.8.self_attn.linear_q.bias', 'encoder.layers.8.self_attn.linear_q.weight', 'encoder.layers.8.self_attn.linear_v.bias', 'encoder.layers.8.self_attn.linear_v.weight', 'encoder.layers.8.self_attn_layer_norm.bias', 'encoder.layers.8.self_attn_layer_norm.weight', 'encoder.layers.9.conv_module.depthwise_conv.weight', 'encoder.layers.9.conv_module.depthwise_layer_norm.bias', 'encoder.layers.9.conv_module.depthwise_layer_norm.weight', 'encoder.layers.9.conv_module.layer_norm.bias', 'encoder.layers.9.conv_module.layer_norm.weight', 'encoder.layers.9.conv_module.pointwise_conv1.weight', 'encoder.layers.9.conv_module.pointwise_conv2.weight', 'encoder.layers.9.ffn1.intermediate_dense.bias', 'encoder.layers.9.ffn1.intermediate_dense.weight', 'encoder.layers.9.ffn1.output_dense.bias', 'encoder.layers.9.ffn1.output_dense.weight', 'encoder.layers.9.ffn1_layer_norm.bias', 'encoder.layers.9.ffn1_layer_norm.weight', 'encoder.layers.9.ffn2.intermediate_dense.bias', 'encoder.layers.9.ffn2.intermediate_dense.weight', 'encoder.layers.9.ffn2.output_dense.bias', 'encoder.layers.9.ffn2.output_dense.weight', 'encoder.layers.9.ffn2_layer_norm.bias', 'encoder.layers.9.ffn2_layer_norm.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.self_attn.distance_embedding.weight', 'encoder.layers.9.self_attn.linear_k.bias', 'encoder.layers.9.self_attn.linear_k.weight', 'encoder.layers.9.self_attn.linear_out.bias', 'encoder.layers.9.self_attn.linear_out.weight', 'encoder.layers.9.self_attn.linear_q.bias', 'encoder.layers.9.self_attn.linear_q.weight', 'encoder.layers.9.self_attn.linear_v.bias', 'encoder.layers.9.self_attn.linear_v.weight', 'encoder.layers.9.self_attn_layer_norm.bias', 'encoder.layers.9.self_attn_layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of the model checkpoint at /mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/w2v-bert2.0/model.safetensors were not used when initializing Wav2Vec2BertModel: ['encoder.layers.10.conv_module.depthwise_conv.weight', 'encoder.layers.10.conv_module.depthwise_layer_norm.bias', 'encoder.layers.10.conv_module.depthwise_layer_norm.weight', 'encoder.layers.10.conv_module.layer_norm.bias', 'encoder.layers.10.conv_module.layer_norm.weight', 'encoder.layers.10.conv_module.pointwise_conv1.weight', 'encoder.layers.10.conv_module.pointwise_conv2.weight', 'encoder.layers.10.ffn1.intermediate_dense.bias', 'encoder.layers.10.ffn1.intermediate_dense.weight', 'encoder.layers.10.ffn1.output_dense.bias', 'encoder.layers.10.ffn1.output_dense.weight', 'encoder.layers.10.ffn1_layer_norm.bias', 'encoder.layers.10.ffn1_layer_norm.weight', 'encoder.layers.10.ffn2.intermediate_dense.bias', 'encoder.layers.10.ffn2.intermediate_dense.weight', 'encoder.layers.10.ffn2.output_dense.bias', 'encoder.layers.10.ffn2.output_dense.weight', 'encoder.layers.10.ffn2_layer_norm.bias', 'encoder.layers.10.ffn2_layer_norm.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.self_attn.distance_embedding.weight', 'encoder.layers.10.self_attn.linear_k.bias', 'encoder.layers.10.self_attn.linear_k.weight', 'encoder.layers.10.self_attn.linear_out.bias', 'encoder.layers.10.self_attn.linear_out.weight', 'encoder.layers.10.self_attn.linear_q.bias', 'encoder.layers.10.self_attn.linear_q.weight', 'encoder.layers.10.self_attn.linear_v.bias', 'encoder.layers.10.self_attn.linear_v.weight', 'encoder.layers.10.self_attn_layer_norm.bias', 'encoder.layers.10.self_attn_layer_norm.weight', 'encoder.layers.11.conv_module.depthwise_conv.weight', 'encoder.layers.11.conv_module.depthwise_layer_norm.bias', 'encoder.layers.11.conv_module.depthwise_layer_norm.weight', 'encoder.layers.11.conv_module.layer_norm.bias', 'encoder.layers.11.conv_module.layer_norm.weight', 'encoder.layers.11.conv_module.pointwise_conv1.weight', 'encoder.layers.11.conv_module.pointwise_conv2.weight', 'encoder.layers.11.ffn1.intermediate_dense.bias', 'encoder.layers.11.ffn1.intermediate_dense.weight', 'encoder.layers.11.ffn1.output_dense.bias', 'encoder.layers.11.ffn1.output_dense.weight', 'encoder.layers.11.ffn1_layer_norm.bias', 'encoder.layers.11.ffn1_layer_norm.weight', 'encoder.layers.11.ffn2.intermediate_dense.bias', 'encoder.layers.11.ffn2.intermediate_dense.weight', 'encoder.layers.11.ffn2.output_dense.bias', 'encoder.layers.11.ffn2.output_dense.weight', 'encoder.layers.11.ffn2_layer_norm.bias', 'encoder.layers.11.ffn2_layer_norm.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.self_attn.distance_embedding.weight', 'encoder.layers.11.self_attn.linear_k.bias', 'encoder.layers.11.self_attn.linear_k.weight', 'encoder.layers.11.self_attn.linear_out.bias', 'encoder.layers.11.self_attn.linear_out.weight', 'encoder.layers.11.self_attn.linear_q.bias', 'encoder.layers.11.self_attn.linear_q.weight', 'encoder.layers.11.self_attn.linear_v.bias', 'encoder.layers.11.self_attn.linear_v.weight', 'encoder.layers.11.self_attn_layer_norm.bias', 'encoder.layers.11.self_attn_layer_norm.weight', 'encoder.layers.12.conv_module.depthwise_conv.weight', 'encoder.layers.12.conv_module.depthwise_layer_norm.bias', 'encoder.layers.12.conv_module.depthwise_layer_norm.weight', 'encoder.layers.12.conv_module.layer_norm.bias', 'encoder.layers.12.conv_module.layer_norm.weight', 'encoder.layers.12.conv_module.pointwise_conv1.weight', 'encoder.layers.12.conv_module.pointwise_conv2.weight', 'encoder.layers.12.ffn1.intermediate_dense.bias', 'encoder.layers.12.ffn1.intermediate_dense.weight', 'encoder.layers.12.ffn1.output_dense.bias', 'encoder.layers.12.ffn1.output_dense.weight', 'encoder.layers.12.ffn1_layer_norm.bias', 'encoder.layers.12.ffn1_layer_norm.weight', 'encoder.layers.12.ffn2.intermediate_dense.bias', 'encoder.layers.12.ffn2.intermediate_dense.weight', 'encoder.layers.12.ffn2.output_dense.bias', 'encoder.layers.12.ffn2.output_dense.weight', 'encoder.layers.12.ffn2_layer_norm.bias', 'encoder.layers.12.ffn2_layer_norm.weight', 'encoder.layers.12.final_layer_norm.bias', 'encoder.layers.12.final_layer_norm.weight', 'encoder.layers.12.self_attn.distance_embedding.weight', 'encoder.layers.12.self_attn.linear_k.bias', 'encoder.layers.12.self_attn.linear_k.weight', 'encoder.layers.12.self_attn.linear_out.bias', 'encoder.layers.12.self_attn.linear_out.weight', 'encoder.layers.12.self_attn.linear_q.bias', 'encoder.layers.12.self_attn.linear_q.weight', 'encoder.layers.12.self_attn.linear_v.bias', 'encoder.layers.12.self_attn.linear_v.weight', 'encoder.layers.12.self_attn_layer_norm.bias', 'encoder.layers.12.self_attn_layer_norm.weight', 'encoder.layers.13.conv_module.depthwise_conv.weight', 'encoder.layers.13.conv_module.depthwise_layer_norm.bias', 'encoder.layers.13.conv_module.depthwise_layer_norm.weight', 'encoder.layers.13.conv_module.layer_norm.bias', 'encoder.layers.13.conv_module.layer_norm.weight', 'encoder.layers.13.conv_module.pointwise_conv1.weight', 'encoder.layers.13.conv_module.pointwise_conv2.weight', 'encoder.layers.13.ffn1.intermediate_dense.bias', 'encoder.layers.13.ffn1.intermediate_dense.weight', 'encoder.layers.13.ffn1.output_dense.bias', 'encoder.layers.13.ffn1.output_dense.weight', 'encoder.layers.13.ffn1_layer_norm.bias', 'encoder.layers.13.ffn1_layer_norm.weight', 'encoder.layers.13.ffn2.intermediate_dense.bias', 'encoder.layers.13.ffn2.intermediate_dense.weight', 'encoder.layers.13.ffn2.output_dense.bias', 'encoder.layers.13.ffn2.output_dense.weight', 'encoder.layers.13.ffn2_layer_norm.bias', 'encoder.layers.13.ffn2_layer_norm.weight', 'encoder.layers.13.final_layer_norm.bias', 'encoder.layers.13.final_layer_norm.weight', 'encoder.layers.13.self_attn.distance_embedding.weight', 'encoder.layers.13.self_attn.linear_k.bias', 'encoder.layers.13.self_attn.linear_k.weight', 'encoder.layers.13.self_attn.linear_out.bias', 'encoder.layers.13.self_attn.linear_out.weight', 'encoder.layers.13.self_attn.linear_q.bias', 'encoder.layers.13.self_attn.linear_q.weight', 'encoder.layers.13.self_attn.linear_v.bias', 'encoder.layers.13.self_attn.linear_v.weight', 'encoder.layers.13.self_attn_layer_norm.bias', 'encoder.layers.13.self_attn_layer_norm.weight', 'encoder.layers.14.conv_module.depthwise_conv.weight', 'encoder.layers.14.conv_module.depthwise_layer_norm.bias', 'encoder.layers.14.conv_module.depthwise_layer_norm.weight', 'encoder.layers.14.conv_module.layer_norm.bias', 'encoder.layers.14.conv_module.layer_norm.weight', 'encoder.layers.14.conv_module.pointwise_conv1.weight', 'encoder.layers.14.conv_module.pointwise_conv2.weight', 'encoder.layers.14.ffn1.intermediate_dense.bias', 'encoder.layers.14.ffn1.intermediate_dense.weight', 'encoder.layers.14.ffn1.output_dense.bias', 'encoder.layers.14.ffn1.output_dense.weight', 'encoder.layers.14.ffn1_layer_norm.bias', 'encoder.layers.14.ffn1_layer_norm.weight', 'encoder.layers.14.ffn2.intermediate_dense.bias', 'encoder.layers.14.ffn2.intermediate_dense.weight', 'encoder.layers.14.ffn2.output_dense.bias', 'encoder.layers.14.ffn2.output_dense.weight', 'encoder.layers.14.ffn2_layer_norm.bias', 'encoder.layers.14.ffn2_layer_norm.weight', 'encoder.layers.14.final_layer_norm.bias', 'encoder.layers.14.final_layer_norm.weight', 'encoder.layers.14.self_attn.distance_embedding.weight', 'encoder.layers.14.self_attn.linear_k.bias', 'encoder.layers.14.self_attn.linear_k.weight', 'encoder.layers.14.self_attn.linear_out.bias', 'encoder.layers.14.self_attn.linear_out.weight', 'encoder.layers.14.self_attn.linear_q.bias', 'encoder.layers.14.self_attn.linear_q.weight', 'encoder.layers.14.self_attn.linear_v.bias', 'encoder.layers.14.self_attn.linear_v.weight', 'encoder.layers.14.self_attn_layer_norm.bias', 'encoder.layers.14.self_attn_layer_norm.weight', 'encoder.layers.15.conv_module.depthwise_conv.weight', 'encoder.layers.15.conv_module.depthwise_layer_norm.bias', 'encoder.layers.15.conv_module.depthwise_layer_norm.weight', 'encoder.layers.15.conv_module.layer_norm.bias', 'encoder.layers.15.conv_module.layer_norm.weight', 'encoder.layers.15.conv_module.pointwise_conv1.weight', 'encoder.layers.15.conv_module.pointwise_conv2.weight', 'encoder.layers.15.ffn1.intermediate_dense.bias', 'encoder.layers.15.ffn1.intermediate_dense.weight', 'encoder.layers.15.ffn1.output_dense.bias', 'encoder.layers.15.ffn1.output_dense.weight', 'encoder.layers.15.ffn1_layer_norm.bias', 'encoder.layers.15.ffn1_layer_norm.weight', 'encoder.layers.15.ffn2.intermediate_dense.bias', 'encoder.layers.15.ffn2.intermediate_dense.weight', 'encoder.layers.15.ffn2.output_dense.bias', 'encoder.layers.15.ffn2.output_dense.weight', 'encoder.layers.15.ffn2_layer_norm.bias', 'encoder.layers.15.ffn2_layer_norm.weight', 'encoder.layers.15.final_layer_norm.bias', 'encoder.layers.15.final_layer_norm.weight', 'encoder.layers.15.self_attn.distance_embedding.weight', 'encoder.layers.15.self_attn.linear_k.bias', 'encoder.layers.15.self_attn.linear_k.weight', 'encoder.layers.15.self_attn.linear_out.bias', 'encoder.layers.15.self_attn.linear_out.weight', 'encoder.layers.15.self_attn.linear_q.bias', 'encoder.layers.15.self_attn.linear_q.weight', 'encoder.layers.15.self_attn.linear_v.bias', 'encoder.layers.15.self_attn.linear_v.weight', 'encoder.layers.15.self_attn_layer_norm.bias', 'encoder.layers.15.self_attn_layer_norm.weight', 'encoder.layers.16.conv_module.depthwise_conv.weight', 'encoder.layers.16.conv_module.depthwise_layer_norm.bias', 'encoder.layers.16.conv_module.depthwise_layer_norm.weight', 'encoder.layers.16.conv_module.layer_norm.bias', 'encoder.layers.16.conv_module.layer_norm.weight', 'encoder.layers.16.conv_module.pointwise_conv1.weight', 'encoder.layers.16.conv_module.pointwise_conv2.weight', 'encoder.layers.16.ffn1.intermediate_dense.bias', 'encoder.layers.16.ffn1.intermediate_dense.weight', 'encoder.layers.16.ffn1.output_dense.bias', 'encoder.layers.16.ffn1.output_dense.weight', 'encoder.layers.16.ffn1_layer_norm.bias', 'encoder.layers.16.ffn1_layer_norm.weight', 'encoder.layers.16.ffn2.intermediate_dense.bias', 'encoder.layers.16.ffn2.intermediate_dense.weight', 'encoder.layers.16.ffn2.output_dense.bias', 'encoder.layers.16.ffn2.output_dense.weight', 'encoder.layers.16.ffn2_layer_norm.bias', 'encoder.layers.16.ffn2_layer_norm.weight', 'encoder.layers.16.final_layer_norm.bias', 'encoder.layers.16.final_layer_norm.weight', 'encoder.layers.16.self_attn.distance_embedding.weight', 'encoder.layers.16.self_attn.linear_k.bias', 'encoder.layers.16.self_attn.linear_k.weight', 'encoder.layers.16.self_attn.linear_out.bias', 'encoder.layers.16.self_attn.linear_out.weight', 'encoder.layers.16.self_attn.linear_q.bias', 'encoder.layers.16.self_attn.linear_q.weight', 'encoder.layers.16.self_attn.linear_v.bias', 'encoder.layers.16.self_attn.linear_v.weight', 'encoder.layers.16.self_attn_layer_norm.bias', 'encoder.layers.16.self_attn_layer_norm.weight', 'encoder.layers.17.conv_module.depthwise_conv.weight', 'encoder.layers.17.conv_module.depthwise_layer_norm.bias', 'encoder.layers.17.conv_module.depthwise_layer_norm.weight', 'encoder.layers.17.conv_module.layer_norm.bias', 'encoder.layers.17.conv_module.layer_norm.weight', 'encoder.layers.17.conv_module.pointwise_conv1.weight', 'encoder.layers.17.conv_module.pointwise_conv2.weight', 'encoder.layers.17.ffn1.intermediate_dense.bias', 'encoder.layers.17.ffn1.intermediate_dense.weight', 'encoder.layers.17.ffn1.output_dense.bias', 'encoder.layers.17.ffn1.output_dense.weight', 'encoder.layers.17.ffn1_layer_norm.bias', 'encoder.layers.17.ffn1_layer_norm.weight', 'encoder.layers.17.ffn2.intermediate_dense.bias', 'encoder.layers.17.ffn2.intermediate_dense.weight', 'encoder.layers.17.ffn2.output_dense.bias', 'encoder.layers.17.ffn2.output_dense.weight', 'encoder.layers.17.ffn2_layer_norm.bias', 'encoder.layers.17.ffn2_layer_norm.weight', 'encoder.layers.17.final_layer_norm.bias', 'encoder.layers.17.final_layer_norm.weight', 'encoder.layers.17.self_attn.distance_embedding.weight', 'encoder.layers.17.self_attn.linear_k.bias', 'encoder.layers.17.self_attn.linear_k.weight', 'encoder.layers.17.self_attn.linear_out.bias', 'encoder.layers.17.self_attn.linear_out.weight', 'encoder.layers.17.self_attn.linear_q.bias', 'encoder.layers.17.self_attn.linear_q.weight', 'encoder.layers.17.self_attn.linear_v.bias', 'encoder.layers.17.self_attn.linear_v.weight', 'encoder.layers.17.self_attn_layer_norm.bias', 'encoder.layers.17.self_attn_layer_norm.weight', 'encoder.layers.18.conv_module.depthwise_conv.weight', 'encoder.layers.18.conv_module.depthwise_layer_norm.bias', 'encoder.layers.18.conv_module.depthwise_layer_norm.weight', 'encoder.layers.18.conv_module.layer_norm.bias', 'encoder.layers.18.conv_module.layer_norm.weight', 'encoder.layers.18.conv_module.pointwise_conv1.weight', 'encoder.layers.18.conv_module.pointwise_conv2.weight', 'encoder.layers.18.ffn1.intermediate_dense.bias', 'encoder.layers.18.ffn1.intermediate_dense.weight', 'encoder.layers.18.ffn1.output_dense.bias', 'encoder.layers.18.ffn1.output_dense.weight', 'encoder.layers.18.ffn1_layer_norm.bias', 'encoder.layers.18.ffn1_layer_norm.weight', 'encoder.layers.18.ffn2.intermediate_dense.bias', 'encoder.layers.18.ffn2.intermediate_dense.weight', 'encoder.layers.18.ffn2.output_dense.bias', 'encoder.layers.18.ffn2.output_dense.weight', 'encoder.layers.18.ffn2_layer_norm.bias', 'encoder.layers.18.ffn2_layer_norm.weight', 'encoder.layers.18.final_layer_norm.bias', 'encoder.layers.18.final_layer_norm.weight', 'encoder.layers.18.self_attn.distance_embedding.weight', 'encoder.layers.18.self_attn.linear_k.bias', 'encoder.layers.18.self_attn.linear_k.weight', 'encoder.layers.18.self_attn.linear_out.bias', 'encoder.layers.18.self_attn.linear_out.weight', 'encoder.layers.18.self_attn.linear_q.bias', 'encoder.layers.18.self_attn.linear_q.weight', 'encoder.layers.18.self_attn.linear_v.bias', 'encoder.layers.18.self_attn.linear_v.weight', 'encoder.layers.18.self_attn_layer_norm.bias', 'encoder.layers.18.self_attn_layer_norm.weight', 'encoder.layers.19.conv_module.depthwise_conv.weight', 'encoder.layers.19.conv_module.depthwise_layer_norm.bias', 'encoder.layers.19.conv_module.depthwise_layer_norm.weight', 'encoder.layers.19.conv_module.layer_norm.bias', 'encoder.layers.19.conv_module.layer_norm.weight', 'encoder.layers.19.conv_module.pointwise_conv1.weight', 'encoder.layers.19.conv_module.pointwise_conv2.weight', 'encoder.layers.19.ffn1.intermediate_dense.bias', 'encoder.layers.19.ffn1.intermediate_dense.weight', 'encoder.layers.19.ffn1.output_dense.bias', 'encoder.layers.19.ffn1.output_dense.weight', 'encoder.layers.19.ffn1_layer_norm.bias', 'encoder.layers.19.ffn1_layer_norm.weight', 'encoder.layers.19.ffn2.intermediate_dense.bias', 'encoder.layers.19.ffn2.intermediate_dense.weight', 'encoder.layers.19.ffn2.output_dense.bias', 'encoder.layers.19.ffn2.output_dense.weight', 'encoder.layers.19.ffn2_layer_norm.bias', 'encoder.layers.19.ffn2_layer_norm.weight', 'encoder.layers.19.final_layer_norm.bias', 'encoder.layers.19.final_layer_norm.weight', 'encoder.layers.19.self_attn.distance_embedding.weight', 'encoder.layers.19.self_attn.linear_k.bias', 'encoder.layers.19.self_attn.linear_k.weight', 'encoder.layers.19.self_attn.linear_out.bias', 'encoder.layers.19.self_attn.linear_out.weight', 'encoder.layers.19.self_attn.linear_q.bias', 'encoder.layers.19.self_attn.linear_q.weight', 'encoder.layers.19.self_attn.linear_v.bias', 'encoder.layers.19.self_attn.linear_v.weight', 'encoder.layers.19.self_attn_layer_norm.bias', 'encoder.layers.19.self_attn_layer_norm.weight', 'encoder.layers.20.conv_module.depthwise_conv.weight', 'encoder.layers.20.conv_module.depthwise_layer_norm.bias', 'encoder.layers.20.conv_module.depthwise_layer_norm.weight', 'encoder.layers.20.conv_module.layer_norm.bias', 'encoder.layers.20.conv_module.layer_norm.weight', 'encoder.layers.20.conv_module.pointwise_conv1.weight', 'encoder.layers.20.conv_module.pointwise_conv2.weight', 'encoder.layers.20.ffn1.intermediate_dense.bias', 'encoder.layers.20.ffn1.intermediate_dense.weight', 'encoder.layers.20.ffn1.output_dense.bias', 'encoder.layers.20.ffn1.output_dense.weight', 'encoder.layers.20.ffn1_layer_norm.bias', 'encoder.layers.20.ffn1_layer_norm.weight', 'encoder.layers.20.ffn2.intermediate_dense.bias', 'encoder.layers.20.ffn2.intermediate_dense.weight', 'encoder.layers.20.ffn2.output_dense.bias', 'encoder.layers.20.ffn2.output_dense.weight', 'encoder.layers.20.ffn2_layer_norm.bias', 'encoder.layers.20.ffn2_layer_norm.weight', 'encoder.layers.20.final_layer_norm.bias', 'encoder.layers.20.final_layer_norm.weight', 'encoder.layers.20.self_attn.distance_embedding.weight', 'encoder.layers.20.self_attn.linear_k.bias', 'encoder.layers.20.self_attn.linear_k.weight', 'encoder.layers.20.self_attn.linear_out.bias', 'encoder.layers.20.self_attn.linear_out.weight', 'encoder.layers.20.self_attn.linear_q.bias', 'encoder.layers.20.self_attn.linear_q.weight', 'encoder.layers.20.self_attn.linear_v.bias', 'encoder.layers.20.self_attn.linear_v.weight', 'encoder.layers.20.self_attn_layer_norm.bias', 'encoder.layers.20.self_attn_layer_norm.weight', 'encoder.layers.21.conv_module.depthwise_conv.weight', 'encoder.layers.21.conv_module.depthwise_layer_norm.bias', 'encoder.layers.21.conv_module.depthwise_layer_norm.weight', 'encoder.layers.21.conv_module.layer_norm.bias', 'encoder.layers.21.conv_module.layer_norm.weight', 'encoder.layers.21.conv_module.pointwise_conv1.weight', 'encoder.layers.21.conv_module.pointwise_conv2.weight', 'encoder.layers.21.ffn1.intermediate_dense.bias', 'encoder.layers.21.ffn1.intermediate_dense.weight', 'encoder.layers.21.ffn1.output_dense.bias', 'encoder.layers.21.ffn1.output_dense.weight', 'encoder.layers.21.ffn1_layer_norm.bias', 'encoder.layers.21.ffn1_layer_norm.weight', 'encoder.layers.21.ffn2.intermediate_dense.bias', 'encoder.layers.21.ffn2.intermediate_dense.weight', 'encoder.layers.21.ffn2.output_dense.bias', 'encoder.layers.21.ffn2.output_dense.weight', 'encoder.layers.21.ffn2_layer_norm.bias', 'encoder.layers.21.ffn2_layer_norm.weight', 'encoder.layers.21.final_layer_norm.bias', 'encoder.layers.21.final_layer_norm.weight', 'encoder.layers.21.self_attn.distance_embedding.weight', 'encoder.layers.21.self_attn.linear_k.bias', 'encoder.layers.21.self_attn.linear_k.weight', 'encoder.layers.21.self_attn.linear_out.bias', 'encoder.layers.21.self_attn.linear_out.weight', 'encoder.layers.21.self_attn.linear_q.bias', 'encoder.layers.21.self_attn.linear_q.weight', 'encoder.layers.21.self_attn.linear_v.bias', 'encoder.layers.21.self_attn.linear_v.weight', 'encoder.layers.21.self_attn_layer_norm.bias', 'encoder.layers.21.self_attn_layer_norm.weight', 'encoder.layers.22.conv_module.depthwise_conv.weight', 'encoder.layers.22.conv_module.depthwise_layer_norm.bias', 'encoder.layers.22.conv_module.depthwise_layer_norm.weight', 'encoder.layers.22.conv_module.layer_norm.bias', 'encoder.layers.22.conv_module.layer_norm.weight', 'encoder.layers.22.conv_module.pointwise_conv1.weight', 'encoder.layers.22.conv_module.pointwise_conv2.weight', 'encoder.layers.22.ffn1.intermediate_dense.bias', 'encoder.layers.22.ffn1.intermediate_dense.weight', 'encoder.layers.22.ffn1.output_dense.bias', 'encoder.layers.22.ffn1.output_dense.weight', 'encoder.layers.22.ffn1_layer_norm.bias', 'encoder.layers.22.ffn1_layer_norm.weight', 'encoder.layers.22.ffn2.intermediate_dense.bias', 'encoder.layers.22.ffn2.intermediate_dense.weight', 'encoder.layers.22.ffn2.output_dense.bias', 'encoder.layers.22.ffn2.output_dense.weight', 'encoder.layers.22.ffn2_layer_norm.bias', 'encoder.layers.22.ffn2_layer_norm.weight', 'encoder.layers.22.final_layer_norm.bias', 'encoder.layers.22.final_layer_norm.weight', 'encoder.layers.22.self_attn.distance_embedding.weight', 'encoder.layers.22.self_attn.linear_k.bias', 'encoder.layers.22.self_attn.linear_k.weight', 'encoder.layers.22.self_attn.linear_out.bias', 'encoder.layers.22.self_attn.linear_out.weight', 'encoder.layers.22.self_attn.linear_q.bias', 'encoder.layers.22.self_attn.linear_q.weight', 'encoder.layers.22.self_attn.linear_v.bias', 'encoder.layers.22.self_attn.linear_v.weight', 'encoder.layers.22.self_attn_layer_norm.bias', 'encoder.layers.22.self_attn_layer_norm.weight', 'encoder.layers.23.conv_module.depthwise_conv.weight', 'encoder.layers.23.conv_module.depthwise_layer_norm.bias', 'encoder.layers.23.conv_module.depthwise_layer_norm.weight', 'encoder.layers.23.conv_module.layer_norm.bias', 'encoder.layers.23.conv_module.layer_norm.weight', 'encoder.layers.23.conv_module.pointwise_conv1.weight', 'encoder.layers.23.conv_module.pointwise_conv2.weight', 'encoder.layers.23.ffn1.intermediate_dense.bias', 'encoder.layers.23.ffn1.intermediate_dense.weight', 'encoder.layers.23.ffn1.output_dense.bias', 'encoder.layers.23.ffn1.output_dense.weight', 'encoder.layers.23.ffn1_layer_norm.bias', 'encoder.layers.23.ffn1_layer_norm.weight', 'encoder.layers.23.ffn2.intermediate_dense.bias', 'encoder.layers.23.ffn2.intermediate_dense.weight', 'encoder.layers.23.ffn2.output_dense.bias', 'encoder.layers.23.ffn2.output_dense.weight', 'encoder.layers.23.ffn2_layer_norm.bias', 'encoder.layers.23.ffn2_layer_norm.weight', 'encoder.layers.23.final_layer_norm.bias', 'encoder.layers.23.final_layer_norm.weight', 'encoder.layers.23.self_attn.distance_embedding.weight', 'encoder.layers.23.self_attn.linear_k.bias', 'encoder.layers.23.self_attn.linear_k.weight', 'encoder.layers.23.self_attn.linear_out.bias', 'encoder.layers.23.self_attn.linear_out.weight', 'encoder.layers.23.self_attn.linear_q.bias', 'encoder.layers.23.self_attn.linear_q.weight', 'encoder.layers.23.self_attn.linear_v.bias', 'encoder.layers.23.self_attn.linear_v.weight', 'encoder.layers.23.self_attn_layer_norm.bias', 'encoder.layers.23.self_attn_layer_norm.weight', 'encoder.layers.6.conv_module.depthwise_conv.weight', 'encoder.layers.6.conv_module.depthwise_layer_norm.bias', 'encoder.layers.6.conv_module.depthwise_layer_norm.weight', 'encoder.layers.6.conv_module.layer_norm.bias', 'encoder.layers.6.conv_module.layer_norm.weight', 'encoder.layers.6.conv_module.pointwise_conv1.weight', 'encoder.layers.6.conv_module.pointwise_conv2.weight', 'encoder.layers.6.ffn1.intermediate_dense.bias', 'encoder.layers.6.ffn1.intermediate_dense.weight', 'encoder.layers.6.ffn1.output_dense.bias', 'encoder.layers.6.ffn1.output_dense.weight', 'encoder.layers.6.ffn1_layer_norm.bias', 'encoder.layers.6.ffn1_layer_norm.weight', 'encoder.layers.6.ffn2.intermediate_dense.bias', 'encoder.layers.6.ffn2.intermediate_dense.weight', 'encoder.layers.6.ffn2.output_dense.bias', 'encoder.layers.6.ffn2.output_dense.weight', 'encoder.layers.6.ffn2_layer_norm.bias', 'encoder.layers.6.ffn2_layer_norm.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.self_attn.distance_embedding.weight', 'encoder.layers.6.self_attn.linear_k.bias', 'encoder.layers.6.self_attn.linear_k.weight', 'encoder.layers.6.self_attn.linear_out.bias', 'encoder.layers.6.self_attn.linear_out.weight', 'encoder.layers.6.self_attn.linear_q.bias', 'encoder.layers.6.self_attn.linear_q.weight', 'encoder.layers.6.self_attn.linear_v.bias', 'encoder.layers.6.self_attn.linear_v.weight', 'encoder.layers.6.self_attn_layer_norm.bias', 'encoder.layers.6.self_attn_layer_norm.weight', 'encoder.layers.7.conv_module.depthwise_conv.weight', 'encoder.layers.7.conv_module.depthwise_layer_norm.bias', 'encoder.layers.7.conv_module.depthwise_layer_norm.weight', 'encoder.layers.7.conv_module.layer_norm.bias', 'encoder.layers.7.conv_module.layer_norm.weight', 'encoder.layers.7.conv_module.pointwise_conv1.weight', 'encoder.layers.7.conv_module.pointwise_conv2.weight', 'encoder.layers.7.ffn1.intermediate_dense.bias', 'encoder.layers.7.ffn1.intermediate_dense.weight', 'encoder.layers.7.ffn1.output_dense.bias', 'encoder.layers.7.ffn1.output_dense.weight', 'encoder.layers.7.ffn1_layer_norm.bias', 'encoder.layers.7.ffn1_layer_norm.weight', 'encoder.layers.7.ffn2.intermediate_dense.bias', 'encoder.layers.7.ffn2.intermediate_dense.weight', 'encoder.layers.7.ffn2.output_dense.bias', 'encoder.layers.7.ffn2.output_dense.weight', 'encoder.layers.7.ffn2_layer_norm.bias', 'encoder.layers.7.ffn2_layer_norm.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.self_attn.distance_embedding.weight', 'encoder.layers.7.self_attn.linear_k.bias', 'encoder.layers.7.self_attn.linear_k.weight', 'encoder.layers.7.self_attn.linear_out.bias', 'encoder.layers.7.self_attn.linear_out.weight', 'encoder.layers.7.self_attn.linear_q.bias', 'encoder.layers.7.self_attn.linear_q.weight', 'encoder.layers.7.self_attn.linear_v.bias', 'encoder.layers.7.self_attn.linear_v.weight', 'encoder.layers.7.self_attn_layer_norm.bias', 'encoder.layers.7.self_attn_layer_norm.weight', 'encoder.layers.8.conv_module.depthwise_conv.weight', 'encoder.layers.8.conv_module.depthwise_layer_norm.bias', 'encoder.layers.8.conv_module.depthwise_layer_norm.weight', 'encoder.layers.8.conv_module.layer_norm.bias', 'encoder.layers.8.conv_module.layer_norm.weight', 'encoder.layers.8.conv_module.pointwise_conv1.weight', 'encoder.layers.8.conv_module.pointwise_conv2.weight', 'encoder.layers.8.ffn1.intermediate_dense.bias', 'encoder.layers.8.ffn1.intermediate_dense.weight', 'encoder.layers.8.ffn1.output_dense.bias', 'encoder.layers.8.ffn1.output_dense.weight', 'encoder.layers.8.ffn1_layer_norm.bias', 'encoder.layers.8.ffn1_layer_norm.weight', 'encoder.layers.8.ffn2.intermediate_dense.bias', 'encoder.layers.8.ffn2.intermediate_dense.weight', 'encoder.layers.8.ffn2.output_dense.bias', 'encoder.layers.8.ffn2.output_dense.weight', 'encoder.layers.8.ffn2_layer_norm.bias', 'encoder.layers.8.ffn2_layer_norm.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.self_attn.distance_embedding.weight', 'encoder.layers.8.self_attn.linear_k.bias', 'encoder.layers.8.self_attn.linear_k.weight', 'encoder.layers.8.self_attn.linear_out.bias', 'encoder.layers.8.self_attn.linear_out.weight', 'encoder.layers.8.self_attn.linear_q.bias', 'encoder.layers.8.self_attn.linear_q.weight', 'encoder.layers.8.self_attn.linear_v.bias', 'encoder.layers.8.self_attn.linear_v.weight', 'encoder.layers.8.self_attn_layer_norm.bias', 'encoder.layers.8.self_attn_layer_norm.weight', 'encoder.layers.9.conv_module.depthwise_conv.weight', 'encoder.layers.9.conv_module.depthwise_layer_norm.bias', 'encoder.layers.9.conv_module.depthwise_layer_norm.weight', 'encoder.layers.9.conv_module.layer_norm.bias', 'encoder.layers.9.conv_module.layer_norm.weight', 'encoder.layers.9.conv_module.pointwise_conv1.weight', 'encoder.layers.9.conv_module.pointwise_conv2.weight', 'encoder.layers.9.ffn1.intermediate_dense.bias', 'encoder.layers.9.ffn1.intermediate_dense.weight', 'encoder.layers.9.ffn1.output_dense.bias', 'encoder.layers.9.ffn1.output_dense.weight', 'encoder.layers.9.ffn1_layer_norm.bias', 'encoder.layers.9.ffn1_layer_norm.weight', 'encoder.layers.9.ffn2.intermediate_dense.bias', 'encoder.layers.9.ffn2.intermediate_dense.weight', 'encoder.layers.9.ffn2.output_dense.bias', 'encoder.layers.9.ffn2.output_dense.weight', 'encoder.layers.9.ffn2_layer_norm.bias', 'encoder.layers.9.ffn2_layer_norm.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.self_attn.distance_embedding.weight', 'encoder.layers.9.self_attn.linear_k.bias', 'encoder.layers.9.self_attn.linear_k.weight', 'encoder.layers.9.self_attn.linear_out.bias', 'encoder.layers.9.self_attn.linear_out.weight', 'encoder.layers.9.self_attn.linear_q.bias', 'encoder.layers.9.self_attn.linear_q.weight', 'encoder.layers.9.self_attn.linear_v.bias', 'encoder.layers.9.self_attn.linear_v.weight', 'encoder.layers.9.self_attn_layer_norm.bias', 'encoder.layers.9.self_attn_layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
2025-02-06 12:08:43,817 (train_accelerate_ddp:949) INFO: model: TSVADModel(
  (rs_dropout): Dropout(p=0.1, inplace=False)
  (speech_encoder): Wav2Vec2BertModel(
    (feature_projection): Wav2Vec2BertFeatureProjection(
      (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
      (projection): Linear(in_features=160, out_features=1024, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder): Wav2Vec2BertEncoder(
      (dropout): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0-5): 6 x Wav2Vec2BertEncoderLayer(
          (ffn1_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (ffn1): Wav2Vec2BertFeedForward(
            (intermediate_dropout): Dropout(p=0.0, inplace=False)
            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): SiLU()
            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)
            (output_dropout): Dropout(p=0.0, inplace=False)
          )
          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (self_attn_dropout): Dropout(p=0.0, inplace=False)
          (self_attn): Wav2Vec2BertSelfAttention(
            (linear_q): Linear(in_features=1024, out_features=1024, bias=True)
            (linear_k): Linear(in_features=1024, out_features=1024, bias=True)
            (linear_v): Linear(in_features=1024, out_features=1024, bias=True)
            (linear_out): Linear(in_features=1024, out_features=1024, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (distance_embedding): Embedding(73, 64)
          )
          (conv_module): Wav2Vec2BertConvolutionModule(
            (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (pointwise_conv1): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
            (glu): GLU(dim=1)
            (depthwise_conv): Conv1d(1024, 1024, kernel_size=(31,), stride=(1,), groups=1024, bias=False)
            (depthwise_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (activation): SiLU()
            (pointwise_conv2): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (ffn2_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (ffn2): Wav2Vec2BertFeedForward(
            (intermediate_dropout): Dropout(p=0.0, inplace=False)
            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): SiLU()
            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)
            (output_dropout): Dropout(p=0.0, inplace=False)
          )
          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (speech_down_or_up): Sequential(
    (0): Conv1d(1024, 192, kernel_size=(5,), stride=(2,), padding=(2,))
    (1): BatchNorm1D(
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ReLU()
  )
  (pos_encoder): PositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (single_backend): Mamba2BlockV2(
    (forward_blocks): ModuleList(
      (0-1): 2 x Block(
        (norm): RMSNorm()
        (mixer): Mamba2(
          (in_proj): Linear(in_features=384, out_features=3608, bias=False)
          (conv1d): Conv1d(2048, 2048, kernel_size=(4,), stride=(1,), padding=(3,), groups=2048)
          (act): SiLU()
          (norm): RMSNorm()
          (out_proj): Linear(in_features=1536, out_features=384, bias=False)
        )
      )
    )
    (backward_blocks): ModuleList(
      (0-1): 2 x Block(
        (norm): RMSNorm()
        (mixer): Mamba2(
          (in_proj): Linear(in_features=384, out_features=3608, bias=False)
          (conv1d): Conv1d(2048, 2048, kernel_size=(4,), stride=(1,), padding=(3,), groups=2048)
          (act): SiLU()
          (norm): RMSNorm()
          (out_proj): Linear(in_features=1536, out_features=384, bias=False)
        )
      )
    )
  )
  (backend_down): Sequential(
    (0): Conv1d(5376, 384, kernel_size=(5,), stride=(1,), padding=(2,))
    (1): BatchNorm1D(
      (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ReLU()
  )
  (multi_backend): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (linear1): Linear(in_features=384, out_features=1536, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=1536, out_features=384, bias=True)
        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc): Linear(in_features=384, out_features=7, bias=True)
)
2025-02-06 12:08:43,817 (train_accelerate_ddp:949) INFO: model: TSVADModel(
  (rs_dropout): Dropout(p=0.1, inplace=False)
  (speech_encoder): Wav2Vec2BertModel(
    (feature_projection): Wav2Vec2BertFeatureProjection(
      (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
      (projection): Linear(in_features=160, out_features=1024, bias=True)
      (dropout): Dropout(p=0.0, inplace=False)
    )
    (encoder): Wav2Vec2BertEncoder(
      (dropout): Dropout(p=0.0, inplace=False)
      (layers): ModuleList(
        (0-5): 6 x Wav2Vec2BertEncoderLayer(
          (ffn1_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (ffn1): Wav2Vec2BertFeedForward(
            (intermediate_dropout): Dropout(p=0.0, inplace=False)
            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): SiLU()
            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)
            (output_dropout): Dropout(p=0.0, inplace=False)
          )
          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (self_attn_dropout): Dropout(p=0.0, inplace=False)
          (self_attn): Wav2Vec2BertSelfAttention(
            (linear_q): Linear(in_features=1024, out_features=1024, bias=True)
            (linear_k): Linear(in_features=1024, out_features=1024, bias=True)
            (linear_v): Linear(in_features=1024, out_features=1024, bias=True)
            (linear_out): Linear(in_features=1024, out_features=1024, bias=True)
            (dropout): Dropout(p=0.0, inplace=False)
            (distance_embedding): Embedding(73, 64)
          )
          (conv_module): Wav2Vec2BertConvolutionModule(
            (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (pointwise_conv1): Conv1d(1024, 2048, kernel_size=(1,), stride=(1,), bias=False)
            (glu): GLU(dim=1)
            (depthwise_conv): Conv1d(1024, 1024, kernel_size=(31,), stride=(1,), groups=1024, bias=False)
            (depthwise_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
            (activation): SiLU()
            (pointwise_conv2): Conv1d(1024, 1024, kernel_size=(1,), stride=(1,), bias=False)
            (dropout): Dropout(p=0.1, inplace=False)
          )
          (ffn2_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
          (ffn2): Wav2Vec2BertFeedForward(
            (intermediate_dropout): Dropout(p=0.0, inplace=False)
            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): SiLU()
            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)
            (output_dropout): Dropout(p=0.0, inplace=False)
          )
          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
  )
  (speech_down_or_up): Sequential(
    (0): Conv1d(1024, 192, kernel_size=(5,), stride=(2,), padding=(2,))
    (1): BatchNorm1D(
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ReLU()
  )
  (pos_encoder): PositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (single_backend): Mamba2BlockV2(
    (forward_blocks): ModuleList(
      (0-1): 2 x Block(
        (norm): RMSNorm()
        (mixer): Mamba2(
          (in_proj): Linear(in_features=384, out_features=3608, bias=False)
          (conv1d): Conv1d(2048, 2048, kernel_size=(4,), stride=(1,), padding=(3,), groups=2048)
          (act): SiLU()
          (norm): RMSNorm()
          (out_proj): Linear(in_features=1536, out_features=384, bias=False)
        )
      )
    )
    (backward_blocks): ModuleList(
      (0-1): 2 x Block(
        (norm): RMSNorm()
        (mixer): Mamba2(
          (in_proj): Linear(in_features=384, out_features=3608, bias=False)
          (conv1d): Conv1d(2048, 2048, kernel_size=(4,), stride=(1,), padding=(3,), groups=2048)
          (act): SiLU()
          (norm): RMSNorm()
          (out_proj): Linear(in_features=1536, out_features=384, bias=False)
        )
      )
    )
  )
  (backend_down): Sequential(
    (0): Conv1d(5376, 384, kernel_size=(5,), stride=(1,), padding=(2,))
    (1): BatchNorm1D(
      (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ReLU()
  )
  (multi_backend): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (linear1): Linear(in_features=384, out_features=1536, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=1536, out_features=384, bias=True)
        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc): Linear(in_features=384, out_features=7, bias=True)
)
2025-02-06 12:08:43,817 (train_accelerate_ddp:951) INFO: Number of model parameters: 168056359
2025-02-06 12:08:43,818 (train_accelerate_ddp:951) INFO: Number of model parameters: 168056359
pgpu23:752237:752237 [0] NCCL INFO Bootstrap : Using ib1:20.20.20.23<0>
pgpu23:752237:752237 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
pgpu23:752237:752237 [0] NCCL INFO cudaDriverVersion 12040
NCCL version 2.20.5+cuda11.0
pgpu23:752238:752238 [1] NCCL INFO cudaDriverVersion 12040
pgpu23:752238:752238 [1] NCCL INFO Bootstrap : Using ib1:20.20.20.23<0>
pgpu23:752238:752238 [1] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
pgpu23:752237:752280 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/IB [2]mlx5_3:1/IB [RO]; OOB ib1:20.20.20.23<0>
pgpu23:752237:752280 [0] NCCL INFO Using non-device net plugin version 0
pgpu23:752237:752280 [0] NCCL INFO Using network IB
pgpu23:752238:752281 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/IB [2]mlx5_3:1/IB [RO]; OOB ib1:20.20.20.23<0>
pgpu23:752238:752281 [1] NCCL INFO Using non-device net plugin version 0
pgpu23:752238:752281 [1] NCCL INFO Using network IB
pgpu23:752237:752280 [0] NCCL INFO comm 0x55556f7ada10 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 25000 commId 0x8a2bdd0b36830b12 - Init START
pgpu23:752238:752281 [1] NCCL INFO comm 0x55556370ec60 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId 68000 commId 0x8a2bdd0b36830b12 - Init START
pgpu23:752237:752280 [0] NCCL INFO Setting affinity for GPU 0 to 7e,00000000,00000000,00000000,0000007e
pgpu23:752238:752281 [1] NCCL INFO Setting affinity for GPU 1 to 7e,00000000,00000000,00000000,0000007e
pgpu23:752237:752280 [0] NCCL INFO comm 0x55556f7ada10 rank 0 nRanks 2 nNodes 1 localRanks 2 localRank 0 MNNVL 0
pgpu23:752238:752281 [1] NCCL INFO comm 0x55556370ec60 rank 1 nRanks 2 nNodes 1 localRanks 2 localRank 1 MNNVL 0
pgpu23:752237:752280 [0] NCCL INFO Channel 00/16 :    0   1
pgpu23:752237:752280 [0] NCCL INFO Channel 01/16 :    0   1
pgpu23:752237:752280 [0] NCCL INFO Channel 02/16 :    0   1
pgpu23:752237:752280 [0] NCCL INFO Channel 03/16 :    0   1
pgpu23:752237:752280 [0] NCCL INFO Channel 04/16 :    0   1
pgpu23:752237:752280 [0] NCCL INFO Channel 05/16 :    0   1
pgpu23:752237:752280 [0] NCCL INFO Channel 06/16 :    0   1
pgpu23:752237:752280 [0] NCCL INFO Channel 07/16 :    0   1
pgpu23:752238:752281 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] 0/-1/-1->1->-1 [5] 0/-1/-1->1->-1 [6] 0/-1/-1->1->-1 [7] 0/-1/-1->1->-1 [8] -1/-1/-1->1->0 [9] -1/-1/-1->1->0 [10] -1/-1/-1->1->0 [11] -1/-1/-1->1->0 [12] 0/-1/-1->1->-1 [13] 0/-1/-1->1->-1 [14] 0/-1/-1->1->-1 [15] 0/-1/-1->1->-1
pgpu23:752237:752280 [0] NCCL INFO Channel 08/16 :    0   1
pgpu23:752237:752280 [0] NCCL INFO Channel 09/16 :    0   1
pgpu23:752238:752281 [1] NCCL INFO P2P Chunksize set to 524288
pgpu23:752237:752280 [0] NCCL INFO Channel 10/16 :    0   1
pgpu23:752237:752280 [0] NCCL INFO Channel 11/16 :    0   1
pgpu23:752237:752280 [0] NCCL INFO Channel 12/16 :    0   1
pgpu23:752237:752280 [0] NCCL INFO Channel 13/16 :    0   1
pgpu23:752237:752280 [0] NCCL INFO Channel 14/16 :    0   1
pgpu23:752237:752280 [0] NCCL INFO Channel 15/16 :    0   1
pgpu23:752237:752280 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] -1/-1/-1->0->1 [5] -1/-1/-1->0->1 [6] -1/-1/-1->0->1 [7] -1/-1/-1->0->1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] -1/-1/-1->0->1 [13] -1/-1/-1->0->1 [14] -1/-1/-1->0->1 [15] -1/-1/-1->0->1
pgpu23:752237:752280 [0] NCCL INFO P2P Chunksize set to 524288
pgpu23:752238:752281 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu23:752237:752280 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu23:752238:752281 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu23:752237:752280 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu23:752238:752281 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu23:752237:752280 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu23:752238:752281 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu23:752237:752280 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu23:752238:752281 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu23:752237:752280 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu23:752238:752281 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu23:752237:752280 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu23:752238:752281 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu23:752237:752280 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu23:752238:752281 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu23:752237:752280 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu23:752238:752281 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu23:752237:752280 [0] NCCL INFO Channel 08/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu23:752238:752281 [1] NCCL INFO Channel 09/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu23:752237:752280 [0] NCCL INFO Channel 09/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu23:752238:752281 [1] NCCL INFO Channel 10/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu23:752237:752280 [0] NCCL INFO Channel 10/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu23:752238:752281 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu23:752237:752280 [0] NCCL INFO Channel 11/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu23:752238:752281 [1] NCCL INFO Channel 12/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu23:752237:752280 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu23:752238:752281 [1] NCCL INFO Channel 13/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu23:752237:752280 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu23:752238:752281 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu23:752237:752280 [0] NCCL INFO Channel 14/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu23:752238:752281 [1] NCCL INFO Channel 15/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu23:752237:752280 [0] NCCL INFO Channel 15/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu23:752238:752281 [1] NCCL INFO Connected all rings
pgpu23:752238:752281 [1] NCCL INFO Connected all trees
pgpu23:752237:752280 [0] NCCL INFO Connected all rings
pgpu23:752238:752281 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
pgpu23:752237:752280 [0] NCCL INFO Connected all trees
pgpu23:752238:752281 [1] NCCL INFO 16 coll channels, 0 collnet channels, 0 nvls channels, 16 p2p channels, 16 p2p channels per peer
pgpu23:752237:752280 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
pgpu23:752237:752280 [0] NCCL INFO 16 coll channels, 0 collnet channels, 0 nvls channels, 16 p2p channels, 16 p2p channels per peer
pgpu23:752238:752281 [1] NCCL INFO comm 0x55556370ec60 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId 68000 commId 0x8a2bdd0b36830b12 - Init COMPLETE
pgpu23:752237:752280 [0] NCCL INFO comm 0x55556f7ada10 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 25000 commId 0x8a2bdd0b36830b12 - Init COMPLETE
2025-02-06 12:08:45,484 (train_accelerate_ddp:1032) INFO: start training from epoch 1
2025-02-06 12:08:45,484 (train_accelerate_ddp:1033) INFO: Train set grouped total_num_itrs = 4114
2025-02-06 12:08:45,484 (train_accelerate_ddp:1032) INFO: start training from epoch 1
2025-02-06 12:08:45,484 (train_accelerate_ddp:1033) INFO: Train set grouped total_num_itrs = 4114
/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/ts_vad_dataset.py:398: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  feature = torch.load(path, map_location="cpu")
/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/ts_vad_dataset.py:398: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  feature = torch.load(path, map_location="cpu")
/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/ts_vad_dataset.py:392: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  feature = torch.load(path, map_location="cpu")
/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/ts_vad_dataset.py:392: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  feature = torch.load(path, map_location="cpu")
2025-02-06 12:09:07,537 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 0, num_updates: 0, {'loss': 0.6831934452056885, 'DER': 2.219870630957785, 'ACC': np.float64(0.5630803571428571), 'MI': 0.052768951429868365, 'FA': 1.6103608715388107, 'CF': 0.5567408079891057}, batch size: 64, grad_norm: 2.1591787338256836, grad_scale: , lr: 1.00e-08, 
2025-02-06 12:09:07,537 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 0, num_updates: 0, {'loss': 0.6844578981399536, 'DER': 2.1683184762748464, 'ACC': np.float64(0.5620357142857143), 'MI': 0.05974198549360501, 'FA': 1.5609877636897183, 'CF': 0.5475887270915232}, batch size: 64, grad_norm: 2.1591787338256836, grad_scale: , lr: 1.00e-08, 
2025-02-06 12:23:09,902 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 500, num_updates: 500, {'loss': 0.38217103481292725, 'DER': 0.9543510044945037, 'ACC': np.float64(0.8329464285714285), 'MI': 0.8847674229707045, 'FA': 0.010775978772946337, 'CF': 0.05880760275085287}, batch size: 64, grad_norm: 0.5049715042114258, grad_scale: , lr: 5.01e-06, 
2025-02-06 12:23:09,902 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 500, num_updates: 500, {'loss': 0.36349722743034363, 'DER': 0.9331181638873947, 'ACC': np.float64(0.8478482142857143), 'MI': 0.8188990496682804, 'FA': 0.02880879803956727, 'CF': 0.08541031617954695}, batch size: 64, grad_norm: 0.5049715042114258, grad_scale: , lr: 5.01e-06, 
2025-02-06 12:23:09,903 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 12:23:09,903 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 12:24:19,845 (model:870) WARNING: All labels are zero
2025-02-06 12:24:20,642 (model:870) WARNING: All labels are zero
2025-02-06 12:24:21,514 (model:870) WARNING: All labels are zero
2025-02-06 12:26:29,922 (model:870) WARNING: All labels are zero
2025-02-06 12:26:47,061 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 500,  validation: loss=0.3413, DER=0.9904, ACC=0.8477, MI=0.9858, FA=0.0001322, CF=0.00447, over 0.00 frames. 
2025-02-06 12:26:47,062 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 9954MB
2025-02-06 12:26:47,126 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 500,  validation: loss=0.3395, DER=0.9902, ACC=0.8495, MI=0.9856, FA=0.0001228, CF=0.004494, over 0.00 frames. 
2025-02-06 12:26:47,126 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 9954MB
2025-02-06 12:40:45,326 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 1000, num_updates: 1000, {'loss': 0.3301979899406433, 'DER': 0.8779737247011481, 'ACC': np.float64(0.8593482142857143), 'MI': 0.7977275417209138, 'FA': 0.02597940584684578, 'CF': 0.054266777133388566}, batch size: 64, grad_norm: 0.406840980052948, grad_scale: , lr: 1.00e-05, 
2025-02-06 12:40:45,326 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 1000, num_updates: 1000, {'loss': 0.33265799283981323, 'DER': 0.9015164925945595, 'ACC': np.float64(0.8525803571428571), 'MI': 0.8082256446568714, 'FA': 0.02053460789520269, 'CF': 0.07275624004248539}, batch size: 64, grad_norm: 0.406840980052948, grad_scale: , lr: 1.00e-05, 
2025-02-06 12:40:45,326 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 12:40:45,326 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 12:41:55,361 (model:870) WARNING: All labels are zero
2025-02-06 12:41:56,181 (model:870) WARNING: All labels are zero
2025-02-06 12:41:56,208 (model:870) WARNING: All labels are zero
2025-02-06 12:44:05,041 (model:870) WARNING: All labels are zero
2025-02-06 12:44:22,188 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 1000,  validation: loss=0.3234, DER=0.97, ACC=0.8486, MI=0.9386, FA=0.0002802, CF=0.03119, over 0.00 frames. 
2025-02-06 12:44:22,189 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 9954MB
2025-02-06 12:44:22,225 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 1000,  validation: loss=0.3231, DER=0.971, ACC=0.8463, MI=0.938, FA=0.0002635, CF=0.03278, over 0.00 frames. 
2025-02-06 12:44:22,225 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 9954MB
2025-02-06 12:58:27,034 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-1500.pt
2025-02-06 12:58:28,044 (checkpoint:355) WARNING: No checkpoints found in /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10
2025-02-06 12:58:29,695 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 1500, num_updates: 1500, {'loss': 0.33432966470718384, 'DER': 0.8829883531470641, 'ACC': np.float64(0.8500089285714285), 'MI': 0.6977249411622715, 'FA': 0.054492788606601894, 'CF': 0.13077062337819081}, batch size: 64, grad_norm: 0.4630581736564636, grad_scale: , lr: 1.50e-05, 
2025-02-06 12:58:29,695 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 1500, num_updates: 1500, {'loss': 0.2864554524421692, 'DER': 0.7199695204920263, 'ACC': np.float64(0.8656160714285714), 'MI': 0.5599521036303271, 'FA': 0.060795732868883685, 'CF': 0.09922168399281554}, batch size: 64, grad_norm: 0.4630581736564636, grad_scale: , lr: 1.50e-05, 
2025-02-06 12:58:29,695 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 12:58:29,695 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 12:59:39,644 (model:870) WARNING: All labels are zero
2025-02-06 12:59:40,367 (model:870) WARNING: All labels are zero
2025-02-06 12:59:40,458 (model:870) WARNING: All labels are zero
2025-02-06 13:01:46,889 (model:870) WARNING: All labels are zero
2025-02-06 13:02:04,088 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 1500,  validation: loss=0.3111, DER=0.944, ACC=0.8508, MI=0.897, FA=0.007122, CF=0.03996, over 0.00 frames. 
2025-02-06 13:02:04,089 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 9954MB
2025-02-06 13:02:04,855 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 1500,  validation: loss=0.3109, DER=0.9401, ACC=0.8498, MI=0.893, FA=0.008266, CF=0.03885, over 0.00 frames. 
2025-02-06 13:02:04,855 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 9954MB
2025-02-06 13:16:03,804 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 2000, num_updates: 2000, {'loss': 0.26939526200294495, 'DER': 0.7074140824063141, 'ACC': np.float64(0.8723660714285715), 'MI': 0.41203157044310484, 'FA': 0.11441178298427693, 'CF': 0.18097072897893232}, batch size: 64, grad_norm: 0.5039320588111877, grad_scale: , lr: 2.00e-05, 
2025-02-06 13:16:03,804 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 2000, num_updates: 2000, {'loss': 0.2971765697002411, 'DER': 0.7571163006854885, 'ACC': np.float64(0.8558839285714286), 'MI': 0.48019054258161964, 'FA': 0.09637504356918787, 'CF': 0.18055071453468108}, batch size: 64, grad_norm: 0.5039320588111877, grad_scale: , lr: 2.00e-05, 
2025-02-06 13:16:03,804 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 13:16:03,804 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 13:17:14,600 (model:870) WARNING: All labels are zero
2025-02-06 13:17:15,379 (model:870) WARNING: All labels are zero
2025-02-06 13:17:15,422 (model:870) WARNING: All labels are zero
2025-02-06 13:19:24,767 (model:870) WARNING: All labels are zero
2025-02-06 13:19:41,625 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 2000,  validation: loss=0.2731, DER=0.785, ACC=0.8628, MI=0.6371, FA=0.02846, CF=0.1195, over 0.00 frames. 
2025-02-06 13:19:41,626 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 9954MB
2025-02-06 13:19:41,910 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 2000,  validation: loss=0.2748, DER=0.7904, ACC=0.8609, MI=0.6427, FA=0.02823, CF=0.1194, over 0.00 frames. 
2025-02-06 13:19:41,911 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 9954MB
2025-02-06 13:33:44,132 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 2500, num_updates: 2500, {'loss': 0.2883571982383728, 'DER': 0.732328422975905, 'ACC': np.float64(0.86996786996787), 'MI': 0.5674317688706177, 'FA': 0.0722850291195615, 'CF': 0.0926116249857257}, batch size: 64, grad_norm: 0.4317832291126251, grad_scale: , lr: 1.94e-05, 
2025-02-06 13:33:44,132 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 2500, num_updates: 2500, {'loss': 0.26079949736595154, 'DER': 0.6150688099919047, 'ACC': np.float64(0.8876517857142857), 'MI': 0.4404995952353417, 'FA': 0.062044639759454144, 'CF': 0.11252457499710883}, batch size: 64, grad_norm: 0.4317832291126251, grad_scale: , lr: 1.94e-05, 
2025-02-06 13:33:44,132 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 13:33:44,132 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 13:34:55,186 (model:870) WARNING: All labels are zero
2025-02-06 13:34:55,983 (model:870) WARNING: All labels are zero
2025-02-06 13:34:56,017 (model:870) WARNING: All labels are zero
2025-02-06 13:37:05,908 (model:870) WARNING: All labels are zero
2025-02-06 13:37:23,210 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 2500,  validation: loss=0.2465, DER=0.6928, ACC=0.8792, MI=0.5589, FA=0.03177, CF=0.1021, over 0.00 frames. 
2025-02-06 13:37:23,211 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 9954MB
2025-02-06 13:37:23,311 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 2500,  validation: loss=0.2498, DER=0.6981, ACC=0.8767, MI=0.5614, FA=0.03004, CF=0.1067, over 0.00 frames. 
2025-02-06 13:37:23,311 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 9954MB
2025-02-06 13:51:22,760 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-3000.pt
2025-02-06 13:51:23,681 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-06 13:51:23,740 (checkpoint:355) WARNING: No checkpoints found in /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10
2025-02-06 13:51:25,247 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 3000, num_updates: 3000, {'loss': 0.25951164960861206, 'DER': 0.6233478926768393, 'ACC': np.float64(0.8789352352136013), 'MI': 0.3862385841511146, 'FA': 0.09785013330308015, 'CF': 0.1392591752226445}, batch size: 64, grad_norm: 0.46723413467407227, grad_scale: , lr: 1.89e-05, 
2025-02-06 13:51:25,247 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 13:51:25,247 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 3000, num_updates: 3000, {'loss': 0.23569048941135406, 'DER': 0.5808072059587736, 'ACC': np.float64(0.8910178571428571), 'MI': 0.3512904902130608, 'FA': 0.10554881921589006, 'CF': 0.12396789652982274}, batch size: 64, grad_norm: 0.46723413467407227, grad_scale: , lr: 1.89e-05, 
2025-02-06 13:51:25,247 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 13:52:35,862 (model:870) WARNING: All labels are zero
2025-02-06 13:52:36,687 (model:870) WARNING: All labels are zero
2025-02-06 13:52:36,715 (model:870) WARNING: All labels are zero
2025-02-06 13:54:46,353 (model:870) WARNING: All labels are zero
2025-02-06 13:55:03,604 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 3000,  validation: loss=0.2291, DER=0.6476, ACC=0.8873, MI=0.4828, FA=0.07438, CF=0.09043, over 0.00 frames. 
2025-02-06 13:55:03,605 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 9954MB
2025-02-06 13:55:03,637 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 3000,  validation: loss=0.2293, DER=0.6601, ACC=0.8864, MI=0.4876, FA=0.08142, CF=0.09114, over 0.00 frames. 
2025-02-06 13:55:03,638 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 9954MB
2025-02-06 14:09:14,144 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 3500, num_updates: 3500, {'loss': 0.25583934783935547, 'DER': 0.6205128205128205, 'ACC': np.float64(0.8785178571428571), 'MI': 0.4252136752136752, 'FA': 0.0889957264957265, 'CF': 0.1063034188034188}, batch size: 64, grad_norm: 0.44134894013404846, grad_scale: , lr: 1.83e-05, 
2025-02-06 14:09:14,144 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 3500, num_updates: 3500, {'loss': 0.2290172129869461, 'DER': 0.575814574358352, 'ACC': np.float64(0.8962575402069455), 'MI': 0.36005096778108125, 'FA': 0.09137795036708937, 'CF': 0.12438565621018143}, batch size: 64, grad_norm: 0.44134894013404846, grad_scale: , lr: 1.83e-05, 
2025-02-06 14:09:14,145 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 14:09:14,145 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 14:10:25,551 (model:870) WARNING: All labels are zero
2025-02-06 14:10:26,387 (model:870) WARNING: All labels are zero
2025-02-06 14:10:26,389 (model:870) WARNING: All labels are zero
2025-02-06 14:12:37,429 (model:870) WARNING: All labels are zero
2025-02-06 14:12:54,840 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 3500,  validation: loss=0.2165, DER=0.5974, ACC=0.8933, MI=0.3797, FA=0.1076, CF=0.1101, over 0.00 frames. 
2025-02-06 14:12:54,840 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 9954MB
2025-02-06 14:12:54,902 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 3500,  validation: loss=0.2179, DER=0.5851, ACC=0.8932, MI=0.3711, FA=0.1015, CF=0.1125, over 0.00 frames. 
2025-02-06 14:12:54,903 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 9954MB
/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
2025-02-06 14:26:57,828 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 4000, num_updates: 4000, {'loss': 0.24682103097438812, 'DER': 0.5588042766746673, 'ACC': np.float64(0.8903214285714286), 'MI': 0.38271874318132226, 'FA': 0.06480471307004146, 'CF': 0.11128082042330352}, batch size: 64, grad_norm: 0.5498332977294922, grad_scale: , lr: 1.78e-05, 
2025-02-06 14:26:57,828 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 4000, num_updates: 4000, {'loss': 0.21779300272464752, 'DER': 0.527380677887941, 'ACC': np.float64(0.9009017857142857), 'MI': 0.29127276919529627, 'FA': 0.12370302052109754, 'CF': 0.11240488817154715}, batch size: 64, grad_norm: 0.5498332977294922, grad_scale: , lr: 1.78e-05, 
2025-02-06 14:26:57,828 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 14:26:57,828 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 14:28:08,408 (model:870) WARNING: All labels are zero
2025-02-06 14:28:09,234 (model:870) WARNING: All labels are zero
2025-02-06 14:28:09,303 (model:870) WARNING: All labels are zero
2025-02-06 14:30:17,572 (model:870) WARNING: All labels are zero
2025-02-06 14:30:34,334 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 4000,  validation: loss=0.2015, DER=0.5318, ACC=0.9015, MI=0.3261, FA=0.09967, CF=0.106, over 0.00 frames. 
2025-02-06 14:30:34,335 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 14:30:34,490 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 4000,  validation: loss=0.2004, DER=0.5359, ACC=0.9026, MI=0.3253, FA=0.1055, CF=0.1051, over 0.00 frames. 
2025-02-06 14:30:34,491 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11774MB
2025-02-06 14:34:33,227 (train_accelerate_ddp:713) INFO: end of epoch 1, batch_idx: 4113 batch_idx_train: 4113, {'loss': 0.21980388462543488, 'DER': 0.5026875298614429, 'ACC': np.float64(0.9003035714285714), 'MI': 0.27669612995699955, 'FA': 0.061813186813186816, 'CF': 0.16417821309125658}, batch size: 64, grad_norm: 0.5344580411911011, grad_scale: , lr: 1.77e-05, 
2025-02-06 14:34:33,227 (train_accelerate_ddp:713) INFO: end of epoch 1, batch_idx: 4113 batch_idx_train: 4113, {'loss': 0.21130771934986115, 'DER': 0.4864729458917836, 'ACC': np.float64(0.9008839285714285), 'MI': 0.2947561790247161, 'FA': 0.06023157425963037, 'CF': 0.1314851926074371}, batch size: 64, grad_norm: 0.5344580411911011, grad_scale: , lr: 1.77e-05, 
2025-02-06 14:34:33,228 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-1.pt
2025-02-06 14:34:34,383 (train_accelerate_ddp:561) INFO:  end of epoch 1, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-1.pt 
2025-02-06 14:34:39,647 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 4114, num_updates: 4000, {'loss': 0.22490926086902618, 'DER': 0.5522545178080589, 'ACC': np.float64(0.8890690593301264), 'MI': 0.2667992280250307, 'FA': 0.11755073396105035, 'CF': 0.16790455582197789}, batch size: 64, grad_norm: 0.5502967834472656, grad_scale: , lr: 1.77e-05, 
2025-02-06 14:34:39,647 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 4114, num_updates: 4000, {'loss': 0.2038317620754242, 'DER': 0.5082577622965587, 'ACC': np.float64(0.9002321428571429), 'MI': 0.25133625608071586, 'FA': 0.09410846195423699, 'CF': 0.16281304426160592}, batch size: 64, grad_norm: 0.5502967834472656, grad_scale: , lr: 1.77e-05, 
2025-02-06 14:48:08,923 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-4500.pt
2025-02-06 14:48:10,532 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-06 14:52:13,567 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 4614, num_updates: 4500, {'loss': 0.19504159688949585, 'DER': 0.46677471636953, 'ACC': np.float64(0.9096875), 'MI': 0.23668887688336634, 'FA': 0.08968125337655321, 'CF': 0.14040458610961043}, batch size: 64, grad_norm: 0.507452130317688, grad_scale: , lr: 1.71e-05, 
2025-02-06 14:52:13,568 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 14:52:13,568 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 4614, num_updates: 4500, {'loss': 0.16130618751049042, 'DER': 0.39666270858071373, 'ACC': np.float64(0.9303214285714285), 'MI': 0.20967439535029062, 'FA': 0.09593150428098243, 'CF': 0.09105680894944065}, batch size: 64, grad_norm: 0.507452130317688, grad_scale: , lr: 1.71e-05, 
2025-02-06 14:52:13,568 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 14:53:24,163 (model:870) WARNING: All labels are zero
2025-02-06 14:53:24,992 (model:870) WARNING: All labels are zero
2025-02-06 14:53:25,001 (model:870) WARNING: All labels are zero
2025-02-06 14:55:34,921 (model:870) WARNING: All labels are zero
2025-02-06 14:55:52,299 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 4614,  validation: loss=0.1537, DER=0.3821, ACC=0.9279, MI=0.2041, FA=0.09501, CF=0.08301, over 0.00 frames. 
2025-02-06 14:55:52,299 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11780MB
2025-02-06 14:55:52,329 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 4614,  validation: loss=0.1579, DER=0.3796, ACC=0.9267, MI=0.1989, FA=0.09455, CF=0.08615, over 0.00 frames. 
2025-02-06 14:55:52,330 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 15:13:26,901 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 5114, num_updates: 5000, {'loss': 0.147571861743927, 'DER': 0.33856762081353575, 'ACC': np.float64(0.9389642857142857), 'MI': 0.20830918994089698, 'FA': 0.07271989801831034, 'CF': 0.05753853285432843}, batch size: 64, grad_norm: 0.4405946135520935, grad_scale: , lr: 1.65e-05, 
2025-02-06 15:13:26,902 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 5114, num_updates: 5000, {'loss': 0.1750897467136383, 'DER': 0.39182883805621943, 'ACC': np.float64(0.9252321428571428), 'MI': 0.24735404574940253, 'FA': 0.059804256287697734, 'CF': 0.08467053601911916}, batch size: 64, grad_norm: 0.4405946135520935, grad_scale: , lr: 1.65e-05, 
2025-02-06 15:13:26,902 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 15:13:26,902 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 15:14:37,787 (model:870) WARNING: All labels are zero
2025-02-06 15:14:38,616 (model:870) WARNING: All labels are zero
2025-02-06 15:14:38,633 (model:870) WARNING: All labels are zero
2025-02-06 15:16:48,892 (model:870) WARNING: All labels are zero
2025-02-06 15:17:06,283 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 5114,  validation: loss=0.1314, DER=0.3205, ACC=0.9386, MI=0.1575, FA=0.09323, CF=0.06979, over 0.00 frames. 
2025-02-06 15:17:06,283 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11780MB
2025-02-06 15:17:07,110 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 5114,  validation: loss=0.1354, DER=0.3224, ACC=0.9369, MI=0.1535, FA=0.09441, CF=0.07443, over 0.00 frames. 
2025-02-06 15:17:07,110 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 15:34:28,490 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 5614, num_updates: 5500, {'loss': 0.16978515684604645, 'DER': 0.41037596647583074, 'ACC': np.float64(0.9263660714285714), 'MI': 0.2440535914536977, 'FA': 0.08994865136044385, 'CF': 0.0763737236616892}, batch size: 64, grad_norm: 0.43595725297927856, grad_scale: , lr: 1.60e-05, 
2025-02-06 15:34:28,491 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 15:34:28,491 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 5614, num_updates: 5500, {'loss': 0.17249061167240143, 'DER': 0.3868780815777678, 'ACC': np.float64(0.9232589285714285), 'MI': 0.20276781712236666, 'FA': 0.08942178395338413, 'CF': 0.09468848050201703}, batch size: 64, grad_norm: 0.43595725297927856, grad_scale: , lr: 1.60e-05, 
2025-02-06 15:34:28,491 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 15:35:39,531 (model:870) WARNING: All labels are zero
2025-02-06 15:35:40,307 (model:870) WARNING: All labels are zero
2025-02-06 15:35:40,352 (model:870) WARNING: All labels are zero
2025-02-06 15:37:50,071 (model:870) WARNING: All labels are zero
2025-02-06 15:38:07,335 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 5614,  validation: loss=0.1165, DER=0.2751, ACC=0.9466, MI=0.1405, FA=0.07904, CF=0.05549, over 0.00 frames. 
2025-02-06 15:38:07,335 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11780MB
2025-02-06 15:38:07,453 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 5614,  validation: loss=0.1191, DER=0.276, ACC=0.9453, MI=0.1388, FA=0.07768, CF=0.0595, over 0.00 frames. 
2025-02-06 15:38:07,453 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 15:51:34,106 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-6000.pt
2025-02-06 15:51:35,745 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-06 15:55:39,384 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 6114, num_updates: 6000, {'loss': 0.2275361865758896, 'DER': 0.5117561381606326, 'ACC': np.float64(0.8958482142857144), 'MI': 0.3637640449438202, 'FA': 0.05295464003329172, 'CF': 0.0950374531835206}, batch size: 64, grad_norm: 0.5450266003608704, grad_scale: , lr: 1.54e-05, 
2025-02-06 15:55:39,385 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 6114, num_updates: 6000, {'loss': 0.16026386618614197, 'DER': 0.36934186578993716, 'ACC': np.float64(0.9295089285714285), 'MI': 0.18152997123231374, 'FA': 0.09364175424176599, 'CF': 0.09417014031585745}, batch size: 64, grad_norm: 0.5450266003608704, grad_scale: , lr: 1.54e-05, 
2025-02-06 15:55:39,385 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 15:55:39,385 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 15:56:50,394 (model:870) WARNING: All labels are zero
2025-02-06 15:56:51,176 (model:870) WARNING: All labels are zero
2025-02-06 15:56:51,218 (model:870) WARNING: All labels are zero
2025-02-06 15:58:59,360 (model:870) WARNING: All labels are zero
2025-02-06 15:59:16,627 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 6114,  validation: loss=0.1125, DER=0.2708, ACC=0.9471, MI=0.1285, FA=0.08101, CF=0.06132, over 0.00 frames. 
2025-02-06 15:59:16,628 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11780MB
2025-02-06 15:59:17,358 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 6114,  validation: loss=0.114, DER=0.2661, ACC=0.9471, MI=0.129, FA=0.07709, CF=0.06006, over 0.00 frames. 
2025-02-06 15:59:17,358 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 16:16:46,113 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 6614, num_updates: 6500, {'loss': 0.1699245572090149, 'DER': 0.4037735849056604, 'ACC': np.float64(0.9252767857142856), 'MI': 0.202063679245283, 'FA': 0.11202830188679246, 'CF': 0.0896816037735849}, batch size: 64, grad_norm: 0.511681318283081, grad_scale: , lr: 1.49e-05, 
2025-02-06 16:16:46,114 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 6614, num_updates: 6500, {'loss': 0.163923978805542, 'DER': 0.3621744936567995, 'ACC': np.float64(0.93), 'MI': 0.21950812374805254, 'FA': 0.06860672156688181, 'CF': 0.07405964834186513}, batch size: 64, grad_norm: 0.511681318283081, grad_scale: , lr: 1.49e-05, 
2025-02-06 16:16:46,114 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 16:16:46,114 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 16:17:56,930 (model:870) WARNING: All labels are zero
2025-02-06 16:17:57,725 (model:870) WARNING: All labels are zero
2025-02-06 16:17:57,761 (model:870) WARNING: All labels are zero
2025-02-06 16:20:05,332 (model:870) WARNING: All labels are zero
2025-02-06 16:20:22,583 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 6614,  validation: loss=0.101, DER=0.2296, ACC=0.9552, MI=0.1152, FA=0.0734, CF=0.04092, over 0.00 frames. 
2025-02-06 16:20:22,584 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11780MB
2025-02-06 16:20:23,313 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 6614,  validation: loss=0.1026, DER=0.2289, ACC=0.9547, MI=0.1169, FA=0.07135, CF=0.04059, over 0.00 frames. 
2025-02-06 16:20:23,313 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 16:37:52,336 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 7114, num_updates: 7000, {'loss': 0.18451662361621857, 'DER': 0.4265503272047367, 'ACC': np.float64(0.921517857142857), 'MI': 0.21396073543159863, 'FA': 0.09130570271112497, 'CF': 0.1212838890620131}, batch size: 64, grad_norm: 0.5342227816581726, grad_scale: , lr: 1.43e-05, 
2025-02-06 16:37:52,336 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 16:37:52,337 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 7114, num_updates: 7000, {'loss': 0.16497613489627838, 'DER': 0.39738698115389065, 'ACC': np.float64(0.9242321428571428), 'MI': 0.2318187073650133, 'FA': 0.07237830963117123, 'CF': 0.0931899641577061}, batch size: 64, grad_norm: 0.5342227816581726, grad_scale: , lr: 1.43e-05, 
2025-02-06 16:37:52,337 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 16:39:02,803 (model:870) WARNING: All labels are zero
2025-02-06 16:39:03,589 (model:870) WARNING: All labels are zero
2025-02-06 16:39:03,623 (model:870) WARNING: All labels are zero
2025-02-06 16:41:12,905 (model:870) WARNING: All labels are zero
2025-02-06 16:41:30,137 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 7114,  validation: loss=0.09738, DER=0.2268, ACC=0.9561, MI=0.1187, FA=0.07022, CF=0.03792, over 0.00 frames. 
2025-02-06 16:41:30,138 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11780MB
2025-02-06 16:41:30,199 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 7114,  validation: loss=0.09849, DER=0.2222, ACC=0.9561, MI=0.1214, FA=0.06361, CF=0.03715, over 0.00 frames. 
2025-02-06 16:41:30,199 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 16:55:02,608 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-7500.pt
2025-02-06 16:55:04,789 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-06 16:59:05,400 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 7614, num_updates: 7500, {'loss': 0.17233936488628387, 'DER': 0.3538107014388489, 'ACC': np.float64(0.9266635170985209), 'MI': 0.18148606115107913, 'FA': 0.07244829136690648, 'CF': 0.0998763489208633}, batch size: 64, grad_norm: 0.45694851875305176, grad_scale: , lr: 1.38e-05, 
2025-02-06 16:59:05,401 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 16:59:05,401 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 7614, num_updates: 7500, {'loss': 0.14502137899398804, 'DER': 0.3445909660480936, 'ACC': np.float64(0.935360020140987), 'MI': 0.18694432842055014, 'FA': 0.07327406169819202, 'CF': 0.08437257592935139}, batch size: 64, grad_norm: 0.45694851875305176, grad_scale: , lr: 1.38e-05, 
2025-02-06 16:59:05,401 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 17:00:16,352 (model:870) WARNING: All labels are zero
2025-02-06 17:00:17,180 (model:870) WARNING: All labels are zero
2025-02-06 17:00:17,198 (model:870) WARNING: All labels are zero
2025-02-06 17:02:28,135 (model:870) WARNING: All labels are zero
2025-02-06 17:02:45,543 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 7614,  validation: loss=0.09906, DER=0.2256, ACC=0.9549, MI=0.1078, FA=0.07294, CF=0.0448, over 0.00 frames. 
2025-02-06 17:02:45,544 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 17:02:45,546 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 7614,  validation: loss=0.09917, DER=0.2337, ACC=0.9544, MI=0.1078, FA=0.07919, CF=0.04676, over 0.00 frames. 
2025-02-06 17:02:45,546 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11780MB
2025-02-06 17:20:24,545 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 8114, num_updates: 8000, {'loss': 0.1542336344718933, 'DER': 0.3530837004405286, 'ACC': np.float64(0.9280714285714285), 'MI': 0.18997797356828194, 'FA': 0.07257709251101321, 'CF': 0.09052863436123348}, batch size: 64, grad_norm: 0.43069353699684143, grad_scale: , lr: 1.32e-05, 
2025-02-06 17:20:24,546 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 17:20:24,546 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 8114, num_updates: 8000, {'loss': 0.14707054197788239, 'DER': 0.3446542351084351, 'ACC': np.float64(0.9373392857142857), 'MI': 0.19249430057871048, 'FA': 0.0865727479978956, 'CF': 0.06558718653182907}, batch size: 64, grad_norm: 0.43069353699684143, grad_scale: , lr: 1.32e-05, 
2025-02-06 17:20:24,546 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 17:21:34,877 (model:870) WARNING: All labels are zero
2025-02-06 17:21:35,703 (model:870) WARNING: All labels are zero
2025-02-06 17:21:35,712 (model:870) WARNING: All labels are zero
2025-02-06 17:23:45,335 (model:870) WARNING: All labels are zero
2025-02-06 17:24:02,723 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 8114,  validation: loss=0.08917, DER=0.2074, ACC=0.9591, MI=0.09538, FA=0.07444, CF=0.03759, over 0.00 frames. 
2025-02-06 17:24:02,724 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11780MB
2025-02-06 17:24:02,746 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 8114,  validation: loss=0.08988, DER=0.204, ACC=0.9591, MI=0.09799, FA=0.07027, CF=0.03574, over 0.00 frames. 
2025-02-06 17:24:02,747 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 17:28:02,644 (train_accelerate_ddp:713) INFO: end of epoch 2, batch_idx: 4113 batch_idx_train: 8227, {'loss': 0.12390677630901337, 'DER': 0.26066834956124535, 'ACC': np.float64(0.9513214285714285), 'MI': 0.12056737588652482, 'FA': 0.07308570741675682, 'CF': 0.0670152662579637}, batch size: 64, grad_norm: 0.4387529790401459, grad_scale: , lr: 1.31e-05, 
2025-02-06 17:28:02,644 (train_accelerate_ddp:713) INFO: end of epoch 2, batch_idx: 4113 batch_idx_train: 8227, {'loss': 0.13838398456573486, 'DER': 0.3405108235024625, 'ACC': np.float64(0.9354179053384502), 'MI': 0.18417134348871836, 'FA': 0.08630168365593861, 'CF': 0.07003779635780552}, batch size: 64, grad_norm: 0.4387529790401459, grad_scale: , lr: 1.31e-05, 
2025-02-06 17:28:02,645 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-2.pt
2025-02-06 17:28:03,811 (train_accelerate_ddp:561) INFO:  end of epoch 2, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-2.pt 
2025-02-06 17:28:08,438 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 8228, num_updates: 8000, {'loss': 0.141474187374115, 'DER': 0.32400204417693484, 'ACC': np.float64(0.9415892857142857), 'MI': 0.19033558571347453, 'FA': 0.08619612742036227, 'CF': 0.047470331043098064}, batch size: 64, grad_norm: 0.371268093585968, grad_scale: , lr: 1.31e-05, 
2025-02-06 17:28:08,438 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 8228, num_updates: 8000, {'loss': 0.15211251378059387, 'DER': 0.3288965941502153, 'ACC': np.float64(0.9370714285714286), 'MI': 0.1951233152508249, 'FA': 0.06850847268049885, 'CF': 0.06526480621889157}, batch size: 64, grad_norm: 0.371268093585968, grad_scale: , lr: 1.31e-05, 
2025-02-06 17:45:43,367 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 8728, num_updates: 8500, {'loss': 0.16711106896400452, 'DER': 0.36169128884360674, 'ACC': np.float64(0.9291785714285714), 'MI': 0.20133582385238014, 'FA': 0.0730740929416426, 'CF': 0.08728137204958397}, batch size: 64, grad_norm: 0.5136919021606445, grad_scale: , lr: 1.25e-05, 
2025-02-06 17:45:43,367 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 8728, num_updates: 8500, {'loss': 0.1337244212627411, 'DER': 0.3226770242007768, 'ACC': np.float64(0.9388908829863604), 'MI': 0.18093815357036153, 'FA': 0.05748431431132357, 'CF': 0.08425455631909172}, batch size: 64, grad_norm: 0.5136919021606445, grad_scale: , lr: 1.25e-05, 
2025-02-06 17:45:43,368 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 17:45:43,368 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 17:46:54,372 (model:870) WARNING: All labels are zero
2025-02-06 17:46:55,129 (model:870) WARNING: All labels are zero
2025-02-06 17:46:55,188 (model:870) WARNING: All labels are zero
2025-02-06 17:49:03,242 (model:870) WARNING: All labels are zero
2025-02-06 17:49:20,723 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 8728,  validation: loss=0.09588, DER=0.2196, ACC=0.958, MI=0.1333, FA=0.05309, CF=0.03318, over 0.00 frames. 
2025-02-06 17:49:20,724 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11780MB
2025-02-06 17:49:21,452 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 8728,  validation: loss=0.09699, DER=0.217, ACC=0.9574, MI=0.1332, FA=0.0497, CF=0.03406, over 0.00 frames. 
2025-02-06 17:49:21,452 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 17:58:57,746 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-9000.pt
2025-02-06 17:58:59,370 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-06 17:58:59,505 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-06 18:07:09,452 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 9228, num_updates: 9000, {'loss': 0.13699816167354584, 'DER': 0.3489964862128521, 'ACC': np.float64(0.9376181813293664), 'MI': 0.1633613245190876, 'FA': 0.12006432017152045, 'CF': 0.06557084152224406}, batch size: 64, grad_norm: 0.45396968722343445, grad_scale: , lr: 1.20e-05, 
2025-02-06 18:07:09,452 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 9228, num_updates: 9000, {'loss': 0.16229236125946045, 'DER': 0.33329909613804437, 'ACC': np.float64(0.930625), 'MI': 0.22201109285127363, 'FA': 0.04555258833196384, 'CF': 0.0657354149548069}, batch size: 64, grad_norm: 0.45396968722343445, grad_scale: , lr: 1.20e-05, 
2025-02-06 18:07:09,453 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 18:07:09,453 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 18:08:21,706 (model:870) WARNING: All labels are zero
2025-02-06 18:08:22,524 (model:870) WARNING: All labels are zero
2025-02-06 18:08:22,541 (model:870) WARNING: All labels are zero
2025-02-06 18:10:32,294 (model:870) WARNING: All labels are zero
2025-02-06 18:10:49,635 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 9228,  validation: loss=0.1033, DER=0.2485, ACC=0.9527, MI=0.1583, FA=0.04613, CF=0.04401, over 0.00 frames. 
2025-02-06 18:10:49,636 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11780MB
2025-02-06 18:10:49,659 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 9228,  validation: loss=0.1042, DER=0.2439, ACC=0.9526, MI=0.159, FA=0.04336, CF=0.04148, over 0.00 frames. 
2025-02-06 18:10:49,660 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 18:28:27,516 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 9728, num_updates: 9500, {'loss': 0.16988931596279144, 'DER': 0.41931922723091075, 'ACC': np.float64(0.9265625), 'MI': 0.2361238883777982, 'FA': 0.09806807727690893, 'CF': 0.08512726157620362}, batch size: 64, grad_norm: 0.44379034638404846, grad_scale: , lr: 1.14e-05, 
2025-02-06 18:28:27,516 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 18:28:27,516 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 9728, num_updates: 9500, {'loss': 0.12834849953651428, 'DER': 0.25506874854346306, 'ACC': np.float64(0.9505892857142857), 'MI': 0.13376835236541598, 'FA': 0.05395012817525052, 'CF': 0.06735026800279655}, batch size: 64, grad_norm: 0.44379034638404846, grad_scale: , lr: 1.14e-05, 
2025-02-06 18:28:27,517 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 18:29:39,233 (model:870) WARNING: All labels are zero
2025-02-06 18:29:40,077 (model:870) WARNING: All labels are zero
2025-02-06 18:29:40,106 (model:870) WARNING: All labels are zero
2025-02-06 18:31:53,772 (model:870) WARNING: All labels are zero
2025-02-06 18:32:11,493 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 9728,  validation: loss=0.08512, DER=0.1908, ACC=0.9616, MI=0.0997, FA=0.05986, CF=0.03122, over 0.00 frames. 
2025-02-06 18:32:11,494 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 18:32:11,571 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 9728,  validation: loss=0.08457, DER=0.193, ACC=0.9622, MI=0.09943, FA=0.0632, CF=0.03037, over 0.00 frames. 
2025-02-06 18:32:11,572 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11780MB
2025-02-06 18:49:56,321 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 10228, num_updates: 10000, {'loss': 0.1367589235305786, 'DER': 0.2904979469087965, 'ACC': np.float64(0.9470089285714286), 'MI': 0.15534092880689376, 'FA': 0.08241281591579434, 'CF': 0.05274420218610838}, batch size: 64, grad_norm: 0.4486514925956726, grad_scale: , lr: 1.09e-05, 
2025-02-06 18:49:56,321 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 10228, num_updates: 10000, {'loss': 0.1351853609085083, 'DER': 0.31072921504876916, 'ACC': np.float64(0.9397410714285714), 'MI': 0.169763121226196, 'FA': 0.05985833720390153, 'CF': 0.08110775661867162}, batch size: 64, grad_norm: 0.4486514925956726, grad_scale: , lr: 1.09e-05, 
2025-02-06 18:49:56,322 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 18:49:56,322 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 18:51:07,975 (model:870) WARNING: All labels are zero
2025-02-06 18:51:08,814 (model:870) WARNING: All labels are zero
2025-02-06 18:51:08,815 (model:870) WARNING: All labels are zero
2025-02-06 18:53:19,787 (model:870) WARNING: All labels are zero
2025-02-06 18:53:37,036 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 10228,  validation: loss=0.08606, DER=0.1979, ACC=0.9616, MI=0.1143, FA=0.0542, CF=0.02944, over 0.00 frames. 
2025-02-06 18:53:37,037 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11780MB
2025-02-06 18:53:37,204 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 10228,  validation: loss=0.08675, DER=0.195, ACC=0.9612, MI=0.1158, FA=0.0504, CF=0.02877, over 0.00 frames. 
2025-02-06 18:53:37,204 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 19:03:10,949 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-10500.pt
2025-02-06 19:03:12,568 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-06 19:11:17,824 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 10728, num_updates: 10500, {'loss': 0.19236840307712555, 'DER': 0.45237824951753886, 'ACC': np.float64(0.9149642857142857), 'MI': 0.29747985015325235, 'FA': 0.06669315472811897, 'CF': 0.08820524463616755}, batch size: 64, grad_norm: 0.5161079168319702, grad_scale: , lr: 1.03e-05, 
2025-02-06 19:11:17,825 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 19:11:17,825 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 10728, num_updates: 10500, {'loss': 0.13223664462566376, 'DER': 0.2942946557534906, 'ACC': np.float64(0.9465213851837936), 'MI': 0.152262879152624, 'FA': 0.07655272026961964, 'CF': 0.065479056331247}, batch size: 64, grad_norm: 0.5161079168319702, grad_scale: , lr: 1.03e-05, 
2025-02-06 19:11:17,825 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 19:12:29,682 (model:870) WARNING: All labels are zero
2025-02-06 19:12:30,331 (model:870) WARNING: All labels are zero
2025-02-06 19:12:31,397 (model:870) WARNING: All labels are zero
2025-02-06 19:14:42,594 (model:870) WARNING: All labels are zero
2025-02-06 19:15:00,219 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 10728,  validation: loss=0.08633, DER=0.1972, ACC=0.961, MI=0.08952, FA=0.07293, CF=0.03477, over 0.00 frames. 
2025-02-06 19:15:00,220 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11780MB
2025-02-06 19:15:01,122 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 10728,  validation: loss=0.08739, DER=0.195, ACC=0.9604, MI=0.09195, FA=0.06901, CF=0.03406, over 0.00 frames. 
2025-02-06 19:15:01,123 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 19:32:42,325 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 11228, num_updates: 11000, {'loss': 0.12278500199317932, 'DER': 0.2519757187034704, 'ACC': np.float64(0.9525535714285714), 'MI': 0.13870117970450122, 'FA': 0.06093231015920284, 'CF': 0.05234222883976635}, batch size: 64, grad_norm: 0.336382120847702, grad_scale: , lr: 9.75e-06, 
2025-02-06 19:32:42,325 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 11228, num_updates: 11000, {'loss': 0.12179157137870789, 'DER': 0.2549355304692098, 'ACC': np.float64(0.9497857142857143), 'MI': 0.16366165534214328, 'FA': 0.04531592745171473, 'CF': 0.045957947675351773}, batch size: 64, grad_norm: 0.336382120847702, grad_scale: , lr: 9.75e-06, 
2025-02-06 19:32:42,326 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 19:32:42,326 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 19:33:52,300 (model:870) WARNING: All labels are zero
2025-02-06 19:33:53,121 (model:870) WARNING: All labels are zero
2025-02-06 19:33:53,190 (model:870) WARNING: All labels are zero
2025-02-06 19:36:00,771 (model:870) WARNING: All labels are zero
2025-02-06 19:36:17,581 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 11228,  validation: loss=0.09685, DER=0.2261, ACC=0.9564, MI=0.1611, FA=0.03524, CF=0.02974, over 0.00 frames. 
2025-02-06 19:36:17,582 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 19:36:17,724 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 11228,  validation: loss=0.09637, DER=0.23, ACC=0.9565, MI=0.16, FA=0.03814, CF=0.03183, over 0.00 frames. 
2025-02-06 19:36:17,724 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11780MB
2025-02-06 19:53:49,538 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 11728, num_updates: 11500, {'loss': 0.1325741857290268, 'DER': 0.32042480783899546, 'ACC': np.float64(0.9420298997035261), 'MI': 0.19139822801150033, 'FA': 0.0719943671888752, 'CF': 0.05703221263861996}, batch size: 64, grad_norm: 0.4955839514732361, grad_scale: , lr: 9.19e-06, 
2025-02-06 19:53:49,539 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 19:53:49,539 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 11728, num_updates: 11500, {'loss': 0.14084143936634064, 'DER': 0.35658596635207224, 'ACC': np.float64(0.9344821428571429), 'MI': 0.18183949821208747, 'FA': 0.10117826367313441, 'CF': 0.07356820446685035}, batch size: 64, grad_norm: 0.4955839514732361, grad_scale: , lr: 9.19e-06, 
2025-02-06 19:53:49,539 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 19:55:00,907 (model:870) WARNING: All labels are zero
2025-02-06 19:55:01,690 (model:870) WARNING: All labels are zero
2025-02-06 19:55:01,732 (model:870) WARNING: All labels are zero
2025-02-06 19:57:10,383 (model:870) WARNING: All labels are zero
2025-02-06 19:57:27,186 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 11728,  validation: loss=0.08373, DER=0.1892, ACC=0.9622, MI=0.09518, FA=0.06185, CF=0.03218, over 0.00 frames. 
2025-02-06 19:57:27,187 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11780MB
2025-02-06 19:57:28,518 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 11728,  validation: loss=0.08419, DER=0.1885, ACC=0.9617, MI=0.09762, FA=0.05902, CF=0.03185, over 0.00 frames. 
2025-02-06 19:57:28,519 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 20:07:00,622 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-12000.pt
2025-02-06 20:07:02,575 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-06 20:15:07,761 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 12228, num_updates: 12000, {'loss': 0.10807351022958755, 'DER': 0.23859727000332925, 'ACC': np.float64(0.9557857142857143), 'MI': 0.15780712462545776, 'FA': 0.04461214071690157, 'CF': 0.036178004660969924}, batch size: 64, grad_norm: 0.36332494020462036, grad_scale: , lr: 8.63e-06, 
2025-02-06 20:15:07,762 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 20:15:07,762 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 12228, num_updates: 12000, {'loss': 0.11838079988956451, 'DER': 0.24988148850438494, 'ACC': np.float64(0.9544107142857143), 'MI': 0.13214031761080824, 'FA': 0.06506281109267599, 'CF': 0.05267835980090069}, batch size: 64, grad_norm: 0.36332494020462036, grad_scale: , lr: 8.63e-06, 
2025-02-06 20:15:07,762 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 20:16:18,439 (model:870) WARNING: All labels are zero
2025-02-06 20:16:19,240 (model:870) WARNING: All labels are zero
2025-02-06 20:16:19,265 (model:870) WARNING: All labels are zero
2025-02-06 20:18:29,151 (model:870) WARNING: All labels are zero
2025-02-06 20:18:46,731 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 12228,  validation: loss=0.0826, DER=0.1876, ACC=0.9632, MI=0.1115, FA=0.05062, CF=0.02543, over 0.00 frames. 
2025-02-06 20:18:46,732 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 20:18:46,866 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 12228,  validation: loss=0.08401, DER=0.1895, ACC=0.9624, MI=0.1134, FA=0.04987, CF=0.02616, over 0.00 frames. 
2025-02-06 20:18:46,866 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 20:22:49,077 (train_accelerate_ddp:713) INFO: end of epoch 3, batch_idx: 4113 batch_idx_train: 12341, {'loss': 0.154147669672966, 'DER': 0.34415619438002265, 'ACC': np.float64(0.9311607142857143), 'MI': 0.2255541772288442, 'FA': 0.046923035434981934, 'CF': 0.07167898171619654}, batch size: 64, grad_norm: 0.3998970091342926, grad_scale: , lr: 8.51e-06, 
2025-02-06 20:22:49,077 (train_accelerate_ddp:713) INFO: end of epoch 3, batch_idx: 4113 batch_idx_train: 12341, {'loss': 0.12291041761636734, 'DER': 0.2605538669368457, 'ACC': np.float64(0.9521071428571429), 'MI': 0.17297084318360914, 'FA': 0.04621186536080153, 'CF': 0.041371158392434985}, batch size: 64, grad_norm: 0.3998970091342926, grad_scale: , lr: 8.51e-06, 
2025-02-06 20:22:49,079 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-3.pt
2025-02-06 20:22:50,289 (train_accelerate_ddp:561) INFO:  end of epoch 3, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-3.pt 
2025-02-06 20:22:54,882 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 12342, num_updates: 12000, {'loss': 0.1702667623758316, 'DER': 0.3959256972894102, 'ACC': np.float64(0.9265803571428571), 'MI': 0.25579437678882094, 'FA': 0.07458330995005331, 'CF': 0.06554801055053594}, batch size: 64, grad_norm: 0.5586980581283569, grad_scale: , lr: 8.51e-06, 
2025-02-06 20:22:54,882 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 12342, num_updates: 12000, {'loss': 0.13455119729042053, 'DER': 0.34531623826759095, 'ACC': np.float64(0.9396607142857143), 'MI': 0.18311760014723022, 'FA': 0.09293908349181032, 'CF': 0.0692595546285504}, batch size: 64, grad_norm: 0.5586980581283569, grad_scale: , lr: 8.51e-06, 
2025-02-06 20:40:48,252 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 12842, num_updates: 12500, {'loss': 0.17363782227039337, 'DER': 0.3872832369942196, 'ACC': np.float64(0.9283928571428571), 'MI': 0.2538097740409879, 'FA': 0.052490220120277924, 'CF': 0.08098324283295381}, batch size: 64, grad_norm: 0.4866720139980316, grad_scale: , lr: 7.95e-06, 
2025-02-06 20:40:48,252 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 20:40:48,252 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 12842, num_updates: 12500, {'loss': 0.16008667647838593, 'DER': 0.382963532513181, 'ACC': np.float64(0.9261003619464677), 'MI': 0.234457381370826, 'FA': 0.0773286467486819, 'CF': 0.07117750439367311}, batch size: 64, grad_norm: 0.4866720139980316, grad_scale: , lr: 7.95e-06, 
2025-02-06 20:40:48,253 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 20:42:00,078 (model:870) WARNING: All labels are zero
2025-02-06 20:42:00,905 (model:870) WARNING: All labels are zero
2025-02-06 20:42:00,906 (model:870) WARNING: All labels are zero
2025-02-06 20:44:11,311 (model:870) WARNING: All labels are zero
2025-02-06 20:44:28,585 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 12842,  validation: loss=0.08464, DER=0.1949, ACC=0.9612, MI=0.109, FA=0.05245, CF=0.03346, over 0.00 frames. 
2025-02-06 20:44:28,585 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 20:44:28,645 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 12842,  validation: loss=0.08593, DER=0.1917, ACC=0.9607, MI=0.1099, FA=0.04878, CF=0.033, over 0.00 frames. 
2025-02-06 20:44:28,645 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 21:02:08,809 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 13342, num_updates: 13000, {'loss': 0.1695260852575302, 'DER': 0.40112701972284515, 'ACC': np.float64(0.9245892857142857), 'MI': 0.2190788338795929, 'FA': 0.09752170662986602, 'CF': 0.08452647921338624}, batch size: 64, grad_norm: 0.5101967453956604, grad_scale: , lr: 7.40e-06, 
2025-02-06 21:02:08,810 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 21:02:08,810 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 13342, num_updates: 13000, {'loss': 0.13200873136520386, 'DER': 0.30013451079010467, 'ACC': np.float64(0.9429651633810424), 'MI': 0.14427744312532897, 'FA': 0.08544359319258436, 'CF': 0.07041347447219136}, batch size: 64, grad_norm: 0.5101967453956604, grad_scale: , lr: 7.40e-06, 
2025-02-06 21:02:08,810 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 21:03:18,976 (model:870) WARNING: All labels are zero
2025-02-06 21:03:19,787 (model:870) WARNING: All labels are zero
2025-02-06 21:03:19,795 (model:870) WARNING: All labels are zero
2025-02-06 21:05:28,394 (model:870) WARNING: All labels are zero
2025-02-06 21:05:45,502 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 13342,  validation: loss=0.08494, DER=0.194, ACC=0.9616, MI=0.09749, FA=0.06317, CF=0.0333, over 0.00 frames. 
2025-02-06 21:05:45,503 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 21:05:45,597 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 13342,  validation: loss=0.08555, DER=0.1935, ACC=0.9612, MI=0.1022, FA=0.06005, CF=0.0313, over 0.00 frames. 
2025-02-06 21:05:45,597 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-06 21:11:21,369 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-13500.pt
2025-02-06 21:11:22,945 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-06 21:11:23,046 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-06 21:23:21,070 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 13842, num_updates: 13500, {'loss': 0.16385090351104736, 'DER': 0.37335887755677016, 'ACC': np.float64(0.9279910714285714), 'MI': 0.23705414999718263, 'FA': 0.05522060066490111, 'CF': 0.08108412689468643}, batch size: 64, grad_norm: 0.4102665185928345, grad_scale: , lr: 6.84e-06, 
2025-02-06 21:23:21,071 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 21:23:21,071 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 13842, num_updates: 13500, {'loss': 0.1250392198562622, 'DER': 0.30194374019075215, 'ACC': np.float64(0.946929007764073), 'MI': 0.15067004708438972, 'FA': 0.09712664493540987, 'CF': 0.054147048170952554}, batch size: 64, grad_norm: 0.4102665185928345, grad_scale: , lr: 6.84e-06, 
2025-02-06 21:23:21,071 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 21:24:31,173 (model:870) WARNING: All labels are zero
2025-02-06 21:24:31,991 (model:870) WARNING: All labels are zero
2025-02-06 21:24:32,011 (model:870) WARNING: All labels are zero
2025-02-06 21:26:41,326 (model:870) WARNING: All labels are zero
2025-02-06 21:26:58,607 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 13842,  validation: loss=0.07717, DER=0.1752, ACC=0.9642, MI=0.09161, FA=0.0554, CF=0.02823, over 0.00 frames. 
2025-02-06 21:26:58,608 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-06 21:26:58,609 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 13842,  validation: loss=0.0772, DER=0.179, ACC=0.9644, MI=0.09061, FA=0.05928, CF=0.02912, over 0.00 frames. 
2025-02-06 21:26:58,609 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 21:44:20,002 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 14342, num_updates: 14000, {'loss': 0.13355298340320587, 'DER': 0.2824566391811203, 'ACC': np.float64(0.9425535714285714), 'MI': 0.1295422234859255, 'FA': 0.0694910435029855, 'CF': 0.08342337219220927}, batch size: 64, grad_norm: 0.4397163391113281, grad_scale: , lr: 6.29e-06, 
2025-02-06 21:44:20,002 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 14342, num_updates: 14000, {'loss': 0.12151026725769043, 'DER': 0.26423085611023267, 'ACC': np.float64(0.9493660714285714), 'MI': 0.14202620284617123, 'FA': 0.0661847752428281, 'CF': 0.056019878021233344}, batch size: 64, grad_norm: 0.4397163391113281, grad_scale: , lr: 6.29e-06, 
2025-02-06 21:44:20,002 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 21:44:20,002 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 21:45:29,517 (model:870) WARNING: All labels are zero
2025-02-06 21:45:30,335 (model:870) WARNING: All labels are zero
2025-02-06 21:45:30,335 (model:870) WARNING: All labels are zero
2025-02-06 21:47:37,792 (model:870) WARNING: All labels are zero
2025-02-06 21:47:54,794 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 14342,  validation: loss=0.1572, DER=0.3935, ACC=0.931, MI=0.3287, FA=0.02599, CF=0.03887, over 0.00 frames. 
2025-02-06 21:47:54,795 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 21:47:54,853 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 14342,  validation: loss=0.1627, DER=0.3958, ACC=0.9296, MI=0.3373, FA=0.023, CF=0.03546, over 0.00 frames. 
2025-02-06 21:47:54,853 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-06 22:05:36,863 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 14842, num_updates: 14500, {'loss': 0.1352657526731491, 'DER': 0.3042156807564586, 'ACC': np.float64(0.9421696428571429), 'MI': 0.18331738616536275, 'FA': 0.060561715540046156, 'CF': 0.0603365790510497}, batch size: 64, grad_norm: 0.35857093334198, grad_scale: , lr: 5.73e-06, 
2025-02-06 22:05:36,864 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 14842, num_updates: 14500, {'loss': 0.11926677823066711, 'DER': 0.27179278703757476, 'ACC': np.float64(0.9509314808967477), 'MI': 0.16237876764039724, 'FA': 0.06533480457634008, 'CF': 0.044079214820837445}, batch size: 64, grad_norm: 0.35857093334198, grad_scale: , lr: 5.73e-06, 
2025-02-06 22:05:36,864 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 22:05:36,864 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 22:06:47,341 (model:870) WARNING: All labels are zero
2025-02-06 22:06:48,152 (model:870) WARNING: All labels are zero
2025-02-06 22:06:48,159 (model:870) WARNING: All labels are zero
2025-02-06 22:08:57,096 (model:870) WARNING: All labels are zero
2025-02-06 22:09:14,102 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 14842,  validation: loss=0.09753, DER=0.2334, ACC=0.9558, MI=0.1587, FA=0.04341, CF=0.03136, over 0.00 frames. 
2025-02-06 22:09:14,102 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 22:09:14,232 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 14842,  validation: loss=0.09928, DER=0.2371, ACC=0.9542, MI=0.1654, FA=0.03985, CF=0.03185, over 0.00 frames. 
2025-02-06 22:09:14,232 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-06 22:14:47,967 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-15000.pt
2025-02-06 22:14:49,609 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-06 22:26:49,785 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 15342, num_updates: 15000, {'loss': 0.12461727112531662, 'DER': 0.27425989224262787, 'ACC': np.float64(0.9495587735156712), 'MI': 0.1568275302705521, 'FA': 0.06517582990556746, 'CF': 0.052256532066508314}, batch size: 64, grad_norm: 0.3909863829612732, grad_scale: , lr: 5.17e-06, 
2025-02-06 22:26:49,786 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 15342, num_updates: 15000, {'loss': 0.1121077612042427, 'DER': 0.25600941334678096, 'ACC': np.float64(0.9534017857142857), 'MI': 0.1649016641452345, 'FA': 0.05468706225135877, 'CF': 0.03642068695018771}, batch size: 64, grad_norm: 0.3909863829612732, grad_scale: , lr: 5.17e-06, 
2025-02-06 22:26:49,786 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 22:26:49,786 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 22:28:00,052 (model:870) WARNING: All labels are zero
2025-02-06 22:28:00,850 (model:870) WARNING: All labels are zero
2025-02-06 22:28:00,867 (model:870) WARNING: All labels are zero
2025-02-06 22:30:09,968 (model:870) WARNING: All labels are zero
2025-02-06 22:30:27,155 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 15342,  validation: loss=0.07726, DER=0.1776, ACC=0.9646, MI=0.09533, FA=0.05447, CF=0.02783, over 0.00 frames. 
2025-02-06 22:30:27,156 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 22:30:27,193 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 15342,  validation: loss=0.0783, DER=0.1764, ACC=0.9641, MI=0.0972, FA=0.0523, CF=0.02691, over 0.00 frames. 
2025-02-06 22:30:27,193 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-06 22:47:57,246 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 15842, num_updates: 15500, {'loss': 0.12067229300737381, 'DER': 0.28309256618513234, 'ACC': np.float64(0.9524285714285714), 'MI': 0.17130634261268524, 'FA': 0.06454212908425817, 'CF': 0.047244094488188976}, batch size: 64, grad_norm: 0.37784138321876526, grad_scale: , lr: 4.62e-06, 
2025-02-06 22:47:57,246 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 15842, num_updates: 15500, {'loss': 0.1313929408788681, 'DER': 0.2935491383325571, 'ACC': np.float64(0.9437946428571429), 'MI': 0.13483931066604565, 'FA': 0.08575919888216116, 'CF': 0.07295062878435025}, batch size: 64, grad_norm: 0.37784138321876526, grad_scale: , lr: 4.62e-06, 
2025-02-06 22:47:57,247 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 22:47:57,247 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 22:49:07,680 (model:870) WARNING: All labels are zero
2025-02-06 22:49:08,488 (model:870) WARNING: All labels are zero
2025-02-06 22:49:08,505 (model:870) WARNING: All labels are zero
2025-02-06 22:51:19,409 (model:870) WARNING: All labels are zero
2025-02-06 22:51:36,312 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 15842,  validation: loss=0.08582, DER=0.1997, ACC=0.9612, MI=0.1253, FA=0.04564, CF=0.02869, over 0.00 frames. 
2025-02-06 22:51:36,312 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 22:51:36,578 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 15842,  validation: loss=0.08696, DER=0.1971, ACC=0.9605, MI=0.1276, FA=0.04085, CF=0.02866, over 0.00 frames. 
2025-02-06 22:51:36,578 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-06 23:09:29,491 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 16342, num_updates: 16000, {'loss': 0.09873057901859283, 'DER': 0.23441232680363114, 'ACC': np.float64(0.9584017857142857), 'MI': 0.11801242236024845, 'FA': 0.07256330625895843, 'CF': 0.04383659818442427}, batch size: 64, grad_norm: 0.3765377998352051, grad_scale: , lr: 4.06e-06, 
2025-02-06 23:09:29,491 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 16342, num_updates: 16000, {'loss': 0.13437476754188538, 'DER': 0.2981285598047193, 'ACC': np.float64(0.9418214285714286), 'MI': 0.16132356929753186, 'FA': 0.08147545429888799, 'CF': 0.05532953620829943}, batch size: 64, grad_norm: 0.3765377998352051, grad_scale: , lr: 4.06e-06, 
2025-02-06 23:09:29,492 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 23:09:29,492 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 23:10:39,637 (model:870) WARNING: All labels are zero
2025-02-06 23:10:40,399 (model:870) WARNING: All labels are zero
2025-02-06 23:10:40,459 (model:870) WARNING: All labels are zero
2025-02-06 23:12:47,331 (model:870) WARNING: All labels are zero
2025-02-06 23:13:04,718 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 16342,  validation: loss=0.0899, DER=0.2035, ACC=0.9598, MI=0.1043, FA=0.06406, CF=0.03515, over 0.00 frames. 
2025-02-06 23:13:04,719 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 23:13:05,479 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 16342,  validation: loss=0.09033, DER=0.1994, ACC=0.9596, MI=0.1062, FA=0.0587, CF=0.03445, over 0.00 frames. 
2025-02-06 23:13:05,479 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-06 23:17:02,661 (train_accelerate_ddp:713) INFO: end of epoch 4, batch_idx: 4113 batch_idx_train: 16455, {'loss': 0.12106157839298248, 'DER': 0.2766143106457243, 'ACC': np.float64(0.9512321428571429), 'MI': 0.16515415939499709, 'FA': 0.07033158813263525, 'CF': 0.04112856311809191}, batch size: 64, grad_norm: 0.31468960642814636, grad_scale: , lr: 3.94e-06, 
2025-02-06 23:17:02,661 (train_accelerate_ddp:713) INFO: end of epoch 4, batch_idx: 4113 batch_idx_train: 16455, {'loss': 0.1172802671790123, 'DER': 0.29665503549512695, 'ACC': np.float64(0.9471339285714285), 'MI': 0.13716760919263626, 'FA': 0.09992780652147756, 'CF': 0.059559619781013116}, batch size: 64, grad_norm: 0.31468960642814636, grad_scale: , lr: 3.94e-06, 
2025-02-06 23:17:02,663 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-4.pt
2025-02-06 23:17:03,925 (train_accelerate_ddp:561) INFO:  end of epoch 4, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-4.pt 
2025-02-06 23:17:08,161 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 16456, num_updates: 16000, {'loss': 0.17313867807388306, 'DER': 0.402479815455594, 'ACC': np.float64(0.9250892857142856), 'MI': 0.24653979238754326, 'FA': 0.07456747404844291, 'CF': 0.08137254901960785}, batch size: 64, grad_norm: 0.4946330785751343, grad_scale: , lr: 3.94e-06, 
2025-02-06 23:17:08,163 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 16456, num_updates: 16000, {'loss': 0.11102931946516037, 'DER': 0.2707482993197279, 'ACC': np.float64(0.9488482142857143), 'MI': 0.13422064477965098, 'FA': 0.0683821354628808, 'CF': 0.0681455190771961}, batch size: 64, grad_norm: 0.4946330785751343, grad_scale: , lr: 3.94e-06, 
2025-02-06 23:18:39,005 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-16500.pt
2025-02-06 23:18:40,630 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-06 23:18:40,634 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-06 23:34:41,163 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 16956, num_updates: 16500, {'loss': 0.12648716568946838, 'DER': 0.29587721263723954, 'ACC': np.float64(0.9418729139114553), 'MI': 0.17471431772350438, 'FA': 0.055119874523862876, 'CF': 0.06604302038987228}, batch size: 64, grad_norm: 0.36738917231559753, grad_scale: , lr: 3.38e-06, 
2025-02-06 23:34:41,164 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 23:34:41,164 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 16956, num_updates: 16500, {'loss': 0.12316498905420303, 'DER': 0.30915959620982225, 'ACC': np.float64(0.946875), 'MI': 0.16417910447761194, 'FA': 0.08565058524803369, 'CF': 0.059329906484176624}, batch size: 64, grad_norm: 0.36738917231559753, grad_scale: , lr: 3.38e-06, 
2025-02-06 23:34:41,164 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 23:35:51,451 (model:870) WARNING: All labels are zero
2025-02-06 23:35:52,239 (model:870) WARNING: All labels are zero
2025-02-06 23:35:52,273 (model:870) WARNING: All labels are zero
2025-02-06 23:37:59,612 (model:870) WARNING: All labels are zero
2025-02-06 23:38:16,324 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 16956,  validation: loss=0.07593, DER=0.1745, ACC=0.9651, MI=0.08391, FA=0.06362, CF=0.02696, over 0.00 frames. 
2025-02-06 23:38:16,325 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 23:38:16,909 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 16956,  validation: loss=0.07616, DER=0.1715, ACC=0.9649, MI=0.08555, FA=0.05922, CF=0.0267, over 0.00 frames. 
2025-02-06 23:38:16,909 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-06 23:56:10,031 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 17456, num_updates: 17000, {'loss': 0.12301618605852127, 'DER': 0.2818388658771367, 'ACC': np.float64(0.9484732142857143), 'MI': 0.1469575870719328, 'FA': 0.08004200455049297, 'CF': 0.054839274254710926}, batch size: 64, grad_norm: 0.4644017219543457, grad_scale: , lr: 2.83e-06, 
2025-02-06 23:56:10,032 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 23:56:10,032 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 17456, num_updates: 17000, {'loss': 0.14825765788555145, 'DER': 0.3291267605633803, 'ACC': np.float64(0.9354553571428571), 'MI': 0.18095774647887325, 'FA': 0.07002816901408451, 'CF': 0.07814084507042253}, batch size: 64, grad_norm: 0.4644017219543457, grad_scale: , lr: 2.83e-06, 
2025-02-06 23:56:10,032 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-06 23:57:20,762 (model:870) WARNING: All labels are zero
2025-02-06 23:57:21,567 (model:870) WARNING: All labels are zero
2025-02-06 23:57:21,594 (model:870) WARNING: All labels are zero
2025-02-06 23:59:31,025 (model:870) WARNING: All labels are zero
2025-02-06 23:59:48,128 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 17456,  validation: loss=0.07882, DER=0.1784, ACC=0.9644, MI=0.1052, FA=0.04743, CF=0.02573, over 0.00 frames. 
2025-02-06 23:59:48,128 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-06 23:59:48,258 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 17456,  validation: loss=0.07973, DER=0.1792, ACC=0.9639, MI=0.1077, FA=0.04579, CF=0.02569, over 0.00 frames. 
2025-02-06 23:59:48,259 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 00:17:27,628 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 17956, num_updates: 17500, {'loss': 0.1737419068813324, 'DER': 0.3784263140922283, 'ACC': np.float64(0.9221696428571429), 'MI': 0.22686230248307, 'FA': 0.061485542298183385, 'CF': 0.09007846931097495}, batch size: 64, grad_norm: 0.6340247392654419, grad_scale: , lr: 2.27e-06, 
2025-02-07 00:17:27,629 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 00:17:27,629 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 17956, num_updates: 17500, {'loss': 0.1797977238893509, 'DER': 0.39273374515757514, 'ACC': np.float64(0.9215892857142857), 'MI': 0.26363731546434926, 'FA': 0.06208773950371689, 'CF': 0.06700869018950895}, batch size: 64, grad_norm: 0.6340247392654419, grad_scale: , lr: 2.27e-06, 
2025-02-07 00:17:27,630 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 00:18:37,681 (model:870) WARNING: All labels are zero
2025-02-07 00:18:38,404 (model:870) WARNING: All labels are zero
2025-02-07 00:18:38,489 (model:870) WARNING: All labels are zero
2025-02-07 00:20:44,727 (model:870) WARNING: All labels are zero
2025-02-07 00:21:01,795 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 17956,  validation: loss=0.08875, DER=0.2028, ACC=0.9603, MI=0.114, FA=0.05603, CF=0.03277, over 0.00 frames. 
2025-02-07 00:21:01,796 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 00:21:02,452 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 17956,  validation: loss=0.08893, DER=0.1996, ACC=0.96, MI=0.1171, FA=0.05095, CF=0.03154, over 0.00 frames. 
2025-02-07 00:21:02,453 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 00:22:31,767 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-18000.pt
2025-02-07 00:22:33,425 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 00:38:43,501 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 18456, num_updates: 18000, {'loss': 0.15690505504608154, 'DER': 0.37995469988674974, 'ACC': np.float64(0.9289420801143214), 'MI': 0.2268969422423556, 'FA': 0.08250283125707815, 'CF': 0.07055492638731597}, batch size: 64, grad_norm: 0.5269218683242798, grad_scale: , lr: 1.71e-06, 
2025-02-07 00:38:43,501 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 18456, num_updates: 18000, {'loss': 0.12435499578714371, 'DER': 0.2793052726861281, 'ACC': np.float64(0.9445357142857144), 'MI': 0.1570491061326092, 'FA': 0.050124462548087806, 'CF': 0.07213170400543109}, batch size: 64, grad_norm: 0.5269218683242798, grad_scale: , lr: 1.71e-06, 
2025-02-07 00:38:43,502 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 00:38:43,502 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 00:39:52,190 (model:870) WARNING: All labels are zero
2025-02-07 00:39:54,612 (model:870) WARNING: All labels are zero
2025-02-07 00:39:55,505 (model:870) WARNING: All labels are zero
2025-02-07 00:41:56,293 (model:870) WARNING: All labels are zero
2025-02-07 00:42:12,892 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 18456,  validation: loss=0.0826, DER=0.1907, ACC=0.9624, MI=0.1065, FA=0.05462, CF=0.02965, over 0.00 frames. 
2025-02-07 00:42:12,893 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 00:42:23,426 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 18456,  validation: loss=0.08344, DER=0.1886, ACC=0.9618, MI=0.1095, FA=0.04983, CF=0.02934, over 0.00 frames. 
2025-02-07 00:42:23,426 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 01:00:05,676 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 18956, num_updates: 18500, {'loss': 0.14199726283550262, 'DER': 0.309153228072147, 'ACC': np.float64(0.9398660714285715), 'MI': 0.1860987806933753, 'FA': 0.05377310782716188, 'CF': 0.06928133955160982}, batch size: 64, grad_norm: 0.3616548776626587, grad_scale: , lr: 1.16e-06, 
2025-02-07 01:00:05,677 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 01:00:05,677 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 18956, num_updates: 18500, {'loss': 0.11472104489803314, 'DER': 0.28727593300029386, 'ACC': np.float64(0.948590828258878), 'MI': 0.17525712606523655, 'FA': 0.06288568909785483, 'CF': 0.04913311783720247}, batch size: 64, grad_norm: 0.3616548776626587, grad_scale: , lr: 1.16e-06, 
2025-02-07 01:00:05,677 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 01:01:16,439 (model:870) WARNING: All labels are zero
2025-02-07 01:01:17,254 (model:870) WARNING: All labels are zero
2025-02-07 01:01:17,270 (model:870) WARNING: All labels are zero
2025-02-07 01:03:26,958 (model:870) WARNING: All labels are zero
2025-02-07 01:03:44,170 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 18956,  validation: loss=0.1208, DER=0.3013, ACC=0.9447, MI=0.2212, FA=0.03936, CF=0.04079, over 0.00 frames. 
2025-02-07 01:03:44,171 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 01:03:44,247 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 18956,  validation: loss=0.1245, DER=0.3032, ACC=0.9432, MI=0.2319, FA=0.03412, CF=0.03717, over 0.00 frames. 
2025-02-07 01:03:44,248 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 01:22:00,041 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 19456, num_updates: 19000, {'loss': 0.11145952343940735, 'DER': 0.26197266785502077, 'ACC': np.float64(0.9500835684632388), 'MI': 0.1257278669043375, 'FA': 0.06815210932857992, 'CF': 0.0680926916221034}, batch size: 64, grad_norm: 0.35642051696777344, grad_scale: , lr: 6.03e-07, 
2025-02-07 01:22:00,041 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 01:22:00,041 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 19456, num_updates: 19000, {'loss': 0.11762546747922897, 'DER': 0.2771148708815672, 'ACC': np.float64(0.950011262783259), 'MI': 0.14455327990501632, 'FA': 0.08032056990204808, 'CF': 0.05224102107450282}, batch size: 64, grad_norm: 0.35642051696777344, grad_scale: , lr: 6.03e-07, 
2025-02-07 01:22:00,041 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 01:23:08,401 (model:870) WARNING: All labels are zero
2025-02-07 01:23:09,018 (model:870) WARNING: All labels are zero
2025-02-07 01:23:09,214 (model:870) WARNING: All labels are zero
2025-02-07 01:25:16,447 (model:870) WARNING: All labels are zero
2025-02-07 01:25:32,933 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 19456,  validation: loss=0.08952, DER=0.2077, ACC=0.9596, MI=0.124, FA=0.05142, CF=0.03226, over 0.00 frames. 
2025-02-07 01:25:32,933 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 01:25:33,363 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 19456,  validation: loss=0.0906, DER=0.2073, ACC=0.9588, MI=0.1292, FA=0.04671, CF=0.0314, over 0.00 frames. 
2025-02-07 01:25:33,363 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 01:27:04,800 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-19500.pt
2025-02-07 01:27:06,439 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 01:43:18,980 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 19956, num_updates: 19500, {'loss': 0.1291673481464386, 'DER': 0.3061980175458585, 'ACC': np.float64(0.9448303571428571), 'MI': 0.17437621055030192, 'FA': 0.08602028027799932, 'CF': 0.04580152671755725}, batch size: 64, grad_norm: 0.41553738713264465, grad_scale: , lr: 4.78e-08, 
2025-02-07 01:43:18,980 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 19956, num_updates: 19500, {'loss': 0.12076306343078613, 'DER': 0.28339822186065433, 'ACC': np.float64(0.9497296572679744), 'MI': 0.15904468592015805, 'FA': 0.08088790749026672, 'CF': 0.04346562845022953}, batch size: 64, grad_norm: 0.41553738713264465, grad_scale: , lr: 4.78e-08, 
2025-02-07 01:43:18,981 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 01:43:18,981 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 01:44:27,068 (model:870) WARNING: All labels are zero
2025-02-07 01:44:32,107 (model:870) WARNING: All labels are zero
2025-02-07 01:44:32,977 (model:870) WARNING: All labels are zero
2025-02-07 01:46:30,557 (model:870) WARNING: All labels are zero
2025-02-07 01:46:47,114 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 19956,  validation: loss=0.08937, DER=0.2062, ACC=0.9597, MI=0.1232, FA=0.05104, CF=0.03197, over 0.00 frames. 
2025-02-07 01:46:47,114 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 01:47:07,025 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 19956,  validation: loss=0.09038, DER=0.2054, ACC=0.959, MI=0.1288, FA=0.0457, CF=0.03084, over 0.00 frames. 
2025-02-07 01:47:07,026 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 02:04:48,922 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 20456, num_updates: 20000, {'loss': 0.1449182629585266, 'DER': 0.3196670603453124, 'ACC': np.float64(0.9341158242728329), 'MI': 0.1694505370901524, 'FA': 0.05854563860300321, 'CF': 0.0916708846521568}, batch size: 64, grad_norm: 0.4465986490249634, grad_scale: , lr: 0.00e+00, 
2025-02-07 02:04:48,922 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 20456, num_updates: 20000, {'loss': 0.1438903659582138, 'DER': 0.3172037016389787, 'ACC': np.float64(0.9401517857142857), 'MI': 0.19868435723046046, 'FA': 0.062047050953283535, 'CF': 0.0564722934552347}, batch size: 64, grad_norm: 0.4465986490249634, grad_scale: , lr: 0.00e+00, 
2025-02-07 02:04:48,922 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 02:04:48,922 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 02:05:58,614 (model:870) WARNING: All labels are zero
2025-02-07 02:05:59,427 (model:870) WARNING: All labels are zero
2025-02-07 02:05:59,464 (model:870) WARNING: All labels are zero
2025-02-07 02:08:07,285 (model:870) WARNING: All labels are zero
2025-02-07 02:08:24,212 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 20456,  validation: loss=0.07903, DER=0.1762, ACC=0.9641, MI=0.1015, FA=0.04833, CF=0.02642, over 0.00 frames. 
2025-02-07 02:08:24,212 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 02:08:24,306 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 20456,  validation: loss=0.07839, DER=0.1787, ACC=0.9645, MI=0.09951, FA=0.05207, CF=0.02713, over 0.00 frames. 
2025-02-07 02:08:24,306 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 02:12:24,483 (train_accelerate_ddp:713) INFO: end of epoch 5, batch_idx: 4113 batch_idx_train: 20569, {'loss': 0.15746058523654938, 'DER': 0.34011996770100356, 'ACC': np.float64(0.9351964285714286), 'MI': 0.17914407659476295, 'FA': 0.08247779443995848, 'CF': 0.07849809666628216}, batch size: 64, grad_norm: 0.4196844696998596, grad_scale: , lr: 0.00e+00, 
2025-02-07 02:12:24,483 (train_accelerate_ddp:713) INFO: end of epoch 5, batch_idx: 4113 batch_idx_train: 20569, {'loss': 0.11798897385597229, 'DER': 0.2714666976096542, 'ACC': np.float64(0.9484107142857143), 'MI': 0.14527732652587608, 'FA': 0.062427477372940354, 'CF': 0.06376189371083778}, batch size: 64, grad_norm: 0.4196844696998596, grad_scale: , lr: 0.00e+00, 
2025-02-07 02:12:24,484 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-5.pt
2025-02-07 02:12:25,792 (train_accelerate_ddp:561) INFO:  end of epoch 5, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-5.pt 
2025-02-07 02:12:30,030 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 20570, num_updates: 20000, {'loss': 0.13384459912776947, 'DER': 0.30612689084775274, 'ACC': np.float64(0.9411875), 'MI': 0.19931439764936337, 'FA': 0.05452171074110349, 'CF': 0.052290782457285884}, batch size: 64, grad_norm: 0.45077040791511536, grad_scale: , lr: 0.00e+00, 
2025-02-07 02:12:30,030 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 20570, num_updates: 20000, {'loss': 0.09960976988077164, 'DER': 0.23773494265297543, 'ACC': np.float64(0.9585714285714285), 'MI': 0.1372125142616946, 'FA': 0.05962889569446946, 'CF': 0.04089353269681138}, batch size: 64, grad_norm: 0.45077040791511536, grad_scale: , lr: 0.00e+00, 
2025-02-07 02:28:00,562 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-21000.pt
2025-02-07 02:28:02,360 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 02:28:02,364 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-07 02:30:32,517 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 21070, num_updates: 20500, {'loss': 0.1374368667602539, 'DER': 0.29758786291202793, 'ACC': np.float64(0.9434017857142857), 'MI': 0.2085789129011133, 'FA': 0.040657061776904604, 'CF': 0.04835188823401004}, batch size: 64, grad_norm: 0.41037771105766296, grad_scale: , lr: 0.00e+00, 
2025-02-07 02:30:32,518 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 02:30:32,518 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 21070, num_updates: 20500, {'loss': 0.11807034909725189, 'DER': 0.2735729386892178, 'ACC': np.float64(0.9492232142857143), 'MI': 0.12727272727272726, 'FA': 0.07635155542132287, 'CF': 0.06994865599516763}, batch size: 64, grad_norm: 0.41037771105766296, grad_scale: , lr: 0.00e+00, 
2025-02-07 02:30:32,519 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 02:31:42,588 (model:870) WARNING: All labels are zero
2025-02-07 02:31:43,378 (model:870) WARNING: All labels are zero
2025-02-07 02:31:43,401 (model:870) WARNING: All labels are zero
2025-02-07 02:33:52,643 (model:870) WARNING: All labels are zero
2025-02-07 02:34:10,039 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 6, batch_idx_train: 21070,  validation: loss=0.08718, DER=0.2004, ACC=0.9605, MI=0.1159, FA=0.05221, CF=0.03223, over 0.00 frames. 
2025-02-07 02:34:10,039 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 02:34:10,046 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 6, batch_idx_train: 21070,  validation: loss=0.08811, DER=0.1992, ACC=0.9599, MI=0.1212, FA=0.04711, CF=0.03088, over 0.00 frames. 
2025-02-07 02:34:10,047 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 02:51:53,428 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 21570, num_updates: 21000, {'loss': 0.11611802130937576, 'DER': 0.28227609744615745, 'ACC': np.float64(0.9477857142857143), 'MI': 0.1486995410144757, 'FA': 0.07173119924679298, 'CF': 0.06184535718488878}, batch size: 64, grad_norm: 0.44877615571022034, grad_scale: , lr: 0.00e+00, 
2025-02-07 02:51:53,428 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 21570, num_updates: 21000, {'loss': 0.1520477682352066, 'DER': 0.3459859454855196, 'ACC': np.float64(0.9297678571428571), 'MI': 0.20464224872231687, 'FA': 0.06856899488926746, 'CF': 0.07277470187393527}, batch size: 64, grad_norm: 0.44877615571022034, grad_scale: , lr: 0.00e+00, 
2025-02-07 02:51:53,428 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 02:51:53,428 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 02:53:03,252 (model:870) WARNING: All labels are zero
2025-02-07 02:53:04,020 (model:870) WARNING: All labels are zero
2025-02-07 02:53:04,061 (model:870) WARNING: All labels are zero
2025-02-07 02:55:11,627 (model:870) WARNING: All labels are zero
2025-02-07 02:55:28,694 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 6, batch_idx_train: 21570,  validation: loss=0.07583, DER=0.1738, ACC=0.9652, MI=0.08446, FA=0.06168, CF=0.02763, over 0.00 frames. 
2025-02-07 02:55:28,695 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 02:55:28,778 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 6, batch_idx_train: 21570,  validation: loss=0.07656, DER=0.1713, ACC=0.9648, MI=0.08642, FA=0.05824, CF=0.02661, over 0.00 frames. 
2025-02-07 02:55:28,778 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 03:13:08,855 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 22070, num_updates: 21500, {'loss': 0.12863095104694366, 'DER': 0.30472796124074175, 'ACC': np.float64(0.943375), 'MI': 0.1902322214178315, 'FA': 0.06604666703792393, 'CF': 0.048449072784986356}, batch size: 64, grad_norm: 0.36547043919563293, grad_scale: , lr: 0.00e+00, 
2025-02-07 03:13:08,855 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 22070, num_updates: 21500, {'loss': 0.12355821579694748, 'DER': 0.2738176057931659, 'ACC': np.float64(0.9461071428571429), 'MI': 0.14465942520932337, 'FA': 0.06149581353247341, 'CF': 0.06766236705136909}, batch size: 64, grad_norm: 0.36547043919563293, grad_scale: , lr: 0.00e+00, 
2025-02-07 03:13:08,856 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 03:13:08,856 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 03:14:18,038 (model:870) WARNING: All labels are zero
2025-02-07 03:14:18,840 (model:870) WARNING: All labels are zero
2025-02-07 03:14:18,917 (model:870) WARNING: All labels are zero
2025-02-07 03:16:28,969 (model:870) WARNING: All labels are zero
2025-02-07 03:16:46,308 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 6, batch_idx_train: 22070,  validation: loss=0.09539, DER=0.2259, ACC=0.9558, MI=0.1569, FA=0.03746, CF=0.0315, over 0.00 frames. 
2025-02-07 03:16:46,309 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 03:16:46,318 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 6, batch_idx_train: 22070,  validation: loss=0.09376, DER=0.2258, ACC=0.957, MI=0.1508, FA=0.0429, CF=0.03211, over 0.00 frames. 
2025-02-07 03:16:46,318 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 03:31:59,377 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-22500.pt
2025-02-07 03:32:00,958 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 03:34:32,475 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 22570, num_updates: 22000, {'loss': 0.08503358066082001, 'DER': 0.19291572566266493, 'ACC': np.float64(0.9663928571428572), 'MI': 0.10662070605016047, 'FA': 0.05550933079757518, 'CF': 0.030785688814929275}, batch size: 64, grad_norm: 0.3785974979400635, grad_scale: , lr: 0.00e+00, 
2025-02-07 03:34:32,476 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 03:34:32,476 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 22570, num_updates: 22000, {'loss': 0.14149266481399536, 'DER': 0.3231550772928388, 'ACC': np.float64(0.9385803571428571), 'MI': 0.21494510296607855, 'FA': 0.055607144807996944, 'CF': 0.052602829518763314}, batch size: 64, grad_norm: 0.3785974979400635, grad_scale: , lr: 0.00e+00, 
2025-02-07 03:34:32,476 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 03:35:40,916 (model:870) WARNING: All labels are zero
2025-02-07 03:35:46,474 (model:870) WARNING: All labels are zero
2025-02-07 03:35:47,363 (model:870) WARNING: All labels are zero
2025-02-07 03:37:45,402 (model:870) WARNING: All labels are zero
2025-02-07 03:38:02,114 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 6, batch_idx_train: 22570,  validation: loss=0.07641, DER=0.1743, ACC=0.9653, MI=0.08254, FA=0.06561, CF=0.02612, over 0.00 frames. 
2025-02-07 03:38:02,115 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 03:38:22,524 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 6, batch_idx_train: 22570,  validation: loss=0.07696, DER=0.172, ACC=0.965, MI=0.08464, FA=0.06198, CF=0.02538, over 0.00 frames. 
2025-02-07 03:38:22,525 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 03:55:58,706 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 23070, num_updates: 22500, {'loss': 0.13160981237888336, 'DER': 0.28408295179100457, 'ACC': np.float64(0.9435), 'MI': 0.16606517640721788, 'FA': 0.06124427686506868, 'CF': 0.05677349851871802}, batch size: 64, grad_norm: 0.33772626519203186, grad_scale: , lr: 0.00e+00, 
2025-02-07 03:55:58,706 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 23070, num_updates: 22500, {'loss': 0.11167368292808533, 'DER': 0.22241519674355495, 'ACC': np.float64(0.9565267857142856), 'MI': 0.12890094979647218, 'FA': 0.05166892808683853, 'CF': 0.041845318860244236}, batch size: 64, grad_norm: 0.33772626519203186, grad_scale: , lr: 0.00e+00, 
2025-02-07 03:55:58,706 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 03:55:58,706 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 03:57:08,225 (model:870) WARNING: All labels are zero
2025-02-07 03:57:08,995 (model:870) WARNING: All labels are zero
2025-02-07 03:57:09,035 (model:870) WARNING: All labels are zero
2025-02-07 03:59:15,051 (model:870) WARNING: All labels are zero
2025-02-07 03:59:32,011 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 6, batch_idx_train: 23070,  validation: loss=0.08524, DER=0.1889, ACC=0.9616, MI=0.1072, FA=0.05179, CF=0.02994, over 0.00 frames. 
2025-02-07 03:59:32,011 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 03:59:32,073 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 6, batch_idx_train: 23070,  validation: loss=0.08478, DER=0.1933, ACC=0.9617, MI=0.1043, FA=0.05729, CF=0.03175, over 0.00 frames. 
2025-02-07 03:59:32,074 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 04:17:30,183 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 23570, num_updates: 23000, {'loss': 0.19791312515735626, 'DER': 0.436225061645371, 'ACC': np.float64(0.9164910714285714), 'MI': 0.2966823582156467, 'FA': 0.051613987895090786, 'CF': 0.0879287155346335}, batch size: 64, grad_norm: 0.5721400380134583, grad_scale: , lr: 0.00e+00, 
2025-02-07 04:17:30,184 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 04:17:30,184 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 23570, num_updates: 23000, {'loss': 0.13734252750873566, 'DER': 0.30673609944565766, 'ACC': np.float64(0.9432589285714286), 'MI': 0.19133210146144802, 'FA': 0.0662971051010695, 'CF': 0.04910689288314015}, batch size: 64, grad_norm: 0.5721400380134583, grad_scale: , lr: 0.00e+00, 
2025-02-07 04:17:30,184 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 04:18:40,267 (model:870) WARNING: All labels are zero
2025-02-07 04:18:40,994 (model:870) WARNING: All labels are zero
2025-02-07 04:18:41,096 (model:870) WARNING: All labels are zero
2025-02-07 04:20:49,019 (model:870) WARNING: All labels are zero
2025-02-07 04:21:06,298 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 6, batch_idx_train: 23570,  validation: loss=0.07919, DER=0.1802, ACC=0.9639, MI=0.09024, FA=0.06093, CF=0.02907, over 0.00 frames. 
2025-02-07 04:21:06,299 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 04:21:06,382 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 6, batch_idx_train: 23570,  validation: loss=0.07955, DER=0.1775, ACC=0.9638, MI=0.09256, FA=0.05733, CF=0.0276, over 0.00 frames. 
2025-02-07 04:21:06,382 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 04:36:24,728 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-24000.pt
2025-02-07 04:36:26,351 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 04:38:56,278 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 24070, num_updates: 23500, {'loss': 0.09249575436115265, 'DER': 0.20015287822661257, 'ACC': np.float64(0.966125), 'MI': 0.10254601046627859, 'FA': 0.07467513376844828, 'CF': 0.022931733991885694}, batch size: 64, grad_norm: 0.33510085940361023, grad_scale: , lr: 0.00e+00, 
2025-02-07 04:38:56,278 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 04:38:56,278 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 24070, num_updates: 23500, {'loss': 0.12291944026947021, 'DER': 0.2920738974970203, 'ACC': np.float64(0.9464107142857143), 'MI': 0.13206197854588797, 'FA': 0.09439809296781883, 'CF': 0.06561382598331347}, batch size: 64, grad_norm: 0.33510085940361023, grad_scale: , lr: 0.00e+00, 
2025-02-07 04:38:56,279 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 04:40:06,228 (model:870) WARNING: All labels are zero
2025-02-07 04:40:06,986 (model:870) WARNING: All labels are zero
2025-02-07 04:40:07,044 (model:870) WARNING: All labels are zero
2025-02-07 04:42:13,704 (model:870) WARNING: All labels are zero
2025-02-07 04:42:30,167 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 6, batch_idx_train: 24070,  validation: loss=0.07638, DER=0.175, ACC=0.9651, MI=0.08227, FA=0.0655, CF=0.02718, over 0.00 frames. 
2025-02-07 04:42:30,168 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 04:42:30,651 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 6, batch_idx_train: 24070,  validation: loss=0.07696, DER=0.1719, ACC=0.9649, MI=0.08409, FA=0.062, CF=0.02585, over 0.00 frames. 
2025-02-07 04:42:30,651 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 05:00:17,499 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 24570, num_updates: 24000, {'loss': 0.16159775853157043, 'DER': 0.37208789998347747, 'ACC': np.float64(0.9286160714285715), 'MI': 0.2405133006553946, 'FA': 0.06333645426006498, 'CF': 0.06823814506801784}, batch size: 64, grad_norm: 0.5512486100196838, grad_scale: , lr: 0.00e+00, 
2025-02-07 05:00:17,499 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 05:00:17,500 (train_accelerate_ddp:702) INFO: [Train] - Epoch 6, batch_idx_train: 24570, num_updates: 24000, {'loss': 0.15070000290870667, 'DER': 0.32514652525816357, 'ACC': np.float64(0.9360714285714286), 'MI': 0.18001674574379012, 'FA': 0.07061121964833939, 'CF': 0.07451855986603405}, batch size: 64, grad_norm: 0.5512486100196838, grad_scale: , lr: 0.00e+00, 
2025-02-07 05:00:17,500 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 05:01:28,042 (model:870) WARNING: All labels are zero
2025-02-07 05:01:28,788 (model:870) WARNING: All labels are zero
2025-02-07 05:01:28,863 (model:870) WARNING: All labels are zero
2025-02-07 05:03:35,878 (model:870) WARNING: All labels are zero
2025-02-07 05:03:52,681 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 6, batch_idx_train: 24570,  validation: loss=0.09243, DER=0.2159, ACC=0.9581, MI=0.131, FA=0.05046, CF=0.0344, over 0.00 frames. 
2025-02-07 05:03:52,682 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 05:03:53,289 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 6, batch_idx_train: 24570,  validation: loss=0.09344, DER=0.2141, ACC=0.9574, MI=0.1364, FA=0.0446, CF=0.03312, over 0.00 frames. 
2025-02-07 05:03:53,289 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 05:07:51,698 (train_accelerate_ddp:713) INFO: end of epoch 6, batch_idx: 4113 batch_idx_train: 24683, {'loss': 0.09684273600578308, 'DER': 0.23157710484859093, 'ACC': np.float64(0.9589196428571429), 'MI': 0.13273819942820467, 'FA': 0.061963941886924556, 'CF': 0.036874963533461695}, batch size: 64, grad_norm: 0.38346922397613525, grad_scale: , lr: 0.00e+00, 
2025-02-07 05:07:51,698 (train_accelerate_ddp:713) INFO: end of epoch 6, batch_idx: 4113 batch_idx_train: 24683, {'loss': 0.10842578858137131, 'DER': 0.24655937846836848, 'ACC': np.float64(0.9526607142857143), 'MI': 0.13401775804661487, 'FA': 0.06487236403995561, 'CF': 0.047669256381798}, batch size: 64, grad_norm: 0.38346922397613525, grad_scale: , lr: 0.00e+00, 
2025-02-07 05:07:51,700 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-6.pt
2025-02-07 05:07:53,009 (train_accelerate_ddp:561) INFO:  end of epoch 6, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-6.pt 
2025-02-07 05:07:57,296 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 24684, num_updates: 24000, {'loss': 0.15008629858493805, 'DER': 0.3219917012448133, 'ACC': np.float64(0.9365446428571429), 'MI': 0.19972337482710928, 'FA': 0.051065006915629325, 'CF': 0.07120331950207469}, batch size: 64, grad_norm: 0.45997732877731323, grad_scale: , lr: 0.00e+00, 
2025-02-07 05:07:57,297 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 24684, num_updates: 24000, {'loss': 0.14007197320461273, 'DER': 0.33462399419202615, 'ACC': np.float64(0.9427767857142857), 'MI': 0.1825881783531974, 'FA': 0.09891705487325307, 'CF': 0.053118760965575655}, batch size: 64, grad_norm: 0.45997732877731323, grad_scale: , lr: 0.00e+00, 
2025-02-07 05:25:54,952 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 25184, num_updates: 24500, {'loss': 0.13458247482776642, 'DER': 0.30023350846468183, 'ACC': np.float64(0.944625), 'MI': 0.16479859894921192, 'FA': 0.07361354349095155, 'CF': 0.06182136602451839}, batch size: 64, grad_norm: 0.4479217827320099, grad_scale: , lr: 0.00e+00, 
2025-02-07 05:25:54,952 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 05:25:54,953 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 25184, num_updates: 24500, {'loss': 0.10842037945985794, 'DER': 0.25398666280081184, 'ACC': np.float64(0.952), 'MI': 0.1257755871267034, 'FA': 0.07045520440707452, 'CF': 0.05775587126703392}, batch size: 64, grad_norm: 0.4479217827320099, grad_scale: , lr: 0.00e+00, 
2025-02-07 05:25:54,953 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 05:27:05,764 (model:870) WARNING: All labels are zero
2025-02-07 05:27:05,784 (model:870) WARNING: All labels are zero
2025-02-07 05:27:06,589 (model:870) WARNING: All labels are zero
2025-02-07 05:29:14,142 (model:870) WARNING: All labels are zero
2025-02-07 05:29:31,033 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 7, batch_idx_train: 25184,  validation: loss=0.074, DER=0.1693, ACC=0.9661, MI=0.08045, FA=0.06316, CF=0.02565, over 0.00 frames. 
2025-02-07 05:29:31,034 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 05:29:32,492 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 7, batch_idx_train: 25184,  validation: loss=0.07486, DER=0.1678, ACC=0.9656, MI=0.08238, FA=0.06025, CF=0.02518, over 0.00 frames. 
2025-02-07 05:29:32,493 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 05:40:45,155 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-25500.pt
2025-02-07 05:40:46,737 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 05:40:46,739 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-07 05:47:21,646 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 25684, num_updates: 25000, {'loss': 0.1304880678653717, 'DER': 0.2919265222814378, 'ACC': np.float64(0.9463214285714285), 'MI': 0.17462297312620478, 'FA': 0.06837509921759836, 'CF': 0.04892844993763465}, batch size: 64, grad_norm: 0.43960630893707275, grad_scale: , lr: 0.00e+00, 
2025-02-07 05:47:21,646 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 25684, num_updates: 25000, {'loss': 0.13949623703956604, 'DER': 0.3242784380305603, 'ACC': np.float64(0.9340982142857144), 'MI': 0.15897000565930958, 'FA': 0.07187323146576118, 'CF': 0.09343520090548953}, batch size: 64, grad_norm: 0.43960630893707275, grad_scale: , lr: 0.00e+00, 
2025-02-07 05:47:21,647 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 05:47:21,647 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 05:48:32,526 (model:870) WARNING: All labels are zero
2025-02-07 05:48:33,335 (model:870) WARNING: All labels are zero
2025-02-07 05:48:33,361 (model:870) WARNING: All labels are zero
2025-02-07 05:50:42,347 (model:870) WARNING: All labels are zero
2025-02-07 05:50:59,539 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 7, batch_idx_train: 25684,  validation: loss=0.07776, DER=0.1776, ACC=0.9643, MI=0.08446, FA=0.06377, CF=0.0294, over 0.00 frames. 
2025-02-07 05:50:59,540 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 05:51:00,165 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 7, batch_idx_train: 25684,  validation: loss=0.07801, DER=0.1737, ACC=0.9642, MI=0.08666, FA=0.05919, CF=0.02786, over 0.00 frames. 
2025-02-07 05:51:00,165 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 06:08:43,795 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 26184, num_updates: 25500, {'loss': 0.11343767493963242, 'DER': 0.2358132195663608, 'ACC': np.float64(0.9553571428571429), 'MI': 0.11390333703465606, 'FA': 0.065513412424756, 'CF': 0.056396470106948746}, batch size: 64, grad_norm: 0.4283696711063385, grad_scale: , lr: 0.00e+00, 
2025-02-07 06:08:43,795 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 26184, num_updates: 25500, {'loss': 0.10725488513708115, 'DER': 0.24899274778404512, 'ACC': np.float64(0.9565982142857143), 'MI': 0.12651087832393232, 'FA': 0.07016673898221037, 'CF': 0.052315130477902434}, batch size: 64, grad_norm: 0.4283696711063385, grad_scale: , lr: 0.00e+00, 
2025-02-07 06:08:43,795 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 06:08:43,795 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 06:09:54,397 (model:870) WARNING: All labels are zero
2025-02-07 06:09:55,223 (model:870) WARNING: All labels are zero
2025-02-07 06:09:55,231 (model:870) WARNING: All labels are zero
2025-02-07 06:12:04,190 (model:870) WARNING: All labels are zero
2025-02-07 06:12:21,264 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 7, batch_idx_train: 26184,  validation: loss=0.122, DER=0.3019, ACC=0.9443, MI=0.22, FA=0.04234, CF=0.03951, over 0.00 frames. 
2025-02-07 06:12:21,265 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 06:12:21,379 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 7, batch_idx_train: 26184,  validation: loss=0.1246, DER=0.3042, ACC=0.9431, MI=0.2305, FA=0.03789, CF=0.03575, over 0.00 frames. 
2025-02-07 06:12:21,379 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 06:30:23,894 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 26684, num_updates: 26000, {'loss': 0.14248032867908478, 'DER': 0.33668468015583763, 'ACC': np.float64(0.9386964285714285), 'MI': 0.15037074274223955, 'FA': 0.09155460600728918, 'CF': 0.0947593314063089}, batch size: 64, grad_norm: 0.4348432719707489, grad_scale: , lr: 0.00e+00, 
2025-02-07 06:30:23,895 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 06:30:23,895 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 26684, num_updates: 26000, {'loss': 0.11818646639585495, 'DER': 0.26146269670553607, 'ACC': np.float64(0.9504553571428571), 'MI': 0.13528812408015398, 'FA': 0.07353107664440167, 'CF': 0.05264349598098041}, batch size: 64, grad_norm: 0.4348432719707489, grad_scale: , lr: 0.00e+00, 
2025-02-07 06:30:23,895 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 06:31:34,129 (model:870) WARNING: All labels are zero
2025-02-07 06:31:34,903 (model:870) WARNING: All labels are zero
2025-02-07 06:31:34,954 (model:870) WARNING: All labels are zero
2025-02-07 06:33:43,378 (model:870) WARNING: All labels are zero
2025-02-07 06:34:00,535 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 7, batch_idx_train: 26684,  validation: loss=0.08163, DER=0.1843, ACC=0.9635, MI=0.09228, FA=0.06373, CF=0.02831, over 0.00 frames. 
2025-02-07 06:34:00,535 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 06:34:00,653 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 7, batch_idx_train: 26684,  validation: loss=0.08212, DER=0.1812, ACC=0.9635, MI=0.09442, FA=0.05987, CF=0.02693, over 0.00 frames. 
2025-02-07 06:34:00,653 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 06:45:10,080 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-27000.pt
2025-02-07 06:45:11,727 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 06:51:45,219 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 27184, num_updates: 26500, {'loss': 0.13110490143299103, 'DER': 0.33275808936825885, 'ACC': np.float64(0.940625), 'MI': 0.15864406779661017, 'FA': 0.09701078582434515, 'CF': 0.07710323574730354}, batch size: 64, grad_norm: 0.39337798953056335, grad_scale: , lr: 0.00e+00, 
2025-02-07 06:51:45,219 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 27184, num_updates: 26500, {'loss': 0.1100144311785698, 'DER': 0.2383177570093458, 'ACC': np.float64(0.9562678571428571), 'MI': 0.12470794392523364, 'FA': 0.06582943925233645, 'CF': 0.0477803738317757}, batch size: 64, grad_norm: 0.39337798953056335, grad_scale: , lr: 0.00e+00, 
2025-02-07 06:51:45,219 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 06:51:45,219 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 06:52:55,442 (model:870) WARNING: All labels are zero
2025-02-07 06:52:56,271 (model:870) WARNING: All labels are zero
2025-02-07 06:52:56,307 (model:870) WARNING: All labels are zero
2025-02-07 06:55:06,099 (model:870) WARNING: All labels are zero
2025-02-07 06:55:23,353 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 7, batch_idx_train: 27184,  validation: loss=0.07709, DER=0.1725, ACC=0.9646, MI=0.09335, FA=0.05267, CF=0.02647, over 0.00 frames. 
2025-02-07 06:55:23,354 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 06:55:23,378 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 7, batch_idx_train: 27184,  validation: loss=0.07655, DER=0.175, ACC=0.965, MI=0.09183, FA=0.05601, CF=0.02718, over 0.00 frames. 
2025-02-07 06:55:23,378 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 07:13:12,754 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 27684, num_updates: 27000, {'loss': 0.1266937553882599, 'DER': 0.28851928851928854, 'ACC': np.float64(0.946), 'MI': 0.15921690921690923, 'FA': 0.06854931854931855, 'CF': 0.06075306075306075}, batch size: 64, grad_norm: 0.4272459149360657, grad_scale: , lr: 0.00e+00, 
2025-02-07 07:13:12,754 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 07:13:12,755 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 27684, num_updates: 27000, {'loss': 0.15246795117855072, 'DER': 0.36083209835885616, 'ACC': np.float64(0.9279821428571429), 'MI': 0.2131840386409792, 'FA': 0.0657555299412701, 'CF': 0.08189252977660684}, batch size: 64, grad_norm: 0.4272459149360657, grad_scale: , lr: 0.00e+00, 
2025-02-07 07:13:12,755 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 07:14:23,129 (model:870) WARNING: All labels are zero
2025-02-07 07:14:23,953 (model:870) WARNING: All labels are zero
2025-02-07 07:14:23,972 (model:870) WARNING: All labels are zero
2025-02-07 07:16:36,606 (model:870) WARNING: All labels are zero
2025-02-07 07:16:53,942 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 7, batch_idx_train: 27684,  validation: loss=0.08306, DER=0.189, ACC=0.9629, MI=0.09873, FA=0.06159, CF=0.02864, over 0.00 frames. 
2025-02-07 07:16:53,942 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 07:16:54,032 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 7, batch_idx_train: 27684,  validation: loss=0.08353, DER=0.1859, ACC=0.9628, MI=0.1009, FA=0.0573, CF=0.02762, over 0.00 frames. 
2025-02-07 07:16:54,032 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 07:34:53,750 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 28184, num_updates: 27500, {'loss': 0.12834276258945465, 'DER': 0.3020611661701222, 'ACC': np.float64(0.9424392693490679), 'MI': 0.14975375448410044, 'FA': 0.06408463549583511, 'CF': 0.08822277619018666}, batch size: 64, grad_norm: 0.44896697998046875, grad_scale: , lr: 0.00e+00, 
2025-02-07 07:34:53,751 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 07:34:53,751 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 28184, num_updates: 27500, {'loss': 0.12143222242593765, 'DER': 0.2591981257654012, 'ACC': np.float64(0.9511517857142857), 'MI': 0.17874447580001065, 'FA': 0.04834673340077738, 'CF': 0.032106916564613175}, batch size: 64, grad_norm: 0.44896697998046875, grad_scale: , lr: 0.00e+00, 
2025-02-07 07:34:53,751 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 07:36:03,810 (model:870) WARNING: All labels are zero
2025-02-07 07:36:04,585 (model:870) WARNING: All labels are zero
2025-02-07 07:36:04,618 (model:870) WARNING: All labels are zero
2025-02-07 07:38:12,400 (model:870) WARNING: All labels are zero
2025-02-07 07:38:29,509 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 7, batch_idx_train: 28184,  validation: loss=0.08362, DER=0.1898, ACC=0.9623, MI=0.09713, FA=0.06099, CF=0.03165, over 0.00 frames. 
2025-02-07 07:38:29,510 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 07:38:29,608 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 7, batch_idx_train: 28184,  validation: loss=0.08393, DER=0.1857, ACC=0.9623, MI=0.09957, FA=0.05621, CF=0.02988, over 0.00 frames. 
2025-02-07 07:38:29,608 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 07:49:37,825 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-28500.pt
2025-02-07 07:49:39,465 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 07:56:09,222 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 28684, num_updates: 28000, {'loss': 0.11670421063899994, 'DER': 0.2645937574457946, 'ACC': np.float64(0.9522201074086981), 'MI': 0.1401000714796283, 'FA': 0.07058613295210865, 'CF': 0.05390755301405766}, batch size: 64, grad_norm: 0.45733582973480225, grad_scale: , lr: 0.00e+00, 
2025-02-07 07:56:09,223 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 07:56:09,223 (train_accelerate_ddp:702) INFO: [Train] - Epoch 7, batch_idx_train: 28684, num_updates: 28000, {'loss': 0.12239757180213928, 'DER': 0.28844036697247705, 'ACC': np.float64(0.9490446428571429), 'MI': 0.1510703363914373, 'FA': 0.07675840978593272, 'CF': 0.060611620795107034}, batch size: 64, grad_norm: 0.45733582973480225, grad_scale: , lr: 0.00e+00, 
2025-02-07 07:56:09,223 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 07:57:19,681 (model:870) WARNING: All labels are zero
2025-02-07 07:57:20,477 (model:870) WARNING: All labels are zero
2025-02-07 07:57:20,503 (model:870) WARNING: All labels are zero
2025-02-07 07:59:27,605 (model:870) WARNING: All labels are zero
2025-02-07 07:59:44,316 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 7, batch_idx_train: 28684,  validation: loss=0.08998, DER=0.206, ACC=0.9597, MI=0.1187, FA=0.05479, CF=0.03255, over 0.00 frames. 
2025-02-07 07:59:44,317 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 07:59:45,366 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 7, batch_idx_train: 28684,  validation: loss=0.09062, DER=0.2034, ACC=0.9594, MI=0.1228, FA=0.04942, CF=0.03122, over 0.00 frames. 
2025-02-07 07:59:45,366 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 08:03:44,282 (train_accelerate_ddp:713) INFO: end of epoch 7, batch_idx: 4113 batch_idx_train: 28797, {'loss': 0.15345077216625214, 'DER': 0.3402466049207341, 'ACC': np.float64(0.9349642857142857), 'MI': 0.19921586453775783, 'FA': 0.06739019262458094, 'CF': 0.07364054775839536}, batch size: 64, grad_norm: 0.4574300944805145, grad_scale: , lr: 0.00e+00, 
2025-02-07 08:03:44,283 (train_accelerate_ddp:713) INFO: end of epoch 7, batch_idx: 4113 batch_idx_train: 28797, {'loss': 0.10592202842235565, 'DER': 0.22109275730622618, 'ACC': np.float64(0.9567678571428571), 'MI': 0.10604135381771976, 'FA': 0.05648608062839321, 'CF': 0.058565322860113206}, batch size: 64, grad_norm: 0.4574300944805145, grad_scale: , lr: 0.00e+00, 
2025-02-07 08:03:44,284 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-7.pt
2025-02-07 08:03:45,502 (train_accelerate_ddp:561) INFO:  end of epoch 7, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-7.pt 
2025-02-07 08:03:49,853 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 28798, num_updates: 28000, {'loss': 0.1454571634531021, 'DER': 0.297608657706406, 'ACC': np.float64(0.9435803571428572), 'MI': 0.1672775935299936, 'FA': 0.060278117181590735, 'CF': 0.07005294699482167}, batch size: 64, grad_norm: 0.4078987240791321, grad_scale: , lr: 0.00e+00, 
2025-02-07 08:03:49,854 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 28798, num_updates: 28000, {'loss': 0.10166715830564499, 'DER': 0.26549064238745573, 'ACC': np.float64(0.9555205386240733), 'MI': 0.12828780981284774, 'FA': 0.08858118361153262, 'CF': 0.048621648963075366}, batch size: 64, grad_norm: 0.4078987240791321, grad_scale: , lr: 0.00e+00, 
2025-02-07 08:21:43,131 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 29298, num_updates: 28500, {'loss': 0.14250649511814117, 'DER': 0.3283450218123585, 'ACC': np.float64(0.9360178571428571), 'MI': 0.19962449610690816, 'FA': 0.061350709591915624, 'CF': 0.06736981611353471}, batch size: 64, grad_norm: 0.45194295048713684, grad_scale: , lr: 0.00e+00, 
2025-02-07 08:21:43,131 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 29298, num_updates: 28500, {'loss': 0.12578801810741425, 'DER': 0.28470694420939807, 'ACC': np.float64(0.9453911104317096), 'MI': 0.17352061826592205, 'FA': 0.0533085124386529, 'CF': 0.05787781350482315}, batch size: 64, grad_norm: 0.45194295048713684, grad_scale: , lr: 0.00e+00, 
2025-02-07 08:21:43,132 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 08:21:43,132 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 08:22:53,414 (model:870) WARNING: All labels are zero
2025-02-07 08:22:54,190 (model:870) WARNING: All labels are zero
2025-02-07 08:22:54,241 (model:870) WARNING: All labels are zero
2025-02-07 08:25:01,439 (model:870) WARNING: All labels are zero
2025-02-07 08:25:17,927 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 8, batch_idx_train: 29298,  validation: loss=0.0784, DER=0.1792, ACC=0.9642, MI=0.09614, FA=0.05491, CF=0.02811, over 0.00 frames. 
2025-02-07 08:25:17,927 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 08:25:18,423 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 8, batch_idx_train: 29298,  validation: loss=0.07901, DER=0.1764, ACC=0.9639, MI=0.09849, FA=0.05062, CF=0.02732, over 0.00 frames. 
2025-02-07 08:25:18,423 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 08:43:03,123 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 29798, num_updates: 29000, {'loss': 0.08845510333776474, 'DER': 0.1940808525425692, 'ACC': np.float64(0.9669642857142857), 'MI': 0.10986910691532492, 'FA': 0.0639986099849415, 'CF': 0.02021313564230279}, batch size: 64, grad_norm: 0.3307678997516632, grad_scale: , lr: 0.00e+00, 
2025-02-07 08:43:03,124 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 08:43:03,124 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 29798, num_updates: 29000, {'loss': 0.14133521914482117, 'DER': 0.3041641847620079, 'ACC': np.float64(0.9398571428571428), 'MI': 0.18947311420371474, 'FA': 0.054096496453132616, 'CF': 0.06059457410516056}, batch size: 64, grad_norm: 0.3307678997516632, grad_scale: , lr: 0.00e+00, 
2025-02-07 08:43:03,124 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 08:44:13,498 (model:870) WARNING: All labels are zero
2025-02-07 08:44:14,316 (model:870) WARNING: All labels are zero
2025-02-07 08:44:14,323 (model:870) WARNING: All labels are zero
2025-02-07 08:46:22,846 (model:870) WARNING: All labels are zero
2025-02-07 08:46:39,864 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 8, batch_idx_train: 29798,  validation: loss=0.0773, DER=0.1728, ACC=0.9645, MI=0.09389, FA=0.0522, CF=0.02675, over 0.00 frames. 
2025-02-07 08:46:39,865 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 08:46:39,896 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 8, batch_idx_train: 29798,  validation: loss=0.07667, DER=0.1754, ACC=0.9649, MI=0.09197, FA=0.0559, CF=0.02756, over 0.00 frames. 
2025-02-07 08:46:39,896 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 08:53:48,132 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-30000.pt
2025-02-07 08:53:49,778 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 08:53:49,792 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-07 09:04:31,689 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 30298, num_updates: 29500, {'loss': 0.21388962864875793, 'DER': 0.5327478960848884, 'ACC': np.float64(0.9053042219845215), 'MI': 0.3027198438834004, 'FA': 0.12031955116477619, 'CF': 0.1097085010367118}, batch size: 64, grad_norm: 0.6304662823677063, grad_scale: , lr: 0.00e+00, 
2025-02-07 09:04:31,690 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 30298, num_updates: 29500, {'loss': 0.16544966399669647, 'DER': 0.37040166751168946, 'ACC': np.float64(0.9284196428571428), 'MI': 0.22494507351698495, 'FA': 0.06422173398681764, 'CF': 0.08123486000788688}, batch size: 64, grad_norm: 0.6304662823677063, grad_scale: , lr: 0.00e+00, 
2025-02-07 09:04:31,690 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 09:04:31,690 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 09:05:41,861 (model:870) WARNING: All labels are zero
2025-02-07 09:05:42,660 (model:870) WARNING: All labels are zero
2025-02-07 09:05:42,678 (model:870) WARNING: All labels are zero
2025-02-07 09:07:51,300 (model:870) WARNING: All labels are zero
2025-02-07 09:08:08,462 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 8, batch_idx_train: 30298,  validation: loss=0.08296, DER=0.189, ACC=0.9623, MI=0.09806, FA=0.05923, CF=0.03173, over 0.00 frames. 
2025-02-07 09:08:08,463 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 09:08:08,530 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 8, batch_idx_train: 30298,  validation: loss=0.08314, DER=0.1848, ACC=0.9624, MI=0.1004, FA=0.05446, CF=0.02996, over 0.00 frames. 
2025-02-07 09:08:08,531 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 09:26:01,080 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 30798, num_updates: 30000, {'loss': 0.10780183970928192, 'DER': 0.27920531461519177, 'ACC': np.float64(0.9534553571428571), 'MI': 0.14163950864878416, 'FA': 0.09006016545500126, 'CF': 0.04750564051140637}, batch size: 64, grad_norm: 0.38609495759010315, grad_scale: , lr: 0.00e+00, 
2025-02-07 09:26:01,080 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 30798, num_updates: 30000, {'loss': 0.11725243926048279, 'DER': 0.2594780367307486, 'ACC': np.float64(0.9508035714285714), 'MI': 0.17527655461282354, 'FA': 0.04779293308989367, 'CF': 0.03640854902803136}, batch size: 64, grad_norm: 0.38609495759010315, grad_scale: , lr: 0.00e+00, 
2025-02-07 09:26:01,080 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 09:26:01,080 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 09:27:10,254 (model:870) WARNING: All labels are zero
2025-02-07 09:27:11,066 (model:870) WARNING: All labels are zero
2025-02-07 09:27:11,077 (model:870) WARNING: All labels are zero
2025-02-07 09:29:18,537 (model:870) WARNING: All labels are zero
2025-02-07 09:29:35,339 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 8, batch_idx_train: 30798,  validation: loss=0.07789, DER=0.1735, ACC=0.9645, MI=0.09626, FA=0.05118, CF=0.02602, over 0.00 frames. 
2025-02-07 09:29:35,340 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 09:29:35,431 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 8, batch_idx_train: 30798,  validation: loss=0.07726, DER=0.1761, ACC=0.9648, MI=0.09461, FA=0.05469, CF=0.02682, over 0.00 frames. 
2025-02-07 09:29:35,432 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 09:47:15,414 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 31298, num_updates: 30500, {'loss': 0.16782310605049133, 'DER': 0.36123069858217094, 'ACC': np.float64(0.9330357142857143), 'MI': 0.2395958900177946, 'FA': 0.052350611331152055, 'CF': 0.06928419723322427}, batch size: 64, grad_norm: 0.5846708416938782, grad_scale: , lr: 0.00e+00, 
2025-02-07 09:47:15,414 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 09:47:15,415 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 31298, num_updates: 30500, {'loss': 0.1607850193977356, 'DER': 0.3701187485727335, 'ACC': np.float64(0.9298392857142856), 'MI': 0.22493720027403516, 'FA': 0.06668189084265815, 'CF': 0.07849965745604019}, batch size: 64, grad_norm: 0.5846708416938782, grad_scale: , lr: 0.00e+00, 
2025-02-07 09:47:15,415 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 09:48:25,160 (model:870) WARNING: All labels are zero
2025-02-07 09:48:25,921 (model:870) WARNING: All labels are zero
2025-02-07 09:48:25,961 (model:870) WARNING: All labels are zero
2025-02-07 09:50:33,331 (model:870) WARNING: All labels are zero
2025-02-07 09:50:50,440 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 8, batch_idx_train: 31298,  validation: loss=0.08045, DER=0.1844, ACC=0.9632, MI=0.09302, FA=0.06044, CF=0.03096, over 0.00 frames. 
2025-02-07 09:50:50,441 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 09:50:50,500 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 8, batch_idx_train: 31298,  validation: loss=0.08112, DER=0.1807, ACC=0.963, MI=0.09524, FA=0.05575, CF=0.02972, over 0.00 frames. 
2025-02-07 09:50:50,500 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 09:57:55,893 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-31500.pt
2025-02-07 09:57:57,594 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 10:08:31,344 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 31798, num_updates: 31000, {'loss': 0.11890055984258652, 'DER': 0.2878028404344194, 'ACC': np.float64(0.9500089285714286), 'MI': 0.18719417591598042, 'FA': 0.05430242272347535, 'CF': 0.0463062417949636}, batch size: 64, grad_norm: 0.4279412627220154, grad_scale: , lr: 0.00e+00, 
2025-02-07 10:08:31,344 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 31798, num_updates: 31000, {'loss': 0.1498468816280365, 'DER': 0.3399118202813353, 'ACC': np.float64(0.9328214285714286), 'MI': 0.22580306529498215, 'FA': 0.059101406676464414, 'CF': 0.05500734830988872}, batch size: 64, grad_norm: 0.4279412627220154, grad_scale: , lr: 0.00e+00, 
2025-02-07 10:08:31,344 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 10:08:31,344 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 10:09:41,622 (model:870) WARNING: All labels are zero
2025-02-07 10:09:42,387 (model:870) WARNING: All labels are zero
2025-02-07 10:09:42,436 (model:870) WARNING: All labels are zero
2025-02-07 10:11:49,306 (model:870) WARNING: All labels are zero
2025-02-07 10:12:06,488 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 8, batch_idx_train: 31798,  validation: loss=0.07753, DER=0.1757, ACC=0.9651, MI=0.08887, FA=0.06124, CF=0.02555, over 0.00 frames. 
2025-02-07 10:12:06,488 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 10:12:07,202 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 8, batch_idx_train: 31798,  validation: loss=0.07801, DER=0.1731, ACC=0.9649, MI=0.09045, FA=0.05721, CF=0.02541, over 0.00 frames. 
2025-02-07 10:12:07,203 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 10:30:08,707 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 32298, num_updates: 31500, {'loss': 0.12498892843723297, 'DER': 0.30989807196364977, 'ACC': np.float64(0.9450535714285715), 'MI': 0.13127839862458554, 'FA': 0.11064718162839249, 'CF': 0.06797249171067174}, batch size: 64, grad_norm: 0.3986937403678894, grad_scale: , lr: 0.00e+00, 
2025-02-07 10:30:08,707 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 32298, num_updates: 31500, {'loss': 0.12437444925308228, 'DER': 0.26713819368879216, 'ACC': np.float64(0.9454910714285715), 'MI': 0.15457018498367792, 'FA': 0.04755168661588683, 'CF': 0.06501632208922742}, batch size: 64, grad_norm: 0.3986937403678894, grad_scale: , lr: 0.00e+00, 
2025-02-07 10:30:08,708 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 10:30:08,708 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 10:31:18,679 (model:870) WARNING: All labels are zero
2025-02-07 10:31:19,496 (model:870) WARNING: All labels are zero
2025-02-07 10:31:19,505 (model:870) WARNING: All labels are zero
2025-02-07 10:33:28,790 (model:870) WARNING: All labels are zero
2025-02-07 10:33:46,013 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 8, batch_idx_train: 32298,  validation: loss=0.0787, DER=0.1788, ACC=0.9645, MI=0.08872, FA=0.06214, CF=0.02792, over 0.00 frames. 
2025-02-07 10:33:46,014 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 10:33:46,043 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 8, batch_idx_train: 32298,  validation: loss=0.0792, DER=0.1752, ACC=0.9643, MI=0.09033, FA=0.05802, CF=0.02689, over 0.00 frames. 
2025-02-07 10:33:46,044 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 10:51:31,700 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 32798, num_updates: 32000, {'loss': 0.17775942385196686, 'DER': 0.426813507894589, 'ACC': np.float64(0.9211428571428572), 'MI': 0.29195931898634603, 'FA': 0.06540428162049784, 'CF': 0.06944990728774512}, batch size: 64, grad_norm: 0.4854138195514679, grad_scale: , lr: 0.00e+00, 
2025-02-07 10:51:31,701 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 10:51:31,702 (train_accelerate_ddp:702) INFO: [Train] - Epoch 8, batch_idx_train: 32798, num_updates: 32000, {'loss': 0.13472872972488403, 'DER': 0.2957956359765833, 'ACC': np.float64(0.9404732142857143), 'MI': 0.1722724853645556, 'FA': 0.06450239489089941, 'CF': 0.05902075572112826}, batch size: 64, grad_norm: 0.4854138195514679, grad_scale: , lr: 0.00e+00, 
2025-02-07 10:51:31,702 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 10:52:41,702 (model:870) WARNING: All labels are zero
2025-02-07 10:52:42,488 (model:870) WARNING: All labels are zero
2025-02-07 10:52:42,505 (model:870) WARNING: All labels are zero
2025-02-07 10:54:51,267 (model:870) WARNING: All labels are zero
2025-02-07 10:55:08,463 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 8, batch_idx_train: 32798,  validation: loss=0.07805, DER=0.1793, ACC=0.9643, MI=0.0859, FA=0.06482, CF=0.02856, over 0.00 frames. 
2025-02-07 10:55:08,463 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 10:55:08,518 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 8, batch_idx_train: 32798,  validation: loss=0.07845, DER=0.1758, ACC=0.9642, MI=0.08802, FA=0.06057, CF=0.02718, over 0.00 frames. 
2025-02-07 10:55:08,519 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 10:59:07,784 (train_accelerate_ddp:713) INFO: end of epoch 8, batch_idx: 4113 batch_idx_train: 32911, {'loss': 0.1283392608165741, 'DER': 0.2900772360120276, 'ACC': np.float64(0.9458482142857143), 'MI': 0.14226755497906962, 'FA': 0.08030186899357349, 'CF': 0.06750781203938447}, batch size: 64, grad_norm: 0.5325881838798523, grad_scale: , lr: 0.00e+00, 
2025-02-07 10:59:07,785 (train_accelerate_ddp:713) INFO: end of epoch 8, batch_idx: 4113 batch_idx_train: 32911, {'loss': 0.10253044217824936, 'DER': 0.2598696578518611, 'ACC': np.float64(0.9559055259105397), 'MI': 0.11398671512720893, 'FA': 0.09712996616117307, 'CF': 0.048752976563479135}, batch size: 64, grad_norm: 0.5325881838798523, grad_scale: , lr: 0.00e+00, 
2025-02-07 10:59:07,786 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-8.pt
2025-02-07 10:59:08,992 (train_accelerate_ddp:561) INFO:  end of epoch 8, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-8.pt 
2025-02-07 10:59:12,344 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 32912, num_updates: 32000, {'loss': 0.12807248532772064, 'DER': 0.27578005549578116, 'ACC': np.float64(0.9480625), 'MI': 0.15844611812673423, 'FA': 0.06370689166996998, 'CF': 0.05362704569907696}, batch size: 64, grad_norm: 0.39459988474845886, grad_scale: , lr: 0.00e+00, 
2025-02-07 10:59:12,344 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 32912, num_updates: 32000, {'loss': 0.1301899254322052, 'DER': 0.31053523590837023, 'ACC': np.float64(0.9386339285714286), 'MI': 0.18391558690066154, 'FA': 0.06139631512765841, 'CF': 0.0652233338800503}, batch size: 64, grad_norm: 0.39459988474845886, grad_scale: , lr: 0.00e+00, 
2025-02-07 11:02:18,835 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-33000.pt
2025-02-07 11:02:20,434 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 11:02:20,435 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-07 11:17:14,854 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 33412, num_updates: 32500, {'loss': 0.1333439201116562, 'DER': 0.30576191868967534, 'ACC': np.float64(0.9445892857142857), 'MI': 0.17777127815150628, 'FA': 0.07072243346007605, 'CF': 0.05726820707809301}, batch size: 64, grad_norm: 0.4027097225189209, grad_scale: , lr: 0.00e+00, 
2025-02-07 11:17:14,854 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 11:17:14,855 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 33412, num_updates: 32500, {'loss': 0.12350186705589294, 'DER': 0.2705129710059866, 'ACC': np.float64(0.9506785714285715), 'MI': 0.14896114567437493, 'FA': 0.06784833900692569, 'CF': 0.053703486324685995}, batch size: 64, grad_norm: 0.4027097225189209, grad_scale: , lr: 0.00e+00, 
2025-02-07 11:17:14,855 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 11:18:23,978 (model:870) WARNING: All labels are zero
2025-02-07 11:18:24,790 (model:870) WARNING: All labels are zero
2025-02-07 11:18:24,825 (model:870) WARNING: All labels are zero
2025-02-07 11:20:33,242 (model:870) WARNING: All labels are zero
2025-02-07 11:20:50,132 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 9, batch_idx_train: 33412,  validation: loss=0.07745, DER=0.1723, ACC=0.9647, MI=0.08685, FA=0.05894, CF=0.02647, over 0.00 frames. 
2025-02-07 11:20:50,133 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 11:20:50,201 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 9, batch_idx_train: 33412,  validation: loss=0.07692, DER=0.1753, ACC=0.9649, MI=0.08511, FA=0.06263, CF=0.02756, over 0.00 frames. 
2025-02-07 11:20:50,201 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 11:38:43,545 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 33912, num_updates: 33000, {'loss': 0.11671730875968933, 'DER': 0.2559075196917323, 'ACC': np.float64(0.9503392857142857), 'MI': 0.12234374114580382, 'FA': 0.07429024763415878, 'CF': 0.059273530911769706}, batch size: 64, grad_norm: 0.3475184440612793, grad_scale: , lr: 0.00e+00, 
2025-02-07 11:38:43,546 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 11:38:43,546 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 33912, num_updates: 33000, {'loss': 0.1369534581899643, 'DER': 0.30828090460805985, 'ACC': np.float64(0.9415982142857143), 'MI': 0.16850875701411325, 'FA': 0.07731111488975798, 'CF': 0.06246103270418863}, batch size: 64, grad_norm: 0.3475184440612793, grad_scale: , lr: 0.00e+00, 
2025-02-07 11:38:43,546 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 11:39:52,909 (model:870) WARNING: All labels are zero
2025-02-07 11:39:53,712 (model:870) WARNING: All labels are zero
2025-02-07 11:39:53,786 (model:870) WARNING: All labels are zero
2025-02-07 11:41:59,673 (model:870) WARNING: All labels are zero
2025-02-07 11:42:15,941 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 9, batch_idx_train: 33912,  validation: loss=0.09869, DER=0.236, ACC=0.9541, MI=0.167, FA=0.03704, CF=0.03197, over 0.00 frames. 
2025-02-07 11:42:15,942 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 11:42:16,737 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 9, batch_idx_train: 33912,  validation: loss=0.09681, DER=0.2341, ACC=0.9555, MI=0.1585, FA=0.04266, CF=0.03291, over 0.00 frames. 
2025-02-07 11:42:16,737 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 11:59:52,625 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 34412, num_updates: 33500, {'loss': 0.1354765146970749, 'DER': 0.30324949312291083, 'ACC': np.float64(0.9433303571428571), 'MI': 0.19957257931941477, 'FA': 0.05912652748095786, 'CF': 0.04455038632253822}, batch size: 64, grad_norm: 0.3758492171764374, grad_scale: , lr: 0.00e+00, 
2025-02-07 11:59:52,625 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 11:59:52,626 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 34412, num_updates: 33500, {'loss': 0.09935027360916138, 'DER': 0.22140017667844522, 'ACC': np.float64(0.9589732142857144), 'MI': 0.13847173144876326, 'FA': 0.05062941696113074, 'CF': 0.03229902826855124}, batch size: 64, grad_norm: 0.3758492171764374, grad_scale: , lr: 0.00e+00, 
2025-02-07 11:59:52,626 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 12:01:02,375 (model:870) WARNING: All labels are zero
2025-02-07 12:01:03,192 (model:870) WARNING: All labels are zero
2025-02-07 12:01:03,196 (model:870) WARNING: All labels are zero
2025-02-07 12:03:11,603 (model:870) WARNING: All labels are zero
2025-02-07 12:03:28,747 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 9, batch_idx_train: 34412,  validation: loss=0.07543, DER=0.1724, ACC=0.9655, MI=0.08422, FA=0.06164, CF=0.02649, over 0.00 frames. 
2025-02-07 12:03:28,748 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 12:03:28,793 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 9, batch_idx_train: 34412,  validation: loss=0.07604, DER=0.1702, ACC=0.9652, MI=0.08613, FA=0.05846, CF=0.02558, over 0.00 frames. 
2025-02-07 12:03:28,793 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11782MB
2025-02-07 12:06:33,870 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-34500.pt
2025-02-07 12:06:35,500 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 12:21:43,315 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 34912, num_updates: 34000, {'loss': 0.13944871723651886, 'DER': 0.3241940343476951, 'ACC': np.float64(0.9412410714285715), 'MI': 0.15932509792106056, 'FA': 0.09249774028321783, 'CF': 0.0723711961434167}, batch size: 64, grad_norm: 0.49690788984298706, grad_scale: , lr: 0.00e+00, 
2025-02-07 12:21:43,315 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 12:21:43,316 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 34912, num_updates: 34000, {'loss': 0.1369858682155609, 'DER': 0.29096545615589015, 'ACC': np.float64(0.9424464285714286), 'MI': 0.16519043401240036, 'FA': 0.059898139946855625, 'CF': 0.06587688219663419}, batch size: 64, grad_norm: 0.49690788984298706, grad_scale: , lr: 0.00e+00, 
2025-02-07 12:21:43,316 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 12:22:53,023 (model:870) WARNING: All labels are zero
2025-02-07 12:22:53,781 (model:870) WARNING: All labels are zero
2025-02-07 12:22:53,837 (model:870) WARNING: All labels are zero
2025-02-07 12:25:02,119 (model:870) WARNING: All labels are zero
2025-02-07 12:25:19,468 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 9, batch_idx_train: 34912,  validation: loss=0.07425, DER=0.1708, ACC=0.9656, MI=0.08251, FA=0.06137, CF=0.02687, over 0.00 frames. 
2025-02-07 12:25:19,469 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 12:25:19,483 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 9, batch_idx_train: 34912,  validation: loss=0.07497, DER=0.168, ACC=0.9653, MI=0.0843, FA=0.0576, CF=0.02612, over 0.00 frames. 
2025-02-07 12:25:19,483 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 12:42:58,583 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 35412, num_updates: 34500, {'loss': 0.118985116481781, 'DER': 0.3001016685604928, 'ACC': np.float64(0.9499642857142857), 'MI': 0.187548591591412, 'FA': 0.07750732611685904, 'CF': 0.03504575085222176}, batch size: 64, grad_norm: 0.37977370619773865, grad_scale: , lr: 0.00e+00, 
2025-02-07 12:42:58,583 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 12:42:58,584 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 35412, num_updates: 34500, {'loss': 0.11571483314037323, 'DER': 0.27593129600713806, 'ACC': np.float64(0.9461607142857144), 'MI': 0.15207450368057104, 'FA': 0.06351773366049521, 'CF': 0.060339058666071824}, batch size: 64, grad_norm: 0.37977370619773865, grad_scale: , lr: 0.00e+00, 
2025-02-07 12:42:58,584 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 12:44:09,111 (model:870) WARNING: All labels are zero
2025-02-07 12:44:09,934 (model:870) WARNING: All labels are zero
2025-02-07 12:44:09,952 (model:870) WARNING: All labels are zero
2025-02-07 12:46:20,686 (model:870) WARNING: All labels are zero
2025-02-07 12:46:38,080 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 9, batch_idx_train: 35412,  validation: loss=0.1071, DER=0.2591, ACC=0.9503, MI=0.1884, FA=0.03552, CF=0.03521, over 0.00 frames. 
2025-02-07 12:46:38,081 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 12:46:38,105 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 9, batch_idx_train: 35412,  validation: loss=0.1046, DER=0.258, ACC=0.9516, MI=0.1795, FA=0.04096, CF=0.03756, over 0.00 frames. 
2025-02-07 12:46:38,105 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 13:04:19,202 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 35912, num_updates: 35000, {'loss': 0.16727279126644135, 'DER': 0.3284239215891818, 'ACC': np.float64(0.9301785714285714), 'MI': 0.19262015828921852, 'FA': 0.05435295350909377, 'CF': 0.08145080979086954}, batch size: 64, grad_norm: 0.3798755705356598, grad_scale: , lr: 0.00e+00, 
2025-02-07 13:04:19,202 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 35912, num_updates: 35000, {'loss': 0.11652176827192307, 'DER': 0.26310947562097514, 'ACC': np.float64(0.9499553571428571), 'MI': 0.16148059959954544, 'FA': 0.06142107256886195, 'CF': 0.04020780345256778}, batch size: 64, grad_norm: 0.3798755705356598, grad_scale: , lr: 0.00e+00, 
2025-02-07 13:04:19,202 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 13:04:19,202 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 13:05:29,479 (model:870) WARNING: All labels are zero
2025-02-07 13:05:30,264 (model:870) WARNING: All labels are zero
2025-02-07 13:05:30,297 (model:870) WARNING: All labels are zero
2025-02-07 13:07:39,199 (model:870) WARNING: All labels are zero
2025-02-07 13:07:56,386 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 9, batch_idx_train: 35912,  validation: loss=0.07894, DER=0.1805, ACC=0.9642, MI=0.1002, FA=0.05309, CF=0.02719, over 0.00 frames. 
2025-02-07 13:07:56,387 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 13:07:56,510 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 9, batch_idx_train: 35912,  validation: loss=0.07951, DER=0.1776, ACC=0.9638, MI=0.102, FA=0.04889, CF=0.02667, over 0.00 frames. 
2025-02-07 13:07:56,510 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 13:11:19,760 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-36000.pt
2025-02-07 13:11:21,425 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 13:26:02,992 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 36412, num_updates: 35500, {'loss': 0.10103709250688553, 'DER': 0.22899636693914624, 'ACC': np.float64(0.9592946428571429), 'MI': 0.13794277929155313, 'FA': 0.061251135331516805, 'CF': 0.029802452316076294}, batch size: 64, grad_norm: 0.407391756772995, grad_scale: , lr: 0.00e+00, 
2025-02-07 13:26:02,992 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 13:26:02,992 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 36412, num_updates: 35500, {'loss': 0.12010778486728668, 'DER': 0.2876905041031653, 'ACC': np.float64(0.9472232142857143), 'MI': 0.1611957796014068, 'FA': 0.06770222743259086, 'CF': 0.05879249706916764}, batch size: 64, grad_norm: 0.407391756772995, grad_scale: , lr: 0.00e+00, 
2025-02-07 13:26:02,992 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 13:27:12,732 (model:870) WARNING: All labels are zero
2025-02-07 13:27:13,536 (model:870) WARNING: All labels are zero
2025-02-07 13:27:13,542 (model:870) WARNING: All labels are zero
2025-02-07 13:29:21,930 (model:870) WARNING: All labels are zero
2025-02-07 13:29:39,321 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 9, batch_idx_train: 36412,  validation: loss=0.07784, DER=0.1735, ACC=0.9647, MI=0.08844, FA=0.05902, CF=0.02602, over 0.00 frames. 
2025-02-07 13:29:39,321 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 13:29:39,322 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 9, batch_idx_train: 36412,  validation: loss=0.07724, DER=0.1756, ACC=0.965, MI=0.08669, FA=0.06212, CF=0.02682, over 0.00 frames. 
2025-02-07 13:29:39,322 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 13:47:20,954 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 36912, num_updates: 36000, {'loss': 0.14660879969596863, 'DER': 0.33507666706287886, 'ACC': np.float64(0.9387104551177305), 'MI': 0.19523356709853798, 'FA': 0.06697967431356235, 'CF': 0.07286342565077855}, batch size: 64, grad_norm: 0.486195832490921, grad_scale: , lr: 0.00e+00, 
2025-02-07 13:47:20,955 (train_accelerate_ddp:702) INFO: [Train] - Epoch 9, batch_idx_train: 36912, num_updates: 36000, {'loss': 0.11433162540197372, 'DER': 0.2794859476339179, 'ACC': np.float64(0.9511607142857144), 'MI': 0.1567379293778525, 'FA': 0.07374489550804708, 'CF': 0.049003122748018255}, batch size: 64, grad_norm: 0.486195832490921, grad_scale: , lr: 0.00e+00, 
2025-02-07 13:47:20,963 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 13:47:20,963 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 13:48:30,836 (model:870) WARNING: All labels are zero
2025-02-07 13:48:31,652 (model:870) WARNING: All labels are zero
2025-02-07 13:48:31,711 (model:870) WARNING: All labels are zero
2025-02-07 13:50:40,018 (model:870) WARNING: All labels are zero
2025-02-07 13:50:57,020 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 9, batch_idx_train: 36912,  validation: loss=0.07702, DER=0.1714, ACC=0.9649, MI=0.08696, FA=0.05834, CF=0.02611, over 0.00 frames. 
2025-02-07 13:50:57,021 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 13:50:57,105 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 9, batch_idx_train: 36912,  validation: loss=0.07639, DER=0.1742, ACC=0.9651, MI=0.08498, FA=0.06191, CF=0.02728, over 0.00 frames. 
2025-02-07 13:50:57,106 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 13:54:54,616 (train_accelerate_ddp:713) INFO: end of epoch 9, batch_idx: 4113 batch_idx_train: 37025, {'loss': 0.14073869585990906, 'DER': 0.31661993512562536, 'ACC': np.float64(0.9395178571428571), 'MI': 0.19621749408983452, 'FA': 0.06459948320413436, 'CF': 0.055802957831656494}, batch size: 64, grad_norm: 0.36239388585090637, grad_scale: , lr: 0.00e+00, 
2025-02-07 13:54:54,617 (train_accelerate_ddp:713) INFO: end of epoch 9, batch_idx: 4113 batch_idx_train: 37025, {'loss': 0.11673545092344284, 'DER': 0.25424464334147, 'ACC': np.float64(0.9512053571428571), 'MI': 0.16132356929753186, 'FA': 0.050718741524274476, 'CF': 0.04220233251966368}, batch size: 64, grad_norm: 0.36239388585090637, grad_scale: , lr: 0.00e+00, 
2025-02-07 13:54:54,617 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-9.pt
2025-02-07 13:54:55,908 (train_accelerate_ddp:561) INFO:  end of epoch 9, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-9.pt 
2025-02-07 13:54:58,969 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 37026, num_updates: 36000, {'loss': 0.15490823984146118, 'DER': 0.35554829576391156, 'ACC': np.float64(0.9292410714285715), 'MI': 0.2198627899379288, 'FA': 0.05972993575084395, 'CF': 0.07595557007513884}, batch size: 64, grad_norm: 0.3894425630569458, grad_scale: , lr: 0.00e+00, 
2025-02-07 13:54:58,970 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 37026, num_updates: 36000, {'loss': 0.10670552402734756, 'DER': 0.2440087145969499, 'ACC': np.float64(0.9584017857142857), 'MI': 0.12115710481723553, 'FA': 0.08490680222706366, 'CF': 0.03794480755265069}, batch size: 64, grad_norm: 0.3894425630569458, grad_scale: , lr: 0.00e+00, 
2025-02-07 14:12:05,470 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-37500.pt
2025-02-07 14:12:07,099 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 14:12:07,115 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-07 14:13:04,859 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 37526, num_updates: 36500, {'loss': 0.11135534197092056, 'DER': 0.246206143013233, 'ACC': np.float64(0.955328001147735), 'MI': 0.1120553599611509, 'FA': 0.0779409979361418, 'CF': 0.05620978511594027}, batch size: 64, grad_norm: 0.443378746509552, grad_scale: , lr: 0.00e+00, 
2025-02-07 14:13:04,859 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 37526, num_updates: 36500, {'loss': 0.1314089298248291, 'DER': 0.3114772409941357, 'ACC': np.float64(0.9415714285714285), 'MI': 0.1890533370566881, 'FA': 0.06841664339569953, 'CF': 0.05400726054174811}, batch size: 64, grad_norm: 0.443378746509552, grad_scale: , lr: 0.00e+00, 
2025-02-07 14:13:04,860 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 14:13:04,860 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 14:14:13,610 (model:870) WARNING: All labels are zero
2025-02-07 14:14:13,992 (model:870) WARNING: All labels are zero
2025-02-07 14:14:14,389 (model:870) WARNING: All labels are zero
2025-02-07 14:16:19,824 (model:870) WARNING: All labels are zero
2025-02-07 14:16:36,397 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 10, batch_idx_train: 37526,  validation: loss=0.08169, DER=0.1871, ACC=0.9629, MI=0.1071, FA=0.05099, CF=0.02905, over 0.00 frames. 
2025-02-07 14:16:36,398 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 14:16:36,708 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 10, batch_idx_train: 37526,  validation: loss=0.08242, DER=0.185, ACC=0.9624, MI=0.1103, FA=0.04628, CF=0.02838, over 0.00 frames. 
2025-02-07 14:16:36,708 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 14:34:13,967 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 38026, num_updates: 37000, {'loss': 0.11622354388237, 'DER': 0.27256637168141595, 'ACC': np.float64(0.9516221545079764), 'MI': 0.15887905604719765, 'FA': 0.06778761061946903, 'CF': 0.04589970501474926}, batch size: 64, grad_norm: 0.3999554216861725, grad_scale: , lr: 0.00e+00, 
2025-02-07 14:34:13,968 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 38026, num_updates: 37000, {'loss': 0.12401610612869263, 'DER': 0.27631578947368424, 'ACC': np.float64(0.9473839285714285), 'MI': 0.13993598862019915, 'FA': 0.06341868183973447, 'CF': 0.07296111901375059}, batch size: 64, grad_norm: 0.3999554216861725, grad_scale: , lr: 0.00e+00, 
2025-02-07 14:34:13,968 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 14:34:13,968 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 14:35:23,905 (model:870) WARNING: All labels are zero
2025-02-07 14:35:24,699 (model:870) WARNING: All labels are zero
2025-02-07 14:35:24,725 (model:870) WARNING: All labels are zero
2025-02-07 14:37:33,049 (model:870) WARNING: All labels are zero
2025-02-07 14:37:50,172 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 10, batch_idx_train: 38026,  validation: loss=0.07659, DER=0.1753, ACC=0.965, MI=0.09569, FA=0.05266, CF=0.02691, over 0.00 frames. 
2025-02-07 14:37:50,173 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 14:37:50,185 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 10, batch_idx_train: 38026,  validation: loss=0.07736, DER=0.1734, ACC=0.9645, MI=0.09756, FA=0.04945, CF=0.02637, over 0.00 frames. 
2025-02-07 14:37:50,186 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 14:55:29,728 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 38526, num_updates: 37500, {'loss': 0.11603337526321411, 'DER': 0.2645230560578662, 'ACC': np.float64(0.950875), 'MI': 0.15195524412296565, 'FA': 0.06617314647377938, 'CF': 0.04639466546112116}, batch size: 64, grad_norm: 0.38012900948524475, grad_scale: , lr: 0.00e+00, 
2025-02-07 14:55:29,729 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 38526, num_updates: 37500, {'loss': 0.1307549923658371, 'DER': 0.3093040803296767, 'ACC': np.float64(0.944380351509689), 'MI': 0.1539265192408149, 'FA': 0.10650647164664229, 'CF': 0.04887108944221951}, batch size: 64, grad_norm: 0.38012900948524475, grad_scale: , lr: 0.00e+00, 
2025-02-07 14:55:29,729 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 14:55:29,729 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 14:56:38,714 (model:870) WARNING: All labels are zero
2025-02-07 14:56:39,510 (model:870) WARNING: All labels are zero
2025-02-07 14:56:40,235 (model:870) WARNING: All labels are zero
2025-02-07 14:58:48,266 (model:870) WARNING: All labels are zero
2025-02-07 14:59:04,682 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 10, batch_idx_train: 38526,  validation: loss=0.08068, DER=0.1786, ACC=0.9638, MI=0.09131, FA=0.05997, CF=0.0273, over 0.00 frames. 
2025-02-07 14:59:04,683 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 14:59:05,428 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 10, batch_idx_train: 38526,  validation: loss=0.08034, DER=0.1827, ACC=0.9638, MI=0.08928, FA=0.06462, CF=0.02876, over 0.00 frames. 
2025-02-07 14:59:05,429 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 15:16:27,488 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-39000.pt
2025-02-07 15:16:29,244 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 15:17:25,658 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 39026, num_updates: 38000, {'loss': 0.09664497524499893, 'DER': 0.24343620451404882, 'ACC': np.float64(0.9576071428571429), 'MI': 0.14958544449562414, 'FA': 0.06391064025794564, 'CF': 0.029940119760479042}, batch size: 64, grad_norm: 0.28770512342453003, grad_scale: , lr: 0.00e+00, 
2025-02-07 15:17:25,658 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 39026, num_updates: 38000, {'loss': 0.11839491128921509, 'DER': 0.2829797951530755, 'ACC': np.float64(0.9482000017995483), 'MI': 0.16275815749706163, 'FA': 0.08098729501315274, 'CF': 0.03923434264286114}, batch size: 64, grad_norm: 0.28770512342453003, grad_scale: , lr: 0.00e+00, 
2025-02-07 15:17:25,659 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 15:17:25,659 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 15:18:35,120 (model:870) WARNING: All labels are zero
2025-02-07 15:18:35,931 (model:870) WARNING: All labels are zero
2025-02-07 15:18:35,975 (model:870) WARNING: All labels are zero
2025-02-07 15:20:43,899 (model:870) WARNING: All labels are zero
2025-02-07 15:21:00,893 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 10, batch_idx_train: 39026,  validation: loss=0.07902, DER=0.1762, ACC=0.9641, MI=0.09735, FA=0.05243, CF=0.02645, over 0.00 frames. 
2025-02-07 15:21:00,894 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 15:21:00,941 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 10, batch_idx_train: 39026,  validation: loss=0.07845, DER=0.1784, ACC=0.9645, MI=0.09557, FA=0.05597, CF=0.02682, over 0.00 frames. 
2025-02-07 15:21:00,942 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 15:38:36,532 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 39526, num_updates: 38500, {'loss': 0.0995873287320137, 'DER': 0.20739146035163258, 'ACC': np.float64(0.9646785714285715), 'MI': 0.119722521229518, 'FA': 0.05848582705418012, 'CF': 0.029183112067934457}, batch size: 64, grad_norm: 0.43167346715927124, grad_scale: , lr: 0.00e+00, 
2025-02-07 15:38:36,532 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 39526, num_updates: 38500, {'loss': 0.1630377173423767, 'DER': 0.35020497403662204, 'ACC': np.float64(0.9285714285714286), 'MI': 0.21005739273025417, 'FA': 0.053074610549330416, 'CF': 0.08707297075703745}, batch size: 64, grad_norm: 0.43167346715927124, grad_scale: , lr: 0.00e+00, 
2025-02-07 15:38:36,532 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 15:38:36,532 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 15:39:46,075 (model:870) WARNING: All labels are zero
2025-02-07 15:39:46,895 (model:870) WARNING: All labels are zero
2025-02-07 15:39:46,905 (model:870) WARNING: All labels are zero
2025-02-07 15:41:55,772 (model:870) WARNING: All labels are zero
2025-02-07 15:42:12,680 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 10, batch_idx_train: 39526,  validation: loss=0.08227, DER=0.1866, ACC=0.9629, MI=0.08822, FA=0.06737, CF=0.03104, over 0.00 frames. 
2025-02-07 15:42:12,681 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 15:42:13,273 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 10, batch_idx_train: 39526,  validation: loss=0.08267, DER=0.1825, ACC=0.9629, MI=0.09038, FA=0.06272, CF=0.02938, over 0.00 frames. 
2025-02-07 15:42:13,273 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 15:59:49,771 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 40026, num_updates: 39000, {'loss': 0.11843094229698181, 'DER': 0.2770997846374731, 'ACC': np.float64(0.9505803571428572), 'MI': 0.13831060062215841, 'FA': 0.0847690835128021, 'CF': 0.05402010050251256}, batch size: 64, grad_norm: 0.37249162793159485, grad_scale: , lr: 0.00e+00, 
2025-02-07 15:59:49,771 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 40026, num_updates: 39000, {'loss': 0.10417144000530243, 'DER': 0.21925561717454692, 'ACC': np.float64(0.9602160879452769), 'MI': 0.1202332628208793, 'FA': 0.06523354868217941, 'CF': 0.033788805671488197}, batch size: 64, grad_norm: 0.37249162793159485, grad_scale: , lr: 0.00e+00, 
2025-02-07 15:59:49,772 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 15:59:49,772 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 16:00:59,426 (model:870) WARNING: All labels are zero
2025-02-07 16:01:00,210 (model:870) WARNING: All labels are zero
2025-02-07 16:01:00,234 (model:870) WARNING: All labels are zero
2025-02-07 16:03:08,006 (model:870) WARNING: All labels are zero
2025-02-07 16:03:24,565 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 10, batch_idx_train: 40026,  validation: loss=0.07849, DER=0.1784, ACC=0.9645, MI=0.08371, FA=0.06663, CF=0.02809, over 0.00 frames. 
2025-02-07 16:03:24,566 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 16:03:25,023 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 10, batch_idx_train: 40026,  validation: loss=0.07896, DER=0.1756, ACC=0.9643, MI=0.08566, FA=0.06316, CF=0.02677, over 0.00 frames. 
2025-02-07 16:03:25,023 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 16:20:15,993 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-40500.pt
2025-02-07 16:20:17,619 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 16:21:14,795 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 40526, num_updates: 39500, {'loss': 0.1290060132741928, 'DER': 0.33781565656565654, 'ACC': np.float64(0.9424107142857143), 'MI': 0.16041666666666668, 'FA': 0.10801767676767676, 'CF': 0.06938131313131313}, batch size: 64, grad_norm: 0.44138914346694946, grad_scale: , lr: 0.00e+00, 
2025-02-07 16:21:14,796 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 16:21:14,796 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 40526, num_updates: 39500, {'loss': 0.1295894980430603, 'DER': 0.25387630916856824, 'ACC': np.float64(0.9521517857142857), 'MI': 0.1329354631092388, 'FA': 0.06126031244514657, 'CF': 0.0596805336141829}, batch size: 64, grad_norm: 0.44138914346694946, grad_scale: , lr: 0.00e+00, 
2025-02-07 16:21:14,796 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 16:22:24,859 (model:870) WARNING: All labels are zero
2025-02-07 16:22:25,667 (model:870) WARNING: All labels are zero
2025-02-07 16:22:25,684 (model:870) WARNING: All labels are zero
2025-02-07 16:24:35,032 (model:870) WARNING: All labels are zero
2025-02-07 16:24:52,191 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 10, batch_idx_train: 40526,  validation: loss=0.08824, DER=0.2009, ACC=0.96, MI=0.09548, FA=0.06803, CF=0.03744, over 0.00 frames. 
2025-02-07 16:24:52,191 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 16:24:52,266 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 10, batch_idx_train: 40526,  validation: loss=0.08865, DER=0.1971, ACC=0.9599, MI=0.09866, FA=0.06293, CF=0.03547, over 0.00 frames. 
2025-02-07 16:24:52,266 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 16:42:32,473 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 41026, num_updates: 40000, {'loss': 0.2700592279434204, 'DER': 0.6413080311758725, 'ACC': np.float64(0.8778035714285715), 'MI': 0.4185022026431718, 'FA': 0.09115554049474754, 'CF': 0.13165028803795323}, batch size: 64, grad_norm: 0.8256483674049377, grad_scale: , lr: 0.00e+00, 
2025-02-07 16:42:32,473 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 16:42:32,474 (train_accelerate_ddp:702) INFO: [Train] - Epoch 10, batch_idx_train: 41026, num_updates: 40000, {'loss': 0.13648349046707153, 'DER': 0.28736612138327916, 'ACC': np.float64(0.9414375), 'MI': 0.16768796291362498, 'FA': 0.05754782330686844, 'CF': 0.06213033516278574}, batch size: 64, grad_norm: 0.8256483674049377, grad_scale: , lr: 0.00e+00, 
2025-02-07 16:42:32,474 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 16:43:42,209 (model:870) WARNING: All labels are zero
2025-02-07 16:43:43,000 (model:870) WARNING: All labels are zero
2025-02-07 16:43:43,570 (model:870) WARNING: All labels are zero
2025-02-07 16:45:50,920 (model:870) WARNING: All labels are zero
2025-02-07 16:46:08,218 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 10, batch_idx_train: 41026,  validation: loss=0.07596, DER=0.1711, ACC=0.9651, MI=0.08947, FA=0.05588, CF=0.02579, over 0.00 frames. 
2025-02-07 16:46:08,219 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 10, batch_idx_train: 41026,  validation: loss=0.07528, DER=0.1723, ACC=0.9654, MI=0.08782, FA=0.05803, CF=0.02647, over 0.00 frames. 
2025-02-07 16:46:08,219 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 16:46:08,219 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 16:50:07,567 (train_accelerate_ddp:713) INFO: end of epoch 10, batch_idx: 4113 batch_idx_train: 41139, {'loss': 0.1297440230846405, 'DER': 0.2882198812897706, 'ACC': np.float64(0.9415625), 'MI': 0.16068659429977006, 'FA': 0.06577188385647827, 'CF': 0.06176140313352227}, batch size: 64, grad_norm: 0.3388739824295044, grad_scale: , lr: 0.00e+00, 
2025-02-07 16:50:07,567 (train_accelerate_ddp:713) INFO: end of epoch 10, batch_idx: 4113 batch_idx_train: 41139, {'loss': 0.11217129230499268, 'DER': 0.2644364324132632, 'ACC': np.float64(0.9529732142857144), 'MI': 0.16064779242272, 'FA': 0.05691825758023524, 'CF': 0.046870382410307936}, batch size: 64, grad_norm: 0.3388739824295044, grad_scale: , lr: 0.00e+00, 
2025-02-07 16:50:07,568 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-10.pt
2025-02-07 16:50:08,753 (train_accelerate_ddp:561) INFO:  end of epoch 10, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-10.pt 
2025-02-07 16:50:12,000 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 41140, num_updates: 40000, {'loss': 0.1344500184059143, 'DER': 0.3287943604265831, 'ACC': np.float64(0.9402946428571429), 'MI': 0.17804422485991445, 'FA': 0.07664035669096825, 'CF': 0.07410977887570043}, batch size: 64, grad_norm: 0.41801726818084717, grad_scale: , lr: 0.00e+00, 
2025-02-07 16:50:12,001 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 41140, num_updates: 40000, {'loss': 0.11177464574575424, 'DER': 0.23699319325244156, 'ACC': np.float64(0.9596875), 'MI': 0.15010358094110685, 'FA': 0.0566439775081385, 'CF': 0.03024563480319621}, batch size: 64, grad_norm: 0.41801726818084717, grad_scale: , lr: 0.00e+00, 
2025-02-07 17:07:46,799 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 41640, num_updates: 40500, {'loss': 0.11971381306648254, 'DER': 0.29616238503013004, 'ACC': np.float64(0.946951894768117), 'MI': 0.14208690136378052, 'FA': 0.07649857278782113, 'CF': 0.07757691087852839}, batch size: 64, grad_norm: 0.3774751126766205, grad_scale: , lr: 0.00e+00, 
2025-02-07 17:07:46,799 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 17:07:46,799 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 41640, num_updates: 40500, {'loss': 0.12012538313865662, 'DER': 0.26326770811042155, 'ACC': np.float64(0.9476607142857143), 'MI': 0.15503958912903917, 'FA': 0.05788572651401669, 'CF': 0.050342392467365715}, batch size: 64, grad_norm: 0.3774751126766205, grad_scale: , lr: 0.00e+00, 
2025-02-07 17:07:46,800 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 17:08:57,784 (model:870) WARNING: All labels are zero
2025-02-07 17:08:58,599 (model:870) WARNING: All labels are zero
2025-02-07 17:08:58,624 (model:870) WARNING: All labels are zero
2025-02-07 17:11:07,811 (model:870) WARNING: All labels are zero
2025-02-07 17:11:25,016 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 11, batch_idx_train: 41640,  validation: loss=0.07667, DER=0.1756, ACC=0.9648, MI=0.08326, FA=0.06383, CF=0.02852, over 0.00 frames. 
2025-02-07 17:11:25,017 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 17:11:25,737 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 11, batch_idx_train: 41640,  validation: loss=0.07707, DER=0.1718, ACC=0.9647, MI=0.08532, FA=0.05959, CF=0.02687, over 0.00 frames. 
2025-02-07 17:11:25,737 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 17:24:04,033 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-42000.pt
2025-02-07 17:24:05,807 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 17:24:05,923 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-07 17:29:07,070 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 42140, num_updates: 41000, {'loss': 0.17184549570083618, 'DER': 0.3561250474074877, 'ACC': np.float64(0.9268482142857143), 'MI': 0.22668906106084413, 'FA': 0.04166440916725361, 'CF': 0.08777157717938994}, batch size: 64, grad_norm: 0.6177408695220947, grad_scale: , lr: 0.00e+00, 
2025-02-07 17:29:07,071 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 17:29:07,071 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 42140, num_updates: 41000, {'loss': 0.1593717336654663, 'DER': 0.3540259887646825, 'ACC': np.float64(0.9328214285714286), 'MI': 0.1996822334449299, 'FA': 0.08142767973670771, 'CF': 0.07291607558304489}, batch size: 64, grad_norm: 0.6177408695220947, grad_scale: , lr: 0.00e+00, 
2025-02-07 17:29:07,072 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 17:30:16,754 (model:870) WARNING: All labels are zero
2025-02-07 17:30:17,567 (model:870) WARNING: All labels are zero
2025-02-07 17:30:17,626 (model:870) WARNING: All labels are zero
2025-02-07 17:32:25,940 (model:870) WARNING: All labels are zero
2025-02-07 17:32:42,865 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 11, batch_idx_train: 42140,  validation: loss=0.1023, DER=0.2346, ACC=0.9541, MI=0.1479, FA=0.05113, CF=0.03561, over 0.00 frames. 
2025-02-07 17:32:42,866 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 17:32:42,949 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 11, batch_idx_train: 42140,  validation: loss=0.1012, DER=0.2339, ACC=0.955, MI=0.1398, FA=0.05678, CF=0.03739, over 0.00 frames. 
2025-02-07 17:32:42,950 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 17:50:38,827 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 42640, num_updates: 41500, {'loss': 0.15260417759418488, 'DER': 0.3750812695785803, 'ACC': np.float64(0.9331762555768576), 'MI': 0.20799101601749512, 'FA': 0.10130622377209055, 'CF': 0.06578402978899463}, batch size: 64, grad_norm: 0.5328845381736755, grad_scale: , lr: 0.00e+00, 
2025-02-07 17:50:38,828 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 17:50:38,828 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 42640, num_updates: 41500, {'loss': 0.15375007688999176, 'DER': 0.346431718061674, 'ACC': np.float64(0.9296964285714285), 'MI': 0.17527165932452277, 'FA': 0.05509544787077827, 'CF': 0.11606461086637299}, batch size: 64, grad_norm: 0.5328845381736755, grad_scale: , lr: 0.00e+00, 
2025-02-07 17:50:38,828 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 17:51:47,235 (model:870) WARNING: All labels are zero
2025-02-07 17:51:48,014 (model:870) WARNING: All labels are zero
2025-02-07 17:51:48,240 (model:870) WARNING: All labels are zero
2025-02-07 17:53:54,249 (model:870) WARNING: All labels are zero
2025-02-07 17:54:10,160 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 11, batch_idx_train: 42640,  validation: loss=0.08207, DER=0.1821, ACC=0.9631, MI=0.1048, FA=0.04988, CF=0.0275, over 0.00 frames. 
2025-02-07 17:54:10,160 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 17:54:11,061 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 11, batch_idx_train: 42640,  validation: loss=0.08141, DER=0.1848, ACC=0.9634, MI=0.1027, FA=0.05395, CF=0.02816, over 0.00 frames. 
2025-02-07 17:54:11,062 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 18:11:47,073 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 43140, num_updates: 42000, {'loss': 0.13841359317302704, 'DER': 0.2955100307822949, 'ACC': np.float64(0.9418482142857143), 'MI': 0.1940876764674663, 'FA': 0.051268442840462794, 'CF': 0.05015391147436578}, batch size: 64, grad_norm: 0.3580436706542969, grad_scale: , lr: 0.00e+00, 
2025-02-07 18:11:47,074 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 43140, num_updates: 42000, {'loss': 0.12003610283136368, 'DER': 0.28197381671701915, 'ACC': np.float64(0.9514017857142857), 'MI': 0.1713168651146259, 'FA': 0.07019726319530833, 'CF': 0.04045968840708489}, batch size: 64, grad_norm: 0.3580436706542969, grad_scale: , lr: 0.00e+00, 
2025-02-07 18:11:47,074 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 18:11:47,074 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 18:12:56,750 (model:870) WARNING: All labels are zero
2025-02-07 18:12:57,502 (model:870) WARNING: All labels are zero
2025-02-07 18:12:57,560 (model:870) WARNING: All labels are zero
2025-02-07 18:15:04,495 (model:870) WARNING: All labels are zero
2025-02-07 18:15:21,396 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 11, batch_idx_train: 43140,  validation: loss=0.09013, DER=0.2077, ACC=0.9593, MI=0.1218, FA=0.05288, CF=0.03302, over 0.00 frames. 
2025-02-07 18:15:21,396 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 18:15:21,511 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 11, batch_idx_train: 43140,  validation: loss=0.09093, DER=0.2061, ACC=0.9588, MI=0.127, FA=0.04741, CF=0.03166, over 0.00 frames. 
2025-02-07 18:15:21,511 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 18:28:00,392 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-43500.pt
2025-02-07 18:28:02,083 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 18:32:59,866 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 43640, num_updates: 42500, {'loss': 0.2068140208721161, 'DER': 0.5153626295105395, 'ACC': np.float64(0.9098329775210348), 'MI': 0.34512325830653806, 'FA': 0.08705490055972372, 'CF': 0.08318447064427772}, batch size: 64, grad_norm: 0.6111736297607422, grad_scale: , lr: 0.00e+00, 
2025-02-07 18:32:59,866 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 18:32:59,867 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 43640, num_updates: 42500, {'loss': 0.14218446612358093, 'DER': 0.34528832630098455, 'ACC': np.float64(0.9380357142857143), 'MI': 0.20833333333333334, 'FA': 0.07553914674167839, 'CF': 0.061415846225972806}, batch size: 64, grad_norm: 0.6111736297607422, grad_scale: , lr: 0.00e+00, 
2025-02-07 18:32:59,867 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 18:34:09,179 (model:870) WARNING: All labels are zero
2025-02-07 18:34:09,996 (model:870) WARNING: All labels are zero
2025-02-07 18:34:10,005 (model:870) WARNING: All labels are zero
2025-02-07 18:36:18,684 (model:870) WARNING: All labels are zero
2025-02-07 18:36:35,280 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 11, batch_idx_train: 43640,  validation: loss=0.07872, DER=0.1802, ACC=0.9641, MI=0.1008, FA=0.05149, CF=0.02783, over 0.00 frames. 
2025-02-07 18:36:35,281 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 18:36:35,539 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 11, batch_idx_train: 43640,  validation: loss=0.07946, DER=0.1778, ACC=0.9636, MI=0.1027, FA=0.04771, CF=0.02745, over 0.00 frames. 
2025-02-07 18:36:35,539 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 18:54:28,982 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 44140, num_updates: 43000, {'loss': 0.17802755534648895, 'DER': 0.4002444240757715, 'ACC': np.float64(0.9268153592700545), 'MI': 0.2139932783379163, 'FA': 0.09245340666055607, 'CF': 0.09379773907729912}, batch size: 64, grad_norm: 0.5368144512176514, grad_scale: , lr: 0.00e+00, 
2025-02-07 18:54:28,982 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 18:54:28,983 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 44140, num_updates: 43000, {'loss': 0.13580608367919922, 'DER': 0.2722811883300443, 'ACC': np.float64(0.9426785714285715), 'MI': 0.14155421622486533, 'FA': 0.06058989812790015, 'CF': 0.0701370739772788}, batch size: 64, grad_norm: 0.5368144512176514, grad_scale: , lr: 0.00e+00, 
2025-02-07 18:54:28,983 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 18:55:38,471 (model:870) WARNING: All labels are zero
2025-02-07 18:55:39,276 (model:870) WARNING: All labels are zero
2025-02-07 18:55:39,293 (model:870) WARNING: All labels are zero
2025-02-07 18:57:47,508 (model:870) WARNING: All labels are zero
2025-02-07 18:58:04,615 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 11, batch_idx_train: 44140,  validation: loss=0.07645, DER=0.1741, ACC=0.9652, MI=0.09029, FA=0.05728, CF=0.0265, over 0.00 frames. 
2025-02-07 18:58:04,615 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 18:58:04,667 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 11, batch_idx_train: 44140,  validation: loss=0.07703, DER=0.172, ACC=0.9649, MI=0.09202, FA=0.05435, CF=0.02565, over 0.00 frames. 
2025-02-07 18:58:04,667 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 19:15:41,484 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 44640, num_updates: 43500, {'loss': 0.14593283832073212, 'DER': 0.31268925327086783, 'ACC': np.float64(0.9416517857142856), 'MI': 0.17625549905730445, 'FA': 0.075758441410044, 'CF': 0.0606753128035194}, batch size: 64, grad_norm: 0.427984356880188, grad_scale: , lr: 0.00e+00, 
2025-02-07 19:15:41,485 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 19:15:41,485 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 44640, num_updates: 43500, {'loss': 0.1380714774131775, 'DER': 0.3065631376105192, 'ACC': np.float64(0.9416071428571429), 'MI': 0.17059623668102472, 'FA': 0.07186579007027885, 'CF': 0.0641011108592156}, batch size: 64, grad_norm: 0.427984356880188, grad_scale: , lr: 0.00e+00, 
2025-02-07 19:15:41,485 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 19:16:51,230 (model:870) WARNING: All labels are zero
2025-02-07 19:16:52,044 (model:870) WARNING: All labels are zero
2025-02-07 19:16:52,053 (model:870) WARNING: All labels are zero
2025-02-07 19:19:01,340 (model:870) WARNING: All labels are zero
2025-02-07 19:19:18,514 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 11, batch_idx_train: 44640,  validation: loss=0.0923, DER=0.2163, ACC=0.9579, MI=0.131, FA=0.04976, CF=0.03559, over 0.00 frames. 
2025-02-07 19:19:18,515 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 19:19:18,560 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 11, batch_idx_train: 44640,  validation: loss=0.09358, DER=0.2146, ACC=0.957, MI=0.1355, FA=0.04429, CF=0.03479, over 0.00 frames. 
2025-02-07 19:19:18,560 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 19:32:19,232 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-45000.pt
2025-02-07 19:32:20,912 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 19:37:20,213 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 45140, num_updates: 44000, {'loss': 0.14550518989562988, 'DER': 0.30576145552560646, 'ACC': np.float64(0.9417142857142856), 'MI': 0.1817160826594789, 'FA': 0.06323000898472597, 'CF': 0.060815363881401616}, batch size: 64, grad_norm: 0.4035309851169586, grad_scale: , lr: 0.00e+00, 
2025-02-07 19:37:20,213 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 19:37:20,213 (train_accelerate_ddp:702) INFO: [Train] - Epoch 11, batch_idx_train: 45140, num_updates: 44000, {'loss': 0.12350370734930038, 'DER': 0.2607405649181106, 'ACC': np.float64(0.9500892857142856), 'MI': 0.12135058153334916, 'FA': 0.06841917873249466, 'CF': 0.0709708046522668}, batch size: 64, grad_norm: 0.4035309851169586, grad_scale: , lr: 0.00e+00, 
2025-02-07 19:37:20,213 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 19:38:30,242 (model:870) WARNING: All labels are zero
2025-02-07 19:38:31,048 (model:870) WARNING: All labels are zero
2025-02-07 19:38:31,063 (model:870) WARNING: All labels are zero
2025-02-07 19:40:39,963 (model:870) WARNING: All labels are zero
2025-02-07 19:40:57,128 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 11, batch_idx_train: 45140,  validation: loss=0.07488, DER=0.1718, ACC=0.9656, MI=0.09009, FA=0.05578, CF=0.02592, over 0.00 frames. 
2025-02-07 19:40:57,129 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 19:40:57,198 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 11, batch_idx_train: 45140,  validation: loss=0.07558, DER=0.17, ACC=0.9651, MI=0.09158, FA=0.05281, CF=0.02564, over 0.00 frames. 
2025-02-07 19:40:57,198 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 19:44:56,090 (train_accelerate_ddp:713) INFO: end of epoch 11, batch_idx: 4113 batch_idx_train: 45253, {'loss': 0.13516980409622192, 'DER': 0.2916287534121929, 'ACC': np.float64(0.9457589285714285), 'MI': 0.1941537761601456, 'FA': 0.04361919927206551, 'CF': 0.053855777979981805}, batch size: 64, grad_norm: 0.43677762150764465, grad_scale: , lr: 0.00e+00, 
2025-02-07 19:44:56,090 (train_accelerate_ddp:713) INFO: end of epoch 11, batch_idx: 4113 batch_idx_train: 45253, {'loss': 0.13212157785892487, 'DER': 0.3201754385964912, 'ACC': np.float64(0.9427678571428572), 'MI': 0.1939900426742532, 'FA': 0.06644144144144144, 'CF': 0.059743954480796585}, batch size: 64, grad_norm: 0.43677762150764465, grad_scale: , lr: 0.00e+00, 
2025-02-07 19:44:56,092 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-11.pt
2025-02-07 19:44:57,394 (train_accelerate_ddp:561) INFO:  end of epoch 11, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-11.pt 
2025-02-07 19:45:00,538 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 45254, num_updates: 44000, {'loss': 0.12853826582431793, 'DER': 0.2841199333703498, 'ACC': np.float64(0.9470892857142856), 'MI': 0.17840088839533594, 'FA': 0.06079955580233204, 'CF': 0.04491948917268184}, batch size: 64, grad_norm: 0.3685961663722992, grad_scale: , lr: 0.00e+00, 
2025-02-07 19:45:00,538 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 45254, num_updates: 44000, {'loss': 0.09994111955165863, 'DER': 0.23312847181184257, 'ACC': np.float64(0.96075), 'MI': 0.1320174920222196, 'FA': 0.0744592837726037, 'CF': 0.026651696017019263}, batch size: 64, grad_norm: 0.3685961663722992, grad_scale: , lr: 0.00e+00, 
2025-02-07 20:02:41,555 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 45754, num_updates: 44500, {'loss': 0.1457992047071457, 'DER': 0.31454661780957366, 'ACC': np.float64(0.9401875), 'MI': 0.15674984005118361, 'FA': 0.08270807886930727, 'CF': 0.07508869888908276}, batch size: 64, grad_norm: 0.5479753613471985, grad_scale: , lr: 0.00e+00, 
2025-02-07 20:02:41,556 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 20:02:41,556 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 45754, num_updates: 44500, {'loss': 0.13672316074371338, 'DER': 0.2877258235919235, 'ACC': np.float64(0.9443571428571429), 'MI': 0.19495217853347502, 'FA': 0.04936238044633369, 'CF': 0.043411264612114774}, batch size: 64, grad_norm: 0.5479753613471985, grad_scale: , lr: 0.00e+00, 
2025-02-07 20:02:41,556 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 20:03:51,560 (model:870) WARNING: All labels are zero
2025-02-07 20:03:52,345 (model:870) WARNING: All labels are zero
2025-02-07 20:03:52,380 (model:870) WARNING: All labels are zero
2025-02-07 20:06:00,647 (model:870) WARNING: All labels are zero
2025-02-07 20:06:17,776 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 12, batch_idx_train: 45754,  validation: loss=0.08149, DER=0.1857, ACC=0.9631, MI=0.1051, FA=0.05149, CF=0.02914, over 0.00 frames. 
2025-02-07 20:06:17,776 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 20:06:17,814 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 12, batch_idx_train: 45754,  validation: loss=0.08219, DER=0.1828, ACC=0.9627, MI=0.1075, FA=0.04704, CF=0.02817, over 0.00 frames. 
2025-02-07 20:06:17,814 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 20:24:03,130 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 46254, num_updates: 45000, {'loss': 0.1304696649312973, 'DER': 0.285512404480268, 'ACC': np.float64(0.9423660714285714), 'MI': 0.1876373913953732, 'FA': 0.045535433895111485, 'CF': 0.05233957918978331}, batch size: 64, grad_norm: 0.3863089084625244, grad_scale: , lr: 0.00e+00, 
2025-02-07 20:24:03,131 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 46254, num_updates: 45000, {'loss': 0.1092894896864891, 'DER': 0.2591011647051649, 'ACC': np.float64(0.955875), 'MI': 0.1515336300993963, 'FA': 0.06530886029635953, 'CF': 0.04225867430940911}, batch size: 64, grad_norm: 0.3863089084625244, grad_scale: , lr: 0.00e+00, 
2025-02-07 20:24:03,131 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 20:24:03,131 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 20:25:12,365 (model:870) WARNING: All labels are zero
2025-02-07 20:25:13,178 (model:870) WARNING: All labels are zero
2025-02-07 20:25:13,229 (model:870) WARNING: All labels are zero
2025-02-07 20:27:24,488 (model:870) WARNING: All labels are zero
2025-02-07 20:27:41,769 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 12, batch_idx_train: 46254,  validation: loss=0.07695, DER=0.1756, ACC=0.965, MI=0.09445, FA=0.05474, CF=0.02639, over 0.00 frames. 
2025-02-07 20:27:41,770 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 20:27:41,792 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 12, batch_idx_train: 46254,  validation: loss=0.07753, DER=0.1736, ACC=0.9645, MI=0.09616, FA=0.05126, CF=0.02618, over 0.00 frames. 
2025-02-07 20:27:41,792 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 20:36:41,956 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-46500.pt
2025-02-07 20:36:43,588 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 20:36:43,590 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-07 20:45:40,183 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 46754, num_updates: 45500, {'loss': 0.13410577178001404, 'DER': 0.32236268526591105, 'ACC': np.float64(0.9379642857142857), 'MI': 0.20384699215344376, 'FA': 0.062282040104620746, 'CF': 0.05623365300784656}, batch size: 64, grad_norm: 0.5838335156440735, grad_scale: , lr: 0.00e+00, 
2025-02-07 20:45:40,183 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 20:45:40,184 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 46754, num_updates: 45500, {'loss': 0.14206936955451965, 'DER': 0.33329643568740314, 'ACC': np.float64(0.9335982142857143), 'MI': 0.1833628514500775, 'FA': 0.07161833075049812, 'CF': 0.07831525348682754}, batch size: 64, grad_norm: 0.5838335156440735, grad_scale: , lr: 0.00e+00, 
2025-02-07 20:45:40,184 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 20:46:49,431 (model:870) WARNING: All labels are zero
2025-02-07 20:46:50,236 (model:870) WARNING: All labels are zero
2025-02-07 20:46:50,296 (model:870) WARNING: All labels are zero
2025-02-07 20:48:56,035 (model:870) WARNING: All labels are zero
2025-02-07 20:49:12,196 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 12, batch_idx_train: 46754,  validation: loss=0.1486, DER=0.3564, ACC=0.9353, MI=0.2951, FA=0.02651, CF=0.03487, over 0.00 frames. 
2025-02-07 20:49:12,197 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 20:49:12,722 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 12, batch_idx_train: 46754,  validation: loss=0.1433, DER=0.3568, ACC=0.9365, MI=0.289, FA=0.03005, CF=0.03782, over 0.00 frames. 
2025-02-07 20:49:12,722 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 21:06:55,501 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 47254, num_updates: 46000, {'loss': 0.18012356758117676, 'DER': 0.4039032006245121, 'ACC': np.float64(0.9162857142857144), 'MI': 0.25807962529274003, 'FA': 0.061774655217278165, 'CF': 0.08404892011449389}, batch size: 64, grad_norm: 0.6860054135322571, grad_scale: , lr: 0.00e+00, 
2025-02-07 21:06:55,502 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 21:06:55,503 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 47254, num_updates: 46000, {'loss': 0.148329958319664, 'DER': 0.3595679012345679, 'ACC': np.float64(0.9301964285714286), 'MI': 0.18495656149977138, 'FA': 0.08733424782807499, 'CF': 0.08727709190672153}, batch size: 64, grad_norm: 0.6860054135322571, grad_scale: , lr: 0.00e+00, 
2025-02-07 21:06:55,503 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 21:08:05,059 (model:870) WARNING: All labels are zero
2025-02-07 21:08:05,867 (model:870) WARNING: All labels are zero
2025-02-07 21:08:05,895 (model:870) WARNING: All labels are zero
2025-02-07 21:10:13,105 (model:870) WARNING: All labels are zero
2025-02-07 21:10:29,888 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 12, batch_idx_train: 47254,  validation: loss=0.0956, DER=0.2298, ACC=0.9561, MI=0.1543, FA=0.04225, CF=0.03322, over 0.00 frames. 
2025-02-07 21:10:29,888 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 21:10:30,224 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 12, batch_idx_train: 47254,  validation: loss=0.09713, DER=0.2306, ACC=0.955, MI=0.1622, FA=0.03692, CF=0.03146, over 0.00 frames. 
2025-02-07 21:10:30,225 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 21:28:33,158 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 47754, num_updates: 46500, {'loss': 0.1270732432603836, 'DER': 0.267591674925669, 'ACC': np.float64(0.9441160714285715), 'MI': 0.15726879140368263, 'FA': 0.05143185019039174, 'CF': 0.058891033331594594}, batch size: 64, grad_norm: 0.3602653741836548, grad_scale: , lr: 0.00e+00, 
2025-02-07 21:28:33,159 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 21:28:33,159 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 47754, num_updates: 46500, {'loss': 0.15454113483428955, 'DER': 0.32497929892354405, 'ACC': np.float64(0.9341517857142857), 'MI': 0.1683687551752691, 'FA': 0.07446867237096329, 'CF': 0.08214187137731162}, batch size: 64, grad_norm: 0.3602653741836548, grad_scale: , lr: 0.00e+00, 
2025-02-07 21:28:33,159 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 21:29:43,512 (model:870) WARNING: All labels are zero
2025-02-07 21:29:44,334 (model:870) WARNING: All labels are zero
2025-02-07 21:29:44,335 (model:870) WARNING: All labels are zero
2025-02-07 21:31:52,989 (model:870) WARNING: All labels are zero
2025-02-07 21:32:09,996 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 12, batch_idx_train: 47754,  validation: loss=0.07924, DER=0.1801, ACC=0.964, MI=0.09796, FA=0.05376, CF=0.02842, over 0.00 frames. 
2025-02-07 21:32:09,996 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 21:32:10,128 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 12, batch_idx_train: 47754,  validation: loss=0.07997, DER=0.1776, ACC=0.9637, MI=0.1001, FA=0.05002, CF=0.02753, over 0.00 frames. 
2025-02-07 21:32:10,128 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 21:40:58,104 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-48000.pt
2025-02-07 21:40:59,703 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 21:50:00,997 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 48254, num_updates: 47000, {'loss': 0.13871827721595764, 'DER': 0.3100588550026752, 'ACC': np.float64(0.9399553571428572), 'MI': 0.20251471375066882, 'FA': 0.05778491171749599, 'CF': 0.04975922953451043}, batch size: 64, grad_norm: 0.44550609588623047, grad_scale: , lr: 0.00e+00, 
2025-02-07 21:50:00,997 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 48254, num_updates: 47000, {'loss': 0.11226929724216461, 'DER': 0.2712505168645519, 'ACC': np.float64(0.9493392857142857), 'MI': 0.1592533522358084, 'FA': 0.04808317089018843, 'CF': 0.06391399373855514}, batch size: 64, grad_norm: 0.44550609588623047, grad_scale: , lr: 0.00e+00, 
2025-02-07 21:50:00,997 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 21:50:00,997 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 21:51:10,854 (model:870) WARNING: All labels are zero
2025-02-07 21:51:11,668 (model:870) WARNING: All labels are zero
2025-02-07 21:51:11,695 (model:870) WARNING: All labels are zero
2025-02-07 21:53:20,725 (model:870) WARNING: All labels are zero
2025-02-07 21:53:37,954 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 12, batch_idx_train: 48254,  validation: loss=0.1078, DER=0.2611, ACC=0.9509, MI=0.176, FA=0.04832, CF=0.03681, over 0.00 frames. 
2025-02-07 21:53:37,954 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 21:53:37,986 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 12, batch_idx_train: 48254,  validation: loss=0.1099, DER=0.265, ACC=0.9493, MI=0.1877, FA=0.04269, CF=0.03464, over 0.00 frames. 
2025-02-07 21:53:37,986 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 22:11:20,978 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 48754, num_updates: 47500, {'loss': 0.12774261832237244, 'DER': 0.274895078214422, 'ACC': np.float64(0.9520803571428571), 'MI': 0.1397685361821188, 'FA': 0.06873966679384459, 'CF': 0.0663868752384586}, batch size: 64, grad_norm: 0.3695627450942993, grad_scale: , lr: 0.00e+00, 
2025-02-07 22:11:20,978 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 48754, num_updates: 47500, {'loss': 0.10788802802562714, 'DER': 0.22817670324772993, 'ACC': np.float64(0.9554910714285715), 'MI': 0.11258425714444878, 'FA': 0.06606874268842962, 'CF': 0.04952370341485154}, batch size: 64, grad_norm: 0.3695627450942993, grad_scale: , lr: 0.00e+00, 
2025-02-07 22:11:20,979 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 22:11:20,979 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 22:12:29,714 (model:870) WARNING: All labels are zero
2025-02-07 22:12:30,520 (model:870) WARNING: All labels are zero
2025-02-07 22:12:30,595 (model:870) WARNING: All labels are zero
2025-02-07 22:14:35,138 (model:870) WARNING: All labels are zero
2025-02-07 22:14:51,306 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 12, batch_idx_train: 48754,  validation: loss=0.08654, DER=0.1966, ACC=0.9606, MI=0.1245, FA=0.04319, CF=0.02893, over 0.00 frames. 
2025-02-07 22:14:51,307 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 22:14:51,999 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 12, batch_idx_train: 48754,  validation: loss=0.08569, DER=0.1982, ACC=0.9611, MI=0.1198, FA=0.04846, CF=0.02996, over 0.00 frames. 
2025-02-07 22:14:51,999 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 22:32:49,423 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 49254, num_updates: 48000, {'loss': 0.1534353345632553, 'DER': 0.3685225082208867, 'ACC': np.float64(0.9309756184756185), 'MI': 0.22179385417847827, 'FA': 0.07738972672638621, 'CF': 0.06933892731602223}, batch size: 64, grad_norm: 0.5205403566360474, grad_scale: , lr: 0.00e+00, 
2025-02-07 22:32:49,423 (train_accelerate_ddp:702) INFO: [Train] - Epoch 12, batch_idx_train: 49254, num_updates: 48000, {'loss': 0.1537240594625473, 'DER': 0.3133047210300429, 'ACC': np.float64(0.9369821428571429), 'MI': 0.17262137004626274, 'FA': 0.06058748118833956, 'CF': 0.08009586979544062}, batch size: 64, grad_norm: 0.5205403566360474, grad_scale: , lr: 0.00e+00, 
2025-02-07 22:32:49,424 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 22:32:49,424 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 22:33:59,534 (model:870) WARNING: All labels are zero
2025-02-07 22:34:00,350 (model:870) WARNING: All labels are zero
2025-02-07 22:34:00,368 (model:870) WARNING: All labels are zero
2025-02-07 22:36:09,863 (model:870) WARNING: All labels are zero
2025-02-07 22:36:27,103 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 12, batch_idx_train: 49254,  validation: loss=0.07607, DER=0.17, ACC=0.9652, MI=0.08572, FA=0.05902, CF=0.0253, over 0.00 frames. 
2025-02-07 22:36:27,104 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 22:36:27,120 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 12, batch_idx_train: 49254,  validation: loss=0.07546, DER=0.172, ACC=0.9656, MI=0.08401, FA=0.06221, CF=0.02576, over 0.00 frames. 
2025-02-07 22:36:27,120 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 22:40:23,263 (train_accelerate_ddp:713) INFO: end of epoch 12, batch_idx: 4113 batch_idx_train: 49367, {'loss': 0.12041860073804855, 'DER': 0.2746511095859071, 'ACC': np.float64(0.9489821428571429), 'MI': 0.15825897963852664, 'FA': 0.0642301532830016, 'CF': 0.05216197666437886}, batch size: 64, grad_norm: 0.41303780674934387, grad_scale: , lr: 0.00e+00, 
2025-02-07 22:40:23,264 (train_accelerate_ddp:713) INFO: end of epoch 12, batch_idx: 4113 batch_idx_train: 49367, {'loss': 0.12983012199401855, 'DER': 0.3028392991383797, 'ACC': np.float64(0.9455892857142857), 'MI': 0.1978257098247846, 'FA': 0.05545596484126525, 'CF': 0.04955762447232984}, batch size: 64, grad_norm: 0.41303780674934387, grad_scale: , lr: 0.00e+00, 
2025-02-07 22:40:23,265 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-12.pt
2025-02-07 22:40:24,514 (train_accelerate_ddp:561) INFO:  end of epoch 12, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-12.pt 
2025-02-07 22:40:27,717 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 49368, num_updates: 48000, {'loss': 0.1098550334572792, 'DER': 0.2408629296000918, 'ACC': np.float64(0.9552589285714286), 'MI': 0.13156233863101727, 'FA': 0.06265419702794194, 'CF': 0.0466463939411326}, batch size: 64, grad_norm: 0.44273611903190613, grad_scale: , lr: 0.00e+00, 
2025-02-07 22:40:27,718 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 49368, num_updates: 48000, {'loss': 0.15873748064041138, 'DER': 0.3739709033494981, 'ACC': np.float64(0.9284821428571429), 'MI': 0.2176609901883388, 'FA': 0.07860606744107364, 'CF': 0.0777038457200857}, batch size: 64, grad_norm: 0.44273611903190613, grad_scale: , lr: 0.00e+00, 
2025-02-07 22:45:04,998 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-49500.pt
2025-02-07 22:45:06,573 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-07 22:45:06,581 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-07 22:58:09,245 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 49868, num_updates: 48500, {'loss': 0.13113734126091003, 'DER': 0.3202860136842754, 'ACC': np.float64(0.9440803571428571), 'MI': 0.1635948961351168, 'FA': 0.09092029834186033, 'CF': 0.06577081920729828}, batch size: 64, grad_norm: 0.4999009966850281, grad_scale: , lr: 0.00e+00, 
2025-02-07 22:58:09,245 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 22:58:09,246 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 49868, num_updates: 48500, {'loss': 0.1285654455423355, 'DER': 0.3077652637818613, 'ACC': np.float64(0.9425357142857144), 'MI': 0.16710136336692352, 'FA': 0.06692353289863663, 'CF': 0.07374036751630113}, batch size: 64, grad_norm: 0.4999009966850281, grad_scale: , lr: 0.00e+00, 
2025-02-07 22:58:09,246 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 22:59:18,458 (model:870) WARNING: All labels are zero
2025-02-07 22:59:19,273 (model:870) WARNING: All labels are zero
2025-02-07 22:59:19,282 (model:870) WARNING: All labels are zero
2025-02-07 23:01:27,277 (model:870) WARNING: All labels are zero
2025-02-07 23:01:44,334 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 13, batch_idx_train: 49868,  validation: loss=0.09149, DER=0.2028, ACC=0.9593, MI=0.1097, FA=0.0595, CF=0.03355, over 0.00 frames. 
2025-02-07 23:01:44,334 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 23:01:44,358 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 13, batch_idx_train: 49868,  validation: loss=0.09104, DER=0.2066, ACC=0.9594, MI=0.1061, FA=0.06485, CF=0.03565, over 0.00 frames. 
2025-02-07 23:01:44,358 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 23:19:43,087 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 50368, num_updates: 49000, {'loss': 0.12650009989738464, 'DER': 0.2739237887234899, 'ACC': np.float64(0.9495446428571429), 'MI': 0.15179033277774584, 'FA': 0.07126846370481062, 'CF': 0.05086499224093339}, batch size: 64, grad_norm: 0.3765716254711151, grad_scale: , lr: 0.00e+00, 
2025-02-07 23:19:43,088 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 23:19:43,088 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 50368, num_updates: 49000, {'loss': 0.11251905560493469, 'DER': 0.2574308165357021, 'ACC': np.float64(0.9529821428571429), 'MI': 0.1548229131078465, 'FA': 0.06018676688304293, 'CF': 0.042421136544812665}, batch size: 64, grad_norm: 0.3765716254711151, grad_scale: , lr: 0.00e+00, 
2025-02-07 23:19:43,088 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 23:20:53,277 (model:870) WARNING: All labels are zero
2025-02-07 23:20:54,023 (model:870) WARNING: All labels are zero
2025-02-07 23:20:54,114 (model:870) WARNING: All labels are zero
2025-02-07 23:23:01,520 (model:870) WARNING: All labels are zero
2025-02-07 23:23:18,589 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 13, batch_idx_train: 50368,  validation: loss=0.08033, DER=0.1825, ACC=0.9637, MI=0.08856, FA=0.06466, CF=0.0293, over 0.00 frames. 
2025-02-07 23:23:18,590 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 23:23:18,681 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 13, batch_idx_train: 50368,  validation: loss=0.08081, DER=0.1789, ACC=0.9636, MI=0.09085, FA=0.06016, CF=0.02787, over 0.00 frames. 
2025-02-07 23:23:18,681 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 23:41:00,417 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 50868, num_updates: 49500, {'loss': 0.13849680125713348, 'DER': 0.3259693674201446, 'ACC': np.float64(0.9397767857142857), 'MI': 0.19313329157888742, 'FA': 0.07475943745373798, 'CF': 0.05807663838751922}, batch size: 64, grad_norm: 0.450764536857605, grad_scale: , lr: 0.00e+00, 
2025-02-07 23:41:00,418 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 23:41:00,418 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 50868, num_updates: 49500, {'loss': 0.12820623815059662, 'DER': 0.3003101309441764, 'ACC': np.float64(0.9436339285714286), 'MI': 0.16546060188375833, 'FA': 0.07259361359981621, 'CF': 0.062255915460601885}, batch size: 64, grad_norm: 0.450764536857605, grad_scale: , lr: 0.00e+00, 
2025-02-07 23:41:00,418 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-07 23:42:09,989 (model:870) WARNING: All labels are zero
2025-02-07 23:42:10,810 (model:870) WARNING: All labels are zero
2025-02-07 23:42:10,820 (model:870) WARNING: All labels are zero
2025-02-07 23:44:19,393 (model:870) WARNING: All labels are zero
2025-02-07 23:44:36,062 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 13, batch_idx_train: 50868,  validation: loss=0.1169, DER=0.2856, ACC=0.9467, MI=0.2221, FA=0.03051, CF=0.03296, over 0.00 frames. 
2025-02-07 23:44:36,063 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-07 23:44:36,527 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 13, batch_idx_train: 50868,  validation: loss=0.1131, DER=0.2826, ACC=0.9484, MI=0.2135, FA=0.0347, CF=0.03442, over 0.00 frames. 
2025-02-07 23:44:36,527 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-07 23:49:14,755 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-51000.pt
2025-02-07 23:49:16,333 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 00:02:19,073 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 51368, num_updates: 50000, {'loss': 0.10539475828409195, 'DER': 0.2538494309536851, 'ACC': np.float64(0.9574196428571429), 'MI': 0.13590164932140467, 'FA': 0.08155316170653033, 'CF': 0.036394619925750105}, batch size: 64, grad_norm: 0.3167761564254761, grad_scale: , lr: 0.00e+00, 
2025-02-08 00:02:19,073 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 51368, num_updates: 50000, {'loss': 0.13187521696090698, 'DER': 0.30013196396809916, 'ACC': np.float64(0.9422685222572165), 'MI': 0.1415456996959091, 'FA': 0.08956337139250674, 'CF': 0.06902289287968329}, batch size: 64, grad_norm: 0.3167761564254761, grad_scale: , lr: 0.00e+00, 
2025-02-08 00:02:19,074 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 00:02:19,074 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 00:03:29,099 (model:870) WARNING: All labels are zero
2025-02-08 00:03:29,917 (model:870) WARNING: All labels are zero
2025-02-08 00:03:29,917 (model:870) WARNING: All labels are zero
2025-02-08 00:05:39,336 (model:870) WARNING: All labels are zero
2025-02-08 00:05:56,588 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 13, batch_idx_train: 51368,  validation: loss=0.159, DER=0.3996, ACC=0.9305, MI=0.3386, FA=0.02599, CF=0.03503, over 0.00 frames. 
2025-02-08 00:05:56,589 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 00:05:56,596 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 13, batch_idx_train: 51368,  validation: loss=0.1658, DER=0.3968, ACC=0.9297, MI=0.3424, FA=0.02244, CF=0.032, over 0.00 frames. 
2025-02-08 00:05:56,596 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 00:24:02,488 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 51868, num_updates: 50500, {'loss': 0.1311878263950348, 'DER': 0.305312517870418, 'ACC': np.float64(0.9430535714285715), 'MI': 0.18139189111911705, 'FA': 0.06450506090238463, 'CF': 0.05941556584891634}, batch size: 64, grad_norm: 0.37200918793678284, grad_scale: , lr: 0.00e+00, 
2025-02-08 00:24:02,489 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 00:24:02,489 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 51868, num_updates: 50500, {'loss': 0.10525023192167282, 'DER': 0.2198254294768444, 'ACC': np.float64(0.9599642857142857), 'MI': 0.1360426975037527, 'FA': 0.05431700672708067, 'CF': 0.02946572524601101}, batch size: 64, grad_norm: 0.37200918793678284, grad_scale: , lr: 0.00e+00, 
2025-02-08 00:24:02,489 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 00:25:11,238 (model:870) WARNING: All labels are zero
2025-02-08 00:25:12,048 (model:870) WARNING: All labels are zero
2025-02-08 00:25:12,117 (model:870) WARNING: All labels are zero
2025-02-08 00:27:19,190 (model:870) WARNING: All labels are zero
2025-02-08 00:27:36,106 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 13, batch_idx_train: 51868,  validation: loss=0.08269, DER=0.1828, ACC=0.9625, MI=0.09805, FA=0.05446, CF=0.03029, over 0.00 frames. 
2025-02-08 00:27:36,107 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 00:27:36,145 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 13, batch_idx_train: 51868,  validation: loss=0.08207, DER=0.186, ACC=0.9628, MI=0.09553, FA=0.05911, CF=0.03138, over 0.00 frames. 
2025-02-08 00:27:36,145 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 00:45:16,768 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 52368, num_updates: 51000, {'loss': 0.1505151093006134, 'DER': 0.3482500140900637, 'ACC': np.float64(0.9359642857142857), 'MI': 0.2144507693174773, 'FA': 0.07783351180747337, 'CF': 0.055965732965113}, batch size: 64, grad_norm: 0.45704126358032227, grad_scale: , lr: 0.00e+00, 
2025-02-08 00:45:16,768 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 52368, num_updates: 51000, {'loss': 0.12527596950531006, 'DER': 0.2759383088869715, 'ACC': np.float64(0.9436071428571429), 'MI': 0.12990724762726488, 'FA': 0.08137402933563417, 'CF': 0.06465703192407248}, batch size: 64, grad_norm: 0.45704126358032227, grad_scale: , lr: 0.00e+00, 
2025-02-08 00:45:16,768 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 00:45:16,768 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 00:46:25,524 (model:870) WARNING: All labels are zero
2025-02-08 00:46:26,327 (model:870) WARNING: All labels are zero
2025-02-08 00:46:26,354 (model:870) WARNING: All labels are zero
2025-02-08 00:48:33,133 (model:870) WARNING: All labels are zero
2025-02-08 00:48:49,991 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 13, batch_idx_train: 52368,  validation: loss=0.078, DER=0.1742, ACC=0.9645, MI=0.0917, FA=0.05606, CF=0.02646, over 0.00 frames. 
2025-02-08 00:48:49,992 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 00:48:50,031 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 13, batch_idx_train: 52368,  validation: loss=0.07748, DER=0.1763, ACC=0.9648, MI=0.08984, FA=0.05929, CF=0.02721, over 0.00 frames. 
2025-02-08 00:48:50,031 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 00:53:28,754 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-52500.pt
2025-02-08 00:53:30,370 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 01:06:41,958 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 52868, num_updates: 51500, {'loss': 0.13293088972568512, 'DER': 0.3232800982800983, 'ACC': np.float64(0.9415), 'MI': 0.16517199017199016, 'FA': 0.07893120393120392, 'CF': 0.07917690417690418}, batch size: 64, grad_norm: 0.4024203419685364, grad_scale: , lr: 0.00e+00, 
2025-02-08 01:06:41,958 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 01:06:41,959 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 52868, num_updates: 51500, {'loss': 0.12220225483179092, 'DER': 0.26010476978218916, 'ACC': np.float64(0.9504017857142857), 'MI': 0.16763165150261924, 'FA': 0.04626413013509788, 'CF': 0.04620898814447202}, batch size: 64, grad_norm: 0.4024203419685364, grad_scale: , lr: 0.00e+00, 
2025-02-08 01:06:41,959 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 01:07:52,052 (model:870) WARNING: All labels are zero
2025-02-08 01:07:52,867 (model:870) WARNING: All labels are zero
2025-02-08 01:07:52,894 (model:870) WARNING: All labels are zero
2025-02-08 01:10:03,636 (model:870) WARNING: All labels are zero
2025-02-08 01:10:20,490 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 13, batch_idx_train: 52868,  validation: loss=0.08487, DER=0.1941, ACC=0.9617, MI=0.1094, FA=0.05355, CF=0.03114, over 0.00 frames. 
2025-02-08 01:10:20,491 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 01:10:21,050 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 13, batch_idx_train: 52868,  validation: loss=0.0856, DER=0.1907, ACC=0.9613, MI=0.1118, FA=0.04846, CF=0.03037, over 0.00 frames. 
2025-02-08 01:10:21,050 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 01:28:09,603 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 53368, num_updates: 52000, {'loss': 0.20003752410411835, 'DER': 0.47469111199681147, 'ACC': np.float64(0.9085625), 'MI': 0.2661845926094631, 'FA': 0.10009679439731253, 'CF': 0.10840972499003587}, batch size: 64, grad_norm: 0.48953455686569214, grad_scale: , lr: 0.00e+00, 
2025-02-08 01:28:09,603 (train_accelerate_ddp:702) INFO: [Train] - Epoch 13, batch_idx_train: 53368, num_updates: 52000, {'loss': 0.131400004029274, 'DER': 0.2914117132867133, 'ACC': np.float64(0.9456428571428571), 'MI': 0.20623907342657344, 'FA': 0.04397945804195804, 'CF': 0.041193181818181816}, batch size: 64, grad_norm: 0.48953455686569214, grad_scale: , lr: 0.00e+00, 
2025-02-08 01:28:09,603 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 01:28:09,603 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 01:29:19,401 (model:870) WARNING: All labels are zero
2025-02-08 01:29:20,215 (model:870) WARNING: All labels are zero
2025-02-08 01:29:20,243 (model:870) WARNING: All labels are zero
2025-02-08 01:31:29,773 (model:870) WARNING: All labels are zero
2025-02-08 01:31:46,931 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 13, batch_idx_train: 53368,  validation: loss=0.1266, DER=0.3073, ACC=0.9426, MI=0.2379, FA=0.03351, CF=0.03591, over 0.00 frames. 
2025-02-08 01:31:46,932 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 01:31:46,971 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 13, batch_idx_train: 53368,  validation: loss=0.123, DER=0.3054, ACC=0.944, MI=0.2286, FA=0.0378, CF=0.03898, over 0.00 frames. 
2025-02-08 01:31:46,971 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 01:35:42,457 (train_accelerate_ddp:713) INFO: end of epoch 13, batch_idx: 4113 batch_idx_train: 53481, {'loss': 0.12269614636898041, 'DER': 0.2706081796990888, 'ACC': np.float64(0.9483571428571429), 'MI': 0.19479762661580843, 'FA': 0.03999788090697182, 'CF': 0.03581267217630854}, batch size: 64, grad_norm: 0.34253552556037903, grad_scale: , lr: 0.00e+00, 
2025-02-08 01:35:42,457 (train_accelerate_ddp:713) INFO: end of epoch 13, batch_idx: 4113 batch_idx_train: 53481, {'loss': 0.11867638677358627, 'DER': 0.2744333852979974, 'ACC': np.float64(0.9523482142857144), 'MI': 0.14785945557021227, 'FA': 0.08100491665667346, 'CF': 0.04556901307111164}, batch size: 64, grad_norm: 0.34253552556037903, grad_scale: , lr: 0.00e+00, 
2025-02-08 01:35:42,459 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-13.pt
2025-02-08 01:35:43,643 (train_accelerate_ddp:561) INFO:  end of epoch 13, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-13.pt 
2025-02-08 01:35:46,948 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 53482, num_updates: 52000, {'loss': 0.15115541219711304, 'DER': 0.35649654030398015, 'ACC': np.float64(0.93725), 'MI': 0.21899580105269384, 'FA': 0.07836063634750724, 'CF': 0.05914010290377905}, batch size: 64, grad_norm: 0.4826420545578003, grad_scale: , lr: 0.00e+00, 
2025-02-08 01:35:46,949 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 53482, num_updates: 52000, {'loss': 0.10168065875768661, 'DER': 0.2287987580050456, 'ACC': np.float64(0.9620892857142856), 'MI': 0.09981240701209651, 'FA': 0.08312309981240701, 'CF': 0.04586325118054208}, batch size: 64, grad_norm: 0.4826420545578003, grad_scale: , lr: 0.00e+00, 
2025-02-08 01:53:24,468 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 53982, num_updates: 52500, {'loss': 0.2511129379272461, 'DER': 0.537294155634485, 'ACC': np.float64(0.8909998476525043), 'MI': 0.3679367129480142, 'FA': 0.0520934237434076, 'CF': 0.11726401894306318}, batch size: 64, grad_norm: 1.2025402784347534, grad_scale: , lr: 0.00e+00, 
2025-02-08 01:53:24,469 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 01:53:24,469 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 53982, num_updates: 52500, {'loss': 0.12757450342178345, 'DER': 0.3053222910754619, 'ACC': np.float64(0.9411964285714286), 'MI': 0.16980367174378874, 'FA': 0.05941970232234899, 'CF': 0.07609891700932414}, batch size: 64, grad_norm: 1.2025402784347534, grad_scale: , lr: 0.00e+00, 
2025-02-08 01:53:24,469 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 01:54:34,830 (model:870) WARNING: All labels are zero
2025-02-08 01:54:35,610 (model:870) WARNING: All labels are zero
2025-02-08 01:54:35,652 (model:870) WARNING: All labels are zero
2025-02-08 01:56:44,440 (model:870) WARNING: All labels are zero
2025-02-08 01:57:01,096 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 14, batch_idx_train: 53982,  validation: loss=0.1238, DER=0.3037, ACC=0.9436, MI=0.2359, FA=0.03286, CF=0.03492, over 0.00 frames. 
2025-02-08 01:57:01,097 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 01:57:01,200 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 14, batch_idx_train: 53982,  validation: loss=0.12, DER=0.3023, ACC=0.9452, MI=0.2279, FA=0.03776, CF=0.0367, over 0.00 frames. 
2025-02-08 01:57:01,201 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 01:57:37,382 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-54000.pt
2025-02-08 01:57:39,000 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 01:57:39,002 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-08 02:14:56,758 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 54482, num_updates: 53000, {'loss': 0.13314715027809143, 'DER': 0.29532198547791927, 'ACC': np.float64(0.944375), 'MI': 0.14748244256636114, 'FA': 0.07237233662659208, 'CF': 0.07546720628496607}, batch size: 64, grad_norm: 0.4186233580112457, grad_scale: , lr: 0.00e+00, 
2025-02-08 02:14:56,758 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 02:14:56,759 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 54482, num_updates: 53000, {'loss': 0.08885328471660614, 'DER': 0.19871756812919314, 'ACC': np.float64(0.9658303571428571), 'MI': 0.11173781392863504, 'FA': 0.0584812681826278, 'CF': 0.028498486017930296}, batch size: 64, grad_norm: 0.4186233580112457, grad_scale: , lr: 0.00e+00, 
2025-02-08 02:14:56,759 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 02:16:06,326 (model:870) WARNING: All labels are zero
2025-02-08 02:16:07,147 (model:870) WARNING: All labels are zero
2025-02-08 02:16:07,182 (model:870) WARNING: All labels are zero
2025-02-08 02:18:14,682 (model:870) WARNING: All labels are zero
2025-02-08 02:18:31,550 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 14, batch_idx_train: 54482,  validation: loss=0.08659, DER=0.1921, ACC=0.9611, MI=0.1117, FA=0.05022, CF=0.03022, over 0.00 frames. 
2025-02-08 02:18:31,550 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 02:18:31,636 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 14, batch_idx_train: 54482,  validation: loss=0.08578, DER=0.1956, ACC=0.9614, MI=0.109, FA=0.05555, CF=0.03107, over 0.00 frames. 
2025-02-08 02:18:31,637 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 02:36:11,968 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 54982, num_updates: 53500, {'loss': 0.13007840514183044, 'DER': 0.3121661397579854, 'ACC': np.float64(0.9411607142857144), 'MI': 0.19862640357571132, 'FA': 0.06649950942984847, 'CF': 0.0470402267524256}, batch size: 64, grad_norm: 0.46365711092948914, grad_scale: , lr: 0.00e+00, 
2025-02-08 02:36:11,968 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 02:36:11,969 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 54982, num_updates: 53500, {'loss': 0.12216191738843918, 'DER': 0.27157275953859805, 'ACC': np.float64(0.9466607142857143), 'MI': 0.16365350488021296, 'FA': 0.04819210292812777, 'CF': 0.05972715173025732}, batch size: 64, grad_norm: 0.46365711092948914, grad_scale: , lr: 0.00e+00, 
2025-02-08 02:36:11,969 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 02:37:21,100 (model:870) WARNING: All labels are zero
2025-02-08 02:37:21,899 (model:870) WARNING: All labels are zero
2025-02-08 02:37:21,968 (model:870) WARNING: All labels are zero
2025-02-08 02:39:28,311 (model:870) WARNING: All labels are zero
2025-02-08 02:39:45,513 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 14, batch_idx_train: 54982,  validation: loss=0.1064, DER=0.2598, ACC=0.9511, MI=0.1779, FA=0.04511, CF=0.03683, over 0.00 frames. 
2025-02-08 02:39:45,513 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 02:39:45,517 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 14, batch_idx_train: 54982,  validation: loss=0.1089, DER=0.2636, ACC=0.9494, MI=0.188, FA=0.03999, CF=0.03571, over 0.00 frames. 
2025-02-08 02:39:45,517 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 02:57:28,896 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 55482, num_updates: 54000, {'loss': 0.1473608911037445, 'DER': 0.3153511563759813, 'ACC': np.float64(0.9391160714285715), 'MI': 0.206450244005941, 'FA': 0.06253978357733928, 'CF': 0.04636112879270104}, batch size: 64, grad_norm: 0.39684921503067017, grad_scale: , lr: 0.00e+00, 
2025-02-08 02:57:28,896 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 02:57:28,896 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 55482, num_updates: 54000, {'loss': 0.14142024517059326, 'DER': 0.3265129371007903, 'ACC': np.float64(0.9356517857142856), 'MI': 0.19037566309407816, 'FA': 0.07253437263180687, 'CF': 0.06360290137490528}, batch size: 64, grad_norm: 0.39684921503067017, grad_scale: , lr: 0.00e+00, 
2025-02-08 02:57:28,897 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 02:58:38,552 (model:870) WARNING: All labels are zero
2025-02-08 02:58:39,362 (model:870) WARNING: All labels are zero
2025-02-08 02:58:39,432 (model:870) WARNING: All labels are zero
2025-02-08 03:00:47,606 (model:870) WARNING: All labels are zero
2025-02-08 03:01:04,352 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 14, batch_idx_train: 55482,  validation: loss=0.07713, DER=0.1721, ACC=0.9646, MI=0.09208, FA=0.05345, CF=0.02654, over 0.00 frames. 
2025-02-08 03:01:04,352 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 03:01:05,071 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 14, batch_idx_train: 55482,  validation: loss=0.07654, DER=0.1746, ACC=0.965, MI=0.09027, FA=0.05691, CF=0.02739, over 0.00 frames. 
2025-02-08 03:01:05,071 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 03:01:46,856 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-55500.pt
2025-02-08 03:01:48,477 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 03:18:58,057 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 55982, num_updates: 54500, {'loss': 0.14965322613716125, 'DER': 0.3410190720182181, 'ACC': np.float64(0.9354821428571429), 'MI': 0.19925989183034443, 'FA': 0.07139197267292913, 'CF': 0.07036720751494449}, batch size: 64, grad_norm: 0.5828873515129089, grad_scale: , lr: 0.00e+00, 
2025-02-08 03:18:58,058 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 03:18:58,058 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 55982, num_updates: 54500, {'loss': 0.1545914113521576, 'DER': 0.34353244018019075, 'ACC': np.float64(0.9358111456503131), 'MI': 0.1801907213479202, 'FA': 0.0900953606739601, 'CF': 0.07324635815831042}, batch size: 64, grad_norm: 0.5828873515129089, grad_scale: , lr: 0.00e+00, 
2025-02-08 03:18:58,058 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 03:20:06,261 (model:870) WARNING: All labels are zero
2025-02-08 03:20:11,918 (model:870) WARNING: All labels are zero
2025-02-08 03:20:12,799 (model:870) WARNING: All labels are zero
2025-02-08 03:22:10,244 (model:870) WARNING: All labels are zero
2025-02-08 03:22:26,975 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 14, batch_idx_train: 55982,  validation: loss=0.08754, DER=0.1986, ACC=0.9609, MI=0.1089, FA=0.05744, CF=0.03224, over 0.00 frames. 
2025-02-08 03:22:26,976 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 03:22:47,644 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 14, batch_idx_train: 55982,  validation: loss=0.08819, DER=0.1958, ACC=0.9606, MI=0.1126, FA=0.05221, CF=0.03095, over 0.00 frames. 
2025-02-08 03:22:47,644 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 03:40:26,574 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 56482, num_updates: 55000, {'loss': 0.11847057193517685, 'DER': 0.29688091930799343, 'ACC': np.float64(0.9496607142857143), 'MI': 0.11339815633287031, 'FA': 0.12438439196868291, 'CF': 0.059098371006440206}, batch size: 64, grad_norm: 0.38885268568992615, grad_scale: , lr: 0.00e+00, 
2025-02-08 03:40:26,574 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 03:40:26,574 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 56482, num_updates: 55000, {'loss': 0.14295323193073273, 'DER': 0.3279848730415991, 'ACC': np.float64(0.9367410714285714), 'MI': 0.2298757428417072, 'FA': 0.043327930848190165, 'CF': 0.05478119935170178}, batch size: 64, grad_norm: 0.38885268568992615, grad_scale: , lr: 0.00e+00, 
2025-02-08 03:40:26,574 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 03:41:36,135 (model:870) WARNING: All labels are zero
2025-02-08 03:41:36,905 (model:870) WARNING: All labels are zero
2025-02-08 03:41:36,938 (model:870) WARNING: All labels are zero
2025-02-08 03:43:44,727 (model:870) WARNING: All labels are zero
2025-02-08 03:44:02,056 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 14, batch_idx_train: 56482,  validation: loss=0.07507, DER=0.1714, ACC=0.9658, MI=0.08273, FA=0.06285, CF=0.02581, over 0.00 frames. 
2025-02-08 03:44:02,058 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 03:44:02,095 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 14, batch_idx_train: 56482,  validation: loss=0.07578, DER=0.1686, ACC=0.9654, MI=0.08437, FA=0.05886, CF=0.02538, over 0.00 frames. 
2025-02-08 03:44:02,095 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 04:01:56,042 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 56982, num_updates: 55500, {'loss': 0.16784940659999847, 'DER': 0.33886559515490333, 'ACC': np.float64(0.9343571428571429), 'MI': 0.19525972513393897, 'FA': 0.05433263452131377, 'CF': 0.08927323549965059}, batch size: 64, grad_norm: 0.4620387852191925, grad_scale: , lr: 0.00e+00, 
2025-02-08 04:01:56,042 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 04:01:56,042 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 56982, num_updates: 55500, {'loss': 0.1111311987042427, 'DER': 0.2488301842089676, 'ACC': np.float64(0.9540714285714286), 'MI': 0.12989397618906592, 'FA': 0.0630812059468104, 'CF': 0.05585500207309128}, batch size: 64, grad_norm: 0.4620387852191925, grad_scale: , lr: 0.00e+00, 
2025-02-08 04:01:56,042 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 04:03:05,908 (model:870) WARNING: All labels are zero
2025-02-08 04:03:06,616 (model:870) WARNING: All labels are zero
2025-02-08 04:03:06,730 (model:870) WARNING: All labels are zero
2025-02-08 04:05:12,959 (model:870) WARNING: All labels are zero
2025-02-08 04:05:29,503 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 14, batch_idx_train: 56982,  validation: loss=0.07571, DER=0.1726, ACC=0.9654, MI=0.08347, FA=0.06226, CF=0.02683, over 0.00 frames. 
2025-02-08 04:05:29,504 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 04:05:29,873 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 14, batch_idx_train: 56982,  validation: loss=0.07642, DER=0.1704, ACC=0.9651, MI=0.08526, FA=0.0591, CF=0.02603, over 0.00 frames. 
2025-02-08 04:05:29,874 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 04:06:05,456 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-57000.pt
2025-02-08 04:06:07,073 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 04:23:12,404 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 57482, num_updates: 56000, {'loss': 0.17070457339286804, 'DER': 0.40811427902347636, 'ACC': np.float64(0.9262952661187183), 'MI': 0.2563081786780633, 'FA': 0.07745448158772905, 'CF': 0.07435161875768398}, batch size: 64, grad_norm: 0.4941539466381073, grad_scale: , lr: 0.00e+00, 
2025-02-08 04:23:12,405 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 04:23:12,405 (train_accelerate_ddp:702) INFO: [Train] - Epoch 14, batch_idx_train: 57482, num_updates: 56000, {'loss': 0.13044172525405884, 'DER': 0.3112559450413951, 'ACC': np.float64(0.9441339285714285), 'MI': 0.1693382655158241, 'FA': 0.0857847454641536, 'CF': 0.056132934061417415}, batch size: 64, grad_norm: 0.4941539466381073, grad_scale: , lr: 0.00e+00, 
2025-02-08 04:23:12,405 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 04:24:22,217 (model:870) WARNING: All labels are zero
2025-02-08 04:24:23,020 (model:870) WARNING: All labels are zero
2025-02-08 04:24:23,036 (model:870) WARNING: All labels are zero
2025-02-08 04:26:31,563 (model:870) WARNING: All labels are zero
2025-02-08 04:26:48,680 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 14, batch_idx_train: 57482,  validation: loss=0.094, DER=0.2285, ACC=0.9567, MI=0.1539, FA=0.04223, CF=0.03232, over 0.00 frames. 
2025-02-08 04:26:48,680 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 04:26:48,750 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 14, batch_idx_train: 57482,  validation: loss=0.09564, DER=0.229, ACC=0.9555, MI=0.1603, FA=0.03728, CF=0.03149, over 0.00 frames. 
2025-02-08 04:26:48,750 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 04:30:47,508 (train_accelerate_ddp:713) INFO: end of epoch 14, batch_idx: 4113 batch_idx_train: 57595, {'loss': 0.13772383332252502, 'DER': 0.28902127659574467, 'ACC': np.float64(0.9475982142857143), 'MI': 0.19931914893617023, 'FA': 0.04573049645390071, 'CF': 0.04397163120567376}, batch size: 64, grad_norm: 0.39097490906715393, grad_scale: , lr: 0.00e+00, 
2025-02-08 04:30:47,509 (train_accelerate_ddp:713) INFO: end of epoch 14, batch_idx: 4113 batch_idx_train: 57595, {'loss': 0.1079489067196846, 'DER': 0.25598101068149165, 'ACC': np.float64(0.9564375), 'MI': 0.12086951090011869, 'FA': 0.08632644137672559, 'CF': 0.048785058404647384}, batch size: 64, grad_norm: 0.39097490906715393, grad_scale: , lr: 0.00e+00, 
2025-02-08 04:30:47,510 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-14.pt
2025-02-08 04:30:48,715 (train_accelerate_ddp:561) INFO:  end of epoch 14, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-14.pt 
2025-02-08 04:30:52,218 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 57596, num_updates: 56000, {'loss': 0.16283951699733734, 'DER': 0.38620002215084726, 'ACC': np.float64(0.9223482142857143), 'MI': 0.2184073540812936, 'FA': 0.07237789345442464, 'CF': 0.09541477461512902}, batch size: 64, grad_norm: 0.5382636785507202, grad_scale: , lr: 0.00e+00, 
2025-02-08 04:30:52,219 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 57596, num_updates: 56000, {'loss': 0.13540102541446686, 'DER': 0.29860352853284294, 'ACC': np.float64(0.9440892857142856), 'MI': 0.160967760473536, 'FA': 0.07637492098155278, 'CF': 0.06126084707775415}, batch size: 64, grad_norm: 0.5382636785507202, grad_scale: , lr: 0.00e+00, 
2025-02-08 04:48:37,108 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 58096, num_updates: 56500, {'loss': 0.14680680632591248, 'DER': 0.346524183224801, 'ACC': np.float64(0.9334464285714286), 'MI': 0.20888295207881116, 'FA': 0.06929370512606445, 'CF': 0.06834752601992541}, batch size: 64, grad_norm: 0.42001205682754517, grad_scale: , lr: 0.00e+00, 
2025-02-08 04:48:37,109 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 04:48:37,109 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 58096, num_updates: 56500, {'loss': 0.1518285572528839, 'DER': 0.36515334599228955, 'ACC': np.float64(0.9318303571428571), 'MI': 0.21192243512284942, 'FA': 0.07906093561194545, 'CF': 0.07416997525749468}, batch size: 64, grad_norm: 0.42001205682754517, grad_scale: , lr: 0.00e+00, 
2025-02-08 04:48:37,110 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 04:49:46,311 (model:870) WARNING: All labels are zero
2025-02-08 04:49:48,348 (model:870) WARNING: All labels are zero
2025-02-08 04:49:49,151 (model:870) WARNING: All labels are zero
2025-02-08 04:51:50,730 (model:870) WARNING: All labels are zero
2025-02-08 04:52:07,433 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 15, batch_idx_train: 58096,  validation: loss=0.0819, DER=0.1863, ACC=0.963, MI=0.09481, FA=0.06136, CF=0.03017, over 0.00 frames. 
2025-02-08 04:52:07,433 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 04:52:17,405 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 15, batch_idx_train: 58096,  validation: loss=0.08244, DER=0.1826, ACC=0.9628, MI=0.09697, FA=0.05648, CF=0.02914, over 0.00 frames. 
2025-02-08 04:52:17,405 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 05:06:49,023 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-58500.pt
2025-02-08 05:06:50,662 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 05:06:50,664 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-08 05:10:16,267 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 58596, num_updates: 57000, {'loss': 0.14850954711437225, 'DER': 0.3406568516421291, 'ACC': np.float64(0.9356584646987898), 'MI': 0.20334088335220837, 'FA': 0.07004530011325029, 'CF': 0.06727066817667045}, batch size: 64, grad_norm: 0.41318178176879883, grad_scale: , lr: 0.00e+00, 
2025-02-08 05:10:16,267 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 05:10:16,268 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 58596, num_updates: 57000, {'loss': 0.12208784371614456, 'DER': 0.27819211574048114, 'ACC': np.float64(0.9480089285714286), 'MI': 0.16323669601300958, 'FA': 0.06661806762743229, 'CF': 0.048337352100039255}, batch size: 64, grad_norm: 0.41318178176879883, grad_scale: , lr: 0.00e+00, 
2025-02-08 05:10:16,268 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 05:11:25,733 (model:870) WARNING: All labels are zero
2025-02-08 05:11:26,516 (model:870) WARNING: All labels are zero
2025-02-08 05:11:26,539 (model:870) WARNING: All labels are zero
2025-02-08 05:13:31,029 (model:870) WARNING: All labels are zero
2025-02-08 05:13:47,194 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 15, batch_idx_train: 58596,  validation: loss=0.08085, DER=0.1797, ACC=0.9634, MI=0.08945, FA=0.06144, CF=0.02883, over 0.00 frames. 
2025-02-08 05:13:47,195 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 05:13:47,443 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 15, batch_idx_train: 58596,  validation: loss=0.08053, DER=0.1833, ACC=0.9634, MI=0.08725, FA=0.06546, CF=0.03061, over 0.00 frames. 
2025-02-08 05:13:47,443 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 05:31:28,371 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 59096, num_updates: 57500, {'loss': 0.13023294508457184, 'DER': 0.3053777208706786, 'ACC': np.float64(0.9459375), 'MI': 0.17675474333604935, 'FA': 0.08159702013735304, 'CF': 0.04702595739727622}, batch size: 64, grad_norm: 0.37084445357322693, grad_scale: , lr: 0.00e+00, 
2025-02-08 05:31:28,371 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 59096, num_updates: 57500, {'loss': 0.12857463955879211, 'DER': 0.26453278265358804, 'ACC': np.float64(0.9483035714285715), 'MI': 0.17496128033040784, 'FA': 0.05518843572534848, 'CF': 0.0343830665978317}, batch size: 64, grad_norm: 0.37084445357322693, grad_scale: , lr: 0.00e+00, 
2025-02-08 05:31:28,372 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 05:31:28,372 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 05:32:38,115 (model:870) WARNING: All labels are zero
2025-02-08 05:32:38,939 (model:870) WARNING: All labels are zero
2025-02-08 05:32:38,941 (model:870) WARNING: All labels are zero
2025-02-08 05:34:47,263 (model:870) WARNING: All labels are zero
2025-02-08 05:35:04,297 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 15, batch_idx_train: 59096,  validation: loss=0.1374, DER=0.3345, ACC=0.9392, MI=0.2754, FA=0.02629, CF=0.03278, over 0.00 frames. 
2025-02-08 05:35:04,298 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 05:35:04,322 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 15, batch_idx_train: 59096,  validation: loss=0.1323, DER=0.334, ACC=0.9406, MI=0.2692, FA=0.03002, CF=0.03475, over 0.00 frames. 
2025-02-08 05:35:04,323 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 05:53:20,526 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 59596, num_updates: 58000, {'loss': 0.12614993751049042, 'DER': 0.29136446056210336, 'ACC': np.float64(0.9460982142857144), 'MI': 0.1732207615593835, 'FA': 0.06742973708068903, 'CF': 0.05071396192203082}, batch size: 64, grad_norm: 0.43206867575645447, grad_scale: , lr: 0.00e+00, 
2025-02-08 05:53:20,526 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 05:53:20,527 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 59596, num_updates: 58000, {'loss': 0.11402050405740738, 'DER': 0.270131555660433, 'ACC': np.float64(0.9508035714285714), 'MI': 0.15255737124653412, 'FA': 0.06265117102235856, 'CF': 0.05492301339154032}, batch size: 64, grad_norm: 0.43206867575645447, grad_scale: , lr: 0.00e+00, 
2025-02-08 05:53:20,527 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 05:54:30,231 (model:870) WARNING: All labels are zero
2025-02-08 05:54:30,884 (model:870) WARNING: All labels are zero
2025-02-08 05:54:31,034 (model:870) WARNING: All labels are zero
2025-02-08 05:56:37,984 (model:870) WARNING: All labels are zero
2025-02-08 05:56:55,239 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 15, batch_idx_train: 59596,  validation: loss=0.08589, DER=0.1954, ACC=0.9614, MI=0.1087, FA=0.05548, CF=0.03119, over 0.00 frames. 
2025-02-08 05:56:55,240 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 05:56:56,001 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 15, batch_idx_train: 59596,  validation: loss=0.08648, DER=0.1925, ACC=0.9612, MI=0.1124, FA=0.05045, CF=0.02966, over 0.00 frames. 
2025-02-08 05:56:56,002 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 06:11:08,531 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-60000.pt
2025-02-08 06:11:10,160 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 06:14:34,919 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 60096, num_updates: 58500, {'loss': 0.1549651026725769, 'DER': 0.39857088655621603, 'ACC': np.float64(0.9286570797457513), 'MI': 0.1927406095864424, 'FA': 0.10402175287719742, 'CF': 0.1018085240925762}, batch size: 64, grad_norm: 0.7476934194564819, grad_scale: , lr: 0.00e+00, 
2025-02-08 06:14:34,919 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 06:14:34,920 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 60096, num_updates: 58500, {'loss': 0.1443692147731781, 'DER': 0.3315317387304508, 'ACC': np.float64(0.93925), 'MI': 0.187614995400184, 'FA': 0.08423413063477461, 'CF': 0.05968261269549218}, batch size: 64, grad_norm: 0.7476934194564819, grad_scale: , lr: 0.00e+00, 
2025-02-08 06:14:34,920 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 06:15:45,118 (model:870) WARNING: All labels are zero
2025-02-08 06:15:45,944 (model:870) WARNING: All labels are zero
2025-02-08 06:15:45,963 (model:870) WARNING: All labels are zero
2025-02-08 06:17:55,895 (model:870) WARNING: All labels are zero
2025-02-08 06:18:13,070 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 15, batch_idx_train: 60096,  validation: loss=0.08662, DER=0.1918, ACC=0.961, MI=0.1062, FA=0.05344, CF=0.03213, over 0.00 frames. 
2025-02-08 06:18:13,070 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 06:18:13,119 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 15, batch_idx_train: 60096,  validation: loss=0.08602, DER=0.1951, ACC=0.9612, MI=0.1031, FA=0.05848, CF=0.03352, over 0.00 frames. 
2025-02-08 06:18:13,119 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 06:35:55,010 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 60596, num_updates: 59000, {'loss': 0.13729797303676605, 'DER': 0.3081297510590147, 'ACC': np.float64(0.9428214285714286), 'MI': 0.17779841002727326, 'FA': 0.06684848836534556, 'CF': 0.06348285266639588}, batch size: 64, grad_norm: 0.4338687062263489, grad_scale: , lr: 0.00e+00, 
2025-02-08 06:35:55,011 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 06:35:55,011 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 60596, num_updates: 59000, {'loss': 0.15132299065589905, 'DER': 0.3336782485568021, 'ACC': np.float64(0.9348303571428571), 'MI': 0.20967214900337655, 'FA': 0.060178629778891185, 'CF': 0.06382746977453436}, batch size: 64, grad_norm: 0.4338687062263489, grad_scale: , lr: 0.00e+00, 
2025-02-08 06:35:55,011 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 06:37:04,403 (model:870) WARNING: All labels are zero
2025-02-08 06:37:05,228 (model:870) WARNING: All labels are zero
2025-02-08 06:37:05,255 (model:870) WARNING: All labels are zero
2025-02-08 06:39:13,450 (model:870) WARNING: All labels are zero
2025-02-08 06:39:30,311 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 15, batch_idx_train: 60596,  validation: loss=0.07756, DER=0.1723, ACC=0.9645, MI=0.08708, FA=0.05816, CF=0.02709, over 0.00 frames. 
2025-02-08 06:39:30,312 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 06:39:30,403 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 15, batch_idx_train: 60596,  validation: loss=0.07681, DER=0.1753, ACC=0.9648, MI=0.08475, FA=0.06219, CF=0.02836, over 0.00 frames. 
2025-02-08 06:39:30,403 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 06:57:39,841 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 61096, num_updates: 59500, {'loss': 0.19730056822299957, 'DER': 0.46397276329742704, 'ACC': np.float64(0.910125), 'MI': 0.24602332979851538, 'FA': 0.12010939331361277, 'CF': 0.09784004018529888}, batch size: 64, grad_norm: 0.5655308365821838, grad_scale: , lr: 0.00e+00, 
2025-02-08 06:57:39,842 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 06:57:39,842 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 61096, num_updates: 59500, {'loss': 0.14243732392787933, 'DER': 0.325617868152074, 'ACC': np.float64(0.9366071428571429), 'MI': 0.22053972202693203, 'FA': 0.046725433994916445, 'CF': 0.05835271213022551}, batch size: 64, grad_norm: 0.5655308365821838, grad_scale: , lr: 0.00e+00, 
2025-02-08 06:57:39,842 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 06:58:48,687 (model:870) WARNING: All labels are zero
2025-02-08 06:58:49,483 (model:870) WARNING: All labels are zero
2025-02-08 06:58:49,524 (model:870) WARNING: All labels are zero
2025-02-08 07:00:57,504 (model:870) WARNING: All labels are zero
2025-02-08 07:01:14,541 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 15, batch_idx_train: 61096,  validation: loss=0.07885, DER=0.1764, ACC=0.9642, MI=0.09142, FA=0.05844, CF=0.0265, over 0.00 frames. 
2025-02-08 07:01:14,542 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 07:01:14,590 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 15, batch_idx_train: 61096,  validation: loss=0.07843, DER=0.1797, ACC=0.9643, MI=0.08927, FA=0.06258, CF=0.02786, over 0.00 frames. 
2025-02-08 07:01:14,590 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 07:15:30,493 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-61500.pt
2025-02-08 07:15:32,099 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 07:18:54,194 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 61596, num_updates: 60000, {'loss': 0.1400778740644455, 'DER': 0.3361714451201853, 'ACC': np.float64(0.9388303571428571), 'MI': 0.21673906747755575, 'FA': 0.05878945844193455, 'CF': 0.06064291920069505}, batch size: 64, grad_norm: 0.4236864149570465, grad_scale: , lr: 0.00e+00, 
2025-02-08 07:18:54,195 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 07:18:54,195 (train_accelerate_ddp:702) INFO: [Train] - Epoch 15, batch_idx_train: 61596, num_updates: 60000, {'loss': 0.10158184915781021, 'DER': 0.24340843720038352, 'ACC': np.float64(0.9553329064723547), 'MI': 0.12452061361457335, 'FA': 0.06549616490891659, 'CF': 0.05339165867689358}, batch size: 64, grad_norm: 0.4236864149570465, grad_scale: , lr: 0.00e+00, 
2025-02-08 07:18:54,195 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 07:20:02,802 (model:870) WARNING: All labels are zero
2025-02-08 07:20:03,597 (model:870) WARNING: All labels are zero
2025-02-08 07:20:03,673 (model:870) WARNING: All labels are zero
2025-02-08 07:22:09,780 (model:870) WARNING: All labels are zero
2025-02-08 07:22:26,381 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 15, batch_idx_train: 61596,  validation: loss=0.1015, DER=0.235, ACC=0.9539, MI=0.1489, FA=0.04885, CF=0.03725, over 0.00 frames. 
2025-02-08 07:22:26,381 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 07:22:26,542 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 15, batch_idx_train: 61596,  validation: loss=0.1003, DER=0.2349, ACC=0.9548, MI=0.1422, FA=0.05435, CF=0.0384, over 0.00 frames. 
2025-02-08 07:22:26,543 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 07:26:22,114 (train_accelerate_ddp:713) INFO: end of epoch 15, batch_idx: 4113 batch_idx_train: 61709, {'loss': 0.15740898251533508, 'DER': 0.38823193373321907, 'ACC': np.float64(0.9253482142857143), 'MI': 0.20382747786346758, 'FA': 0.09500142816338189, 'CF': 0.08940302770636961}, batch size: 64, grad_norm: 0.5013411641120911, grad_scale: , lr: 0.00e+00, 
2025-02-08 07:26:22,114 (train_accelerate_ddp:713) INFO: end of epoch 15, batch_idx: 4113 batch_idx_train: 61709, {'loss': 0.1200796589255333, 'DER': 0.25975873449413905, 'ACC': np.float64(0.9501428571428571), 'MI': 0.13992261295095026, 'FA': 0.061852736997837714, 'CF': 0.05798338454535109}, batch size: 64, grad_norm: 0.5013411641120911, grad_scale: , lr: 0.00e+00, 
2025-02-08 07:26:22,115 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-15.pt
2025-02-08 07:26:23,335 (train_accelerate_ddp:561) INFO:  end of epoch 15, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-15.pt 
2025-02-08 07:26:26,902 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 61710, num_updates: 60000, {'loss': 0.13798601925373077, 'DER': 0.31201137171286425, 'ACC': np.float64(0.9428839285714286), 'MI': 0.21655458968891805, 'FA': 0.05773331146465475, 'CF': 0.037723470559291455}, batch size: 64, grad_norm: 0.4175087809562683, grad_scale: , lr: 0.00e+00, 
2025-02-08 07:26:26,902 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 61710, num_updates: 60000, {'loss': 0.1364237368106842, 'DER': 0.3123796182805113, 'ACC': np.float64(0.9423839285714286), 'MI': 0.1641860736590206, 'FA': 0.08393159399988327, 'CF': 0.06426195062160743}, batch size: 64, grad_norm: 0.4175087809562683, grad_scale: , lr: 0.00e+00, 
2025-02-08 07:44:33,630 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 62210, num_updates: 60500, {'loss': 0.12321629375219345, 'DER': 0.281779777253525, 'ACC': np.float64(0.9486964285714286), 'MI': 0.17781313436111262, 'FA': 0.07049980797717671, 'CF': 0.03346683491523564}, batch size: 64, grad_norm: 0.34260451793670654, grad_scale: , lr: 0.00e+00, 
2025-02-08 07:44:33,630 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 62210, num_updates: 60500, {'loss': 0.1454845815896988, 'DER': 0.3043311192841851, 'ACC': np.float64(0.9422053571428571), 'MI': 0.20442443871109403, 'FA': 0.048910358456386895, 'CF': 0.05099632211670418}, batch size: 64, grad_norm: 0.34260451793670654, grad_scale: , lr: 0.00e+00, 
2025-02-08 07:44:33,631 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 07:44:33,631 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 07:45:42,722 (model:870) WARNING: All labels are zero
2025-02-08 07:45:43,481 (model:870) WARNING: All labels are zero
2025-02-08 07:45:43,538 (model:870) WARNING: All labels are zero
2025-02-08 07:47:50,576 (model:870) WARNING: All labels are zero
2025-02-08 07:48:07,507 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 16, batch_idx_train: 62210,  validation: loss=0.1014, DER=0.2445, ACC=0.9536, MI=0.1618, FA=0.04634, CF=0.03638, over 0.00 frames. 
2025-02-08 07:48:07,507 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 07:48:07,619 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 16, batch_idx_train: 62210,  validation: loss=0.1034, DER=0.247, ACC=0.9522, MI=0.1711, FA=0.04104, CF=0.03491, over 0.00 frames. 
2025-02-08 07:48:07,619 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 08:06:02,315 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 62710, num_updates: 61000, {'loss': 0.13804838061332703, 'DER': 0.30759784291740083, 'ACC': np.float64(0.9410178571428571), 'MI': 0.20764589673767953, 'FA': 0.054834748251374875, 'CF': 0.04511719792834641}, batch size: 64, grad_norm: 0.394657164812088, grad_scale: , lr: 0.00e+00, 
2025-02-08 08:06:02,315 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 62710, num_updates: 61000, {'loss': 0.11566318571567535, 'DER': 0.24794925079295635, 'ACC': np.float64(0.9534642857142857), 'MI': 0.1450289839221262, 'FA': 0.06584272120748114, 'CF': 0.03707754566334901}, batch size: 64, grad_norm: 0.394657164812088, grad_scale: , lr: 0.00e+00, 
2025-02-08 08:06:02,316 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 08:06:02,316 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 08:07:11,750 (model:870) WARNING: All labels are zero
2025-02-08 08:07:12,562 (model:870) WARNING: All labels are zero
2025-02-08 08:07:12,596 (model:870) WARNING: All labels are zero
2025-02-08 08:09:20,570 (model:870) WARNING: All labels are zero
2025-02-08 08:09:37,532 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 16, batch_idx_train: 62710,  validation: loss=0.0813, DER=0.179, ACC=0.9636, MI=0.09137, FA=0.06037, CF=0.02724, over 0.00 frames. 
2025-02-08 08:09:37,533 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 08:09:37,595 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 16, batch_idx_train: 62710,  validation: loss=0.0809, DER=0.183, ACC=0.9636, MI=0.08878, FA=0.06512, CF=0.02913, over 0.00 frames. 
2025-02-08 08:09:37,595 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 08:19:45,579 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-63000.pt
2025-02-08 08:19:47,176 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 08:19:47,178 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-08 08:27:08,951 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 63210, num_updates: 61500, {'loss': 0.1511915922164917, 'DER': 0.3641114982578397, 'ACC': np.float64(0.93325), 'MI': 0.23559814169570267, 'FA': 0.05847851335656214, 'CF': 0.07003484320557492}, batch size: 64, grad_norm: 0.3922002613544464, grad_scale: , lr: 0.00e+00, 
2025-02-08 08:27:08,952 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 08:27:08,952 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 63210, num_updates: 61500, {'loss': 0.11642023175954819, 'DER': 0.2699885389947061, 'ACC': np.float64(0.9493928571428571), 'MI': 0.16940457348687443, 'FA': 0.061234513998799325, 'CF': 0.039349451509032365}, batch size: 64, grad_norm: 0.3922002613544464, grad_scale: , lr: 0.00e+00, 
2025-02-08 08:27:08,952 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 08:28:18,502 (model:870) WARNING: All labels are zero
2025-02-08 08:28:19,316 (model:870) WARNING: All labels are zero
2025-02-08 08:28:19,316 (model:870) WARNING: All labels are zero
2025-02-08 08:30:28,204 (model:870) WARNING: All labels are zero
2025-02-08 08:30:45,402 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 16, batch_idx_train: 63210,  validation: loss=0.0761, DER=0.1701, ACC=0.9652, MI=0.08777, FA=0.05686, CF=0.02551, over 0.00 frames. 
2025-02-08 08:30:45,403 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 08:30:45,419 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 16, batch_idx_train: 63210,  validation: loss=0.0755, DER=0.1725, ACC=0.9655, MI=0.08577, FA=0.06032, CF=0.02643, over 0.00 frames. 
2025-02-08 08:30:45,420 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 08:49:06,356 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 63710, num_updates: 62000, {'loss': 0.1307915598154068, 'DER': 0.28977653631284916, 'ACC': np.float64(0.9448779260005034), 'MI': 0.17134078212290502, 'FA': 0.06564245810055866, 'CF': 0.052793296089385475}, batch size: 64, grad_norm: 0.36114829778671265, grad_scale: , lr: 0.00e+00, 
2025-02-08 08:49:06,357 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 63710, num_updates: 62000, {'loss': 0.11578015238046646, 'DER': 0.281746946300991, 'ACC': np.float64(0.9476607142857143), 'MI': 0.16029038949066604, 'FA': 0.0654528693247292, 'CF': 0.05600368748559576}, batch size: 64, grad_norm: 0.36114829778671265, grad_scale: , lr: 0.00e+00, 
2025-02-08 08:49:06,357 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 08:49:06,357 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 08:50:15,072 (model:870) WARNING: All labels are zero
2025-02-08 08:50:15,765 (model:870) WARNING: All labels are zero
2025-02-08 08:50:15,895 (model:870) WARNING: All labels are zero
2025-02-08 08:52:20,340 (model:870) WARNING: All labels are zero
2025-02-08 08:52:36,788 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 16, batch_idx_train: 63710,  validation: loss=0.08468, DER=0.1921, ACC=0.962, MI=0.1046, FA=0.05649, CF=0.03108, over 0.00 frames. 
2025-02-08 08:52:36,788 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 08:52:37,112 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 16, batch_idx_train: 63710,  validation: loss=0.08536, DER=0.189, ACC=0.9617, MI=0.1072, FA=0.05179, CF=0.03006, over 0.00 frames. 
2025-02-08 08:52:37,113 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 09:10:17,193 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 64210, num_updates: 62500, {'loss': 0.13428565859794617, 'DER': 0.2939930077338701, 'ACC': np.float64(0.9413392857142857), 'MI': 0.18386481618815553, 'FA': 0.05609704417840873, 'CF': 0.05403114736730586}, batch size: 64, grad_norm: 0.3608873188495636, grad_scale: , lr: 0.00e+00, 
2025-02-08 09:10:17,193 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 09:10:17,194 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 64210, num_updates: 62500, {'loss': 0.11551876366138458, 'DER': 0.2505281187553526, 'ACC': np.float64(0.9542348442103943), 'MI': 0.15432486440194118, 'FA': 0.05498144447616329, 'CF': 0.04122180987724807}, batch size: 64, grad_norm: 0.3608873188495636, grad_scale: , lr: 0.00e+00, 
2025-02-08 09:10:17,194 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 09:11:26,666 (model:870) WARNING: All labels are zero
2025-02-08 09:11:27,477 (model:870) WARNING: All labels are zero
2025-02-08 09:11:27,485 (model:870) WARNING: All labels are zero
2025-02-08 09:13:36,004 (model:870) WARNING: All labels are zero
2025-02-08 09:13:52,998 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 16, batch_idx_train: 64210,  validation: loss=0.1101, DER=0.2669, ACC=0.9492, MI=0.1916, FA=0.04054, CF=0.03483, over 0.00 frames. 
2025-02-08 09:13:52,999 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 09:13:53,063 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 16, batch_idx_train: 64210,  validation: loss=0.1077, DER=0.2646, ACC=0.9508, MI=0.1815, FA=0.04606, CF=0.03695, over 0.00 frames. 
2025-02-08 09:13:53,064 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 09:24:06,714 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-64500.pt
2025-02-08 09:24:08,319 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 09:31:35,559 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 64710, num_updates: 63000, {'loss': 0.1483866572380066, 'DER': 0.3471204188481675, 'ACC': np.float64(0.9385892857142857), 'MI': 0.20663176265270505, 'FA': 0.08749272833042467, 'CF': 0.05299592786503781}, batch size: 64, grad_norm: 0.46222156286239624, grad_scale: , lr: 0.00e+00, 
2025-02-08 09:31:35,560 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 09:31:35,561 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 64710, num_updates: 63000, {'loss': 0.1277586668729782, 'DER': 0.3042934319021894, 'ACC': np.float64(0.9437946428571429), 'MI': 0.18657947114017628, 'FA': 0.06403184532271823, 'CF': 0.05368211543929485}, batch size: 64, grad_norm: 0.46222156286239624, grad_scale: , lr: 0.00e+00, 
2025-02-08 09:31:35,561 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 09:32:45,254 (model:870) WARNING: All labels are zero
2025-02-08 09:32:45,398 (model:870) WARNING: All labels are zero
2025-02-08 09:32:46,061 (model:870) WARNING: All labels are zero
2025-02-08 09:34:52,402 (model:870) WARNING: All labels are zero
2025-02-08 09:35:09,429 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 16, batch_idx_train: 64710,  validation: loss=0.1068, DER=0.2576, ACC=0.9516, MI=0.174, FA=0.048, CF=0.03562, over 0.00 frames. 
2025-02-08 09:35:09,430 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 09:35:10,111 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 16, batch_idx_train: 64710,  validation: loss=0.1085, DER=0.2611, ACC=0.9502, MI=0.1844, FA=0.04311, CF=0.03358, over 0.00 frames. 
2025-02-08 09:35:10,111 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 09:52:43,039 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 65210, num_updates: 63500, {'loss': 0.13047336041927338, 'DER': 0.3192788772094662, 'ACC': np.float64(0.9406286904236043), 'MI': 0.16695049621234365, 'FA': 0.08485524693170474, 'CF': 0.06747313406541781}, batch size: 64, grad_norm: 0.5661832690238953, grad_scale: , lr: 0.00e+00, 
2025-02-08 09:52:43,040 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 09:52:43,041 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 65210, num_updates: 63500, {'loss': 0.17988820374011993, 'DER': 0.3904001737525113, 'ACC': np.float64(0.9177589285714286), 'MI': 0.20236737796600968, 'FA': 0.07829722538958571, 'CF': 0.1097355703969159}, batch size: 64, grad_norm: 0.5661832690238953, grad_scale: , lr: 0.00e+00, 
2025-02-08 09:52:43,041 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 09:53:52,639 (model:870) WARNING: All labels are zero
2025-02-08 09:53:53,457 (model:870) WARNING: All labels are zero
2025-02-08 09:53:53,458 (model:870) WARNING: All labels are zero
2025-02-08 09:56:02,158 (model:870) WARNING: All labels are zero
2025-02-08 09:56:19,404 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 16, batch_idx_train: 65210,  validation: loss=0.07985, DER=0.1823, ACC=0.9634, MI=0.08779, FA=0.06307, CF=0.0314, over 0.00 frames. 
2025-02-08 09:56:19,404 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 09:56:19,410 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 16, batch_idx_train: 65210,  validation: loss=0.08044, DER=0.1786, ACC=0.9633, MI=0.09002, FA=0.05862, CF=0.02993, over 0.00 frames. 
2025-02-08 09:56:19,411 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 10:14:46,540 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 65710, num_updates: 64000, {'loss': 0.12401672452688217, 'DER': 0.27411300919842313, 'ACC': np.float64(0.9473303571428571), 'MI': 0.19321944809461236, 'FA': 0.044940867279894874, 'CF': 0.0359526938239159}, batch size: 64, grad_norm: 0.4340079426765442, grad_scale: , lr: 0.00e+00, 
2025-02-08 10:14:46,540 (train_accelerate_ddp:702) INFO: [Train] - Epoch 16, batch_idx_train: 65710, num_updates: 64000, {'loss': 0.1329026222229004, 'DER': 0.2897046232876712, 'ACC': np.float64(0.9428125), 'MI': 0.17444349315068494, 'FA': 0.06223244863013699, 'CF': 0.053028681506849314}, batch size: 64, grad_norm: 0.4340079426765442, grad_scale: , lr: 0.00e+00, 
2025-02-08 10:14:46,540 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 10:14:46,540 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 10:15:54,449 (model:870) WARNING: All labels are zero
2025-02-08 10:15:55,242 (model:870) WARNING: All labels are zero
2025-02-08 10:15:55,504 (model:870) WARNING: All labels are zero
2025-02-08 10:18:01,970 (model:870) WARNING: All labels are zero
2025-02-08 10:18:18,904 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 16, batch_idx_train: 65710,  validation: loss=0.0839, DER=0.1913, ACC=0.9621, MI=0.1033, FA=0.05721, CF=0.03078, over 0.00 frames. 
2025-02-08 10:18:18,905 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 10:18:19,062 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 16, batch_idx_train: 65710,  validation: loss=0.08456, DER=0.1885, ACC=0.9618, MI=0.1063, FA=0.05214, CF=0.03004, over 0.00 frames. 
2025-02-08 10:18:19,062 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 10:22:17,688 (train_accelerate_ddp:713) INFO: end of epoch 16, batch_idx: 4113 batch_idx_train: 65823, {'loss': 0.1738191395998001, 'DER': 0.3856771248075596, 'ACC': np.float64(0.9241964285714286), 'MI': 0.24722620374794288, 'FA': 0.0734193342888995, 'CF': 0.0650315867707172}, batch size: 64, grad_norm: 0.3480057418346405, grad_scale: , lr: 0.00e+00, 
2025-02-08 10:22:17,689 (train_accelerate_ddp:713) INFO: end of epoch 16, batch_idx: 4113 batch_idx_train: 65823, {'loss': 0.09154923260211945, 'DER': 0.216880972041996, 'ACC': np.float64(0.964), 'MI': 0.1292320396366639, 'FA': 0.0667099209626047, 'CF': 0.02093901144272738}, batch size: 64, grad_norm: 0.3480057418346405, grad_scale: , lr: 0.00e+00, 
2025-02-08 10:22:17,690 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-16.pt
2025-02-08 10:22:18,868 (train_accelerate_ddp:561) INFO:  end of epoch 16, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-16.pt 
2025-02-08 10:22:21,978 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 65824, num_updates: 64000, {'loss': 0.149496927857399, 'DER': 0.34581521739130433, 'ACC': np.float64(0.9313963379146707), 'MI': 0.1988586956521739, 'FA': 0.07635869565217392, 'CF': 0.07059782608695653}, batch size: 64, grad_norm: 0.4623252749443054, grad_scale: , lr: 0.00e+00, 
2025-02-08 10:22:21,980 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 65824, num_updates: 64000, {'loss': 0.11699067056179047, 'DER': 0.2920214059839455, 'ACC': np.float64(0.9496964285714286), 'MI': 0.16431525176356118, 'FA': 0.07711019216735587, 'CF': 0.05059596205302846}, batch size: 64, grad_norm: 0.4623252749443054, grad_scale: , lr: 0.00e+00, 
2025-02-08 10:28:30,125 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-66000.pt
2025-02-08 10:28:31,682 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 10:28:31,684 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-08 10:40:00,291 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 66324, num_updates: 64500, {'loss': 0.13047946989536285, 'DER': 0.2891950297136683, 'ACC': np.float64(0.9456517857142857), 'MI': 0.1838465694219341, 'FA': 0.06569421934089681, 'CF': 0.03965424095083739}, batch size: 64, grad_norm: 0.38524168729782104, grad_scale: , lr: 0.00e+00, 
2025-02-08 10:40:00,292 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 10:40:00,292 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 66324, num_updates: 64500, {'loss': 0.10433157533407211, 'DER': 0.25815134275402213, 'ACC': np.float64(0.9528303571428571), 'MI': 0.1082155747231908, 'FA': 0.08490854591056463, 'CF': 0.06502722212026671}, batch size: 64, grad_norm: 0.38524168729782104, grad_scale: , lr: 0.00e+00, 
2025-02-08 10:40:00,292 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 10:41:09,869 (model:870) WARNING: All labels are zero
2025-02-08 10:41:10,673 (model:870) WARNING: All labels are zero
2025-02-08 10:41:10,707 (model:870) WARNING: All labels are zero
2025-02-08 10:43:17,970 (model:870) WARNING: All labels are zero
2025-02-08 10:43:34,616 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 17, batch_idx_train: 66324,  validation: loss=0.08039, DER=0.1787, ACC=0.9633, MI=0.09856, FA=0.05108, CF=0.02905, over 0.00 frames. 
2025-02-08 10:43:34,617 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 10:43:34,771 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 17, batch_idx_train: 66324,  validation: loss=0.0797, DER=0.1819, ACC=0.9637, MI=0.09676, FA=0.05541, CF=0.02972, over 0.00 frames. 
2025-02-08 10:43:34,771 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 11:01:07,478 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 66824, num_updates: 65000, {'loss': 0.21130339801311493, 'DER': 0.47915287888815355, 'ACC': np.float64(0.9105892857142857), 'MI': 0.2489621563082847, 'FA': 0.10685277660790567, 'CF': 0.12333794597196318}, batch size: 64, grad_norm: 0.9113112092018127, grad_scale: , lr: 0.00e+00, 
2025-02-08 11:01:07,478 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 11:01:07,478 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 66824, num_updates: 65000, {'loss': 0.13730213046073914, 'DER': 0.2908573342263898, 'ACC': np.float64(0.9426071428571429), 'MI': 0.15768028577807547, 'FA': 0.06524893949542308, 'CF': 0.06792810895289127}, batch size: 64, grad_norm: 0.9113112092018127, grad_scale: , lr: 0.00e+00, 
2025-02-08 11:01:07,478 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 11:02:17,041 (model:870) WARNING: All labels are zero
2025-02-08 11:02:17,846 (model:870) WARNING: All labels are zero
2025-02-08 11:02:17,855 (model:870) WARNING: All labels are zero
2025-02-08 11:04:25,729 (model:870) WARNING: All labels are zero
2025-02-08 11:04:42,704 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 17, batch_idx_train: 66824,  validation: loss=0.0859, DER=0.1956, ACC=0.9611, MI=0.0965, FA=0.06449, CF=0.03456, over 0.00 frames. 
2025-02-08 11:04:42,705 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 11:04:43,370 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 17, batch_idx_train: 66824,  validation: loss=0.08619, DER=0.1914, ACC=0.961, MI=0.0987, FA=0.05967, CF=0.03304, over 0.00 frames. 
2025-02-08 11:04:43,371 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 11:22:14,330 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 67324, num_updates: 65500, {'loss': 0.1117091029882431, 'DER': 0.23178486742832508, 'ACC': np.float64(0.9543125), 'MI': 0.13386505712438027, 'FA': 0.053944815693037294, 'CF': 0.04397499461090752}, batch size: 64, grad_norm: 0.3303569257259369, grad_scale: , lr: 0.00e+00, 
2025-02-08 11:22:14,331 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 67324, num_updates: 65500, {'loss': 0.1265096366405487, 'DER': 0.28414059394696495, 'ACC': np.float64(0.9459107142857144), 'MI': 0.15972971438305605, 'FA': 0.06456192152631877, 'CF': 0.05984895803759014}, batch size: 64, grad_norm: 0.3303569257259369, grad_scale: , lr: 0.00e+00, 
2025-02-08 11:22:14,331 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 11:22:14,331 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 11:23:24,911 (model:870) WARNING: All labels are zero
2025-02-08 11:23:25,721 (model:870) WARNING: All labels are zero
2025-02-08 11:23:25,737 (model:870) WARNING: All labels are zero
2025-02-08 11:25:35,371 (model:870) WARNING: All labels are zero
2025-02-08 11:25:52,745 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 17, batch_idx_train: 67324,  validation: loss=0.07962, DER=0.1803, ACC=0.9641, MI=0.08541, FA=0.06653, CF=0.02831, over 0.00 frames. 
2025-02-08 11:25:52,745 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 11:25:52,769 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 17, batch_idx_train: 67324,  validation: loss=0.08002, DER=0.1768, ACC=0.9641, MI=0.08757, FA=0.06244, CF=0.02677, over 0.00 frames. 
2025-02-08 11:25:52,769 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 11:32:07,967 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-67500.pt
2025-02-08 11:32:09,573 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 11:43:51,570 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 67824, num_updates: 66000, {'loss': 0.13665346801280975, 'DER': 0.29286856764657215, 'ACC': np.float64(0.9410163257579172), 'MI': 0.15288732005956648, 'FA': 0.07197617340466604, 'CF': 0.06800507418233964}, batch size: 64, grad_norm: 0.3854566216468811, grad_scale: , lr: 0.00e+00, 
2025-02-08 11:43:51,570 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 67824, num_updates: 66000, {'loss': 0.09838730841875076, 'DER': 0.22121774531521285, 'ACC': np.float64(0.9608125), 'MI': 0.1118960665748668, 'FA': 0.0677722564808717, 'CF': 0.04154942225947435}, batch size: 64, grad_norm: 0.3854566216468811, grad_scale: , lr: 0.00e+00, 
2025-02-08 11:43:51,570 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 11:43:51,570 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 11:45:00,654 (model:870) WARNING: All labels are zero
2025-02-08 11:45:01,278 (model:870) WARNING: All labels are zero
2025-02-08 11:45:01,470 (model:870) WARNING: All labels are zero
2025-02-08 11:47:06,499 (model:870) WARNING: All labels are zero
2025-02-08 11:47:23,410 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 17, batch_idx_train: 67824,  validation: loss=0.08577, DER=0.1935, ACC=0.9617, MI=0.1013, FA=0.0604, CF=0.03182, over 0.00 frames. 
2025-02-08 11:47:23,411 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 11:47:24,092 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 17, batch_idx_train: 67824,  validation: loss=0.08647, DER=0.1909, ACC=0.9614, MI=0.103, FA=0.05666, CF=0.03121, over 0.00 frames. 
2025-02-08 11:47:24,092 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 12:05:07,277 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 68324, num_updates: 66500, {'loss': 0.13680310547351837, 'DER': 0.3392410947759893, 'ACC': np.float64(0.9372589285714286), 'MI': 0.16473938055668547, 'FA': 0.10540995990470103, 'CF': 0.06909175431460282}, batch size: 64, grad_norm: 0.36872902512550354, grad_scale: , lr: 0.00e+00, 
2025-02-08 12:05:07,277 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 12:05:07,277 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 68324, num_updates: 66500, {'loss': 0.12568864226341248, 'DER': 0.2778330019880716, 'ACC': np.float64(0.9467321428571429), 'MI': 0.16755025403136736, 'FA': 0.05864811133200795, 'CF': 0.051634636624696265}, batch size: 64, grad_norm: 0.36872902512550354, grad_scale: , lr: 0.00e+00, 
2025-02-08 12:05:07,278 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 12:06:17,389 (model:870) WARNING: All labels are zero
2025-02-08 12:06:18,122 (model:870) WARNING: All labels are zero
2025-02-08 12:06:18,197 (model:870) WARNING: All labels are zero
2025-02-08 12:08:24,887 (model:870) WARNING: All labels are zero
2025-02-08 12:08:42,098 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 17, batch_idx_train: 68324,  validation: loss=0.1089, DER=0.2722, ACC=0.9497, MI=0.1964, FA=0.04027, CF=0.03554, over 0.00 frames. 
2025-02-08 12:08:42,098 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 12:08:42,827 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 17, batch_idx_train: 68324,  validation: loss=0.1118, DER=0.2748, ACC=0.948, MI=0.2055, FA=0.03501, CF=0.03427, over 0.00 frames. 
2025-02-08 12:08:42,828 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 12:26:19,929 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 68824, num_updates: 67000, {'loss': 0.13010524213314056, 'DER': 0.28279995601011765, 'ACC': np.float64(0.9459107142857144), 'MI': 0.16413724843286046, 'FA': 0.06834927966567689, 'CF': 0.05031342791158034}, batch size: 64, grad_norm: 0.49973931908607483, grad_scale: , lr: 0.00e+00, 
2025-02-08 12:26:19,929 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 12:26:19,930 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 68824, num_updates: 67000, {'loss': 0.1501983106136322, 'DER': 0.32153191489361704, 'ACC': np.float64(0.9367767857142857), 'MI': 0.18377304964539007, 'FA': 0.057531914893617024, 'CF': 0.08022695035460993}, batch size: 64, grad_norm: 0.49973931908607483, grad_scale: , lr: 0.00e+00, 
2025-02-08 12:26:19,930 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 12:27:29,746 (model:870) WARNING: All labels are zero
2025-02-08 12:27:30,548 (model:870) WARNING: All labels are zero
2025-02-08 12:27:30,564 (model:870) WARNING: All labels are zero
2025-02-08 12:29:39,314 (model:870) WARNING: All labels are zero
2025-02-08 12:29:56,683 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 17, batch_idx_train: 68824,  validation: loss=0.1183, DER=0.2911, ACC=0.9461, MI=0.209, FA=0.04167, CF=0.04047, over 0.00 frames. 
2025-02-08 12:29:56,684 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 12:29:56,773 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 17, batch_idx_train: 68824,  validation: loss=0.1213, DER=0.2938, ACC=0.9446, MI=0.2203, FA=0.03657, CF=0.03688, over 0.00 frames. 
2025-02-08 12:29:56,774 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 12:36:23,416 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-69000.pt
2025-02-08 12:36:25,063 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 12:47:57,346 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 69324, num_updates: 67500, {'loss': 0.11675964295864105, 'DER': 0.27817188045121527, 'ACC': np.float64(0.9520803571428571), 'MI': 0.15833236422839866, 'FA': 0.08594022560762879, 'CF': 0.033899290615187816}, batch size: 64, grad_norm: 0.3409692943096161, grad_scale: , lr: 0.00e+00, 
2025-02-08 12:47:57,346 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 12:47:57,346 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 69324, num_updates: 67500, {'loss': 0.0992594063282013, 'DER': 0.23690606392028193, 'ACC': np.float64(0.9578928571428571), 'MI': 0.11745048000972172, 'FA': 0.06981407218374043, 'CF': 0.049641511726819784}, batch size: 64, grad_norm: 0.3409692943096161, grad_scale: , lr: 0.00e+00, 
2025-02-08 12:47:57,346 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 12:49:07,345 (model:870) WARNING: All labels are zero
2025-02-08 12:49:08,145 (model:870) WARNING: All labels are zero
2025-02-08 12:49:08,162 (model:870) WARNING: All labels are zero
2025-02-08 12:51:15,677 (model:870) WARNING: All labels are zero
2025-02-08 12:51:32,657 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 17, batch_idx_train: 69324,  validation: loss=0.08836, DER=0.2039, ACC=0.96, MI=0.1144, FA=0.05602, CF=0.03342, over 0.00 frames. 
2025-02-08 12:51:32,658 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 12:51:32,734 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 17, batch_idx_train: 69324,  validation: loss=0.08902, DER=0.2017, ACC=0.9595, MI=0.119, FA=0.05062, CF=0.03205, over 0.00 frames. 
2025-02-08 12:51:32,734 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 13:09:13,035 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 69824, num_updates: 68000, {'loss': 0.14198875427246094, 'DER': 0.2981281126567062, 'ACC': np.float64(0.9402678571428571), 'MI': 0.15776518404029996, 'FA': 0.05552693342492415, 'CF': 0.08483599519148205}, batch size: 64, grad_norm: 0.3795231878757477, grad_scale: , lr: 0.00e+00, 
2025-02-08 13:09:13,036 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 13:09:13,036 (train_accelerate_ddp:702) INFO: [Train] - Epoch 17, batch_idx_train: 69824, num_updates: 68000, {'loss': 0.10005372017621994, 'DER': 0.2287925160247156, 'ACC': np.float64(0.9595089285714286), 'MI': 0.13195126176589478, 'FA': 0.06375238205231853, 'CF': 0.03308887220650228}, batch size: 64, grad_norm: 0.3795231878757477, grad_scale: , lr: 0.00e+00, 
2025-02-08 13:09:13,036 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 13:10:22,351 (model:870) WARNING: All labels are zero
2025-02-08 13:10:23,139 (model:870) WARNING: All labels are zero
2025-02-08 13:10:23,163 (model:870) WARNING: All labels are zero
2025-02-08 13:12:29,999 (model:870) WARNING: All labels are zero
2025-02-08 13:12:46,913 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 17, batch_idx_train: 69824,  validation: loss=0.08029, DER=0.1824, ACC=0.9637, MI=0.09924, FA=0.05453, CF=0.02865, over 0.00 frames. 
2025-02-08 13:12:46,914 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 13:12:46,996 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 17, batch_idx_train: 69824,  validation: loss=0.08094, DER=0.1799, ACC=0.9633, MI=0.1016, FA=0.05064, CF=0.02768, over 0.00 frames. 
2025-02-08 13:12:46,997 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 13:16:43,609 (train_accelerate_ddp:713) INFO: end of epoch 17, batch_idx: 4113 batch_idx_train: 69937, {'loss': 0.10556160658597946, 'DER': 0.2327205676929094, 'ACC': np.float64(0.9549805255853517), 'MI': 0.12879253506174218, 'FA': 0.05570766050176007, 'CF': 0.04822037212940716}, batch size: 64, grad_norm: 0.32884305715560913, grad_scale: , lr: 0.00e+00, 
2025-02-08 13:16:43,609 (train_accelerate_ddp:713) INFO: end of epoch 17, batch_idx: 4113 batch_idx_train: 69937, {'loss': 0.10863475501537323, 'DER': 0.22208883553421369, 'ACC': np.float64(0.9570248967846866), 'MI': 0.13052493724762632, 'FA': 0.05123867728909746, 'CF': 0.040325220997489905}, batch size: 64, grad_norm: 0.32884305715560913, grad_scale: , lr: 0.00e+00, 
2025-02-08 13:16:43,610 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-17.pt
2025-02-08 13:16:44,829 (train_accelerate_ddp:561) INFO:  end of epoch 17, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-17.pt 
2025-02-08 13:16:48,194 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 69938, num_updates: 68000, {'loss': 0.09541691094636917, 'DER': 0.2092253239709996, 'ACC': np.float64(0.9613392857142856), 'MI': 0.1165724724553291, 'FA': 0.054689729976594166, 'CF': 0.03796312153907633}, batch size: 64, grad_norm: 0.3797394633293152, grad_scale: , lr: 0.00e+00, 
2025-02-08 13:16:48,195 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 69938, num_updates: 68000, {'loss': 0.12601898610591888, 'DER': 0.2737676547758611, 'ACC': np.float64(0.9467265265157625), 'MI': 0.14955618824317535, 'FA': 0.0660972478088539, 'CF': 0.05811421872383185}, batch size: 64, grad_norm: 0.3797394633293152, grad_scale: , lr: 0.00e+00, 
2025-02-08 13:34:49,322 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 70438, num_updates: 68500, {'loss': 0.14274126291275024, 'DER': 0.32479738856371004, 'ACC': np.float64(0.9372410714285715), 'MI': 0.2014295362449347, 'FA': 0.052566411526339486, 'CF': 0.07080144079243585}, batch size: 64, grad_norm: 0.4012911915779114, grad_scale: , lr: 0.00e+00, 
2025-02-08 13:34:49,322 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 70438, num_updates: 68500, {'loss': 0.10627233982086182, 'DER': 0.27201162649872834, 'ACC': np.float64(0.9560845236605466), 'MI': 0.15253724112873926, 'FA': 0.09398086472084292, 'CF': 0.02549352064914618}, batch size: 64, grad_norm: 0.4012911915779114, grad_scale: , lr: 0.00e+00, 
2025-02-08 13:34:49,322 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 13:34:49,322 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 13:35:58,864 (model:870) WARNING: All labels are zero
2025-02-08 13:35:59,469 (model:870) WARNING: All labels are zero
2025-02-08 13:35:59,673 (model:870) WARNING: All labels are zero
2025-02-08 13:38:06,153 (model:870) WARNING: All labels are zero
2025-02-08 13:38:23,315 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 18, batch_idx_train: 70438,  validation: loss=0.07871, DER=0.1784, ACC=0.9645, MI=0.08921, FA=0.06192, CF=0.02723, over 0.00 frames. 
2025-02-08 13:38:23,316 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 13:38:24,012 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 18, batch_idx_train: 70438,  validation: loss=0.07916, DER=0.1755, ACC=0.9644, MI=0.09119, FA=0.05822, CF=0.02612, over 0.00 frames. 
2025-02-08 13:38:24,013 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 13:40:33,430 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-70500.pt
2025-02-08 13:40:35,027 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 13:40:35,029 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-08 13:56:05,286 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 70938, num_updates: 69000, {'loss': 0.11876380443572998, 'DER': 0.26518288474810214, 'ACC': np.float64(0.9514732142857143), 'MI': 0.14998849781458476, 'FA': 0.06780538302277432, 'CF': 0.04738900391074304}, batch size: 64, grad_norm: 0.4276053309440613, grad_scale: , lr: 0.00e+00, 
2025-02-08 13:56:05,287 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 13:56:05,287 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 70938, num_updates: 69000, {'loss': 0.14259280264377594, 'DER': 0.31468981035036964, 'ACC': np.float64(0.9349375), 'MI': 0.1825243758705668, 'FA': 0.056466302367941715, 'CF': 0.07569913211186113}, batch size: 64, grad_norm: 0.4276053309440613, grad_scale: , lr: 0.00e+00, 
2025-02-08 13:56:05,287 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 13:57:14,783 (model:870) WARNING: All labels are zero
2025-02-08 13:57:15,568 (model:870) WARNING: All labels are zero
2025-02-08 13:57:15,594 (model:870) WARNING: All labels are zero
2025-02-08 13:59:23,064 (model:870) WARNING: All labels are zero
2025-02-08 13:59:40,076 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 18, batch_idx_train: 70938,  validation: loss=0.07695, DER=0.1754, ACC=0.965, MI=0.08838, FA=0.06016, CF=0.02685, over 0.00 frames. 
2025-02-08 13:59:40,076 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 13:59:40,144 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 18, batch_idx_train: 70938,  validation: loss=0.07753, DER=0.1731, ACC=0.9647, MI=0.09023, FA=0.05664, CF=0.02618, over 0.00 frames. 
2025-02-08 13:59:40,145 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 14:17:22,276 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 71438, num_updates: 69500, {'loss': 0.11463631689548492, 'DER': 0.26954948646125115, 'ACC': np.float64(0.9519642857142857), 'MI': 0.1424486461251167, 'FA': 0.08269140989729225, 'CF': 0.044409430438842205}, batch size: 64, grad_norm: 0.4547477066516876, grad_scale: , lr: 0.00e+00, 
2025-02-08 14:17:22,277 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 14:17:22,277 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 71438, num_updates: 69500, {'loss': 0.15087254345417023, 'DER': 0.34700798599715565, 'ACC': np.float64(0.9310625), 'MI': 0.21726288152280931, 'FA': 0.05442511760201291, 'CF': 0.07531998687233345}, batch size: 64, grad_norm: 0.4547477066516876, grad_scale: , lr: 0.00e+00, 
2025-02-08 14:17:22,278 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 14:18:32,297 (model:870) WARNING: All labels are zero
2025-02-08 14:18:33,046 (model:870) WARNING: All labels are zero
2025-02-08 14:18:33,112 (model:870) WARNING: All labels are zero
2025-02-08 14:20:39,478 (model:870) WARNING: All labels are zero
2025-02-08 14:20:56,585 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 18, batch_idx_train: 71438,  validation: loss=0.1335, DER=0.3377, ACC=0.9393, MI=0.2595, FA=0.03757, CF=0.04065, over 0.00 frames. 
2025-02-08 14:20:56,585 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 14:20:57,309 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 18, batch_idx_train: 71438,  validation: loss=0.1381, DER=0.3374, ACC=0.9379, MI=0.2654, FA=0.03288, CF=0.03908, over 0.00 frames. 
2025-02-08 14:20:57,310 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 14:38:58,005 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 71938, num_updates: 70000, {'loss': 0.13978701829910278, 'DER': 0.3084756550334147, 'ACC': np.float64(0.9395714285714285), 'MI': 0.18160602524663202, 'FA': 0.07637636575792935, 'CF': 0.05049326402885329}, batch size: 64, grad_norm: 0.35004284977912903, grad_scale: , lr: 0.00e+00, 
2025-02-08 14:38:58,005 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 71938, num_updates: 70000, {'loss': 0.09331267327070236, 'DER': 0.19826795136499198, 'ACC': np.float64(0.9629107142857143), 'MI': 0.09268180775407203, 'FA': 0.06561137875659555, 'CF': 0.039974764854324385}, batch size: 64, grad_norm: 0.35004284977912903, grad_scale: , lr: 0.00e+00, 
2025-02-08 14:38:58,006 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 14:38:58,006 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 14:40:07,593 (model:870) WARNING: All labels are zero
2025-02-08 14:40:08,407 (model:870) WARNING: All labels are zero
2025-02-08 14:40:08,457 (model:870) WARNING: All labels are zero
2025-02-08 14:42:16,688 (model:870) WARNING: All labels are zero
2025-02-08 14:42:33,865 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 18, batch_idx_train: 71938,  validation: loss=0.08485, DER=0.187, ACC=0.9621, MI=0.09984, FA=0.05693, CF=0.03026, over 0.00 frames. 
2025-02-08 14:42:33,866 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 14:42:33,897 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 18, batch_idx_train: 71938,  validation: loss=0.08422, DER=0.1904, ACC=0.9622, MI=0.09746, FA=0.06145, CF=0.03154, over 0.00 frames. 
2025-02-08 14:42:33,897 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 14:44:43,733 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-72000.pt
2025-02-08 14:44:45,425 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 15:00:21,972 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 72438, num_updates: 70500, {'loss': 0.14532701671123505, 'DER': 0.3319599109131403, 'ACC': np.float64(0.9346607142857143), 'MI': 0.18992204899777282, 'FA': 0.06653674832962138, 'CF': 0.0755011135857461}, batch size: 64, grad_norm: 0.5733115077018738, grad_scale: , lr: 0.00e+00, 
2025-02-08 15:00:21,972 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 72438, num_updates: 70500, {'loss': 0.16324855387210846, 'DER': 0.34427094323696983, 'ACC': np.float64(0.9294196428571428), 'MI': 0.21233382570162482, 'FA': 0.05918970246887529, 'CF': 0.07274741506646971}, batch size: 64, grad_norm: 0.5733115077018738, grad_scale: , lr: 0.00e+00, 
2025-02-08 15:00:21,973 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 15:00:21,973 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 15:01:32,142 (model:870) WARNING: All labels are zero
2025-02-08 15:01:32,899 (model:870) WARNING: All labels are zero
2025-02-08 15:01:32,960 (model:870) WARNING: All labels are zero
2025-02-08 15:03:39,355 (model:870) WARNING: All labels are zero
2025-02-08 15:03:56,511 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 18, batch_idx_train: 72438,  validation: loss=0.1569, DER=0.3898, ACC=0.9312, MI=0.3156, FA=0.03321, CF=0.04101, over 0.00 frames. 
2025-02-08 15:03:56,512 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 15:03:57,232 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 18, batch_idx_train: 72438,  validation: loss=0.1626, DER=0.3863, ACC=0.9305, MI=0.3199, FA=0.02895, CF=0.03744, over 0.00 frames. 
2025-02-08 15:03:57,233 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 15:21:36,596 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 72938, num_updates: 71000, {'loss': 0.14380134642124176, 'DER': 0.3157412398921833, 'ACC': np.float64(0.9333482142857144), 'MI': 0.1816711590296496, 'FA': 0.04738544474393531, 'CF': 0.08668463611859838}, batch size: 64, grad_norm: 0.48787471652030945, grad_scale: , lr: 0.00e+00, 
2025-02-08 15:21:36,597 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 72938, num_updates: 71000, {'loss': 0.1388198584318161, 'DER': 0.3212786206124391, 'ACC': np.float64(0.9360803571428571), 'MI': 0.1700722163130493, 'FA': 0.07171247830711526, 'CF': 0.07949392599227453}, batch size: 64, grad_norm: 0.48787471652030945, grad_scale: , lr: 0.00e+00, 
2025-02-08 15:21:36,597 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 15:21:36,597 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 15:22:49,365 (model:870) WARNING: All labels are zero
2025-02-08 15:22:50,126 (model:870) WARNING: All labels are zero
2025-02-08 15:22:50,209 (model:870) WARNING: All labels are zero
2025-02-08 15:24:57,277 (model:870) WARNING: All labels are zero
2025-02-08 15:25:14,498 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 18, batch_idx_train: 72938,  validation: loss=0.09088, DER=0.2081, ACC=0.9593, MI=0.1141, FA=0.06143, CF=0.03256, over 0.00 frames. 
2025-02-08 15:25:14,499 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 15:25:15,208 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 18, batch_idx_train: 72938,  validation: loss=0.09156, DER=0.2047, ACC=0.9593, MI=0.1187, FA=0.05529, CF=0.03071, over 0.00 frames. 
2025-02-08 15:25:15,208 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 15:43:14,632 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 73438, num_updates: 71500, {'loss': 0.11973288655281067, 'DER': 0.2660801331589585, 'ACC': np.float64(0.9539107142857144), 'MI': 0.142135299013197, 'FA': 0.08316490310307931, 'CF': 0.0407799310426822}, batch size: 64, grad_norm: 0.3217407464981079, grad_scale: , lr: 0.00e+00, 
2025-02-08 15:43:14,632 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 73438, num_updates: 71500, {'loss': 0.12766453623771667, 'DER': 0.29708208344695936, 'ACC': np.float64(0.9433035714285715), 'MI': 0.19220070902645214, 'FA': 0.05563130624488683, 'CF': 0.0492500681756204}, batch size: 64, grad_norm: 0.3217407464981079, grad_scale: , lr: 0.00e+00, 
2025-02-08 15:43:14,633 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 15:43:14,633 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 15:44:24,554 (model:870) WARNING: All labels are zero
2025-02-08 15:44:25,360 (model:870) WARNING: All labels are zero
2025-02-08 15:44:25,394 (model:870) WARNING: All labels are zero
2025-02-08 15:46:32,451 (model:870) WARNING: All labels are zero
2025-02-08 15:46:48,776 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 18, batch_idx_train: 73438,  validation: loss=0.09582, DER=0.2214, ACC=0.9563, MI=0.1433, FA=0.04438, CF=0.03373, over 0.00 frames. 
2025-02-08 15:46:48,777 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 15:46:49,070 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 18, batch_idx_train: 73438,  validation: loss=0.09473, DER=0.2231, ACC=0.9571, MI=0.1383, FA=0.05, CF=0.03476, over 0.00 frames. 
2025-02-08 15:46:49,070 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 15:48:58,610 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-73500.pt
2025-02-08 15:49:00,193 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 16:04:36,489 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 73938, num_updates: 72000, {'loss': 0.13006706535816193, 'DER': 0.2725238149890967, 'ACC': np.float64(0.9475797078125279), 'MI': 0.132847469298749, 'FA': 0.07574888098244004, 'CF': 0.06392746470790772}, batch size: 64, grad_norm: 0.3652673661708832, grad_scale: , lr: 0.00e+00, 
2025-02-08 16:04:36,489 (train_accelerate_ddp:702) INFO: [Train] - Epoch 18, batch_idx_train: 73938, num_updates: 72000, {'loss': 0.12153299152851105, 'DER': 0.30145669531297614, 'ACC': np.float64(0.9473482142857144), 'MI': 0.1508502468458585, 'FA': 0.09264338392149692, 'CF': 0.05796306454562077}, batch size: 64, grad_norm: 0.3652673661708832, grad_scale: , lr: 0.00e+00, 
2025-02-08 16:04:36,489 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 16:04:36,489 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 16:05:46,052 (model:870) WARNING: All labels are zero
2025-02-08 16:05:46,868 (model:870) WARNING: All labels are zero
2025-02-08 16:05:46,920 (model:870) WARNING: All labels are zero
2025-02-08 16:07:53,928 (model:870) WARNING: All labels are zero
2025-02-08 16:08:10,355 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 18, batch_idx_train: 73938,  validation: loss=0.07898, DER=0.176, ACC=0.9639, MI=0.09195, FA=0.05612, CF=0.02791, over 0.00 frames. 
2025-02-08 16:08:10,355 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 16:08:10,596 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 18, batch_idx_train: 73938,  validation: loss=0.0785, DER=0.1788, ACC=0.9642, MI=0.08997, FA=0.0599, CF=0.02893, over 0.00 frames. 
2025-02-08 16:08:10,597 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 16:12:11,071 (train_accelerate_ddp:713) INFO: end of epoch 18, batch_idx: 4113 batch_idx_train: 74051, {'loss': 0.13909190893173218, 'DER': 0.301056338028169, 'ACC': np.float64(0.9377744323171496), 'MI': 0.17418573943661972, 'FA': 0.04588468309859155, 'CF': 0.08098591549295775}, batch size: 64, grad_norm: 0.44813328981399536, grad_scale: , lr: 0.00e+00, 
2025-02-08 16:12:11,072 (train_accelerate_ddp:713) INFO: end of epoch 18, batch_idx: 4113 batch_idx_train: 74051, {'loss': 0.134334534406662, 'DER': 0.3083111407012872, 'ACC': np.float64(0.9423482142857144), 'MI': 0.17537727474478473, 'FA': 0.08300044385264092, 'CF': 0.049933422103861515}, batch size: 64, grad_norm: 0.44813328981399536, grad_scale: , lr: 0.00e+00, 
2025-02-08 16:12:11,073 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-18.pt
2025-02-08 16:12:12,293 (train_accelerate_ddp:561) INFO:  end of epoch 18, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-18.pt 
2025-02-08 16:12:15,471 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 74052, num_updates: 72000, {'loss': 0.16618914902210236, 'DER': 0.3619835581787521, 'ACC': np.float64(0.9283035714285715), 'MI': 0.24341273187183812, 'FA': 0.057388279932546374, 'CF': 0.061182546374367625}, batch size: 64, grad_norm: 0.41316524147987366, grad_scale: , lr: 0.00e+00, 
2025-02-08 16:12:15,472 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 74052, num_updates: 72000, {'loss': 0.13770939409732819, 'DER': 0.3427457012580344, 'ACC': np.float64(0.9359285714285714), 'MI': 0.2246882382024941, 'FA': 0.06658243146734055, 'CF': 0.05147503158819975}, batch size: 64, grad_norm: 0.41316524147987366, grad_scale: , lr: 0.00e+00, 
2025-02-08 16:30:14,374 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 74552, num_updates: 72500, {'loss': 0.16800826787948608, 'DER': 0.384651992861392, 'ACC': np.float64(0.9265107248182002), 'MI': 0.21546698393813207, 'FA': 0.07650208209399167, 'CF': 0.09268292682926829}, batch size: 64, grad_norm: 0.5033493041992188, grad_scale: , lr: 0.00e+00, 
2025-02-08 16:30:14,375 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 16:30:14,376 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 74552, num_updates: 72500, {'loss': 0.11921859532594681, 'DER': 0.2606087785189753, 'ACC': np.float64(0.9502767857142856), 'MI': 0.1413195806939851, 'FA': 0.06771680026907338, 'CF': 0.05157239755591681}, batch size: 64, grad_norm: 0.5033493041992188, grad_scale: , lr: 0.00e+00, 
2025-02-08 16:30:14,376 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 16:31:24,417 (model:870) WARNING: All labels are zero
2025-02-08 16:31:25,215 (model:870) WARNING: All labels are zero
2025-02-08 16:31:25,222 (model:870) WARNING: All labels are zero
2025-02-08 16:33:34,035 (model:870) WARNING: All labels are zero
2025-02-08 16:33:51,196 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 19, batch_idx_train: 74552,  validation: loss=0.07535, DER=0.1725, ACC=0.9656, MI=0.09028, FA=0.05632, CF=0.02591, over 0.00 frames. 
2025-02-08 16:33:51,197 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 16:33:51,240 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 19, batch_idx_train: 74552,  validation: loss=0.07602, DER=0.1709, ACC=0.9651, MI=0.09194, FA=0.05349, CF=0.02545, over 0.00 frames. 
2025-02-08 16:33:51,241 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 16:49:39,427 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-75000.pt
2025-02-08 16:49:41,046 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 16:49:41,053 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-08 16:51:35,874 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 75052, num_updates: 73000, {'loss': 0.1831030398607254, 'DER': 0.41208673250322025, 'ACC': np.float64(0.9140714285714285), 'MI': 0.24822885358522973, 'FA': 0.059413911550021466, 'CF': 0.10444396736796908}, batch size: 64, grad_norm: 0.4613039493560791, grad_scale: , lr: 0.00e+00, 
2025-02-08 16:51:35,875 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 16:51:35,875 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 75052, num_updates: 73000, {'loss': 0.11068753153085709, 'DER': 0.24934198982277592, 'ACC': np.float64(0.9559375), 'MI': 0.13821138211382114, 'FA': 0.07182546645610341, 'CF': 0.03930514125285138}, batch size: 64, grad_norm: 0.4613039493560791, grad_scale: , lr: 0.00e+00, 
2025-02-08 16:51:35,876 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 16:52:45,787 (model:870) WARNING: All labels are zero
2025-02-08 16:52:46,600 (model:870) WARNING: All labels are zero
2025-02-08 16:52:46,607 (model:870) WARNING: All labels are zero
2025-02-08 16:54:55,655 (model:870) WARNING: All labels are zero
2025-02-08 16:55:12,897 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 19, batch_idx_train: 75052,  validation: loss=0.1067, DER=0.2665, ACC=0.951, MI=0.1958, FA=0.03689, CF=0.03381, over 0.00 frames. 
2025-02-08 16:55:12,898 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 16:55:12,942 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 19, batch_idx_train: 75052,  validation: loss=0.11, DER=0.269, ACC=0.9492, MI=0.2038, FA=0.03231, CF=0.03284, over 0.00 frames. 
2025-02-08 16:55:12,942 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 17:12:55,439 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 75552, num_updates: 73500, {'loss': 0.12996363639831543, 'DER': 0.3254114468189634, 'ACC': np.float64(0.9443928571428571), 'MI': 0.18840579710144928, 'FA': 0.07995578481945467, 'CF': 0.057049864898059445}, batch size: 64, grad_norm: 0.34632256627082825, grad_scale: , lr: 0.00e+00, 
2025-02-08 17:12:55,439 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 17:12:55,439 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 75552, num_updates: 73500, {'loss': 0.09744423627853394, 'DER': 0.22090619587686464, 'ACC': np.float64(0.9594375), 'MI': 0.1404547740097212, 'FA': 0.04754455556176323, 'CF': 0.032906866305380186}, batch size: 64, grad_norm: 0.34632256627082825, grad_scale: , lr: 0.00e+00, 
2025-02-08 17:12:55,440 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 17:14:03,990 (model:870) WARNING: All labels are zero
2025-02-08 17:14:04,273 (model:870) WARNING: All labels are zero
2025-02-08 17:14:04,778 (model:870) WARNING: All labels are zero
2025-02-08 17:16:09,862 (model:870) WARNING: All labels are zero
2025-02-08 17:16:27,089 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 19, batch_idx_train: 75552,  validation: loss=0.07618, DER=0.1742, ACC=0.965, MI=0.08868, FA=0.05812, CF=0.02738, over 0.00 frames. 
2025-02-08 17:16:27,090 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 17:16:27,105 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 19, batch_idx_train: 75552,  validation: loss=0.0768, DER=0.1714, ACC=0.9648, MI=0.09087, FA=0.05429, CF=0.02624, over 0.00 frames. 
2025-02-08 17:16:27,105 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 17:34:24,647 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 76052, num_updates: 74000, {'loss': 0.13697277009487152, 'DER': 0.32551904732215226, 'ACC': np.float64(0.941262466814953), 'MI': 0.15474780223205936, 'FA': 0.0879730656524721, 'CF': 0.0827981794376208}, batch size: 64, grad_norm: 0.44001367688179016, grad_scale: , lr: 0.00e+00, 
2025-02-08 17:34:24,648 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 17:34:24,648 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 76052, num_updates: 74000, {'loss': 0.11618905514478683, 'DER': 0.2816811036252807, 'ACC': np.float64(0.9502809893689372), 'MI': 0.11292909849213988, 'FA': 0.09393647738209818, 'CF': 0.07481552775104267}, batch size: 64, grad_norm: 0.44001367688179016, grad_scale: , lr: 0.00e+00, 
2025-02-08 17:34:24,648 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 17:35:34,993 (model:870) WARNING: All labels are zero
2025-02-08 17:35:35,760 (model:870) WARNING: All labels are zero
2025-02-08 17:35:35,809 (model:870) WARNING: All labels are zero
2025-02-08 17:37:42,598 (model:870) WARNING: All labels are zero
2025-02-08 17:37:59,935 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 19, batch_idx_train: 76052,  validation: loss=0.1145, DER=0.282, ACC=0.9469, MI=0.2107, FA=0.03658, CF=0.03476, over 0.00 frames. 
2025-02-08 17:37:59,936 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 17:38:00,006 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 19, batch_idx_train: 76052,  validation: loss=0.1112, DER=0.2781, ACC=0.9487, MI=0.2006, FA=0.04155, CF=0.03592, over 0.00 frames. 
2025-02-08 17:38:00,006 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 17:53:46,388 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-76500.pt
2025-02-08 17:53:47,972 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 17:55:41,868 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 76552, num_updates: 74500, {'loss': 0.15330436825752258, 'DER': 0.3459067601815288, 'ACC': np.float64(0.9357738954275315), 'MI': 0.20339482524901278, 'FA': 0.0661283668297283, 'CF': 0.07638356810278776}, batch size: 64, grad_norm: 0.48260223865509033, grad_scale: , lr: 0.00e+00, 
2025-02-08 17:55:41,868 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 17:55:41,869 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 76552, num_updates: 74500, {'loss': 0.1337573081254959, 'DER': 0.2818996112895048, 'ACC': np.float64(0.9467917637428374), 'MI': 0.18184890992056785, 'FA': 0.04872964903385725, 'CF': 0.05132105233507971}, batch size: 64, grad_norm: 0.48260223865509033, grad_scale: , lr: 0.00e+00, 
2025-02-08 17:55:41,869 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 17:56:51,468 (model:870) WARNING: All labels are zero
2025-02-08 17:56:52,266 (model:870) WARNING: All labels are zero
2025-02-08 17:56:52,419 (model:870) WARNING: All labels are zero
2025-02-08 17:58:58,707 (model:870) WARNING: All labels are zero
2025-02-08 17:59:15,201 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 19, batch_idx_train: 76552,  validation: loss=0.09063, DER=0.1999, ACC=0.9599, MI=0.1027, FA=0.0642, CF=0.03301, over 0.00 frames. 
2025-02-08 17:59:15,202 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 17:59:15,959 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 19, batch_idx_train: 76552,  validation: loss=0.09029, DER=0.2041, ACC=0.9598, MI=0.09958, FA=0.06932, CF=0.03521, over 0.00 frames. 
2025-02-08 17:59:15,959 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 18:16:55,165 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 77052, num_updates: 75000, {'loss': 0.12678369879722595, 'DER': 0.2861404187151301, 'ACC': np.float64(0.9448214285714286), 'MI': 0.16870132022316744, 'FA': 0.06219963541954372, 'CF': 0.055239463072418934}, batch size: 64, grad_norm: 0.3590269088745117, grad_scale: , lr: 0.00e+00, 
2025-02-08 18:16:55,165 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 77052, num_updates: 75000, {'loss': 0.12311539798974991, 'DER': 0.2951438848920863, 'ACC': np.float64(0.9463600154644274), 'MI': 0.1515587529976019, 'FA': 0.08105515587529977, 'CF': 0.06252997601918465}, batch size: 64, grad_norm: 0.3590269088745117, grad_scale: , lr: 0.00e+00, 
2025-02-08 18:16:55,165 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 18:16:55,165 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 18:18:05,156 (model:870) WARNING: All labels are zero
2025-02-08 18:18:05,932 (model:870) WARNING: All labels are zero
2025-02-08 18:18:05,966 (model:870) WARNING: All labels are zero
2025-02-08 18:20:14,075 (model:870) WARNING: All labels are zero
2025-02-08 18:20:31,113 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 19, batch_idx_train: 77052,  validation: loss=0.1013, DER=0.2332, ACC=0.9545, MI=0.1344, FA=0.05776, CF=0.04106, over 0.00 frames. 
2025-02-08 18:20:31,114 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 18:20:31,183 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 19, batch_idx_train: 77052,  validation: loss=0.1024, DER=0.2341, ACC=0.9537, MI=0.1412, FA=0.05324, CF=0.03958, over 0.00 frames. 
2025-02-08 18:20:31,183 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 18:38:49,096 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 77552, num_updates: 75500, {'loss': 0.09071528166532516, 'DER': 0.19592945874001774, 'ACC': np.float64(0.9635982142857143), 'MI': 0.11091393078970718, 'FA': 0.0548469387755102, 'CF': 0.030168589174800354}, batch size: 64, grad_norm: 0.32289984822273254, grad_scale: , lr: 0.00e+00, 
2025-02-08 18:38:49,097 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 77552, num_updates: 75500, {'loss': 0.1054314523935318, 'DER': 0.24799950375286892, 'ACC': np.float64(0.9570178571428571), 'MI': 0.12263507226598847, 'FA': 0.07474722411761058, 'CF': 0.0506172073692699}, batch size: 64, grad_norm: 0.32289984822273254, grad_scale: , lr: 0.00e+00, 
2025-02-08 18:38:49,098 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 18:38:49,098 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 18:39:58,555 (model:870) WARNING: All labels are zero
2025-02-08 18:39:59,339 (model:870) WARNING: All labels are zero
2025-02-08 18:39:59,355 (model:870) WARNING: All labels are zero
2025-02-08 18:42:07,937 (model:870) WARNING: All labels are zero
2025-02-08 18:42:25,184 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 19, batch_idx_train: 77552,  validation: loss=0.1097, DER=0.2749, ACC=0.9495, MI=0.2029, FA=0.0376, CF=0.03444, over 0.00 frames. 
2025-02-08 18:42:25,185 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 18:42:25,206 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 19, batch_idx_train: 77552,  validation: loss=0.1127, DER=0.2768, ACC=0.9479, MI=0.2106, FA=0.03288, CF=0.03331, over 0.00 frames. 
2025-02-08 18:42:25,207 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 18:58:13,446 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-78000.pt
2025-02-08 18:58:15,099 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 19:00:06,629 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 78052, num_updates: 76000, {'loss': 0.11247412860393524, 'DER': 0.27524653601298216, 'ACC': np.float64(0.9528928571428571), 'MI': 0.1365622269379603, 'FA': 0.08463362876045437, 'CF': 0.05405068031456747}, batch size: 64, grad_norm: 0.37600278854370117, grad_scale: , lr: 0.00e+00, 
2025-02-08 19:00:06,629 (train_accelerate_ddp:702) INFO: [Train] - Epoch 19, batch_idx_train: 78052, num_updates: 76000, {'loss': 0.11269504576921463, 'DER': 0.27943465537637757, 'ACC': np.float64(0.9532946428571429), 'MI': 0.13716456011456324, 'FA': 0.09600896581781956, 'CF': 0.04626112944399477}, batch size: 64, grad_norm: 0.37600278854370117, grad_scale: , lr: 0.00e+00, 
2025-02-08 19:00:06,630 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 19:00:06,630 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 19:01:16,417 (model:870) WARNING: All labels are zero
2025-02-08 19:01:17,230 (model:870) WARNING: All labels are zero
2025-02-08 19:01:17,266 (model:870) WARNING: All labels are zero
2025-02-08 19:03:26,415 (model:870) WARNING: All labels are zero
2025-02-08 19:03:43,629 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 19, batch_idx_train: 78052,  validation: loss=0.1125, DER=0.2755, ACC=0.9482, MI=0.2121, FA=0.03121, CF=0.0322, over 0.00 frames. 
2025-02-08 19:03:43,630 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 19:03:43,670 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 19, batch_idx_train: 78052,  validation: loss=0.1092, DER=0.272, ACC=0.9499, MI=0.2023, FA=0.03563, CF=0.03408, over 0.00 frames. 
2025-02-08 19:03:43,670 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 19:07:42,915 (train_accelerate_ddp:713) INFO: end of epoch 19, batch_idx: 4113 batch_idx_train: 78165, {'loss': 0.13909007608890533, 'DER': 0.3108556267963741, 'ACC': np.float64(0.9379017857142856), 'MI': 0.17322573513154985, 'FA': 0.06406146363033385, 'CF': 0.07356842803449039}, batch size: 64, grad_norm: 0.43686366081237793, grad_scale: , lr: 0.00e+00, 
2025-02-08 19:07:42,916 (train_accelerate_ddp:713) INFO: end of epoch 19, batch_idx: 4113 batch_idx_train: 78165, {'loss': 0.14632539451122284, 'DER': 0.3122044033704811, 'ACC': np.float64(0.9383482142857144), 'MI': 0.17885294917097036, 'FA': 0.0701821147050829, 'CF': 0.06316933949442784}, batch size: 64, grad_norm: 0.43686366081237793, grad_scale: , lr: 0.00e+00, 
2025-02-08 19:07:42,917 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-19.pt
2025-02-08 19:07:44,099 (train_accelerate_ddp:561) INFO:  end of epoch 19, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-19.pt 
2025-02-08 19:07:47,239 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 78166, num_updates: 76000, {'loss': 0.10160680115222931, 'DER': 0.23718622300058378, 'ACC': np.float64(0.9589894570042046), 'MI': 0.13829538820782253, 'FA': 0.07016929363689434, 'CF': 0.0287215411558669}, batch size: 64, grad_norm: 0.4001603126525879, grad_scale: , lr: 0.00e+00, 
2025-02-08 19:07:47,239 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 78166, num_updates: 76000, {'loss': 0.11374500393867493, 'DER': 0.26056126434709453, 'ACC': np.float64(0.9523839285714285), 'MI': 0.1370710894777958, 'FA': 0.0635779099813713, 'CF': 0.059912264887927405}, batch size: 64, grad_norm: 0.4001603126525879, grad_scale: , lr: 0.00e+00, 
2025-02-08 19:25:50,379 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 78666, num_updates: 76500, {'loss': 0.14291279017925262, 'DER': 0.3341196293176074, 'ACC': np.float64(0.9346071428571429), 'MI': 0.19123841617523168, 'FA': 0.0656557146868857, 'CF': 0.07722549845549002}, batch size: 64, grad_norm: 0.4821792542934418, grad_scale: , lr: 0.00e+00, 
2025-02-08 19:25:50,380 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 19:25:50,380 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 78666, num_updates: 76500, {'loss': 0.13356313109397888, 'DER': 0.29826392704098453, 'ACC': np.float64(0.9440982142857144), 'MI': 0.2067355235688386, 'FA': 0.045819140753763324, 'CF': 0.0457092627183826}, batch size: 64, grad_norm: 0.4821792542934418, grad_scale: , lr: 0.00e+00, 
2025-02-08 19:25:50,381 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 19:26:59,974 (model:870) WARNING: All labels are zero
2025-02-08 19:27:00,141 (model:870) WARNING: All labels are zero
2025-02-08 19:27:00,775 (model:870) WARNING: All labels are zero
2025-02-08 19:29:07,526 (model:870) WARNING: All labels are zero
2025-02-08 19:29:24,754 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 20, batch_idx_train: 78666,  validation: loss=0.0762, DER=0.1745, ACC=0.9651, MI=0.08826, FA=0.05894, CF=0.02733, over 0.00 frames. 
2025-02-08 19:29:24,755 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 19:29:25,447 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 20, batch_idx_train: 78666,  validation: loss=0.07676, DER=0.1719, ACC=0.9648, MI=0.08997, FA=0.05574, CF=0.02616, over 0.00 frames. 
2025-02-08 19:29:25,447 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 19:47:10,024 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 79166, num_updates: 77000, {'loss': 0.16555827856063843, 'DER': 0.37396730024842567, 'ACC': np.float64(0.9310571122917733), 'MI': 0.21988560864290255, 'FA': 0.08498469004564099, 'CF': 0.06909700155988215}, batch size: 64, grad_norm: 0.4980258345603943, grad_scale: , lr: 0.00e+00, 
2025-02-08 19:47:10,025 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 19:47:10,025 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 79166, num_updates: 77000, {'loss': 0.11633288860321045, 'DER': 0.27262307608339703, 'ACC': np.float64(0.9493482142857144), 'MI': 0.19130007641087218, 'FA': 0.044318305861805476, 'CF': 0.03700469381071935}, batch size: 64, grad_norm: 0.4980258345603943, grad_scale: , lr: 0.00e+00, 
2025-02-08 19:47:10,025 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 19:48:20,826 (model:870) WARNING: All labels are zero
2025-02-08 19:48:21,655 (model:870) WARNING: All labels are zero
2025-02-08 19:48:21,655 (model:870) WARNING: All labels are zero
2025-02-08 19:50:31,141 (model:870) WARNING: All labels are zero
2025-02-08 19:50:48,268 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 20, batch_idx_train: 79166,  validation: loss=0.1023, DER=0.2363, ACC=0.9547, MI=0.1466, FA=0.05425, CF=0.03543, over 0.00 frames. 
2025-02-08 19:50:48,269 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 19:50:48,361 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 20, batch_idx_train: 79166,  validation: loss=0.1034, DER=0.2364, ACC=0.954, MI=0.154, FA=0.04856, CF=0.03382, over 0.00 frames. 
2025-02-08 19:50:48,362 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 20:02:34,413 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-79500.pt
2025-02-08 20:02:36,011 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 20:02:36,014 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-08 20:08:34,214 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 79666, num_updates: 77500, {'loss': 0.14268408715724945, 'DER': 0.3328, 'ACC': np.float64(0.9388780833621144), 'MI': 0.19845714285714286, 'FA': 0.08285714285714285, 'CF': 0.05148571428571429}, batch size: 64, grad_norm: 0.46467825770378113, grad_scale: , lr: 0.00e+00, 
2025-02-08 20:08:34,215 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 79666, num_updates: 77500, {'loss': 0.11550437659025192, 'DER': 0.2554195804195804, 'ACC': np.float64(0.9538416043873327), 'MI': 0.14271561771561772, 'FA': 0.06794871794871794, 'CF': 0.044755244755244755}, batch size: 64, grad_norm: 0.46467825770378113, grad_scale: , lr: 0.00e+00, 
2025-02-08 20:08:34,215 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 20:08:34,215 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 20:09:43,192 (model:870) WARNING: All labels are zero
2025-02-08 20:09:43,994 (model:870) WARNING: All labels are zero
2025-02-08 20:09:44,093 (model:870) WARNING: All labels are zero
2025-02-08 20:11:50,507 (model:870) WARNING: All labels are zero
2025-02-08 20:12:07,358 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 20, batch_idx_train: 79666,  validation: loss=0.07811, DER=0.1744, ACC=0.9643, MI=0.08489, FA=0.06187, CF=0.02767, over 0.00 frames. 
2025-02-08 20:12:07,359 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 20:12:07,422 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 20, batch_idx_train: 79666,  validation: loss=0.0774, DER=0.1766, ACC=0.9647, MI=0.08318, FA=0.06491, CF=0.02849, over 0.00 frames. 
2025-02-08 20:12:07,422 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 20:30:10,905 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 80166, num_updates: 78000, {'loss': 0.12147678434848785, 'DER': 0.2873176845943482, 'ACC': np.float64(0.9432678571428571), 'MI': 0.12351868732907931, 'FA': 0.08910665451230629, 'CF': 0.07469234275296263}, batch size: 64, grad_norm: 0.40681537985801697, grad_scale: , lr: 0.00e+00, 
2025-02-08 20:30:10,905 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 80166, num_updates: 78000, {'loss': 0.11946629732847214, 'DER': 0.26711852624261384, 'ACC': np.float64(0.9512410714285714), 'MI': 0.16313289305990036, 'FA': 0.05474452554744526, 'CF': 0.04924110763526822}, batch size: 64, grad_norm: 0.40681537985801697, grad_scale: , lr: 0.00e+00, 
2025-02-08 20:30:10,905 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 20:30:10,905 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 20:31:20,423 (model:870) WARNING: All labels are zero
2025-02-08 20:31:21,240 (model:870) WARNING: All labels are zero
2025-02-08 20:31:21,251 (model:870) WARNING: All labels are zero
2025-02-08 20:33:29,248 (model:870) WARNING: All labels are zero
2025-02-08 20:33:46,308 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 20, batch_idx_train: 80166,  validation: loss=0.07875, DER=0.1759, ACC=0.9642, MI=0.08711, FA=0.06139, CF=0.02736, over 0.00 frames. 
2025-02-08 20:33:46,309 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 20:33:46,309 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 20, batch_idx_train: 80166,  validation: loss=0.07833, DER=0.1786, ACC=0.9643, MI=0.08514, FA=0.06486, CF=0.02864, over 0.00 frames. 
2025-02-08 20:33:46,309 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 20:51:25,960 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 80666, num_updates: 78500, {'loss': 0.12494086474180222, 'DER': 0.29407498326266457, 'ACC': np.float64(0.9463392857142857), 'MI': 0.18729078330729748, 'FA': 0.06555456371345682, 'CF': 0.04122963624191029}, batch size: 64, grad_norm: 0.32873281836509705, grad_scale: , lr: 0.00e+00, 
2025-02-08 20:51:25,960 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 80666, num_updates: 78500, {'loss': 0.1121462732553482, 'DER': 0.2636560470151562, 'ACC': np.float64(0.95325), 'MI': 0.11153727188369936, 'FA': 0.09186514073615837, 'CF': 0.06025363439529848}, batch size: 64, grad_norm: 0.32873281836509705, grad_scale: , lr: 0.00e+00, 
2025-02-08 20:51:25,961 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 20:51:25,961 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 20:52:35,595 (model:870) WARNING: All labels are zero
2025-02-08 20:52:36,367 (model:870) WARNING: All labels are zero
2025-02-08 20:52:36,408 (model:870) WARNING: All labels are zero
2025-02-08 20:54:43,684 (model:870) WARNING: All labels are zero
2025-02-08 20:55:00,665 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 20, batch_idx_train: 80666,  validation: loss=0.07773, DER=0.1772, ACC=0.9646, MI=0.09116, FA=0.05821, CF=0.02782, over 0.00 frames. 
2025-02-08 20:55:00,666 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 20:55:00,734 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 20, batch_idx_train: 80666,  validation: loss=0.07829, DER=0.1745, ACC=0.9643, MI=0.09319, FA=0.05439, CF=0.0269, over 0.00 frames. 
2025-02-08 20:55:00,734 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 21:06:46,064 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-81000.pt
2025-02-08 21:06:47,649 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 21:12:43,149 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 81166, num_updates: 79000, {'loss': 0.15928854048252106, 'DER': 0.3593452826926402, 'ACC': np.float64(0.9303214285714285), 'MI': 0.18465794478704398, 'FA': 0.08426027318310184, 'CF': 0.09042706472249439}, batch size: 64, grad_norm: 0.46526506543159485, grad_scale: , lr: 0.00e+00, 
2025-02-08 21:12:43,149 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 81166, num_updates: 79000, {'loss': 0.1289805769920349, 'DER': 0.30762070971495054, 'ACC': np.float64(0.9419332719825331), 'MI': 0.1719604421175102, 'FA': 0.06887725421756835, 'CF': 0.06678301337987202}, batch size: 64, grad_norm: 0.46526506543159485, grad_scale: , lr: 0.00e+00, 
2025-02-08 21:12:43,150 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 21:12:43,150 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 21:13:53,362 (model:870) WARNING: All labels are zero
2025-02-08 21:13:54,183 (model:870) WARNING: All labels are zero
2025-02-08 21:13:54,191 (model:870) WARNING: All labels are zero
2025-02-08 21:16:03,303 (model:870) WARNING: All labels are zero
2025-02-08 21:16:20,403 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 20, batch_idx_train: 81166,  validation: loss=0.08828, DER=0.2018, ACC=0.9605, MI=0.1094, FA=0.06096, CF=0.03146, over 0.00 frames. 
2025-02-08 21:16:20,404 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 21:16:20,496 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 20, batch_idx_train: 81166,  validation: loss=0.08875, DER=0.1988, ACC=0.9605, MI=0.1134, FA=0.05581, CF=0.02959, over 0.00 frames. 
2025-02-08 21:16:20,496 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 21:34:19,427 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 81666, num_updates: 79500, {'loss': 0.12431002408266068, 'DER': 0.2845691382765531, 'ACC': np.float64(0.9489910714285714), 'MI': 0.1566073323116822, 'FA': 0.07579865613580102, 'CF': 0.0521631498290699}, batch size: 64, grad_norm: 0.39850789308547974, grad_scale: , lr: 0.00e+00, 
2025-02-08 21:34:19,427 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 81666, num_updates: 79500, {'loss': 0.1203269436955452, 'DER': 0.289760482728896, 'ACC': np.float64(0.9534017857142857), 'MI': 0.1686472507850502, 'FA': 0.08952650698848592, 'CF': 0.03158672495535989}, batch size: 64, grad_norm: 0.39850789308547974, grad_scale: , lr: 0.00e+00, 
2025-02-08 21:34:19,428 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 21:34:19,428 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 21:35:28,764 (model:870) WARNING: All labels are zero
2025-02-08 21:35:29,572 (model:870) WARNING: All labels are zero
2025-02-08 21:35:29,589 (model:870) WARNING: All labels are zero
2025-02-08 21:37:36,555 (model:870) WARNING: All labels are zero
2025-02-08 21:37:53,322 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 20, batch_idx_train: 81666,  validation: loss=0.08744, DER=0.1936, ACC=0.9608, MI=0.1092, FA=0.05236, CF=0.032, over 0.00 frames. 
2025-02-08 21:37:53,323 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 21:37:53,415 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 20, batch_idx_train: 81666,  validation: loss=0.08683, DER=0.1971, ACC=0.9611, MI=0.1072, FA=0.05703, CF=0.03282, over 0.00 frames. 
2025-02-08 21:37:53,415 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 21:55:28,986 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 82166, num_updates: 80000, {'loss': 0.11631061136722565, 'DER': 0.272391615054788, 'ACC': np.float64(0.9508303571428571), 'MI': 0.14221057646498333, 'FA': 0.07461886612672701, 'CF': 0.05556217246307765}, batch size: 64, grad_norm: 0.3738788962364197, grad_scale: , lr: 0.00e+00, 
2025-02-08 21:55:28,986 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 21:55:28,987 (train_accelerate_ddp:702) INFO: [Train] - Epoch 20, batch_idx_train: 82166, num_updates: 80000, {'loss': 0.12109269201755524, 'DER': 0.24939890710382515, 'ACC': np.float64(0.9536607142857143), 'MI': 0.14857923497267758, 'FA': 0.0666120218579235, 'CF': 0.03420765027322405}, batch size: 64, grad_norm: 0.3738788962364197, grad_scale: , lr: 0.00e+00, 
2025-02-08 21:55:28,987 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 21:56:39,158 (model:870) WARNING: All labels are zero
2025-02-08 21:56:39,945 (model:870) WARNING: All labels are zero
2025-02-08 21:56:39,971 (model:870) WARNING: All labels are zero
2025-02-08 21:58:48,067 (model:870) WARNING: All labels are zero
2025-02-08 21:59:05,106 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 20, batch_idx_train: 82166,  validation: loss=0.09122, DER=0.2082, ACC=0.9592, MI=0.1115, FA=0.06282, CF=0.03388, over 0.00 frames. 
2025-02-08 21:59:05,107 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 21:59:05,198 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 20, batch_idx_train: 82166,  validation: loss=0.09175, DER=0.2048, ACC=0.9593, MI=0.1161, FA=0.0573, CF=0.0314, over 0.00 frames. 
2025-02-08 21:59:05,198 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 22:03:02,342 (train_accelerate_ddp:713) INFO: end of epoch 20, batch_idx: 4113 batch_idx_train: 82279, {'loss': 0.14938515424728394, 'DER': 0.3604717737318218, 'ACC': np.float64(0.9328345442922867), 'MI': 0.21733653956257873, 'FA': 0.07649146914004351, 'CF': 0.06664376502919958}, batch size: 64, grad_norm: 0.48254114389419556, grad_scale: , lr: 0.00e+00, 
2025-02-08 22:03:02,342 (train_accelerate_ddp:713) INFO: end of epoch 20, batch_idx: 4113 batch_idx_train: 82279, {'loss': 0.10494676232337952, 'DER': 0.2446991052825101, 'ACC': np.float64(0.9585625), 'MI': 0.1162519916656453, 'FA': 0.08873636475058218, 'CF': 0.03971074886628263}, batch size: 64, grad_norm: 0.48254114389419556, grad_scale: , lr: 0.00e+00, 
2025-02-08 22:03:02,344 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-20.pt
2025-02-08 22:03:03,513 (train_accelerate_ddp:561) INFO:  end of epoch 20, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-20.pt 
2025-02-08 22:03:06,705 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 82280, num_updates: 80000, {'loss': 0.11747883260250092, 'DER': 0.26854825080277167, 'ACC': np.float64(0.9471339285714285), 'MI': 0.15368148273336713, 'FA': 0.04985634612134528, 'CF': 0.06501042194805927}, batch size: 64, grad_norm: 0.47932565212249756, grad_scale: , lr: 0.00e+00, 
2025-02-08 22:03:06,705 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 82280, num_updates: 80000, {'loss': 0.12373743951320648, 'DER': 0.283477167514431, 'ACC': np.float64(0.9492971887550201), 'MI': 0.1820312053494885, 'FA': 0.06166771446533691, 'CF': 0.03977824769960565}, batch size: 64, grad_norm: 0.47932565212249756, grad_scale: , lr: 0.00e+00, 
2025-02-08 22:10:53,896 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-82500.pt
2025-02-08 22:10:55,554 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 22:10:55,557 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-08 22:21:19,382 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 82780, num_updates: 80500, {'loss': 0.12040256708860397, 'DER': 0.30437188710570007, 'ACC': np.float64(0.9491607142857144), 'MI': 0.1604869950193691, 'FA': 0.09813687511529239, 'CF': 0.04574801697103855}, batch size: 64, grad_norm: 0.44418638944625854, grad_scale: , lr: 0.00e+00, 
2025-02-08 22:21:19,382 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 82780, num_updates: 80500, {'loss': 0.1312975138425827, 'DER': 0.29350104821802936, 'ACC': np.float64(0.9453578812641528), 'MI': 0.14513327343516022, 'FA': 0.0761904761904762, 'CF': 0.07217729859239293}, batch size: 64, grad_norm: 0.44418638944625854, grad_scale: , lr: 0.00e+00, 
2025-02-08 22:21:19,382 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 22:21:19,382 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 22:22:29,144 (model:870) WARNING: All labels are zero
2025-02-08 22:22:29,964 (model:870) WARNING: All labels are zero
2025-02-08 22:22:30,008 (model:870) WARNING: All labels are zero
2025-02-08 22:24:37,976 (model:870) WARNING: All labels are zero
2025-02-08 22:24:55,150 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 21, batch_idx_train: 82780,  validation: loss=0.08478, DER=0.1882, ACC=0.9619, MI=0.1079, FA=0.05089, CF=0.02938, over 0.00 frames. 
2025-02-08 22:24:55,151 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 22:24:55,167 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 21, batch_idx_train: 82780,  validation: loss=0.08415, DER=0.1914, ACC=0.9621, MI=0.105, FA=0.05594, CF=0.03046, over 0.00 frames. 
2025-02-08 22:24:55,168 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 22:42:37,677 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 83280, num_updates: 81000, {'loss': 0.1282372921705246, 'DER': 0.3124923901132351, 'ACC': np.float64(0.9414285714285714), 'MI': 0.13423840253257033, 'FA': 0.09137952027273834, 'CF': 0.08687446730792646}, batch size: 64, grad_norm: 0.42679449915885925, grad_scale: , lr: 0.00e+00, 
2025-02-08 22:42:37,678 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 83280, num_updates: 81000, {'loss': 0.13984273374080658, 'DER': 0.2802965497576276, 'ACC': np.float64(0.9423928571428571), 'MI': 0.14057599087539208, 'FA': 0.052067293983461646, 'CF': 0.08765326489877388}, batch size: 64, grad_norm: 0.42679449915885925, grad_scale: , lr: 0.00e+00, 
2025-02-08 22:42:37,678 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 22:42:37,678 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 22:43:47,702 (model:870) WARNING: All labels are zero
2025-02-08 22:43:48,468 (model:870) WARNING: All labels are zero
2025-02-08 22:43:48,519 (model:870) WARNING: All labels are zero
2025-02-08 22:45:55,977 (model:870) WARNING: All labels are zero
2025-02-08 22:46:12,975 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 21, batch_idx_train: 83280,  validation: loss=0.09697, DER=0.2377, ACC=0.9552, MI=0.1634, FA=0.04167, CF=0.03259, over 0.00 frames. 
2025-02-08 22:46:12,976 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 22:46:13,082 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 21, batch_idx_train: 83280,  validation: loss=0.09907, DER=0.2391, ACC=0.9538, MI=0.1702, FA=0.0367, CF=0.03217, over 0.00 frames. 
2025-02-08 22:46:13,082 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 23:03:54,485 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 83780, num_updates: 81500, {'loss': 0.1522064357995987, 'DER': 0.3322769247582099, 'ACC': np.float64(0.9341244485014453), 'MI': 0.21517949838806621, 'FA': 0.047155893120594504, 'CF': 0.0699415332495492}, batch size: 64, grad_norm: 0.42357754707336426, grad_scale: , lr: 0.00e+00, 
2025-02-08 23:03:54,486 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 23:03:54,486 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 83780, num_updates: 81500, {'loss': 0.1025037169456482, 'DER': 0.24899235998315586, 'ACC': np.float64(0.9550267857142857), 'MI': 0.12669193286410396, 'FA': 0.06827889069361728, 'CF': 0.05402153642543464}, batch size: 64, grad_norm: 0.42357754707336426, grad_scale: , lr: 0.00e+00, 
2025-02-08 23:03:54,487 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 23:05:05,245 (model:870) WARNING: All labels are zero
2025-02-08 23:05:06,081 (model:870) WARNING: All labels are zero
2025-02-08 23:05:06,082 (model:870) WARNING: All labels are zero
2025-02-08 23:07:15,651 (model:870) WARNING: All labels are zero
2025-02-08 23:07:32,883 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 21, batch_idx_train: 83780,  validation: loss=0.08867, DER=0.2016, ACC=0.96, MI=0.1101, FA=0.05693, CF=0.03462, over 0.00 frames. 
2025-02-08 23:07:32,884 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 23:07:32,938 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 21, batch_idx_train: 83780,  validation: loss=0.08923, DER=0.1988, ACC=0.9599, MI=0.1143, FA=0.05202, CF=0.03239, over 0.00 frames. 
2025-02-08 23:07:32,939 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 23:15:21,473 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-84000.pt
2025-02-08 23:15:23,183 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-08 23:25:23,534 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 84280, num_updates: 82000, {'loss': 0.15156656503677368, 'DER': 0.363965800351056, 'ACC': np.float64(0.9338035714285714), 'MI': 0.2361700922937546, 'FA': 0.07196647981428005, 'CF': 0.05582922824302135}, batch size: 64, grad_norm: 0.48003172874450684, grad_scale: , lr: 0.00e+00, 
2025-02-08 23:25:23,534 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 23:25:23,535 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 84280, num_updates: 82000, {'loss': 0.15195006132125854, 'DER': 0.3156813766305856, 'ACC': np.float64(0.9374642857142856), 'MI': 0.18701082431307245, 'FA': 0.05556480710519012, 'CF': 0.07310574521232306}, batch size: 64, grad_norm: 0.48003172874450684, grad_scale: , lr: 0.00e+00, 
2025-02-08 23:25:23,535 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 23:26:34,168 (model:870) WARNING: All labels are zero
2025-02-08 23:26:34,942 (model:870) WARNING: All labels are zero
2025-02-08 23:26:34,994 (model:870) WARNING: All labels are zero
2025-02-08 23:28:42,368 (model:870) WARNING: All labels are zero
2025-02-08 23:28:59,698 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 21, batch_idx_train: 84280,  validation: loss=0.08152, DER=0.186, ACC=0.9632, MI=0.09207, FA=0.06461, CF=0.02934, over 0.00 frames. 
2025-02-08 23:28:59,698 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-08 23:29:00,444 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 21, batch_idx_train: 84280,  validation: loss=0.08205, DER=0.1823, ACC=0.9631, MI=0.09444, FA=0.05983, CF=0.02807, over 0.00 frames. 
2025-02-08 23:29:00,445 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 23:46:44,777 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 84780, num_updates: 82500, {'loss': 0.16275456547737122, 'DER': 0.37344262295081965, 'ACC': np.float64(0.9247678571428571), 'MI': 0.21153005464480873, 'FA': 0.07491803278688525, 'CF': 0.08699453551912568}, batch size: 64, grad_norm: 0.44318893551826477, grad_scale: , lr: 0.00e+00, 
2025-02-08 23:46:44,778 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 23:46:44,778 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 84780, num_updates: 82500, {'loss': 0.1157122403383255, 'DER': 0.2777777777777778, 'ACC': np.float64(0.94975), 'MI': 0.13250180766449746, 'FA': 0.08393588816582309, 'CF': 0.06134008194745722}, batch size: 64, grad_norm: 0.44318893551826477, grad_scale: , lr: 0.00e+00, 
2025-02-08 23:46:44,778 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-08 23:47:55,080 (model:870) WARNING: All labels are zero
2025-02-08 23:47:55,897 (model:870) WARNING: All labels are zero
2025-02-08 23:47:55,940 (model:870) WARNING: All labels are zero
2025-02-08 23:50:05,133 (model:870) WARNING: All labels are zero
2025-02-08 23:50:21,656 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 21, batch_idx_train: 84780,  validation: loss=0.08077, DER=0.1801, ACC=0.9632, MI=0.09787, FA=0.05339, CF=0.02881, over 0.00 frames. 
2025-02-08 23:50:21,657 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-08 23:50:22,346 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 21, batch_idx_train: 84780,  validation: loss=0.08031, DER=0.1832, ACC=0.9635, MI=0.09598, FA=0.05755, CF=0.02969, over 0.00 frames. 
2025-02-08 23:50:22,347 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 00:08:07,609 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 85280, num_updates: 83000, {'loss': 0.17617729306221008, 'DER': 0.42116206538061685, 'ACC': np.float64(0.9243660714285714), 'MI': 0.2668360864040661, 'FA': 0.08623079588772092, 'CF': 0.06809518308882985}, batch size: 64, grad_norm: 0.5635566115379333, grad_scale: , lr: 0.00e+00, 
2025-02-09 00:08:07,609 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 00:08:07,610 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 85280, num_updates: 83000, {'loss': 0.1499854028224945, 'DER': 0.3184252664126774, 'ACC': np.float64(0.9353660714285714), 'MI': 0.17580475953840208, 'FA': 0.0613439346253658, 'CF': 0.08127657224890951}, batch size: 64, grad_norm: 0.5635566115379333, grad_scale: , lr: 0.00e+00, 
2025-02-09 00:08:07,610 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 00:09:18,467 (model:870) WARNING: All labels are zero
2025-02-09 00:09:19,238 (model:870) WARNING: All labels are zero
2025-02-09 00:09:19,288 (model:870) WARNING: All labels are zero
2025-02-09 00:11:26,760 (model:870) WARNING: All labels are zero
2025-02-09 00:11:43,995 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 21, batch_idx_train: 85280,  validation: loss=0.1067, DER=0.2676, ACC=0.951, MI=0.2009, FA=0.03517, CF=0.03149, over 0.00 frames. 
2025-02-09 00:11:43,996 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 00:11:44,742 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 21, batch_idx_train: 85280,  validation: loss=0.11, DER=0.2708, ACC=0.9492, MI=0.2089, FA=0.03093, CF=0.03087, over 0.00 frames. 
2025-02-09 00:11:44,743 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 00:19:34,125 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-85500.pt
2025-02-09 00:19:35,796 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 00:29:41,966 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 85780, num_updates: 83500, {'loss': 0.11726920306682587, 'DER': 0.2816545069428101, 'ACC': np.float64(0.9483542756475939), 'MI': 0.16539185690750766, 'FA': 0.05983760884914097, 'CF': 0.05642504118616145}, batch size: 64, grad_norm: 0.3540950119495392, grad_scale: , lr: 0.00e+00, 
2025-02-09 00:29:41,967 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 85780, num_updates: 83500, {'loss': 0.10878878086805344, 'DER': 0.24274572772106892, 'ACC': np.float64(0.9554642857142857), 'MI': 0.13390297052414268, 'FA': 0.06554650762702145, 'CF': 0.043296249569904806}, batch size: 64, grad_norm: 0.3540950119495392, grad_scale: , lr: 0.00e+00, 
2025-02-09 00:29:41,967 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 00:29:41,967 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 00:30:51,978 (model:870) WARNING: All labels are zero
2025-02-09 00:30:52,560 (model:870) WARNING: All labels are zero
2025-02-09 00:30:52,786 (model:870) WARNING: All labels are zero
2025-02-09 00:32:58,694 (model:870) WARNING: All labels are zero
2025-02-09 00:33:15,580 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 21, batch_idx_train: 85780,  validation: loss=0.08609, DER=0.1986, ACC=0.9609, MI=0.1133, FA=0.05359, CF=0.03166, over 0.00 frames. 
2025-02-09 00:33:15,581 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 00:33:15,768 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 21, batch_idx_train: 85780,  validation: loss=0.08679, DER=0.1968, ACC=0.9604, MI=0.118, FA=0.04858, CF=0.03028, over 0.00 frames. 
2025-02-09 00:33:15,768 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 00:50:55,715 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 86280, num_updates: 84000, {'loss': 0.11531925946474075, 'DER': 0.2844466662500781, 'ACC': np.float64(0.952375), 'MI': 0.15903268137224272, 'FA': 0.07654814722239581, 'CF': 0.04886583765543961}, batch size: 64, grad_norm: 0.3422885537147522, grad_scale: , lr: 0.00e+00, 
2025-02-09 00:50:55,715 (train_accelerate_ddp:702) INFO: [Train] - Epoch 21, batch_idx_train: 86280, num_updates: 84000, {'loss': 0.1267610788345337, 'DER': 0.29391626445167807, 'ACC': np.float64(0.9435), 'MI': 0.17936917723650242, 'FA': 0.053316870580312044, 'CF': 0.061230216634863624}, batch size: 64, grad_norm: 0.3422885537147522, grad_scale: , lr: 0.00e+00, 
2025-02-09 00:50:55,715 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 00:50:55,715 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 00:52:06,071 (model:870) WARNING: All labels are zero
2025-02-09 00:52:06,895 (model:870) WARNING: All labels are zero
2025-02-09 00:52:06,913 (model:870) WARNING: All labels are zero
2025-02-09 00:54:15,789 (model:870) WARNING: All labels are zero
2025-02-09 00:54:32,853 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 21, batch_idx_train: 86280,  validation: loss=0.07561, DER=0.1683, ACC=0.9657, MI=0.08554, FA=0.05833, CF=0.02439, over 0.00 frames. 
2025-02-09 00:54:32,854 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 00:54:32,917 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 21, batch_idx_train: 86280,  validation: loss=0.07496, DER=0.1702, ACC=0.966, MI=0.08385, FA=0.06143, CF=0.02489, over 0.00 frames. 
2025-02-09 00:54:32,917 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 00:58:33,092 (train_accelerate_ddp:713) INFO: end of epoch 21, batch_idx: 4113 batch_idx_train: 86393, {'loss': 0.17686182260513306, 'DER': 0.4100559296883917, 'ACC': np.float64(0.9191946356855996), 'MI': 0.2236616824563406, 'FA': 0.08201118593767835, 'CF': 0.10438306129437279}, batch size: 64, grad_norm: 0.6326254606246948, grad_scale: , lr: 0.00e+00, 
2025-02-09 00:58:33,092 (train_accelerate_ddp:713) INFO: end of epoch 21, batch_idx: 4113 batch_idx_train: 86393, {'loss': 0.11152835935354233, 'DER': 0.2635019730255021, 'ACC': np.float64(0.9505357142857144), 'MI': 0.13528476353142116, 'FA': 0.06543377112904175, 'CF': 0.06278343836503916}, batch size: 64, grad_norm: 0.6326254606246948, grad_scale: , lr: 0.00e+00, 
2025-02-09 00:58:33,093 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-21.pt
2025-02-09 00:58:34,415 (train_accelerate_ddp:561) INFO:  end of epoch 21, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-21.pt 
2025-02-09 00:58:37,757 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 86394, num_updates: 84000, {'loss': 0.13971346616744995, 'DER': 0.2905043834680633, 'ACC': np.float64(0.943066385292224), 'MI': 0.17049982921553, 'FA': 0.048047364226346354, 'CF': 0.07195719002618695}, batch size: 64, grad_norm: 0.39952364563941956, grad_scale: , lr: 0.00e+00, 
2025-02-09 00:58:37,757 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 86394, num_updates: 84000, {'loss': 0.1167321428656578, 'DER': 0.2398769861609431, 'ACC': np.float64(0.954691739761469), 'MI': 0.14397175237769805, 'FA': 0.04954724073124893, 'CF': 0.04635799305199613}, batch size: 64, grad_norm: 0.39952364563941956, grad_scale: , lr: 0.00e+00, 
2025-02-09 01:16:14,219 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 86894, num_updates: 84500, {'loss': 0.1479760706424713, 'DER': 0.37124664460952617, 'ACC': np.float64(0.9363303571428571), 'MI': 0.19982520756601535, 'FA': 0.09750920781571884, 'CF': 0.073912229227792}, batch size: 64, grad_norm: 0.5218695998191833, grad_scale: , lr: 0.00e+00, 
2025-02-09 01:16:14,220 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 01:16:14,220 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 86894, num_updates: 84500, {'loss': 0.11568399518728256, 'DER': 0.27984092636996316, 'ACC': np.float64(0.948807206107966), 'MI': 0.1595414936545997, 'FA': 0.06643663372127025, 'CF': 0.05386279899409322}, batch size: 64, grad_norm: 0.5218695998191833, grad_scale: , lr: 0.00e+00, 
2025-02-09 01:16:14,220 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 01:17:24,626 (model:870) WARNING: All labels are zero
2025-02-09 01:17:25,432 (model:870) WARNING: All labels are zero
2025-02-09 01:17:25,449 (model:870) WARNING: All labels are zero
2025-02-09 01:19:33,283 (model:870) WARNING: All labels are zero
2025-02-09 01:19:50,466 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 22, batch_idx_train: 86894,  validation: loss=0.08118, DER=0.1807, ACC=0.9632, MI=0.09702, FA=0.05517, CF=0.02849, over 0.00 frames. 
2025-02-09 01:19:50,466 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 01:19:50,490 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 22, batch_idx_train: 86894,  validation: loss=0.08062, DER=0.184, ACC=0.9634, MI=0.09476, FA=0.0597, CF=0.02953, over 0.00 frames. 
2025-02-09 01:19:50,490 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 01:23:33,067 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-87000.pt
2025-02-09 01:23:34,675 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 01:23:34,782 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-09 01:37:29,773 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 87394, num_updates: 85000, {'loss': 0.1613650768995285, 'DER': 0.3458279009126467, 'ACC': np.float64(0.9311428571428572), 'MI': 0.21447196870925683, 'FA': 0.05823554976097349, 'CF': 0.07312038244241634}, batch size: 64, grad_norm: 0.45757612586021423, grad_scale: , lr: 0.00e+00, 
2025-02-09 01:37:29,773 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 87394, num_updates: 85000, {'loss': 0.1269320249557495, 'DER': 0.2703964081053937, 'ACC': np.float64(0.9499196428571429), 'MI': 0.1258935428605187, 'FA': 0.08353518048088852, 'CF': 0.06096768476398653}, batch size: 64, grad_norm: 0.45757612586021423, grad_scale: , lr: 0.00e+00, 
2025-02-09 01:37:29,773 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 01:37:29,773 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 01:38:39,200 (model:870) WARNING: All labels are zero
2025-02-09 01:38:40,017 (model:870) WARNING: All labels are zero
2025-02-09 01:38:40,068 (model:870) WARNING: All labels are zero
2025-02-09 01:40:47,099 (model:870) WARNING: All labels are zero
2025-02-09 01:41:03,800 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 22, batch_idx_train: 87394,  validation: loss=0.1098, DER=0.2656, ACC=0.9491, MI=0.1882, FA=0.04126, CF=0.03618, over 0.00 frames. 
2025-02-09 01:41:03,801 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 01:41:03,933 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 22, batch_idx_train: 87394,  validation: loss=0.108, DER=0.2645, ACC=0.9504, MI=0.1783, FA=0.04738, CF=0.03882, over 0.00 frames. 
2025-02-09 01:41:03,933 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 01:58:45,386 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 87894, num_updates: 85500, {'loss': 0.12764783203601837, 'DER': 0.28712338593974174, 'ACC': np.float64(0.9471517857142857), 'MI': 0.13468436154949784, 'FA': 0.0857245337159254, 'CF': 0.0667144906743185}, batch size: 64, grad_norm: 0.44164395332336426, grad_scale: , lr: 0.00e+00, 
2025-02-09 01:58:45,386 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 87894, num_updates: 85500, {'loss': 0.13468261063098907, 'DER': 0.3292513863216266, 'ACC': np.float64(0.9388482142857143), 'MI': 0.15538354898336415, 'FA': 0.10749768946395563, 'CF': 0.06637014787430684}, batch size: 64, grad_norm: 0.44164395332336426, grad_scale: , lr: 0.00e+00, 
2025-02-09 01:58:45,386 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 01:58:45,386 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 01:59:55,503 (model:870) WARNING: All labels are zero
2025-02-09 01:59:56,330 (model:870) WARNING: All labels are zero
2025-02-09 01:59:56,339 (model:870) WARNING: All labels are zero
2025-02-09 02:02:05,060 (model:870) WARNING: All labels are zero
2025-02-09 02:02:22,105 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 22, batch_idx_train: 87894,  validation: loss=0.07514, DER=0.1722, ACC=0.9654, MI=0.08158, FA=0.06332, CF=0.02727, over 0.00 frames. 
2025-02-09 02:02:22,105 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 02:02:22,165 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 22, batch_idx_train: 87894,  validation: loss=0.07571, DER=0.1693, ACC=0.9651, MI=0.08333, FA=0.05958, CF=0.02638, over 0.00 frames. 
2025-02-09 02:02:22,166 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 02:19:57,407 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 88394, num_updates: 86000, {'loss': 0.14526517689228058, 'DER': 0.3203500160068296, 'ACC': np.float64(0.9378125), 'MI': 0.2000853697577633, 'FA': 0.06898943549247678, 'CF': 0.05127521075658948}, batch size: 64, grad_norm: 0.4486997425556183, grad_scale: , lr: 0.00e+00, 
2025-02-09 02:19:57,407 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 02:19:57,408 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 88394, num_updates: 86000, {'loss': 0.14642538130283356, 'DER': 0.31614580512376106, 'ACC': np.float64(0.9324017857142857), 'MI': 0.16828251096788172, 'FA': 0.0539457292964307, 'CF': 0.09391756485944863}, batch size: 64, grad_norm: 0.4486997425556183, grad_scale: , lr: 0.00e+00, 
2025-02-09 02:19:57,408 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 02:21:07,083 (model:870) WARNING: All labels are zero
2025-02-09 02:21:07,904 (model:870) WARNING: All labels are zero
2025-02-09 02:21:07,938 (model:870) WARNING: All labels are zero
2025-02-09 02:23:14,922 (model:870) WARNING: All labels are zero
2025-02-09 02:23:31,064 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 22, batch_idx_train: 88394,  validation: loss=0.08706, DER=0.195, ACC=0.9607, MI=0.1149, FA=0.04972, CF=0.03031, over 0.00 frames. 
2025-02-09 02:23:31,065 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 02:23:31,449 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 22, batch_idx_train: 88394,  validation: loss=0.08641, DER=0.1975, ACC=0.9612, MI=0.1112, FA=0.05503, CF=0.03128, over 0.00 frames. 
2025-02-09 02:23:31,449 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 02:27:10,908 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-88500.pt
2025-02-09 02:27:12,546 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 02:41:07,560 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 88894, num_updates: 86500, {'loss': 0.11702001839876175, 'DER': 0.27763674128779137, 'ACC': np.float64(0.9485357142857144), 'MI': 0.1388760673897992, 'FA': 0.0838333717978306, 'CF': 0.05492730210016155}, batch size: 64, grad_norm: 0.3473001718521118, grad_scale: , lr: 0.00e+00, 
2025-02-09 02:41:07,561 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 88894, num_updates: 86500, {'loss': 0.10156653821468353, 'DER': 0.23714098828566332, 'ACC': np.float64(0.9580714285714286), 'MI': 0.13973954926562407, 'FA': 0.05530118332639591, 'CF': 0.04210025569364334}, batch size: 64, grad_norm: 0.3473001718521118, grad_scale: , lr: 0.00e+00, 
2025-02-09 02:41:07,561 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 02:41:07,561 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 02:42:18,371 (model:870) WARNING: All labels are zero
2025-02-09 02:42:19,197 (model:870) WARNING: All labels are zero
2025-02-09 02:42:19,216 (model:870) WARNING: All labels are zero
2025-02-09 02:44:29,075 (model:870) WARNING: All labels are zero
2025-02-09 02:44:46,153 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 22, batch_idx_train: 88894,  validation: loss=0.088, DER=0.197, ACC=0.9605, MI=0.1185, FA=0.04895, CF=0.02959, over 0.00 frames. 
2025-02-09 02:44:46,154 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 02:44:46,186 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 22, batch_idx_train: 88894,  validation: loss=0.08757, DER=0.1999, ACC=0.9606, MI=0.1137, FA=0.05445, CF=0.03176, over 0.00 frames. 
2025-02-09 02:44:46,186 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 03:02:43,095 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 89394, num_updates: 87000, {'loss': 0.12365484982728958, 'DER': 0.26735559088500266, 'ACC': np.float64(0.9469628408347595), 'MI': 0.1676205617382088, 'FA': 0.0534181240063593, 'CF': 0.04631690514043455}, batch size: 64, grad_norm: 0.37413159012794495, grad_scale: , lr: 0.00e+00, 
2025-02-09 03:02:43,095 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 89394, num_updates: 87000, {'loss': 0.11598678678274155, 'DER': 0.2570836965998256, 'ACC': np.float64(0.9513660714285714), 'MI': 0.17028116826503922, 'FA': 0.047079337401918046, 'CF': 0.03972319093286835}, batch size: 64, grad_norm: 0.37413159012794495, grad_scale: , lr: 0.00e+00, 
2025-02-09 03:02:43,095 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 03:02:43,095 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 03:03:52,113 (model:870) WARNING: All labels are zero
2025-02-09 03:03:52,896 (model:870) WARNING: All labels are zero
2025-02-09 03:03:53,594 (model:870) WARNING: All labels are zero
2025-02-09 03:06:00,937 (model:870) WARNING: All labels are zero
2025-02-09 03:06:17,165 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 22, batch_idx_train: 89394,  validation: loss=0.07714, DER=0.1719, ACC=0.9648, MI=0.0864, FA=0.05923, CF=0.02627, over 0.00 frames. 
2025-02-09 03:06:17,165 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 03:06:17,934 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 22, batch_idx_train: 89394,  validation: loss=0.07661, DER=0.1744, ACC=0.9651, MI=0.08444, FA=0.06265, CF=0.02731, over 0.00 frames. 
2025-02-09 03:06:17,934 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 03:23:50,446 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 89894, num_updates: 87500, {'loss': 0.20918817818164825, 'DER': 0.46933580189770885, 'ACC': np.float64(0.9128303571428571), 'MI': 0.2895163156676695, 'FA': 0.08429761629252489, 'CF': 0.09552186993751446}, batch size: 64, grad_norm: 0.5616723895072937, grad_scale: , lr: 0.00e+00, 
2025-02-09 03:23:50,447 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 03:23:50,447 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 89894, num_updates: 87500, {'loss': 0.1401519775390625, 'DER': 0.3367900639093211, 'ACC': np.float64(0.9383993940924009), 'MI': 0.19082358615699987, 'FA': 0.07084287953695888, 'CF': 0.07512359821536235}, batch size: 64, grad_norm: 0.5616723895072937, grad_scale: , lr: 0.00e+00, 
2025-02-09 03:23:50,447 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 03:24:59,915 (model:870) WARNING: All labels are zero
2025-02-09 03:25:00,704 (model:870) WARNING: All labels are zero
2025-02-09 03:25:00,729 (model:870) WARNING: All labels are zero
2025-02-09 03:27:07,605 (model:870) WARNING: All labels are zero
2025-02-09 03:27:24,377 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 22, batch_idx_train: 89894,  validation: loss=0.09026, DER=0.2058, ACC=0.9596, MI=0.1102, FA=0.06072, CF=0.0349, over 0.00 frames. 
2025-02-09 03:27:24,377 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 03:27:24,521 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 22, batch_idx_train: 89894,  validation: loss=0.0907, DER=0.2016, ACC=0.9594, MI=0.1142, FA=0.05461, CF=0.03279, over 0.00 frames. 
2025-02-09 03:27:24,521 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 03:31:07,465 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-90000.pt
2025-02-09 03:31:09,049 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 03:45:13,405 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 90394, num_updates: 88000, {'loss': 0.14928114414215088, 'DER': 0.317969195664575, 'ACC': np.float64(0.9371987601010554), 'MI': 0.16486023958927554, 'FA': 0.07119224187107816, 'CF': 0.08191671420422134}, batch size: 64, grad_norm: 0.5053286552429199, grad_scale: , lr: 0.00e+00, 
2025-02-09 03:45:13,405 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 03:45:13,406 (train_accelerate_ddp:702) INFO: [Train] - Epoch 22, batch_idx_train: 90394, num_updates: 88000, {'loss': 0.14112937450408936, 'DER': 0.29319858279607364, 'ACC': np.float64(0.9410982142857144), 'MI': 0.13492478364407273, 'FA': 0.0683045826799094, 'CF': 0.08996921647209154}, batch size: 64, grad_norm: 0.5053286552429199, grad_scale: , lr: 0.00e+00, 
2025-02-09 03:45:13,406 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 03:46:23,121 (model:870) WARNING: All labels are zero
2025-02-09 03:46:23,924 (model:870) WARNING: All labels are zero
2025-02-09 03:46:23,951 (model:870) WARNING: All labels are zero
2025-02-09 03:48:32,756 (model:870) WARNING: All labels are zero
2025-02-09 03:48:49,860 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 22, batch_idx_train: 90394,  validation: loss=0.08343, DER=0.1882, ACC=0.962, MI=0.115, FA=0.04513, CF=0.02815, over 0.00 frames. 
2025-02-09 03:48:49,861 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 03:48:49,902 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 22, batch_idx_train: 90394,  validation: loss=0.08275, DER=0.1905, ACC=0.9624, MI=0.1117, FA=0.04997, CF=0.02891, over 0.00 frames. 
2025-02-09 03:48:49,902 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 03:52:47,463 (train_accelerate_ddp:713) INFO: end of epoch 22, batch_idx: 4113 batch_idx_train: 90507, {'loss': 0.14782720804214478, 'DER': 0.32642725598526706, 'ACC': np.float64(0.9339027274943347), 'MI': 0.17178867403314918, 'FA': 0.05973756906077348, 'CF': 0.09490101289134438}, batch size: 64, grad_norm: 0.4207792282104492, grad_scale: , lr: 0.00e+00, 
2025-02-09 03:52:47,464 (train_accelerate_ddp:713) INFO: end of epoch 22, batch_idx: 4113 batch_idx_train: 90507, {'loss': 0.11358566582202911, 'DER': 0.2570085706386508, 'ACC': np.float64(0.9528035714285714), 'MI': 0.16870334531379597, 'FA': 0.0530273707492397, 'CF': 0.03527785457561515}, batch size: 64, grad_norm: 0.4207792282104492, grad_scale: , lr: 0.00e+00, 
2025-02-09 03:52:47,465 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-22.pt
2025-02-09 03:52:48,720 (train_accelerate_ddp:561) INFO:  end of epoch 22, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-22.pt 
2025-02-09 03:52:52,412 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 90508, num_updates: 88000, {'loss': 0.20754405856132507, 'DER': 0.5005963740458015, 'ACC': np.float64(0.9079642857142857), 'MI': 0.27588263358778625, 'FA': 0.11056774809160305, 'CF': 0.11414599236641221}, batch size: 64, grad_norm: 0.6705485582351685, grad_scale: , lr: 0.00e+00, 
2025-02-09 03:52:52,413 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 90508, num_updates: 88000, {'loss': 0.16894790530204773, 'DER': 0.3453628467357803, 'ACC': np.float64(0.9329732142857143), 'MI': 0.21793219389184645, 'FA': 0.05211543849817876, 'CF': 0.07531521434575511}, batch size: 64, grad_norm: 0.6705485582351685, grad_scale: , lr: 0.00e+00, 
2025-02-09 04:10:29,423 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 91008, num_updates: 88500, {'loss': 0.13162578642368317, 'DER': 0.3050867254569877, 'ACC': np.float64(0.9458571428571428), 'MI': 0.18215266016469076, 'FA': 0.07387724113765111, 'CF': 0.049056824154645795}, batch size: 64, grad_norm: 0.4475923776626587, grad_scale: , lr: 0.00e+00, 
2025-02-09 04:10:29,424 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 04:10:29,424 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 91008, num_updates: 88500, {'loss': 0.11429964751005173, 'DER': 0.23840876397034413, 'ACC': np.float64(0.9539285714285715), 'MI': 0.1460661724023459, 'FA': 0.045258382206484454, 'CF': 0.04708420936151378}, batch size: 64, grad_norm: 0.4475923776626587, grad_scale: , lr: 0.00e+00, 
2025-02-09 04:10:29,424 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 04:11:38,418 (model:870) WARNING: All labels are zero
2025-02-09 04:11:39,185 (model:870) WARNING: All labels are zero
2025-02-09 04:11:39,217 (model:870) WARNING: All labels are zero
2025-02-09 04:13:45,242 (model:870) WARNING: All labels are zero
2025-02-09 04:14:01,874 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 23, batch_idx_train: 91008,  validation: loss=0.07992, DER=0.1818, ACC=0.9639, MI=0.08831, FA=0.06476, CF=0.0287, over 0.00 frames. 
2025-02-09 04:14:01,875 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 04:14:02,015 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 23, batch_idx_train: 91008,  validation: loss=0.08029, DER=0.178, ACC=0.9639, MI=0.09022, FA=0.06071, CF=0.02705, over 0.00 frames. 
2025-02-09 04:14:02,015 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 04:31:17,059 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-91500.pt
2025-02-09 04:31:18,622 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 04:31:18,627 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-09 04:31:37,935 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 91508, num_updates: 89000, {'loss': 0.1206149086356163, 'DER': 0.28099608347460103, 'ACC': np.float64(0.9505267857142856), 'MI': 0.17133337230373533, 'FA': 0.06675629859121997, 'CF': 0.04290641257964576}, batch size: 64, grad_norm: 0.4645802080631256, grad_scale: , lr: 0.00e+00, 
2025-02-09 04:31:37,935 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 91508, num_updates: 89000, {'loss': 0.1754307895898819, 'DER': 0.379161791298798, 'ACC': np.float64(0.9220625), 'MI': 0.23976172747580043, 'FA': 0.05430273375172854, 'CF': 0.08509733007126902}, batch size: 64, grad_norm: 0.4645802080631256, grad_scale: , lr: 0.00e+00, 
2025-02-09 04:31:37,935 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 04:31:37,935 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 04:32:46,316 (model:870) WARNING: All labels are zero
2025-02-09 04:32:48,338 (model:870) WARNING: All labels are zero
2025-02-09 04:32:49,202 (model:870) WARNING: All labels are zero
2025-02-09 04:34:50,209 (model:870) WARNING: All labels are zero
2025-02-09 04:35:06,663 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 23, batch_idx_train: 91508,  validation: loss=0.09626, DER=0.2283, ACC=0.9562, MI=0.1428, FA=0.05005, CF=0.0354, over 0.00 frames. 
2025-02-09 04:35:06,663 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 04:35:16,941 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 23, batch_idx_train: 91508,  validation: loss=0.09743, DER=0.2276, ACC=0.9553, MI=0.1485, FA=0.04461, CF=0.0345, over 0.00 frames. 
2025-02-09 04:35:16,941 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 04:53:07,229 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 92008, num_updates: 89500, {'loss': 0.11656563729047775, 'DER': 0.27642422070942313, 'ACC': np.float64(0.9532232142857143), 'MI': 0.16899558103427684, 'FA': 0.07100203033560253, 'CF': 0.036426609339543774}, batch size: 64, grad_norm: 0.35393375158309937, grad_scale: , lr: 0.00e+00, 
2025-02-09 04:53:07,230 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 92008, num_updates: 89500, {'loss': 0.10851512849330902, 'DER': 0.2500612294881215, 'ACC': np.float64(0.9578367730671083), 'MI': 0.1318883174136664, 'FA': 0.0799044819985305, 'CF': 0.038268430075924564}, batch size: 64, grad_norm: 0.35393375158309937, grad_scale: , lr: 0.00e+00, 
2025-02-09 04:53:07,230 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 04:53:07,230 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 04:54:16,449 (model:870) WARNING: All labels are zero
2025-02-09 04:54:17,244 (model:870) WARNING: All labels are zero
2025-02-09 04:54:17,260 (model:870) WARNING: All labels are zero
2025-02-09 04:56:24,334 (model:870) WARNING: All labels are zero
2025-02-09 04:56:41,369 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 23, batch_idx_train: 92008,  validation: loss=0.0849, DER=0.1941, ACC=0.9618, MI=0.1099, FA=0.05448, CF=0.02969, over 0.00 frames. 
2025-02-09 04:56:41,370 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 04:56:41,389 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 23, batch_idx_train: 92008,  validation: loss=0.08547, DER=0.1917, ACC=0.9615, MI=0.1134, FA=0.04972, CF=0.02855, over 0.00 frames. 
2025-02-09 04:56:41,390 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 05:14:20,352 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 92508, num_updates: 90000, {'loss': 0.11296722292900085, 'DER': 0.25299939182838505, 'ACC': np.float64(0.9530446428571429), 'MI': 0.1460717642505667, 'FA': 0.06916569912091558, 'CF': 0.037761928456902745}, batch size: 64, grad_norm: 0.2798379957675934, grad_scale: , lr: 0.00e+00, 
2025-02-09 05:14:20,352 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 92508, num_updates: 90000, {'loss': 0.09974875301122665, 'DER': 0.24396875903962972, 'ACC': np.float64(0.957579185520362), 'MI': 0.1469482210008678, 'FA': 0.06763089383858838, 'CF': 0.02938964420017356}, batch size: 64, grad_norm: 0.2798379957675934, grad_scale: , lr: 0.00e+00, 
2025-02-09 05:14:20,353 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 05:14:20,353 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 05:15:30,006 (model:870) WARNING: All labels are zero
2025-02-09 05:15:30,823 (model:870) WARNING: All labels are zero
2025-02-09 05:15:30,833 (model:870) WARNING: All labels are zero
2025-02-09 05:17:39,636 (model:870) WARNING: All labels are zero
2025-02-09 05:17:56,837 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 23, batch_idx_train: 92508,  validation: loss=0.0757, DER=0.1722, ACC=0.9656, MI=0.08494, FA=0.06174, CF=0.02554, over 0.00 frames. 
2025-02-09 05:17:56,837 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 05:17:56,866 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 23, batch_idx_train: 92508,  validation: loss=0.07634, DER=0.1699, ACC=0.9653, MI=0.0867, FA=0.05816, CF=0.02502, over 0.00 frames. 
2025-02-09 05:17:56,866 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 05:35:49,586 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-93000.pt
2025-02-09 05:35:51,165 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 05:36:10,396 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 93008, num_updates: 90500, {'loss': 0.1801844835281372, 'DER': 0.3812154696132597, 'ACC': np.float64(0.9199553571428571), 'MI': 0.24351486450933965, 'FA': 0.04719810576164167, 'CF': 0.09050249934227834}, batch size: 64, grad_norm: 0.5319060683250427, grad_scale: , lr: 0.00e+00, 
2025-02-09 05:36:10,397 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 05:36:10,397 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 93008, num_updates: 90500, {'loss': 0.10378091782331467, 'DER': 0.22904252241828174, 'ACC': np.float64(0.9580267857142857), 'MI': 0.1342782759618166, 'FA': 0.05183685276251085, 'CF': 0.0429273936939543}, batch size: 64, grad_norm: 0.5319060683250427, grad_scale: , lr: 0.00e+00, 
2025-02-09 05:36:10,397 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 05:37:19,031 (model:870) WARNING: All labels are zero
2025-02-09 05:37:19,706 (model:870) WARNING: All labels are zero
2025-02-09 05:37:19,848 (model:870) WARNING: All labels are zero
2025-02-09 05:39:23,958 (model:870) WARNING: All labels are zero
2025-02-09 05:39:40,694 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 23, batch_idx_train: 93008,  validation: loss=0.1467, DER=0.3663, ACC=0.9345, MI=0.2864, FA=0.03689, CF=0.04303, over 0.00 frames. 
2025-02-09 05:39:40,695 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 05:39:41,304 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 23, batch_idx_train: 93008,  validation: loss=0.1514, DER=0.3644, ACC=0.9337, MI=0.293, FA=0.03275, CF=0.03863, over 0.00 frames. 
2025-02-09 05:39:41,305 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 05:57:20,286 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 93508, num_updates: 91000, {'loss': 0.12112653255462646, 'DER': 0.27945402298850575, 'ACC': np.float64(0.9504464285714286), 'MI': 0.15750718390804597, 'FA': 0.06914511494252873, 'CF': 0.052801724137931036}, batch size: 64, grad_norm: 0.40861326456069946, grad_scale: , lr: 0.00e+00, 
2025-02-09 05:57:20,286 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 93508, num_updates: 91000, {'loss': 0.13333608210086823, 'DER': 0.3273915626856803, 'ACC': np.float64(0.9389403807615231), 'MI': 0.1518716577540107, 'FA': 0.09738562091503268, 'CF': 0.07813428401663695}, batch size: 64, grad_norm: 0.40861326456069946, grad_scale: , lr: 0.00e+00, 
2025-02-09 05:57:20,286 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 05:57:20,286 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 05:58:29,428 (model:870) WARNING: All labels are zero
2025-02-09 05:58:30,227 (model:870) WARNING: All labels are zero
2025-02-09 05:58:30,255 (model:870) WARNING: All labels are zero
2025-02-09 06:00:37,852 (model:870) WARNING: All labels are zero
2025-02-09 06:00:54,844 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 23, batch_idx_train: 93508,  validation: loss=0.07656, DER=0.1713, ACC=0.9651, MI=0.08455, FA=0.06134, CF=0.02542, over 0.00 frames. 
2025-02-09 06:00:54,845 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 06:00:54,913 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 23, batch_idx_train: 93508,  validation: loss=0.07591, DER=0.1729, ACC=0.9655, MI=0.08272, FA=0.06415, CF=0.02601, over 0.00 frames. 
2025-02-09 06:00:54,913 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 06:18:33,855 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 94008, num_updates: 91500, {'loss': 0.14922165870666504, 'DER': 0.34296028880866425, 'ACC': np.float64(0.9383664008734484), 'MI': 0.21884132714457624, 'FA': 0.07243137929058506, 'CF': 0.051687582373502954}, batch size: 64, grad_norm: 0.43607795238494873, grad_scale: , lr: 0.00e+00, 
2025-02-09 06:18:33,856 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 06:18:33,856 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 94008, num_updates: 91500, {'loss': 0.10270512104034424, 'DER': 0.2546490874546606, 'ACC': np.float64(0.9539553571428571), 'MI': 0.13621970176751685, 'FA': 0.07617018826645172, 'CF': 0.042259197420692035}, batch size: 64, grad_norm: 0.43607795238494873, grad_scale: , lr: 0.00e+00, 
2025-02-09 06:18:33,856 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 06:19:44,760 (model:870) WARNING: All labels are zero
2025-02-09 06:19:45,559 (model:870) WARNING: All labels are zero
2025-02-09 06:19:45,584 (model:870) WARNING: All labels are zero
2025-02-09 06:21:55,690 (model:870) WARNING: All labels are zero
2025-02-09 06:22:13,054 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 23, batch_idx_train: 94008,  validation: loss=0.08287, DER=0.1891, ACC=0.9626, MI=0.08818, FA=0.06911, CF=0.03181, over 0.00 frames. 
2025-02-09 06:22:13,054 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 06:22:13,132 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 23, batch_idx_train: 94008,  validation: loss=0.08345, DER=0.1847, ACC=0.9625, MI=0.09013, FA=0.06413, CF=0.03047, over 0.00 frames. 
2025-02-09 06:22:13,132 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 06:39:38,889 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-94500.pt
2025-02-09 06:39:40,514 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 06:39:59,723 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 94508, num_updates: 92000, {'loss': 0.14404523372650146, 'DER': 0.32539772086201063, 'ACC': np.float64(0.937220455892655), 'MI': 0.20805596299221482, 'FA': 0.04840347512129076, 'CF': 0.06893828274850503}, batch size: 64, grad_norm: 0.41667696833610535, grad_scale: , lr: 0.00e+00, 
2025-02-09 06:39:59,723 (train_accelerate_ddp:702) INFO: [Train] - Epoch 23, batch_idx_train: 94508, num_updates: 92000, {'loss': 0.10598030686378479, 'DER': 0.24655891255925524, 'ACC': np.float64(0.9572678571428571), 'MI': 0.1479239248386544, 'FA': 0.07184876349306071, 'CF': 0.026786224227540123}, batch size: 64, grad_norm: 0.41667696833610535, grad_scale: , lr: 0.00e+00, 
2025-02-09 06:39:59,724 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 06:39:59,724 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 06:41:09,416 (model:870) WARNING: All labels are zero
2025-02-09 06:41:10,222 (model:870) WARNING: All labels are zero
2025-02-09 06:41:10,257 (model:870) WARNING: All labels are zero
2025-02-09 06:43:18,269 (model:870) WARNING: All labels are zero
2025-02-09 06:43:35,239 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 23, batch_idx_train: 94508,  validation: loss=0.07531, DER=0.1688, ACC=0.9655, MI=0.09097, FA=0.05313, CF=0.02473, over 0.00 frames. 
2025-02-09 06:43:35,240 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 06:43:35,341 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 23, batch_idx_train: 94508,  validation: loss=0.07454, DER=0.1702, ACC=0.966, MI=0.08923, FA=0.05591, CF=0.02503, over 0.00 frames. 
2025-02-09 06:43:35,341 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 06:47:34,411 (train_accelerate_ddp:713) INFO: end of epoch 23, batch_idx: 4113 batch_idx_train: 94621, {'loss': 0.10087869316339493, 'DER': 0.21618296706369178, 'ACC': np.float64(0.9596785714285715), 'MI': 0.11770955656209808, 'FA': 0.0621260414919197, 'CF': 0.036347369009673995}, batch size: 64, grad_norm: 0.43460512161254883, grad_scale: , lr: 0.00e+00, 
2025-02-09 06:47:34,412 (train_accelerate_ddp:713) INFO: end of epoch 23, batch_idx: 4113 batch_idx_train: 94621, {'loss': 0.12963265180587769, 'DER': 0.31528189910979226, 'ACC': np.float64(0.9446071428571429), 'MI': 0.16592482690405538, 'FA': 0.08110781404549951, 'CF': 0.06824925816023739}, batch size: 64, grad_norm: 0.43460512161254883, grad_scale: , lr: 0.00e+00, 
2025-02-09 06:47:34,413 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-23.pt
2025-02-09 06:47:35,582 (train_accelerate_ddp:561) INFO:  end of epoch 23, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-23.pt 
2025-02-09 06:47:38,546 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 94622, num_updates: 92000, {'loss': 0.13257931172847748, 'DER': 0.3466522678185745, 'ACC': np.float64(0.9404910714285715), 'MI': 0.18856491480681545, 'FA': 0.1048716102711783, 'CF': 0.05321574274058075}, batch size: 64, grad_norm: 0.42074111104011536, grad_scale: , lr: 0.00e+00, 
2025-02-09 06:47:38,546 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 94622, num_updates: 92000, {'loss': 0.12613582611083984, 'DER': 0.3011848205597848, 'ACC': np.float64(0.9451517857142857), 'MI': 0.17921126438097418, 'FA': 0.07154713525270448, 'CF': 0.05042642092610612}, batch size: 64, grad_norm: 0.42074111104011536, grad_scale: , lr: 0.00e+00, 
2025-02-09 07:05:26,635 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 95122, num_updates: 92500, {'loss': 0.12667275965213776, 'DER': 0.27649821741836905, 'ACC': np.float64(0.9480486728453439), 'MI': 0.15692377341406824, 'FA': 0.06966215833852074, 'CF': 0.04991228566578009}, batch size: 64, grad_norm: 0.37812796235084534, grad_scale: , lr: 0.00e+00, 
2025-02-09 07:05:26,635 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 95122, num_updates: 92500, {'loss': 0.10375966131687164, 'DER': 0.22277676950998185, 'ACC': np.float64(0.9588571428571429), 'MI': 0.12948049001814882, 'FA': 0.05473003629764065, 'CF': 0.03856624319419238}, batch size: 64, grad_norm: 0.37812796235084534, grad_scale: , lr: 0.00e+00, 
2025-02-09 07:05:26,635 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 07:05:26,635 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 07:06:36,322 (model:870) WARNING: All labels are zero
2025-02-09 07:06:37,121 (model:870) WARNING: All labels are zero
2025-02-09 07:06:37,139 (model:870) WARNING: All labels are zero
2025-02-09 07:08:43,893 (model:870) WARNING: All labels are zero
2025-02-09 07:09:00,948 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 24, batch_idx_train: 95122,  validation: loss=0.08515, DER=0.1965, ACC=0.9615, MI=0.1176, FA=0.04956, CF=0.02932, over 0.00 frames. 
2025-02-09 07:09:00,949 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 07:09:01,001 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 24, batch_idx_train: 95122,  validation: loss=0.08623, DER=0.1957, ACC=0.9608, MI=0.1216, FA=0.04516, CF=0.02893, over 0.00 frames. 
2025-02-09 07:09:01,001 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 07:26:36,746 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 95622, num_updates: 93000, {'loss': 0.15979833900928497, 'DER': 0.35512162833029953, 'ACC': np.float64(0.9313660714285714), 'MI': 0.22714987037343481, 'FA': 0.05907661757405262, 'CF': 0.06889514038281207}, batch size: 64, grad_norm: 0.6929613351821899, grad_scale: , lr: 0.00e+00, 
2025-02-09 07:26:36,747 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 07:26:36,747 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 95622, num_updates: 93000, {'loss': 0.1697109192609787, 'DER': 0.40331793874574623, 'ACC': np.float64(0.925375), 'MI': 0.22678658240155566, 'FA': 0.07194944093339815, 'CF': 0.10458191541079241}, batch size: 64, grad_norm: 0.6929613351821899, grad_scale: , lr: 0.00e+00, 
2025-02-09 07:26:36,748 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 07:27:45,555 (model:870) WARNING: All labels are zero
2025-02-09 07:27:46,333 (model:870) WARNING: All labels are zero
2025-02-09 07:27:46,357 (model:870) WARNING: All labels are zero
2025-02-09 07:29:54,222 (model:870) WARNING: All labels are zero
2025-02-09 07:30:11,361 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 24, batch_idx_train: 95622,  validation: loss=0.1093, DER=0.246, ACC=0.9523, MI=0.1602, FA=0.04916, CF=0.03667, over 0.00 frames. 
2025-02-09 07:30:11,362 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 07:30:11,364 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 24, batch_idx_train: 95622,  validation: loss=0.1082, DER=0.2463, ACC=0.9529, MI=0.1539, FA=0.05441, CF=0.03802, over 0.00 frames. 
2025-02-09 07:30:11,364 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 07:43:30,596 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-96000.pt
2025-02-09 07:43:32,357 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 07:43:32,460 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-09 07:47:52,266 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 96122, num_updates: 93500, {'loss': 0.1733347624540329, 'DER': 0.3931923488178686, 'ACC': np.float64(0.9265011002829299), 'MI': 0.21468456694784366, 'FA': 0.08560057027444458, 'CF': 0.09290721159558037}, batch size: 64, grad_norm: 0.4252887964248657, grad_scale: , lr: 0.00e+00, 
2025-02-09 07:47:52,266 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 07:47:52,267 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 96122, num_updates: 93500, {'loss': 0.12057512253522873, 'DER': 0.26993130724396336, 'ACC': np.float64(0.9489017857142856), 'MI': 0.19593047460449625, 'FA': 0.046107410491257286, 'CF': 0.027893422148209824}, batch size: 64, grad_norm: 0.4252887964248657, grad_scale: , lr: 0.00e+00, 
2025-02-09 07:47:52,267 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 07:49:00,457 (model:870) WARNING: All labels are zero
2025-02-09 07:49:01,250 (model:870) WARNING: All labels are zero
2025-02-09 07:49:01,349 (model:870) WARNING: All labels are zero
2025-02-09 07:51:06,675 (model:870) WARNING: All labels are zero
2025-02-09 07:51:22,948 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 24, batch_idx_train: 96122,  validation: loss=0.07783, DER=0.173, ACC=0.9646, MI=0.09211, FA=0.05468, CF=0.02617, over 0.00 frames. 
2025-02-09 07:51:22,949 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 07:51:23,201 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 24, batch_idx_train: 96122,  validation: loss=0.07721, DER=0.1754, ACC=0.965, MI=0.09025, FA=0.05812, CF=0.02702, over 0.00 frames. 
2025-02-09 07:51:23,201 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 08:09:08,622 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 96622, num_updates: 94000, {'loss': 0.1433974802494049, 'DER': 0.31977611940298506, 'ACC': np.float64(0.9368928571428571), 'MI': 0.21881663113006397, 'FA': 0.04397654584221748, 'CF': 0.05698294243070363}, batch size: 64, grad_norm: 0.42874160408973694, grad_scale: , lr: 0.00e+00, 
2025-02-09 08:09:08,622 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 08:09:08,622 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 96622, num_updates: 94000, {'loss': 0.12609313428401947, 'DER': 0.3011393824901116, 'ACC': np.float64(0.9456339285714286), 'MI': 0.15986776078871243, 'FA': 0.08294468386563551, 'CF': 0.05832693783576362}, batch size: 64, grad_norm: 0.42874160408973694, grad_scale: , lr: 0.00e+00, 
2025-02-09 08:09:08,623 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 08:10:18,641 (model:870) WARNING: All labels are zero
2025-02-09 08:10:19,460 (model:870) WARNING: All labels are zero
2025-02-09 08:10:19,472 (model:870) WARNING: All labels are zero
2025-02-09 08:12:29,182 (model:870) WARNING: All labels are zero
2025-02-09 08:12:46,623 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 24, batch_idx_train: 96622,  validation: loss=0.07466, DER=0.167, ACC=0.9658, MI=0.08335, FA=0.05923, CF=0.02439, over 0.00 frames. 
2025-02-09 08:12:46,624 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 08:12:46,626 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 24, batch_idx_train: 96622,  validation: loss=0.07386, DER=0.1682, ACC=0.9663, MI=0.08143, FA=0.0619, CF=0.02486, over 0.00 frames. 
2025-02-09 08:12:46,627 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 08:30:27,658 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 97122, num_updates: 94500, {'loss': 0.10383136570453644, 'DER': 0.2373080145210835, 'ACC': np.float64(0.9568303571428571), 'MI': 0.15760960625523596, 'FA': 0.04697012007819045, 'CF': 0.03272828818765708}, batch size: 64, grad_norm: 0.3491629362106323, grad_scale: , lr: 0.00e+00, 
2025-02-09 08:30:27,658 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 08:30:27,659 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 97122, num_updates: 94500, {'loss': 0.10361682623624802, 'DER': 0.23563286630254096, 'ACC': np.float64(0.9581339285714285), 'MI': 0.12265495131797673, 'FA': 0.07023272381857042, 'CF': 0.042745191165993825}, batch size: 64, grad_norm: 0.3491629362106323, grad_scale: , lr: 0.00e+00, 
2025-02-09 08:30:27,659 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 08:31:36,019 (model:870) WARNING: All labels are zero
2025-02-09 08:31:36,811 (model:870) WARNING: All labels are zero
2025-02-09 08:31:36,958 (model:870) WARNING: All labels are zero
2025-02-09 08:33:42,603 (model:870) WARNING: All labels are zero
2025-02-09 08:33:57,176 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 24, batch_idx_train: 97122,  validation: loss=0.09175, DER=0.2001, ACC=0.9597, MI=0.1034, FA=0.06274, CF=0.03391, over 0.00 frames. 
2025-02-09 08:33:57,177 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 08:33:59,246 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 24, batch_idx_train: 97122,  validation: loss=0.09116, DER=0.2046, ACC=0.9598, MI=0.1008, FA=0.06817, CF=0.03566, over 0.00 frames. 
2025-02-09 08:33:59,246 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 08:47:15,345 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-97500.pt
2025-02-09 08:47:17,098 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 08:51:37,892 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 97622, num_updates: 95000, {'loss': 0.10727229714393616, 'DER': 0.2664169362619899, 'ACC': np.float64(0.9500267857142857), 'MI': 0.150632839548215, 'FA': 0.06453260684488336, 'CF': 0.05125148986889154}, batch size: 64, grad_norm: 0.3522399663925171, grad_scale: , lr: 0.00e+00, 
2025-02-09 08:51:37,892 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 97622, num_updates: 95000, {'loss': 0.13265062868595123, 'DER': 0.29890453834115804, 'ACC': np.float64(0.94425), 'MI': 0.18136597361949475, 'FA': 0.06746031746031746, 'CF': 0.050078247261345854}, batch size: 64, grad_norm: 0.3522399663925171, grad_scale: , lr: 0.00e+00, 
2025-02-09 08:51:37,892 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 08:51:37,892 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 08:52:46,748 (model:870) WARNING: All labels are zero
2025-02-09 08:52:47,536 (model:870) WARNING: All labels are zero
2025-02-09 08:52:47,544 (model:870) WARNING: All labels are zero
2025-02-09 08:54:54,624 (model:870) WARNING: All labels are zero
2025-02-09 08:55:11,631 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 24, batch_idx_train: 97622,  validation: loss=0.1194, DER=0.2889, ACC=0.9457, MI=0.1935, FA=0.0516, CF=0.04379, over 0.00 frames. 
2025-02-09 08:55:11,632 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 08:55:11,675 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 24, batch_idx_train: 97622,  validation: loss=0.1208, DER=0.2914, ACC=0.9447, MI=0.2047, FA=0.0471, CF=0.03958, over 0.00 frames. 
2025-02-09 08:55:11,676 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 09:12:46,542 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 98122, num_updates: 95500, {'loss': 0.1720474809408188, 'DER': 0.3967650397275823, 'ACC': np.float64(0.922125), 'MI': 0.22196367763904654, 'FA': 0.07656072644721906, 'CF': 0.09824063564131669}, batch size: 64, grad_norm: 0.5157378315925598, grad_scale: , lr: 0.00e+00, 
2025-02-09 09:12:46,542 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 98122, num_updates: 95500, {'loss': 0.16866569221019745, 'DER': 0.3867986080904741, 'ACC': np.float64(0.9242589285714286), 'MI': 0.2396150500217486, 'FA': 0.07274902131361462, 'CF': 0.07443453675511091}, batch size: 64, grad_norm: 0.5157378315925598, grad_scale: , lr: 0.00e+00, 
2025-02-09 09:12:46,542 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 09:12:46,542 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 09:13:54,533 (model:870) WARNING: All labels are zero
2025-02-09 09:13:55,330 (model:870) WARNING: All labels are zero
2025-02-09 09:13:55,403 (model:870) WARNING: All labels are zero
2025-02-09 09:15:59,630 (model:870) WARNING: All labels are zero
2025-02-09 09:16:15,361 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 24, batch_idx_train: 98122,  validation: loss=0.1209, DER=0.2935, ACC=0.9447, MI=0.2126, FA=0.04414, CF=0.03684, over 0.00 frames. 
2025-02-09 09:16:15,362 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 09:16:16,290 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 24, batch_idx_train: 98122,  validation: loss=0.1181, DER=0.2901, ACC=0.9463, MI=0.2013, FA=0.04932, CF=0.03949, over 0.00 frames. 
2025-02-09 09:16:16,291 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 09:34:14,149 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 98622, num_updates: 96000, {'loss': 0.1264614462852478, 'DER': 0.28469710020097616, 'ACC': np.float64(0.9462678571428571), 'MI': 0.1607235142118863, 'FA': 0.06310651737008326, 'CF': 0.060867068619006606}, batch size: 64, grad_norm: 0.40947890281677246, grad_scale: , lr: 0.00e+00, 
2025-02-09 09:34:14,150 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 09:34:14,150 (train_accelerate_ddp:702) INFO: [Train] - Epoch 24, batch_idx_train: 98622, num_updates: 96000, {'loss': 0.13060325384140015, 'DER': 0.29559927223106663, 'ACC': np.float64(0.9439196428571429), 'MI': 0.17250397998635433, 'FA': 0.06157607459631567, 'CF': 0.061519217648396636}, batch size: 64, grad_norm: 0.40947890281677246, grad_scale: , lr: 0.00e+00, 
2025-02-09 09:34:14,150 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 09:35:25,563 (model:870) WARNING: All labels are zero
2025-02-09 09:35:26,380 (model:870) WARNING: All labels are zero
2025-02-09 09:35:26,398 (model:870) WARNING: All labels are zero
2025-02-09 09:37:37,925 (model:870) WARNING: All labels are zero
2025-02-09 09:37:55,438 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 24, batch_idx_train: 98622,  validation: loss=0.129, DER=0.3194, ACC=0.9424, MI=0.2532, FA=0.03202, CF=0.03416, over 0.00 frames. 
2025-02-09 09:37:55,439 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 09:37:55,537 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 24, batch_idx_train: 98622,  validation: loss=0.1341, DER=0.3227, ACC=0.9407, MI=0.2628, FA=0.0283, CF=0.03157, over 0.00 frames. 
2025-02-09 09:37:55,538 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 09:42:02,630 (train_accelerate_ddp:713) INFO: end of epoch 24, batch_idx: 4113 batch_idx_train: 98735, {'loss': 0.20894457399845123, 'DER': 0.42592592592592593, 'ACC': np.float64(0.9162232142857143), 'MI': 0.239078087375301, 'FA': 0.07481940144478844, 'CF': 0.11202843710583649}, batch size: 64, grad_norm: 0.7280252575874329, grad_scale: , lr: 0.00e+00, 
2025-02-09 09:42:02,630 (train_accelerate_ddp:713) INFO: end of epoch 24, batch_idx: 4113 batch_idx_train: 98735, {'loss': 0.12091632932424545, 'DER': 0.2600470035252644, 'ACC': np.float64(0.9516339285714286), 'MI': 0.13249118683901293, 'FA': 0.06933019976498238, 'CF': 0.0582256169212691}, batch size: 64, grad_norm: 0.7280252575874329, grad_scale: , lr: 0.00e+00, 
2025-02-09 09:42:02,632 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-24.pt
2025-02-09 09:42:03,921 (train_accelerate_ddp:561) INFO:  end of epoch 24, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-24.pt 
2025-02-09 09:42:08,289 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 98736, num_updates: 96000, {'loss': 0.1188933327794075, 'DER': 0.26167795248479286, 'ACC': np.float64(0.9533571428571429), 'MI': 0.15568690462527257, 'FA': 0.0678870653047171, 'CF': 0.03810398255480317}, batch size: 64, grad_norm: 0.3836704194545746, grad_scale: , lr: 0.00e+00, 
2025-02-09 09:42:08,289 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 98736, num_updates: 96000, {'loss': 0.11968865990638733, 'DER': 0.26575028636884307, 'ACC': np.float64(0.9480446428571428), 'MI': 0.14100801832760596, 'FA': 0.05721649484536082, 'CF': 0.06752577319587628}, batch size: 64, grad_norm: 0.3836704194545746, grad_scale: , lr: 0.00e+00, 
2025-02-09 09:51:41,682 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-99000.pt
2025-02-09 09:51:43,352 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 09:51:43,506 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-09 10:00:29,387 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 99236, num_updates: 96500, {'loss': 0.12518610060214996, 'DER': 0.27933643771827704, 'ACC': np.float64(0.9476696428571428), 'MI': 0.14365541327124565, 'FA': 0.07386495925494761, 'CF': 0.06181606519208382}, batch size: 64, grad_norm: 0.3486962914466858, grad_scale: , lr: 0.00e+00, 
2025-02-09 10:00:29,387 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 10:00:29,388 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 99236, num_updates: 96500, {'loss': 0.11573939770460129, 'DER': 0.2678919182083739, 'ACC': np.float64(0.9534910714285715), 'MI': 0.13905793573515093, 'FA': 0.07972249269717624, 'CF': 0.049111489776046735}, batch size: 64, grad_norm: 0.3486962914466858, grad_scale: , lr: 0.00e+00, 
2025-02-09 10:00:29,388 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 10:01:39,910 (model:870) WARNING: All labels are zero
2025-02-09 10:01:40,640 (model:870) WARNING: All labels are zero
2025-02-09 10:01:40,751 (model:870) WARNING: All labels are zero
2025-02-09 10:03:51,067 (model:870) WARNING: All labels are zero
2025-02-09 10:04:08,834 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 25, batch_idx_train: 99236,  validation: loss=0.09101, DER=0.2178, ACC=0.9583, MI=0.1437, FA=0.04345, CF=0.0306, over 0.00 frames. 
2025-02-09 10:04:08,834 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 10:04:09,651 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 25, batch_idx_train: 99236,  validation: loss=0.09256, DER=0.2183, ACC=0.9572, MI=0.1497, FA=0.03847, CF=0.03013, over 0.00 frames. 
2025-02-09 10:04:09,651 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 10:22:34,806 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 99736, num_updates: 97000, {'loss': 0.12697237730026245, 'DER': 0.31488823766017354, 'ACC': np.float64(0.9430267857142857), 'MI': 0.18657702694937656, 'FA': 0.07653852784002758, 'CF': 0.05177268287076941}, batch size: 64, grad_norm: 0.34580692648887634, grad_scale: , lr: 0.00e+00, 
2025-02-09 10:22:34,806 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 10:22:34,806 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 99736, num_updates: 97000, {'loss': 0.11675640940666199, 'DER': 0.262737977330252, 'ACC': np.float64(0.9501875), 'MI': 0.1609442060085837, 'FA': 0.05755474854187301, 'CF': 0.044239022779795314}, batch size: 64, grad_norm: 0.34580692648887634, grad_scale: , lr: 0.00e+00, 
2025-02-09 10:22:34,806 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 10:23:45,996 (model:870) WARNING: All labels are zero
2025-02-09 10:23:46,803 (model:870) WARNING: All labels are zero
2025-02-09 10:23:46,828 (model:870) WARNING: All labels are zero
2025-02-09 10:25:58,413 (model:870) WARNING: All labels are zero
2025-02-09 10:26:16,173 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 25, batch_idx_train: 99736,  validation: loss=0.1134, DER=0.2814, ACC=0.948, MI=0.2007, FA=0.04262, CF=0.03802, over 0.00 frames. 
2025-02-09 10:26:16,174 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 10:26:16,189 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 25, batch_idx_train: 99736,  validation: loss=0.1158, DER=0.2844, ACC=0.9464, MI=0.2099, FA=0.03832, CF=0.03615, over 0.00 frames. 
2025-02-09 10:26:16,190 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 10:45:05,456 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 100236, num_updates: 97500, {'loss': 0.14678682386875153, 'DER': 0.31425200831413963, 'ACC': np.float64(0.9414464285714286), 'MI': 0.1960564013257682, 'FA': 0.06404134599179821, 'CF': 0.05415426099657323}, batch size: 64, grad_norm: 0.44955769181251526, grad_scale: , lr: 0.00e+00, 
2025-02-09 10:45:05,456 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 10:45:05,457 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 100236, num_updates: 97500, {'loss': 0.11973586678504944, 'DER': 0.25475891941183176, 'ACC': np.float64(0.95075), 'MI': 0.11318819104069304, 'FA': 0.08195600136783313, 'CF': 0.0596147270033056}, batch size: 64, grad_norm: 0.44955769181251526, grad_scale: , lr: 0.00e+00, 
2025-02-09 10:45:05,457 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 10:46:16,720 (model:870) WARNING: All labels are zero
2025-02-09 10:46:17,536 (model:870) WARNING: All labels are zero
2025-02-09 10:46:18,215 (model:870) WARNING: All labels are zero
2025-02-09 10:48:30,513 (model:870) WARNING: All labels are zero
2025-02-09 10:48:47,569 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 25, batch_idx_train: 100236,  validation: loss=0.07879, DER=0.1756, ACC=0.964, MI=0.08863, FA=0.05896, CF=0.02796, over 0.00 frames. 
2025-02-09 10:48:47,569 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 10:48:48,348 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 25, batch_idx_train: 100236,  validation: loss=0.07803, DER=0.1779, ACC=0.9643, MI=0.08656, FA=0.0622, CF=0.02912, over 0.00 frames. 
2025-02-09 10:48:48,348 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 10:58:40,277 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-100500.pt
2025-02-09 10:58:42,080 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 11:07:37,591 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 100736, num_updates: 98000, {'loss': 0.13424478471279144, 'DER': 0.28453619659065754, 'ACC': np.float64(0.944955357142857), 'MI': 0.16609475315474873, 'FA': 0.06176665928713748, 'CF': 0.05667478414877131}, batch size: 64, grad_norm: 0.4024902284145355, grad_scale: , lr: 0.00e+00, 
2025-02-09 11:07:37,592 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 100736, num_updates: 98000, {'loss': 0.11380414664745331, 'DER': 0.25672620393398143, 'ACC': np.float64(0.9525267857142856), 'MI': 0.15543748586931946, 'FA': 0.057483608410581054, 'CF': 0.043805109654080944}, batch size: 64, grad_norm: 0.4024902284145355, grad_scale: , lr: 0.00e+00, 
2025-02-09 11:07:37,592 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 11:07:37,592 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 11:08:49,810 (model:870) WARNING: All labels are zero
2025-02-09 11:08:50,643 (model:870) WARNING: All labels are zero
2025-02-09 11:08:50,643 (model:870) WARNING: All labels are zero
2025-02-09 11:11:04,930 (model:870) WARNING: All labels are zero
2025-02-09 11:11:22,958 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 25, batch_idx_train: 100736,  validation: loss=0.08231, DER=0.1847, ACC=0.9626, MI=0.111, FA=0.04567, CF=0.02807, over 0.00 frames. 
2025-02-09 11:11:22,959 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 11:11:22,967 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 25, batch_idx_train: 100736,  validation: loss=0.08161, DER=0.1876, ACC=0.963, MI=0.109, FA=0.05012, CF=0.02854, over 0.00 frames. 
2025-02-09 11:11:22,967 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 11:30:12,205 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 101236, num_updates: 98500, {'loss': 0.1423618495464325, 'DER': 0.3363366923532899, 'ACC': np.float64(0.9403392857142857), 'MI': 0.21381149970361588, 'FA': 0.06277415530527564, 'CF': 0.05975103734439834}, batch size: 64, grad_norm: 0.45197591185569763, grad_scale: , lr: 0.00e+00, 
2025-02-09 11:30:12,206 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 11:30:12,207 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 101236, num_updates: 98500, {'loss': 0.1287684142589569, 'DER': 0.3066720027442685, 'ACC': np.float64(0.9442053571428571), 'MI': 0.18535246698301983, 'FA': 0.07072208564404552, 'CF': 0.05059745011720313}, batch size: 64, grad_norm: 0.45197591185569763, grad_scale: , lr: 0.00e+00, 
2025-02-09 11:30:12,207 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 11:31:24,793 (model:870) WARNING: All labels are zero
2025-02-09 11:31:25,598 (model:870) WARNING: All labels are zero
2025-02-09 11:31:25,632 (model:870) WARNING: All labels are zero
2025-02-09 11:33:38,362 (model:870) WARNING: All labels are zero
2025-02-09 11:33:56,010 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 25, batch_idx_train: 101236,  validation: loss=0.0902, DER=0.2143, ACC=0.9587, MI=0.1374, FA=0.04491, CF=0.03194, over 0.00 frames. 
2025-02-09 11:33:56,010 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 11:33:56,203 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 25, batch_idx_train: 101236,  validation: loss=0.09169, DER=0.2136, ACC=0.9577, MI=0.1421, FA=0.04007, CF=0.03146, over 0.00 frames. 
2025-02-09 11:33:56,203 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 11:52:47,141 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 101736, num_updates: 99000, {'loss': 0.12907664477825165, 'DER': 0.2899415070535612, 'ACC': np.float64(0.9466517857142857), 'MI': 0.17846083266429635, 'FA': 0.05877967656841381, 'CF': 0.05270099782085101}, batch size: 64, grad_norm: 0.4120030999183655, grad_scale: , lr: 0.00e+00, 
2025-02-09 11:52:47,142 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 11:52:47,143 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 101736, num_updates: 99000, {'loss': 0.14064888656139374, 'DER': 0.3027310344827586, 'ACC': np.float64(0.9433482142857144), 'MI': 0.2034206896551724, 'FA': 0.051972413793103446, 'CF': 0.04733793103448276}, batch size: 64, grad_norm: 0.4120030999183655, grad_scale: , lr: 0.00e+00, 
2025-02-09 11:52:47,143 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 11:53:59,105 (model:870) WARNING: All labels are zero
2025-02-09 11:53:59,955 (model:870) WARNING: All labels are zero
2025-02-09 11:53:59,975 (model:870) WARNING: All labels are zero
2025-02-09 11:56:13,910 (model:870) WARNING: All labels are zero
2025-02-09 11:56:31,822 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 25, batch_idx_train: 101736,  validation: loss=0.07727, DER=0.1762, ACC=0.9647, MI=0.08659, FA=0.06141, CF=0.02819, over 0.00 frames. 
2025-02-09 11:56:31,823 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 11:56:31,877 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 25, batch_idx_train: 101736,  validation: loss=0.07785, DER=0.1737, ACC=0.9644, MI=0.08869, FA=0.0579, CF=0.02713, over 0.00 frames. 
2025-02-09 11:56:31,877 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 12:06:15,356 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-102000.pt
2025-02-09 12:06:17,025 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 12:15:03,398 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 102236, num_updates: 99500, {'loss': 0.13181327283382416, 'DER': 0.282277948162848, 'ACC': np.float64(0.9469107142857144), 'MI': 0.1458897107462866, 'FA': 0.06109808166456191, 'CF': 0.07529015575199952}, batch size: 64, grad_norm: 0.3995373249053955, grad_scale: , lr: 0.00e+00, 
2025-02-09 12:15:03,398 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 102236, num_updates: 99500, {'loss': 0.08839265257120132, 'DER': 0.1993444576877235, 'ACC': np.float64(0.9637767857142857), 'MI': 0.09821215733015494, 'FA': 0.058700834326579264, 'CF': 0.042431466030989275}, batch size: 64, grad_norm: 0.3995373249053955, grad_scale: , lr: 0.00e+00, 
2025-02-09 12:15:03,398 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 12:15:03,398 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 12:16:16,194 (model:870) WARNING: All labels are zero
2025-02-09 12:16:17,034 (model:870) WARNING: All labels are zero
2025-02-09 12:16:17,041 (model:870) WARNING: All labels are zero
2025-02-09 12:18:29,812 (model:870) WARNING: All labels are zero
2025-02-09 12:18:47,747 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 25, batch_idx_train: 102236,  validation: loss=0.07441, DER=0.1707, ACC=0.9657, MI=0.08323, FA=0.06101, CF=0.02646, over 0.00 frames. 
2025-02-09 12:18:47,747 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 12:18:48,542 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 25, batch_idx_train: 102236,  validation: loss=0.0751, DER=0.1687, ACC=0.9654, MI=0.08496, FA=0.05798, CF=0.02571, over 0.00 frames. 
2025-02-09 12:18:48,543 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 12:37:23,275 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 102736, num_updates: 100000, {'loss': 0.1397986263036728, 'DER': 0.30863034199878053, 'ACC': np.float64(0.9403660714285714), 'MI': 0.19128651405132754, 'FA': 0.05576187572750956, 'CF': 0.06158195221994346}, batch size: 64, grad_norm: 0.41138026118278503, grad_scale: , lr: 0.00e+00, 
2025-02-09 12:37:23,276 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 12:37:23,276 (train_accelerate_ddp:702) INFO: [Train] - Epoch 25, batch_idx_train: 102736, num_updates: 100000, {'loss': 0.15765056014060974, 'DER': 0.3432282003710575, 'ACC': np.float64(0.9292180848197445), 'MI': 0.2151073416379539, 'FA': 0.053591306652531145, 'CF': 0.07452955208057249}, batch size: 64, grad_norm: 0.41138026118278503, grad_scale: , lr: 0.00e+00, 
2025-02-09 12:37:23,276 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 12:38:33,358 (model:870) WARNING: All labels are zero
2025-02-09 12:38:34,184 (model:870) WARNING: All labels are zero
2025-02-09 12:38:40,128 (model:870) WARNING: All labels are zero
2025-02-09 12:41:01,890 (model:870) WARNING: All labels are zero
2025-02-09 12:41:02,433 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 25, batch_idx_train: 102736,  validation: loss=0.08399, DER=0.1865, ACC=0.9625, MI=0.1019, FA=0.05688, CF=0.02772, over 0.00 frames. 
2025-02-09 12:41:02,434 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 12:41:19,853 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 25, batch_idx_train: 102736,  validation: loss=0.08356, DER=0.1898, ACC=0.9626, MI=0.09911, FA=0.06182, CF=0.02887, over 0.00 frames. 
2025-02-09 12:41:19,853 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 12:45:23,097 (train_accelerate_ddp:713) INFO: end of epoch 25, batch_idx: 4113 batch_idx_train: 102849, {'loss': 0.12246216088533401, 'DER': 0.29222616968748116, 'ACC': np.float64(0.9449821428571429), 'MI': 0.1330161979887999, 'FA': 0.08038778828204973, 'CF': 0.07882218341663154}, batch size: 64, grad_norm: 0.43064945936203003, grad_scale: , lr: 0.00e+00, 
2025-02-09 12:45:23,098 (train_accelerate_ddp:713) INFO: end of epoch 25, batch_idx: 4113 batch_idx_train: 102849, {'loss': 0.12518154084682465, 'DER': 0.28200770450940404, 'ACC': np.float64(0.9437589285714285), 'MI': 0.12446181735780648, 'FA': 0.08271017448447768, 'CF': 0.07483571266711987}, batch size: 64, grad_norm: 0.43064945936203003, grad_scale: , lr: 0.00e+00, 
2025-02-09 12:45:23,098 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-25.pt
2025-02-09 12:45:24,308 (train_accelerate_ddp:561) INFO:  end of epoch 25, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-25.pt 
2025-02-09 12:45:27,726 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 102850, num_updates: 100000, {'loss': 0.14129799604415894, 'DER': 0.3310222419435354, 'ACC': np.float64(0.9361517857142857), 'MI': 0.20200787619945643, 'FA': 0.0633978590049365, 'CF': 0.06561650673914249}, batch size: 64, grad_norm: 0.4103400409221649, grad_scale: , lr: 0.00e+00, 
2025-02-09 12:45:27,728 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 102850, num_updates: 100000, {'loss': 0.11609061807394028, 'DER': 0.2709777671527612, 'ACC': np.float64(0.9497053571428571), 'MI': 0.11624432225675353, 'FA': 0.08905092039206311, 'CF': 0.06568252450394453}, batch size: 64, grad_norm: 0.4103400409221649, grad_scale: , lr: 0.00e+00, 
2025-02-09 13:03:39,265 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 103350, num_updates: 100500, {'loss': 0.17649075388908386, 'DER': 0.39218648823656377, 'ACC': np.float64(0.9249642857142857), 'MI': 0.2605223397366717, 'FA': 0.07036477444420462, 'CF': 0.06129937405568746}, batch size: 64, grad_norm: 0.3910661041736603, grad_scale: , lr: 0.00e+00, 
2025-02-09 13:03:39,265 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 13:03:39,266 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 103350, num_updates: 100500, {'loss': 0.12153193354606628, 'DER': 0.2617976919326001, 'ACC': np.float64(0.951125), 'MI': 0.16356937747196185, 'FA': 0.06344476350436148, 'CF': 0.03478355095627675}, batch size: 64, grad_norm: 0.3910661041736603, grad_scale: , lr: 0.00e+00, 
2025-02-09 13:03:39,266 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 13:04:48,521 (model:870) WARNING: All labels are zero
2025-02-09 13:04:49,311 (model:870) WARNING: All labels are zero
2025-02-09 13:04:49,797 (model:870) WARNING: All labels are zero
2025-02-09 13:06:58,765 (model:870) WARNING: All labels are zero
2025-02-09 13:07:14,520 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 26, batch_idx_train: 103350,  validation: loss=0.08963, DER=0.204, ACC=0.9593, MI=0.1307, FA=0.04326, CF=0.03008, over 0.00 frames. 
2025-02-09 13:07:14,520 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 13:07:16,128 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 26, batch_idx_train: 103350,  validation: loss=0.08851, DER=0.2054, ACC=0.9599, MI=0.1259, FA=0.04859, CF=0.03092, over 0.00 frames. 
2025-02-09 13:07:16,129 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 13:12:41,408 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-103500.pt
2025-02-09 13:12:43,152 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 13:12:43,256 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-09 13:25:39,368 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 103850, num_updates: 101000, {'loss': 0.11380860209465027, 'DER': 0.24539592168709695, 'ACC': np.float64(0.9555535714285714), 'MI': 0.13727996281879976, 'FA': 0.06431185731714402, 'CF': 0.0438041015511532}, batch size: 64, grad_norm: 0.33494600653648376, grad_scale: , lr: 0.00e+00, 
2025-02-09 13:25:39,369 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 13:25:39,369 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 103850, num_updates: 101000, {'loss': 0.10923389345407486, 'DER': 0.2314961521050249, 'ACC': np.float64(0.9558839285714286), 'MI': 0.13824128564961521, 'FA': 0.04515617926663649, 'CF': 0.0480986871887732}, batch size: 64, grad_norm: 0.33494600653648376, grad_scale: , lr: 0.00e+00, 
2025-02-09 13:25:39,369 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 13:26:51,004 (model:870) WARNING: All labels are zero
2025-02-09 13:26:51,792 (model:870) WARNING: All labels are zero
2025-02-09 13:26:51,840 (model:870) WARNING: All labels are zero
2025-02-09 13:29:02,392 (model:870) WARNING: All labels are zero
2025-02-09 13:29:20,174 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 26, batch_idx_train: 103850,  validation: loss=0.07537, DER=0.172, ACC=0.9657, MI=0.08021, FA=0.06586, CF=0.0259, over 0.00 frames. 
2025-02-09 13:29:20,175 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 13:29:20,939 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 26, batch_idx_train: 103850,  validation: loss=0.07608, DER=0.1701, ACC=0.9653, MI=0.08209, FA=0.06255, CF=0.02541, over 0.00 frames. 
2025-02-09 13:29:20,939 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 13:47:39,733 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 104350, num_updates: 101500, {'loss': 0.1330753117799759, 'DER': 0.30135731057785925, 'ACC': np.float64(0.9453839285714285), 'MI': 0.19305881679170722, 'FA': 0.05933222610388866, 'CF': 0.04896626768226333}, batch size: 64, grad_norm: 0.4730967879295349, grad_scale: , lr: 0.00e+00, 
2025-02-09 13:47:39,734 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 13:47:39,735 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 104350, num_updates: 101500, {'loss': 0.11546272784471512, 'DER': 0.2595392582891839, 'ACC': np.float64(0.9518125), 'MI': 0.13429370795880707, 'FA': 0.0635156854574677, 'CF': 0.0617298648729091}, batch size: 64, grad_norm: 0.4730967879295349, grad_scale: , lr: 0.00e+00, 
2025-02-09 13:47:39,735 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 13:48:51,648 (model:870) WARNING: All labels are zero
2025-02-09 13:48:52,493 (model:870) WARNING: All labels are zero
2025-02-09 13:48:52,530 (model:870) WARNING: All labels are zero
2025-02-09 13:51:03,690 (model:870) WARNING: All labels are zero
2025-02-09 13:51:21,283 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 26, batch_idx_train: 104350,  validation: loss=0.07859, DER=0.1753, ACC=0.9643, MI=0.09473, FA=0.05385, CF=0.02672, over 0.00 frames. 
2025-02-09 13:51:21,284 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 13:51:21,339 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 26, batch_idx_train: 104350,  validation: loss=0.07799, DER=0.1775, ACC=0.9646, MI=0.09322, FA=0.05703, CF=0.0273, over 0.00 frames. 
2025-02-09 13:51:21,340 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 14:09:47,086 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 104850, num_updates: 102000, {'loss': 0.13148832321166992, 'DER': 0.3080209638828757, 'ACC': np.float64(0.9418482142857143), 'MI': 0.18616839466788196, 'FA': 0.05884698644183662, 'CF': 0.06300558277315711}, batch size: 64, grad_norm: 0.38008609414100647, grad_scale: , lr: 0.00e+00, 
2025-02-09 14:09:47,087 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 14:09:47,087 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 104850, num_updates: 102000, {'loss': 0.1092476025223732, 'DER': 0.2586977428296657, 'ACC': np.float64(0.9526168249734643), 'MI': 0.15607852011087855, 'FA': 0.06584827742263959, 'CF': 0.036770945296147536}, batch size: 64, grad_norm: 0.38008609414100647, grad_scale: , lr: 0.00e+00, 
2025-02-09 14:09:47,088 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 14:10:58,515 (model:870) WARNING: All labels are zero
2025-02-09 14:10:59,343 (model:870) WARNING: All labels are zero
2025-02-09 14:10:59,352 (model:870) WARNING: All labels are zero
2025-02-09 14:13:09,647 (model:870) WARNING: All labels are zero
2025-02-09 14:13:26,974 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 26, batch_idx_train: 104850,  validation: loss=0.08287, DER=0.1854, ACC=0.963, MI=0.0988, FA=0.05959, CF=0.027, over 0.00 frames. 
2025-02-09 14:13:26,975 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 14:13:27,223 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 26, batch_idx_train: 104850,  validation: loss=0.0825, DER=0.188, ACC=0.9632, MI=0.09665, FA=0.06361, CF=0.0277, over 0.00 frames. 
2025-02-09 14:13:27,223 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 14:18:59,051 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-105000.pt
2025-02-09 14:19:00,768 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 14:32:00,778 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 105350, num_updates: 102500, {'loss': 0.12532484531402588, 'DER': 0.29583356573149644, 'ACC': np.float64(0.9447142857142856), 'MI': 0.18333426292598584, 'FA': 0.06297060628032795, 'CF': 0.049528696525182665}, batch size: 64, grad_norm: 0.3505707085132599, grad_scale: , lr: 0.00e+00, 
2025-02-09 14:32:00,778 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 105350, num_updates: 102500, {'loss': 0.12206695228815079, 'DER': 0.2784354945784466, 'ACC': np.float64(0.9452053571428571), 'MI': 0.16148484177915468, 'FA': 0.055875193626908605, 'CF': 0.06107545917238327}, batch size: 64, grad_norm: 0.3505707085132599, grad_scale: , lr: 0.00e+00, 
2025-02-09 14:32:00,779 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 14:32:00,779 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 14:33:13,094 (model:870) WARNING: All labels are zero
2025-02-09 14:33:13,907 (model:870) WARNING: All labels are zero
2025-02-09 14:33:13,936 (model:870) WARNING: All labels are zero
2025-02-09 14:35:27,092 (model:870) WARNING: All labels are zero
2025-02-09 14:35:45,055 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 26, batch_idx_train: 105350,  validation: loss=0.09464, DER=0.2262, ACC=0.9568, MI=0.1477, FA=0.04574, CF=0.0328, over 0.00 frames. 
2025-02-09 14:35:45,056 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 14:35:45,080 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 26, batch_idx_train: 105350,  validation: loss=0.09616, DER=0.2273, ACC=0.9557, MI=0.1556, FA=0.04012, CF=0.03156, over 0.00 frames. 
2025-02-09 14:35:45,080 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 14:54:13,174 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 105850, num_updates: 103000, {'loss': 0.1412186324596405, 'DER': 0.31265801449519637, 'ACC': np.float64(0.9373482142857144), 'MI': 0.16989718523512556, 'FA': 0.06118321254003034, 'CF': 0.08157761672004045}, batch size: 64, grad_norm: 0.5600069761276245, grad_scale: , lr: 0.00e+00, 
2025-02-09 14:54:13,175 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 14:54:13,175 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 105850, num_updates: 103000, {'loss': 0.1848180592060089, 'DER': 0.38342277877161596, 'ACC': np.float64(0.925125), 'MI': 0.24800780614734103, 'FA': 0.06423808749390145, 'CF': 0.0711768851303735}, batch size: 64, grad_norm: 0.5600069761276245, grad_scale: , lr: 0.00e+00, 
2025-02-09 14:54:13,175 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 14:55:25,969 (model:870) WARNING: All labels are zero
2025-02-09 14:55:26,162 (model:870) WARNING: All labels are zero
2025-02-09 14:55:26,813 (model:870) WARNING: All labels are zero
2025-02-09 14:57:37,045 (model:870) WARNING: All labels are zero
2025-02-09 14:57:54,689 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 26, batch_idx_train: 105850,  validation: loss=0.08014, DER=0.1824, ACC=0.9636, MI=0.08493, FA=0.06713, CF=0.03038, over 0.00 frames. 
2025-02-09 14:57:54,689 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 14:57:55,455 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 26, batch_idx_train: 105850,  validation: loss=0.08066, DER=0.1786, ACC=0.9635, MI=0.08707, FA=0.06281, CF=0.02869, over 0.00 frames. 
2025-02-09 14:57:55,456 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 15:16:21,492 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 106350, num_updates: 103500, {'loss': 0.14745990931987762, 'DER': 0.331941428650966, 'ACC': np.float64(0.9388125), 'MI': 0.2297199487779077, 'FA': 0.05261399699348589, 'CF': 0.04960748287957241}, batch size: 64, grad_norm: 0.44478461146354675, grad_scale: , lr: 0.00e+00, 
2025-02-09 15:16:21,492 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 106350, num_updates: 103500, {'loss': 0.13955363631248474, 'DER': 0.33792632238228093, 'ACC': np.float64(0.9358660714285715), 'MI': 0.19802994932528611, 'FA': 0.0688378978534419, 'CF': 0.07105847520355292}, batch size: 64, grad_norm: 0.44478461146354675, grad_scale: , lr: 0.00e+00, 
2025-02-09 15:16:21,493 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 15:16:21,493 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 15:17:33,541 (model:870) WARNING: All labels are zero
2025-02-09 15:17:34,364 (model:870) WARNING: All labels are zero
2025-02-09 15:17:34,373 (model:870) WARNING: All labels are zero
2025-02-09 15:19:47,280 (model:870) WARNING: All labels are zero
2025-02-09 15:20:04,779 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 26, batch_idx_train: 106350,  validation: loss=0.09808, DER=0.2231, ACC=0.9555, MI=0.1352, FA=0.05003, CF=0.03791, over 0.00 frames. 
2025-02-09 15:20:04,780 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 15:20:04,970 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 26, batch_idx_train: 106350,  validation: loss=0.09709, DER=0.2256, ACC=0.9562, MI=0.1312, FA=0.05596, CF=0.03843, over 0.00 frames. 
2025-02-09 15:20:04,970 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 15:25:34,586 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-106500.pt
2025-02-09 15:25:36,232 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 15:38:14,762 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 106850, num_updates: 104000, {'loss': 0.1673930436372757, 'DER': 0.37986818454164173, 'ACC': np.float64(0.9316978101794625), 'MI': 0.22150988615937686, 'FA': 0.08466147393648892, 'CF': 0.07369682444577591}, batch size: 64, grad_norm: 0.4724537134170532, grad_scale: , lr: 0.00e+00, 
2025-02-09 15:38:14,762 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 15:38:14,763 (train_accelerate_ddp:702) INFO: [Train] - Epoch 26, batch_idx_train: 106850, num_updates: 104000, {'loss': 0.11999914795160294, 'DER': 0.27553944213788667, 'ACC': np.float64(0.9502053571428571), 'MI': 0.16063388105958715, 'FA': 0.06432372375884451, 'CF': 0.050581837319455}, batch size: 64, grad_norm: 0.4724537134170532, grad_scale: , lr: 0.00e+00, 
2025-02-09 15:38:14,764 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 15:39:24,482 (model:870) WARNING: All labels are zero
2025-02-09 15:39:24,682 (model:870) WARNING: All labels are zero
2025-02-09 15:39:25,306 (model:870) WARNING: All labels are zero
2025-02-09 15:41:35,082 (model:870) WARNING: All labels are zero
2025-02-09 15:41:52,157 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 26, batch_idx_train: 106850,  validation: loss=0.0727, DER=0.1673, ACC=0.9663, MI=0.08098, FA=0.06089, CF=0.02543, over 0.00 frames. 
2025-02-09 15:41:52,158 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 15:41:52,513 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 26, batch_idx_train: 106850,  validation: loss=0.07356, DER=0.1657, ACC=0.9658, MI=0.08284, FA=0.05787, CF=0.02503, over 0.00 frames. 
2025-02-09 15:41:52,514 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 15:45:55,430 (train_accelerate_ddp:713) INFO: end of epoch 26, batch_idx: 4113 batch_idx_train: 106963, {'loss': 0.1343238353729248, 'DER': 0.3228868194842407, 'ACC': np.float64(0.9397232142857144), 'MI': 0.16971107927411652, 'FA': 0.07306590257879657, 'CF': 0.0801098376313276}, batch size: 64, grad_norm: 0.4870487451553345, grad_scale: , lr: 0.00e+00, 
2025-02-09 15:45:55,430 (train_accelerate_ddp:713) INFO: end of epoch 26, batch_idx: 4113 batch_idx_train: 106963, {'loss': 0.1364373117685318, 'DER': 0.2877330924932264, 'ACC': np.float64(0.9444732142857143), 'MI': 0.20427137013228497, 'FA': 0.040801147532274346, 'CF': 0.04266057482866706}, batch size: 64, grad_norm: 0.4870487451553345, grad_scale: , lr: 0.00e+00, 
2025-02-09 15:45:55,431 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-26.pt
2025-02-09 15:45:56,648 (train_accelerate_ddp:561) INFO:  end of epoch 26, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-26.pt 
2025-02-09 15:46:01,004 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 106964, num_updates: 104000, {'loss': 0.11785085499286652, 'DER': 0.2640548137737175, 'ACC': np.float64(0.9532142857142857), 'MI': 0.15384164909814946, 'FA': 0.06740454438978684, 'CF': 0.04280862028578122}, batch size: 64, grad_norm: 0.33200740814208984, grad_scale: , lr: 0.00e+00, 
2025-02-09 15:46:01,004 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 106964, num_updates: 104000, {'loss': 0.09981168061494827, 'DER': 0.22469635627530365, 'ACC': np.float64(0.9598035714285714), 'MI': 0.13202878992352676, 'FA': 0.06421502474134053, 'CF': 0.02845254161043635}, batch size: 64, grad_norm: 0.33200740814208984, grad_scale: , lr: 0.00e+00, 
2025-02-09 16:04:07,823 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 107464, num_updates: 104500, {'loss': 0.12477078288793564, 'DER': 0.270930865541644, 'ACC': np.float64(0.9482589285714286), 'MI': 0.16265650517147523, 'FA': 0.06374523679912901, 'CF': 0.04452912357103974}, batch size: 64, grad_norm: 0.3834218680858612, grad_scale: , lr: 0.00e+00, 
2025-02-09 16:04:07,824 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 16:04:07,824 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 107464, num_updates: 104500, {'loss': 0.13425612449645996, 'DER': 0.29291088643310603, 'ACC': np.float64(0.9447946428571429), 'MI': 0.16235598401128615, 'FA': 0.06001645897013873, 'CF': 0.07053844345168117}, batch size: 64, grad_norm: 0.3834218680858612, grad_scale: , lr: 0.00e+00, 
2025-02-09 16:04:07,824 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 16:05:19,067 (model:870) WARNING: All labels are zero
2025-02-09 16:05:19,866 (model:870) WARNING: All labels are zero
2025-02-09 16:05:19,899 (model:870) WARNING: All labels are zero
2025-02-09 16:07:29,238 (model:870) WARNING: All labels are zero
2025-02-09 16:07:46,612 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 27, batch_idx_train: 107464,  validation: loss=0.09245, DER=0.216, ACC=0.9582, MI=0.1289, FA=0.05387, CF=0.03318, over 0.00 frames. 
2025-02-09 16:07:46,612 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 16:07:47,325 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 27, batch_idx_train: 107464,  validation: loss=0.09353, DER=0.2146, ACC=0.9575, MI=0.1348, FA=0.0476, CF=0.03218, over 0.00 frames. 
2025-02-09 16:07:47,326 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 16:25:49,381 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 107964, num_updates: 105000, {'loss': 0.1484018862247467, 'DER': 0.3447032564528129, 'ACC': np.float64(0.9324017857142857), 'MI': 0.19979396783608996, 'FA': 0.05631545813540892, 'CF': 0.08859383048131403}, batch size: 64, grad_norm: 0.5230634212493896, grad_scale: , lr: 0.00e+00, 
2025-02-09 16:25:49,382 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 16:25:49,382 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 107964, num_updates: 105000, {'loss': 0.14748430252075195, 'DER': 0.32622647666702925, 'ACC': np.float64(0.9322410714285715), 'MI': 0.153268791471772, 'FA': 0.08642445338844773, 'CF': 0.08653323180680952}, batch size: 64, grad_norm: 0.5230634212493896, grad_scale: , lr: 0.00e+00, 
2025-02-09 16:25:49,382 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 16:27:00,149 (model:870) WARNING: All labels are zero
2025-02-09 16:27:00,974 (model:870) WARNING: All labels are zero
2025-02-09 16:27:00,983 (model:870) WARNING: All labels are zero
2025-02-09 16:29:12,012 (model:870) WARNING: All labels are zero
2025-02-09 16:29:29,669 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 27, batch_idx_train: 107964,  validation: loss=0.07384, DER=0.1694, ACC=0.966, MI=0.07918, FA=0.06411, CF=0.02612, over 0.00 frames. 
2025-02-09 16:29:29,670 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 27, batch_idx_train: 107964,  validation: loss=0.07465, DER=0.1673, ACC=0.9656, MI=0.0811, FA=0.06068, CF=0.0255, over 0.00 frames. 
2025-02-09 16:29:29,670 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 16:29:29,670 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 16:30:45,529 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-108000.pt
2025-02-09 16:30:47,125 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 16:30:47,224 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-09 16:47:37,199 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 108464, num_updates: 105500, {'loss': 0.16294625401496887, 'DER': 0.353976111051329, 'ACC': np.float64(0.9290089285714286), 'MI': 0.19756806198213708, 'FA': 0.08258904551813193, 'CF': 0.07381900355105994}, batch size: 64, grad_norm: 0.5053954720497131, grad_scale: , lr: 0.00e+00, 
2025-02-09 16:47:37,200 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 16:47:37,200 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 108464, num_updates: 105500, {'loss': 0.10662481933832169, 'DER': 0.23186129051026938, 'ACC': np.float64(0.9576160714285714), 'MI': 0.12486181416186652, 'FA': 0.06266364112410543, 'CF': 0.04433583522429743}, batch size: 64, grad_norm: 0.5053954720497131, grad_scale: , lr: 0.00e+00, 
2025-02-09 16:47:37,200 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 16:48:47,690 (model:870) WARNING: All labels are zero
2025-02-09 16:48:48,510 (model:870) WARNING: All labels are zero
2025-02-09 16:48:48,518 (model:870) WARNING: All labels are zero
2025-02-09 16:50:59,308 (model:870) WARNING: All labels are zero
2025-02-09 16:51:16,807 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 27, batch_idx_train: 108464,  validation: loss=0.1273, DER=0.3096, ACC=0.9419, MI=0.235, FA=0.03761, CF=0.03701, over 0.00 frames. 
2025-02-09 16:51:16,807 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 16:51:16,831 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 27, batch_idx_train: 108464,  validation: loss=0.1241, DER=0.3065, ACC=0.9432, MI=0.2232, FA=0.0422, CF=0.0411, over 0.00 frames. 
2025-02-09 16:51:16,831 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 17:09:19,745 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 108964, num_updates: 106000, {'loss': 0.11883483082056046, 'DER': 0.25770613222960465, 'ACC': np.float64(0.9511517857142857), 'MI': 0.16610391024942817, 'FA': 0.05135606143121664, 'CF': 0.04024616054895981}, batch size: 64, grad_norm: 0.5623713135719299, grad_scale: , lr: 0.00e+00, 
2025-02-09 17:09:19,746 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 108964, num_updates: 106000, {'loss': 0.1516963094472885, 'DER': 0.32321810606913637, 'ACC': np.float64(0.9350050530570996), 'MI': 0.1919265848440491, 'FA': 0.04898097061141763, 'CF': 0.08231055061366963}, batch size: 64, grad_norm: 0.5623713135719299, grad_scale: , lr: 0.00e+00, 
2025-02-09 17:09:19,746 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 17:09:19,746 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 17:10:31,368 (model:870) WARNING: All labels are zero
2025-02-09 17:10:31,440 (model:870) WARNING: All labels are zero
2025-02-09 17:10:32,199 (model:870) WARNING: All labels are zero
2025-02-09 17:12:41,195 (model:870) WARNING: All labels are zero
2025-02-09 17:12:58,399 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 27, batch_idx_train: 108964,  validation: loss=0.1187, DER=0.2999, ACC=0.9462, MI=0.2352, FA=0.03213, CF=0.03254, over 0.00 frames. 
2025-02-09 17:12:58,400 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 17:12:59,469 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 27, batch_idx_train: 108964,  validation: loss=0.123, DER=0.3006, ACC=0.9446, MI=0.2405, FA=0.02801, CF=0.03209, over 0.00 frames. 
2025-02-09 17:12:59,469 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 17:31:00,721 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 109464, num_updates: 106500, {'loss': 0.14502303302288055, 'DER': 0.3103945834951995, 'ACC': np.float64(0.9381160714285715), 'MI': 0.16521449580997835, 'FA': 0.07092513458016537, 'CF': 0.07425495310505577}, batch size: 64, grad_norm: 0.3755355179309845, grad_scale: , lr: 0.00e+00, 
2025-02-09 17:31:00,722 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 109464, num_updates: 106500, {'loss': 0.10603559017181396, 'DER': 0.24523276227374538, 'ACC': np.float64(0.9592321428571429), 'MI': 0.13075852049155517, 'FA': 0.08329802046128701, 'CF': 0.031176221320903204}, batch size: 64, grad_norm: 0.3755355179309845, grad_scale: , lr: 0.00e+00, 
2025-02-09 17:31:00,722 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 17:31:00,722 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 17:32:11,919 (model:870) WARNING: All labels are zero
2025-02-09 17:32:12,698 (model:870) WARNING: All labels are zero
2025-02-09 17:32:12,742 (model:870) WARNING: All labels are zero
2025-02-09 17:34:22,934 (model:870) WARNING: All labels are zero
2025-02-09 17:34:39,855 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 27, batch_idx_train: 109464,  validation: loss=0.0774, DER=0.1774, ACC=0.9647, MI=0.08398, FA=0.06549, CF=0.02794, over 0.00 frames. 
2025-02-09 17:34:39,855 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 17:34:40,222 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 27, batch_idx_train: 109464,  validation: loss=0.07778, DER=0.1746, ACC=0.9645, MI=0.08602, FA=0.06177, CF=0.0268, over 0.00 frames. 
2025-02-09 17:34:40,222 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 17:35:55,509 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-109500.pt
2025-02-09 17:35:57,134 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 17:52:40,445 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 109964, num_updates: 107000, {'loss': 0.15234509110450745, 'DER': 0.3791276708458414, 'ACC': np.float64(0.9308303571428571), 'MI': 0.219200659250103, 'FA': 0.08305374065571841, 'CF': 0.07687327094002001}, batch size: 64, grad_norm: 0.5971099734306335, grad_scale: , lr: 0.00e+00, 
2025-02-09 17:52:40,446 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 17:52:40,447 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 109964, num_updates: 107000, {'loss': 0.14831013977527618, 'DER': 0.34617825209114506, 'ACC': np.float64(0.9315625), 'MI': 0.181597923276608, 'FA': 0.06858955869627921, 'CF': 0.09599077011825786}, batch size: 64, grad_norm: 0.5971099734306335, grad_scale: , lr: 0.00e+00, 
2025-02-09 17:52:40,447 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 17:53:50,449 (model:870) WARNING: All labels are zero
2025-02-09 17:53:51,253 (model:870) WARNING: All labels are zero
2025-02-09 17:53:51,712 (model:870) WARNING: All labels are zero
2025-02-09 17:56:00,195 (model:870) WARNING: All labels are zero
2025-02-09 17:56:17,621 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 27, batch_idx_train: 109964,  validation: loss=0.07581, DER=0.1699, ACC=0.9651, MI=0.08148, FA=0.06234, CF=0.02608, over 0.00 frames. 
2025-02-09 17:56:17,622 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 17:56:17,646 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 27, batch_idx_train: 109964,  validation: loss=0.07524, DER=0.1722, ACC=0.9655, MI=0.07934, FA=0.06587, CF=0.02703, over 0.00 frames. 
2025-02-09 17:56:17,646 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 18:14:23,134 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 110464, num_updates: 107500, {'loss': 0.14907176792621613, 'DER': 0.3147045350435181, 'ACC': np.float64(0.9401684055392302), 'MI': 0.18226065048098947, 'FA': 0.06590700870361887, 'CF': 0.06653687585890976}, batch size: 64, grad_norm: 0.418235719203949, grad_scale: , lr: 0.00e+00, 
2025-02-09 18:14:23,135 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 110464, num_updates: 107500, {'loss': 0.12507730722427368, 'DER': 0.2819822850095302, 'ACC': np.float64(0.9470982142857143), 'MI': 0.16621818589527973, 'FA': 0.06559031281533804, 'CF': 0.050173786298912434}, batch size: 64, grad_norm: 0.418235719203949, grad_scale: , lr: 0.00e+00, 
2025-02-09 18:14:23,135 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 18:14:23,135 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 18:15:33,482 (model:870) WARNING: All labels are zero
2025-02-09 18:15:34,290 (model:870) WARNING: All labels are zero
2025-02-09 18:15:34,391 (model:870) WARNING: All labels are zero
2025-02-09 18:17:43,604 (model:870) WARNING: All labels are zero
2025-02-09 18:18:00,796 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 27, batch_idx_train: 110464,  validation: loss=0.07737, DER=0.1734, ACC=0.9646, MI=0.09269, FA=0.05444, CF=0.02628, over 0.00 frames. 
2025-02-09 18:18:00,797 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 18:18:00,923 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 27, batch_idx_train: 110464,  validation: loss=0.07694, DER=0.1755, ACC=0.9649, MI=0.09055, FA=0.05791, CF=0.02707, over 0.00 frames. 
2025-02-09 18:18:00,923 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 18:35:57,426 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 110964, num_updates: 108000, {'loss': 0.11925050616264343, 'DER': 0.27150908672647805, 'ACC': np.float64(0.9494553571428571), 'MI': 0.15458937198067632, 'FA': 0.06285944329422591, 'CF': 0.0540602714515758}, batch size: 64, grad_norm: 0.4286692440509796, grad_scale: , lr: 0.00e+00, 
2025-02-09 18:35:57,427 (train_accelerate_ddp:702) INFO: [Train] - Epoch 27, batch_idx_train: 110964, num_updates: 108000, {'loss': 0.11007361114025116, 'DER': 0.2616148767339027, 'ACC': np.float64(0.953824134537973), 'MI': 0.13495669029014476, 'FA': 0.07559512992912956, 'CF': 0.051063056514628384}, batch size: 64, grad_norm: 0.4286692440509796, grad_scale: , lr: 0.00e+00, 
2025-02-09 18:35:57,427 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 18:35:57,427 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 18:37:08,696 (model:870) WARNING: All labels are zero
2025-02-09 18:37:09,455 (model:870) WARNING: All labels are zero
2025-02-09 18:37:09,527 (model:870) WARNING: All labels are zero
2025-02-09 18:39:19,270 (model:870) WARNING: All labels are zero
2025-02-09 18:39:36,889 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 27, batch_idx_train: 110964,  validation: loss=0.08732, DER=0.2007, ACC=0.9607, MI=0.1183, FA=0.05109, CF=0.03129, over 0.00 frames. 
2025-02-09 18:39:36,890 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 18:39:37,766 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 27, batch_idx_train: 110964,  validation: loss=0.088, DER=0.1981, ACC=0.9602, MI=0.122, FA=0.04576, CF=0.03038, over 0.00 frames. 
2025-02-09 18:39:37,766 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 18:40:52,931 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-111000.pt
2025-02-09 18:40:54,531 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 18:43:43,309 (train_accelerate_ddp:713) INFO: end of epoch 27, batch_idx: 4113 batch_idx_train: 111077, {'loss': 0.11386715620756149, 'DER': 0.2606992848223408, 'ACC': np.float64(0.9521964285714286), 'MI': 0.15149279146327618, 'FA': 0.0660120331479169, 'CF': 0.04319446021114769}, batch size: 64, grad_norm: 0.41023769974708557, grad_scale: , lr: 0.00e+00, 
2025-02-09 18:43:43,311 (train_accelerate_ddp:713) INFO: end of epoch 27, batch_idx: 4113 batch_idx_train: 111077, {'loss': 0.1331024020910263, 'DER': 0.2987512007684918, 'ACC': np.float64(0.9459107142857144), 'MI': 0.1973215799288015, 'FA': 0.05786291461829689, 'CF': 0.043566706221393456}, batch size: 64, grad_norm: 0.41023769974708557, grad_scale: , lr: 0.00e+00, 
2025-02-09 18:43:43,312 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-27.pt
2025-02-09 18:43:44,534 (train_accelerate_ddp:561) INFO:  end of epoch 27, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-27.pt 
2025-02-09 18:43:47,880 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 111078, num_updates: 108000, {'loss': 0.14868047833442688, 'DER': 0.31614906832298134, 'ACC': np.float64(0.9391607142857143), 'MI': 0.17888198757763976, 'FA': 0.0686617730095991, 'CF': 0.06860530773574251}, batch size: 64, grad_norm: 0.3987264931201935, grad_scale: , lr: 0.00e+00, 
2025-02-09 18:43:47,880 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 111078, num_updates: 108000, {'loss': 0.12371079623699188, 'DER': 0.29887588364816314, 'ACC': np.float64(0.9429485972509886), 'MI': 0.16096882605168616, 'FA': 0.06808436667052961, 'CF': 0.06982269092594738}, batch size: 64, grad_norm: 0.3987264931201935, grad_scale: , lr: 0.00e+00, 
2025-02-09 19:01:49,510 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 111578, num_updates: 108500, {'loss': 0.10194175690412521, 'DER': 0.21617000488519786, 'ACC': np.float64(0.9637142857142856), 'MI': 0.11968734733756717, 'FA': 0.06448461162677088, 'CF': 0.031998045920859794}, batch size: 64, grad_norm: 0.3134230673313141, grad_scale: , lr: 0.00e+00, 
2025-02-09 19:01:49,510 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 111578, num_updates: 108500, {'loss': 0.1213902160525322, 'DER': 0.26629889669007023, 'ACC': np.float64(0.9504642857142857), 'MI': 0.16973141647163714, 'FA': 0.05371670567257328, 'CF': 0.0428507745458598}, batch size: 64, grad_norm: 0.3134230673313141, grad_scale: , lr: 0.00e+00, 
2025-02-09 19:01:49,510 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 19:01:49,510 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 19:03:00,867 (model:870) WARNING: All labels are zero
2025-02-09 19:03:01,678 (model:870) WARNING: All labels are zero
2025-02-09 19:03:01,704 (model:870) WARNING: All labels are zero
2025-02-09 19:05:11,507 (model:870) WARNING: All labels are zero
2025-02-09 19:05:29,199 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 28, batch_idx_train: 111578,  validation: loss=0.07803, DER=0.1775, ACC=0.9648, MI=0.08527, FA=0.06528, CF=0.02692, over 0.00 frames. 
2025-02-09 19:05:29,200 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 19:05:29,976 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 28, batch_idx_train: 111578,  validation: loss=0.07851, DER=0.1749, ACC=0.9645, MI=0.08694, FA=0.06185, CF=0.02616, over 0.00 frames. 
2025-02-09 19:05:29,977 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 19:23:43,576 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 112078, num_updates: 109000, {'loss': 0.12884683907032013, 'DER': 0.2795633041831449, 'ACC': np.float64(0.9484553571428571), 'MI': 0.17868879852949368, 'FA': 0.05887595387957444, 'CF': 0.041998551774076756}, batch size: 64, grad_norm: 0.34627455472946167, grad_scale: , lr: 0.00e+00, 
2025-02-09 19:23:43,577 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 19:23:43,577 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 112078, num_updates: 109000, {'loss': 0.10463646054267883, 'DER': 0.23286363891539888, 'ACC': np.float64(0.9557073381996012), 'MI': 0.13613652950092628, 'FA': 0.05400550159995509, 'CF': 0.04272160781451749}, batch size: 64, grad_norm: 0.34627455472946167, grad_scale: , lr: 0.00e+00, 
2025-02-09 19:23:43,578 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 19:24:55,096 (model:870) WARNING: All labels are zero
2025-02-09 19:24:55,923 (model:870) WARNING: All labels are zero
2025-02-09 19:24:55,990 (model:870) WARNING: All labels are zero
2025-02-09 19:27:08,365 (model:870) WARNING: All labels are zero
2025-02-09 19:27:26,117 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 28, batch_idx_train: 112078,  validation: loss=0.07619, DER=0.1704, ACC=0.9653, MI=0.08719, FA=0.05815, CF=0.02501, over 0.00 frames. 
2025-02-09 19:27:26,118 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 19:27:26,181 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 28, batch_idx_train: 112078,  validation: loss=0.07547, DER=0.172, ACC=0.9657, MI=0.08548, FA=0.06106, CF=0.0255, over 0.00 frames. 
2025-02-09 19:27:26,182 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 19:42:58,561 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-112500.pt
2025-02-09 19:43:00,218 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 19:43:00,319 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-09 19:45:56,328 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 112578, num_updates: 109500, {'loss': 0.12350136041641235, 'DER': 0.26521619388598183, 'ACC': np.float64(0.9475892857142857), 'MI': 0.1520242357477279, 'FA': 0.055081244836133296, 'CF': 0.05811071330212063}, batch size: 64, grad_norm: 0.39112094044685364, grad_scale: , lr: 0.00e+00, 
2025-02-09 19:45:56,328 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 19:45:56,328 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 112578, num_updates: 109500, {'loss': 0.10369804501533508, 'DER': 0.2602655520039341, 'ACC': np.float64(0.9539553571428571), 'MI': 0.11482665355298746, 'FA': 0.08870174575854438, 'CF': 0.05673715269240226}, batch size: 64, grad_norm: 0.39112094044685364, grad_scale: , lr: 0.00e+00, 
2025-02-09 19:45:56,329 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 19:47:08,725 (model:870) WARNING: All labels are zero
2025-02-09 19:47:09,546 (model:870) WARNING: All labels are zero
2025-02-09 19:47:09,562 (model:870) WARNING: All labels are zero
2025-02-09 19:49:23,638 (model:870) WARNING: All labels are zero
2025-02-09 19:49:41,651 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 28, batch_idx_train: 112578,  validation: loss=0.08953, DER=0.2006, ACC=0.9603, MI=0.1023, FA=0.06354, CF=0.03469, over 0.00 frames. 
2025-02-09 19:49:41,652 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 19:49:41,659 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 28, batch_idx_train: 112578,  validation: loss=0.09007, DER=0.1963, ACC=0.9603, MI=0.1053, FA=0.05807, CF=0.03287, over 0.00 frames. 
2025-02-09 19:49:41,659 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 20:08:10,373 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 113078, num_updates: 110000, {'loss': 0.12987789511680603, 'DER': 0.33028752436647174, 'ACC': np.float64(0.9416339285714286), 'MI': 0.17166179337231968, 'FA': 0.0907041910331384, 'CF': 0.06792153996101365}, batch size: 64, grad_norm: 0.38448798656463623, grad_scale: , lr: 0.00e+00, 
2025-02-09 20:08:10,373 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 113078, num_updates: 110000, {'loss': 0.11150823533535004, 'DER': 0.23784114279361904, 'ACC': np.float64(0.9530446428571429), 'MI': 0.1313990328497582, 'FA': 0.05197042965927408, 'CF': 0.05447168028458674}, batch size: 64, grad_norm: 0.38448798656463623, grad_scale: , lr: 0.00e+00, 
2025-02-09 20:08:10,374 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 20:08:10,374 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 20:09:21,587 (model:870) WARNING: All labels are zero
2025-02-09 20:09:22,341 (model:870) WARNING: All labels are zero
2025-02-09 20:09:22,425 (model:870) WARNING: All labels are zero
2025-02-09 20:11:30,717 (model:870) WARNING: All labels are zero
2025-02-09 20:11:47,969 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 28, batch_idx_train: 113078,  validation: loss=0.07933, DER=0.1799, ACC=0.9644, MI=0.09455, FA=0.05927, CF=0.02605, over 0.00 frames. 
2025-02-09 20:11:47,969 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 20:11:48,465 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 28, batch_idx_train: 113078,  validation: loss=0.07988, DER=0.1774, ACC=0.9642, MI=0.0968, FA=0.05513, CF=0.0255, over 0.00 frames. 
2025-02-09 20:11:48,465 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 20:29:52,540 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 113578, num_updates: 110500, {'loss': 0.10046247392892838, 'DER': 0.22854676258992807, 'ACC': np.float64(0.9559859628968129), 'MI': 0.10820143884892086, 'FA': 0.06664748201438848, 'CF': 0.053697841726618706}, batch size: 64, grad_norm: 0.40282246470451355, grad_scale: , lr: 0.00e+00, 
2025-02-09 20:29:52,540 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 113578, num_updates: 110500, {'loss': 0.1500711888074875, 'DER': 0.30484052917649473, 'ACC': np.float64(0.9360535714285715), 'MI': 0.19762075684545174, 'FA': 0.04481591631627525, 'CF': 0.062403856014767715}, batch size: 64, grad_norm: 0.40282246470451355, grad_scale: , lr: 0.00e+00, 
2025-02-09 20:29:52,540 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 20:29:52,540 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 20:31:04,844 (model:870) WARNING: All labels are zero
2025-02-09 20:31:04,962 (model:870) WARNING: All labels are zero
2025-02-09 20:31:05,679 (model:870) WARNING: All labels are zero
2025-02-09 20:33:17,342 (model:870) WARNING: All labels are zero
2025-02-09 20:33:35,114 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 28, batch_idx_train: 113578,  validation: loss=0.07535, DER=0.1727, ACC=0.9654, MI=0.09421, FA=0.05219, CF=0.02634, over 0.00 frames. 
2025-02-09 20:33:35,115 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 20:33:35,954 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 28, batch_idx_train: 113578,  validation: loss=0.07602, DER=0.1707, ACC=0.9649, MI=0.09623, FA=0.04877, CF=0.02566, over 0.00 frames. 
2025-02-09 20:33:35,955 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 20:49:01,441 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-114000.pt
2025-02-09 20:49:03,111 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 20:51:59,218 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 114078, num_updates: 111000, {'loss': 0.1307447999715805, 'DER': 0.28910166150380173, 'ACC': np.float64(0.946), 'MI': 0.17780906786820613, 'FA': 0.05975781470008448, 'CF': 0.05153477893551112}, batch size: 64, grad_norm: 0.36829903721809387, grad_scale: , lr: 0.00e+00, 
2025-02-09 20:51:59,219 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 20:51:59,219 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 114078, num_updates: 111000, {'loss': 0.1409870982170105, 'DER': 0.2921563413985642, 'ACC': np.float64(0.9404375), 'MI': 0.17973943100239298, 'FA': 0.04982717362403616, 'CF': 0.06258973677213507}, batch size: 64, grad_norm: 0.36829903721809387, grad_scale: , lr: 0.00e+00, 
2025-02-09 20:51:59,220 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 20:53:10,625 (model:870) WARNING: All labels are zero
2025-02-09 20:53:11,453 (model:870) WARNING: All labels are zero
2025-02-09 20:53:11,619 (model:870) WARNING: All labels are zero
2025-02-09 20:55:22,693 (model:870) WARNING: All labels are zero
2025-02-09 20:55:39,296 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 28, batch_idx_train: 114078,  validation: loss=0.09684, DER=0.2258, ACC=0.9556, MI=0.149, FA=0.04323, CF=0.03361, over 0.00 frames. 
2025-02-09 20:55:39,297 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 20:55:40,181 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 28, batch_idx_train: 114078,  validation: loss=0.09553, DER=0.2251, ACC=0.9565, MI=0.1422, FA=0.04792, CF=0.03494, over 0.00 frames. 
2025-02-09 20:55:40,181 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 21:13:57,778 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 114578, num_updates: 111500, {'loss': 0.12610620260238647, 'DER': 0.2839083792403595, 'ACC': np.float64(0.9487678571428572), 'MI': 0.14578138590895912, 'FA': 0.08930124673818499, 'CF': 0.048825746593215424}, batch size: 64, grad_norm: 0.37289315462112427, grad_scale: , lr: 0.00e+00, 
2025-02-09 21:13:57,778 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 21:13:57,779 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 114578, num_updates: 111500, {'loss': 0.09979645162820816, 'DER': 0.21167635932471346, 'ACC': np.float64(0.9619732142857144), 'MI': 0.1267573824177065, 'FA': 0.05612331319518943, 'CF': 0.028795663711817514}, batch size: 64, grad_norm: 0.37289315462112427, grad_scale: , lr: 0.00e+00, 
2025-02-09 21:13:57,779 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 21:15:08,597 (model:870) WARNING: All labels are zero
2025-02-09 21:15:09,412 (model:870) WARNING: All labels are zero
2025-02-09 21:15:09,566 (model:870) WARNING: All labels are zero
2025-02-09 21:17:21,196 (model:870) WARNING: All labels are zero
2025-02-09 21:17:38,228 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 28, batch_idx_train: 114578,  validation: loss=0.0778, DER=0.1731, ACC=0.9646, MI=0.09548, FA=0.05176, CF=0.02587, over 0.00 frames. 
2025-02-09 21:17:38,229 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 21:17:38,914 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 28, batch_idx_train: 114578,  validation: loss=0.0772, DER=0.1758, ACC=0.9649, MI=0.09372, FA=0.05532, CF=0.02674, over 0.00 frames. 
2025-02-09 21:17:38,915 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 21:36:06,363 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 115078, num_updates: 112000, {'loss': 0.12493345886468887, 'DER': 0.2844627818911434, 'ACC': np.float64(0.9434821428571429), 'MI': 0.15599389589103035, 'FA': 0.05516305883682812, 'CF': 0.07330582716328492}, batch size: 64, grad_norm: 0.416439026594162, grad_scale: , lr: 0.00e+00, 
2025-02-09 21:36:06,364 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 21:36:06,364 (train_accelerate_ddp:702) INFO: [Train] - Epoch 28, batch_idx_train: 115078, num_updates: 112000, {'loss': 0.1095455065369606, 'DER': 0.23850506955906625, 'ACC': np.float64(0.9558928571428571), 'MI': 0.12762320207498232, 'FA': 0.0581820325394954, 'CF': 0.05269983494458854}, batch size: 64, grad_norm: 0.416439026594162, grad_scale: , lr: 0.00e+00, 
2025-02-09 21:36:06,364 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 21:37:17,999 (model:870) WARNING: All labels are zero
2025-02-09 21:37:18,843 (model:870) WARNING: All labels are zero
2025-02-09 21:37:18,954 (model:870) WARNING: All labels are zero
2025-02-09 21:39:31,971 (model:870) WARNING: All labels are zero
2025-02-09 21:39:49,767 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 28, batch_idx_train: 115078,  validation: loss=0.145, DER=0.3458, ACC=0.9374, MI=0.2907, FA=0.02342, CF=0.03168, over 0.00 frames. 
2025-02-09 21:39:49,768 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 21:39:49,778 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 28, batch_idx_train: 115078,  validation: loss=0.1388, DER=0.3449, ACC=0.9387, MI=0.2834, FA=0.02705, CF=0.03443, over 0.00 frames. 
2025-02-09 21:39:49,778 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 21:43:57,093 (train_accelerate_ddp:713) INFO: end of epoch 28, batch_idx: 4113 batch_idx_train: 115191, {'loss': 0.14813962578773499, 'DER': 0.3298686464877213, 'ACC': np.float64(0.9378482142857143), 'MI': 0.18440890919474587, 'FA': 0.0777841233580811, 'CF': 0.06767561393489435}, batch size: 64, grad_norm: 0.3986259996891022, grad_scale: , lr: 0.00e+00, 
2025-02-09 21:43:57,094 (train_accelerate_ddp:713) INFO: end of epoch 28, batch_idx: 4113 batch_idx_train: 115191, {'loss': 0.09240160137414932, 'DER': 0.20976322712657117, 'ACC': np.float64(0.963830683845747), 'MI': 0.1317158725518854, 'FA': 0.051973107278573516, 'CF': 0.026074247296112248}, batch size: 64, grad_norm: 0.3986259996891022, grad_scale: , lr: 0.00e+00, 
2025-02-09 21:43:57,095 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-28.pt
2025-02-09 21:43:58,326 (train_accelerate_ddp:561) INFO:  end of epoch 28, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-28.pt 
2025-02-09 21:44:02,222 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 115192, num_updates: 112000, {'loss': 0.12824124097824097, 'DER': 0.29984552892041877, 'ACC': np.float64(0.9414192772401728), 'MI': 0.16700040048057668, 'FA': 0.06487785342410893, 'CF': 0.06796727501573317}, batch size: 64, grad_norm: 0.352062463760376, grad_scale: , lr: 0.00e+00, 
2025-02-09 21:44:02,223 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 115192, num_updates: 112000, {'loss': 0.13594017922878265, 'DER': 0.2817545889654447, 'ACC': np.float64(0.9446160714285714), 'MI': 0.17677378635670332, 'FA': 0.0604849313627518, 'CF': 0.04449587124598959}, batch size: 64, grad_norm: 0.352062463760376, grad_scale: , lr: 0.00e+00, 
2025-02-09 21:55:17,954 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-115500.pt
2025-02-09 21:55:19,580 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 21:55:19,678 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-09 22:02:19,800 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 115692, num_updates: 112500, {'loss': 0.13848231732845306, 'DER': 0.30567886999135196, 'ACC': np.float64(0.9431785714285714), 'MI': 0.18685500144133757, 'FA': 0.05759584894782358, 'CF': 0.061228019602190834}, batch size: 64, grad_norm: 0.49816903471946716, grad_scale: , lr: 0.00e+00, 
2025-02-09 22:02:19,801 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 22:02:19,801 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 115692, num_updates: 112500, {'loss': 0.12814347445964813, 'DER': 0.2762569332617642, 'ACC': np.float64(0.9477321428571429), 'MI': 0.13514641856026718, 'FA': 0.06822925985566887, 'CF': 0.07288125484582811}, batch size: 64, grad_norm: 0.49816903471946716, grad_scale: , lr: 0.00e+00, 
2025-02-09 22:02:19,802 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 22:03:30,882 (model:870) WARNING: All labels are zero
2025-02-09 22:03:31,214 (model:870) WARNING: All labels are zero
2025-02-09 22:03:31,688 (model:870) WARNING: All labels are zero
2025-02-09 22:05:41,091 (model:870) WARNING: All labels are zero
2025-02-09 22:05:58,697 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 29, batch_idx_train: 115692,  validation: loss=0.08534, DER=0.1944, ACC=0.9608, MI=0.1252, FA=0.04013, CF=0.02906, over 0.00 frames. 
2025-02-09 22:05:58,698 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 22:05:58,698 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 29, batch_idx_train: 115692,  validation: loss=0.08429, DER=0.1962, ACC=0.9615, MI=0.1218, FA=0.04494, CF=0.02946, over 0.00 frames. 
2025-02-09 22:05:58,699 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 22:24:01,080 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 116192, num_updates: 113000, {'loss': 0.14613597095012665, 'DER': 0.3307574293993977, 'ACC': np.float64(0.9385), 'MI': 0.17563497926018523, 'FA': 0.09449400534121256, 'CF': 0.060628444797999885}, batch size: 64, grad_norm: 0.44261234998703003, grad_scale: , lr: 0.00e+00, 
2025-02-09 22:24:01,081 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 22:24:01,081 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 116192, num_updates: 113000, {'loss': 0.1387149840593338, 'DER': 0.31901982315205457, 'ACC': np.float64(0.9406110631563803), 'MI': 0.1918164480147951, 'FA': 0.0644974859850893, 'CF': 0.06270588915217014}, batch size: 64, grad_norm: 0.44261234998703003, grad_scale: , lr: 0.00e+00, 
2025-02-09 22:24:01,082 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 22:25:10,658 (model:870) WARNING: All labels are zero
2025-02-09 22:25:11,480 (model:870) WARNING: All labels are zero
2025-02-09 22:25:12,081 (model:870) WARNING: All labels are zero
2025-02-09 22:27:22,625 (model:870) WARNING: All labels are zero
2025-02-09 22:27:39,608 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 29, batch_idx_train: 116192,  validation: loss=0.08419, DER=0.187, ACC=0.9621, MI=0.1017, FA=0.05541, CF=0.02982, over 0.00 frames. 
2025-02-09 22:27:39,609 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 22:27:40,304 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 29, batch_idx_train: 116192,  validation: loss=0.08374, DER=0.1908, ACC=0.9621, MI=0.09897, FA=0.0604, CF=0.03144, over 0.00 frames. 
2025-02-09 22:27:40,304 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 22:46:02,021 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 116692, num_updates: 113500, {'loss': 0.208453968167305, 'DER': 0.4654335788091568, 'ACC': np.float64(0.9065089285714285), 'MI': 0.207569789347491, 'FA': 0.12553519438259977, 'CF': 0.13232859507906605}, batch size: 64, grad_norm: 0.6623637080192566, grad_scale: , lr: 0.00e+00, 
2025-02-09 22:46:02,021 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 116692, num_updates: 113500, {'loss': 0.13889171183109283, 'DER': 0.32281112737920936, 'ACC': np.float64(0.9421875), 'MI': 0.20480234260614935, 'FA': 0.06161054172767204, 'CF': 0.05639824304538799}, batch size: 64, grad_norm: 0.6623637080192566, grad_scale: , lr: 0.00e+00, 
2025-02-09 22:46:02,022 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 22:46:02,022 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 22:47:12,829 (model:870) WARNING: All labels are zero
2025-02-09 22:47:13,662 (model:870) WARNING: All labels are zero
2025-02-09 22:47:13,672 (model:870) WARNING: All labels are zero
2025-02-09 22:49:24,730 (model:870) WARNING: All labels are zero
2025-02-09 22:49:42,079 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 29, batch_idx_train: 116692,  validation: loss=0.1152, DER=0.2645, ACC=0.9492, MI=0.163, FA=0.06004, CF=0.04138, over 0.00 frames. 
2025-02-09 22:49:42,079 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 22:49:42,127 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 29, batch_idx_train: 116692,  validation: loss=0.1147, DER=0.2636, ACC=0.9498, MI=0.1548, FA=0.06484, CF=0.04396, over 0.00 frames. 
2025-02-09 22:49:42,127 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 23:00:54,597 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-117000.pt
2025-02-09 23:00:56,248 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-09 23:08:05,840 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 117192, num_updates: 114000, {'loss': 0.1233595684170723, 'DER': 0.28365718251214433, 'ACC': np.float64(0.9477053571428571), 'MI': 0.14764052741151978, 'FA': 0.08096229470275272, 'CF': 0.05505436039787185}, batch size: 64, grad_norm: 0.46593037247657776, grad_scale: , lr: 0.00e+00, 
2025-02-09 23:08:05,841 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 23:08:05,841 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 117192, num_updates: 114000, {'loss': 0.11927761882543564, 'DER': 0.2791814199123807, 'ACC': np.float64(0.9489910714285714), 'MI': 0.12914841265078317, 'FA': 0.08635899897977554, 'CF': 0.063674008281822}, batch size: 64, grad_norm: 0.46593037247657776, grad_scale: , lr: 0.00e+00, 
2025-02-09 23:08:05,841 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 23:09:17,650 (model:870) WARNING: All labels are zero
2025-02-09 23:09:18,488 (model:870) WARNING: All labels are zero
2025-02-09 23:09:18,525 (model:870) WARNING: All labels are zero
2025-02-09 23:11:31,065 (model:870) WARNING: All labels are zero
2025-02-09 23:11:48,976 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 29, batch_idx_train: 117192,  validation: loss=0.07815, DER=0.1781, ACC=0.9645, MI=0.08946, FA=0.06057, CF=0.02808, over 0.00 frames. 
2025-02-09 23:11:48,976 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 23:11:48,998 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 29, batch_idx_train: 117192,  validation: loss=0.07872, DER=0.1756, ACC=0.9642, MI=0.09147, FA=0.05679, CF=0.02733, over 0.00 frames. 
2025-02-09 23:11:48,998 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 23:30:22,974 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 117692, num_updates: 114500, {'loss': 0.22781960666179657, 'DER': 0.521594874435101, 'ACC': np.float64(0.9045714285714286), 'MI': 0.3531262513586179, 'FA': 0.07865682741261941, 'CF': 0.08981179566386362}, batch size: 64, grad_norm: 0.7646601796150208, grad_scale: , lr: 0.00e+00, 
2025-02-09 23:30:22,974 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 23:30:22,974 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 117692, num_updates: 114500, {'loss': 0.12599729001522064, 'DER': 0.28042671067366065, 'ACC': np.float64(0.9465535714285714), 'MI': 0.1441032592679908, 'FA': 0.06394766311074439, 'CF': 0.07237578829492544}, batch size: 64, grad_norm: 0.7646601796150208, grad_scale: , lr: 0.00e+00, 
2025-02-09 23:30:22,974 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 23:31:34,503 (model:870) WARNING: All labels are zero
2025-02-09 23:31:35,338 (model:870) WARNING: All labels are zero
2025-02-09 23:31:35,346 (model:870) WARNING: All labels are zero
2025-02-09 23:33:48,220 (model:870) WARNING: All labels are zero
2025-02-09 23:34:05,869 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 29, batch_idx_train: 117692,  validation: loss=0.07657, DER=0.1753, ACC=0.9646, MI=0.08948, FA=0.05696, CF=0.02886, over 0.00 frames. 
2025-02-09 23:34:05,869 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-09 23:34:06,017 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 29, batch_idx_train: 117692,  validation: loss=0.07708, DER=0.1727, ACC=0.9644, MI=0.09133, FA=0.05361, CF=0.02772, over 0.00 frames. 
2025-02-09 23:34:06,017 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 23:52:31,201 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 118192, num_updates: 115000, {'loss': 0.09823833405971527, 'DER': 0.2146838578908845, 'ACC': np.float64(0.9606339285714286), 'MI': 0.12257192725634818, 'FA': 0.058555261528067115, 'CF': 0.033556669106469234}, batch size: 64, grad_norm: 0.37332475185394287, grad_scale: , lr: 0.00e+00, 
2025-02-09 23:52:31,201 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 118192, num_updates: 115000, {'loss': 0.1311565786600113, 'DER': 0.31108971658944584, 'ACC': np.float64(0.9430201727041456), 'MI': 0.14669956074372706, 'FA': 0.0927251940549973, 'CF': 0.07166496179072146}, batch size: 64, grad_norm: 0.37332475185394287, grad_scale: , lr: 0.00e+00, 
2025-02-09 23:52:31,202 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 23:52:31,202 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-09 23:53:43,192 (model:870) WARNING: All labels are zero
2025-02-09 23:53:44,021 (model:870) WARNING: All labels are zero
2025-02-09 23:53:44,072 (model:870) WARNING: All labels are zero
2025-02-09 23:55:55,897 (model:870) WARNING: All labels are zero
2025-02-09 23:56:13,178 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 29, batch_idx_train: 118192,  validation: loss=0.07553, DER=0.1685, ACC=0.9654, MI=0.0825, FA=0.06078, CF=0.02526, over 0.00 frames. 
2025-02-09 23:56:13,179 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-09 23:56:13,420 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 29, batch_idx_train: 118192,  validation: loss=0.07479, DER=0.1707, ACC=0.9658, MI=0.08052, FA=0.06414, CF=0.02608, over 0.00 frames. 
2025-02-09 23:56:13,420 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 00:07:26,107 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-118500.pt
2025-02-10 00:07:27,815 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-10 00:14:37,149 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 118692, num_updates: 115500, {'loss': 0.1476036161184311, 'DER': 0.3288028089251331, 'ACC': np.float64(0.9354464285714286), 'MI': 0.17363234794427454, 'FA': 0.0745271265148941, 'CF': 0.08064333446596443}, batch size: 64, grad_norm: 0.45241689682006836, grad_scale: , lr: 0.00e+00, 
2025-02-10 00:14:37,150 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 118692, num_updates: 115500, {'loss': 0.11362829059362411, 'DER': 0.245738556977589, 'ACC': np.float64(0.9527321428571429), 'MI': 0.14871737550997596, 'FA': 0.04688984519085676, 'CF': 0.050131336276756276}, batch size: 64, grad_norm: 0.45241689682006836, grad_scale: , lr: 0.00e+00, 
2025-02-10 00:14:37,150 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 00:14:37,150 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 00:15:49,216 (model:870) WARNING: All labels are zero
2025-02-10 00:15:51,495 (model:870) WARNING: All labels are zero
2025-02-10 00:15:52,405 (model:870) WARNING: All labels are zero
2025-02-10 00:18:01,643 (model:870) WARNING: All labels are zero
2025-02-10 00:18:19,346 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 29, batch_idx_train: 118692,  validation: loss=0.08416, DER=0.1907, ACC=0.9624, MI=0.09661, FA=0.06485, CF=0.02929, over 0.00 frames. 
2025-02-10 00:18:19,347 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 00:18:29,046 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 29, batch_idx_train: 118692,  validation: loss=0.08476, DER=0.1873, ACC=0.9624, MI=0.09933, FA=0.05981, CF=0.02817, over 0.00 frames. 
2025-02-10 00:18:29,047 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 00:36:52,388 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 119192, num_updates: 116000, {'loss': 0.16286832094192505, 'DER': 0.36306095683412215, 'ACC': np.float64(0.9285178571428571), 'MI': 0.20294235045902947, 'FA': 0.06665906369390431, 'CF': 0.09345954268118835}, batch size: 64, grad_norm: 0.5908758640289307, grad_scale: , lr: 0.00e+00, 
2025-02-10 00:36:52,388 (train_accelerate_ddp:702) INFO: [Train] - Epoch 29, batch_idx_train: 119192, num_updates: 116000, {'loss': 0.14313408732414246, 'DER': 0.323310375720925, 'ACC': np.float64(0.9355108200609049), 'MI': 0.17576572036508203, 'FA': 0.06887283722492861, 'CF': 0.07867181813091438}, batch size: 64, grad_norm: 0.5908758640289307, grad_scale: , lr: 0.00e+00, 
2025-02-10 00:36:52,389 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 00:36:52,389 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 00:38:03,183 (model:870) WARNING: All labels are zero
2025-02-10 00:38:04,024 (model:870) WARNING: All labels are zero
2025-02-10 00:38:04,131 (model:870) WARNING: All labels are zero
2025-02-10 00:40:13,945 (model:870) WARNING: All labels are zero
2025-02-10 00:40:30,661 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 29, batch_idx_train: 119192,  validation: loss=0.08171, DER=0.1816, ACC=0.963, MI=0.1006, FA=0.05267, CF=0.02837, over 0.00 frames. 
2025-02-10 00:40:30,662 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 00:40:31,485 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 29, batch_idx_train: 119192,  validation: loss=0.08131, DER=0.1851, ACC=0.9631, MI=0.09826, FA=0.05707, CF=0.02979, over 0.00 frames. 
2025-02-10 00:40:31,486 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 00:44:37,248 (train_accelerate_ddp:713) INFO: end of epoch 29, batch_idx: 4113 batch_idx_train: 119305, {'loss': 0.14476874470710754, 'DER': 0.31154178363204493, 'ACC': np.float64(0.9338240548845852), 'MI': 0.1707514575685597, 'FA': 0.05241848412869791, 'CF': 0.08837184193478731}, batch size: 64, grad_norm: 0.4212948977947235, grad_scale: , lr: 0.00e+00, 
2025-02-10 00:44:37,248 (train_accelerate_ddp:713) INFO: end of epoch 29, batch_idx: 4113 batch_idx_train: 119305, {'loss': 0.1359146237373352, 'DER': 0.2797017924179136, 'ACC': np.float64(0.9441413330687998), 'MI': 0.17950615978427537, 'FA': 0.05239782160418759, 'CF': 0.047797811029450646}, batch size: 64, grad_norm: 0.4212948977947235, grad_scale: , lr: 0.00e+00, 
2025-02-10 00:44:37,249 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-29.pt
2025-02-10 00:44:38,634 (train_accelerate_ddp:561) INFO:  end of epoch 29, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-29.pt 
2025-02-10 00:44:41,959 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 119306, num_updates: 116000, {'loss': 0.17060917615890503, 'DER': 0.39073923639317626, 'ACC': np.float64(0.9232767857142856), 'MI': 0.19560171753510502, 'FA': 0.08726935128234885, 'CF': 0.10786816757572242}, batch size: 64, grad_norm: 0.5634341835975647, grad_scale: , lr: 0.00e+00, 
2025-02-10 00:44:41,959 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 119306, num_updates: 116000, {'loss': 0.1373877078294754, 'DER': 0.2936831242192168, 'ACC': np.float64(0.9376160714285714), 'MI': 0.14312096029547552, 'FA': 0.06474390310140676, 'CF': 0.08581826082233447}, batch size: 64, grad_norm: 0.5634341835975647, grad_scale: , lr: 0.00e+00, 
2025-02-10 01:02:49,021 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 119806, num_updates: 116500, {'loss': 0.13173842430114746, 'DER': 0.317861482381531, 'ACC': np.float64(0.9431964285714286), 'MI': 0.16907654921020657, 'FA': 0.08013365735115431, 'CF': 0.06865127582017011}, batch size: 64, grad_norm: 0.4174591898918152, grad_scale: , lr: 0.00e+00, 
2025-02-10 01:02:49,021 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 01:02:49,022 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 119806, num_updates: 116500, {'loss': 0.12775641679763794, 'DER': 0.2649424977053075, 'ACC': np.float64(0.9489464285714285), 'MI': 0.1661357378111333, 'FA': 0.05501862750391447, 'CF': 0.04378813239025971}, batch size: 64, grad_norm: 0.4174591898918152, grad_scale: , lr: 0.00e+00, 
2025-02-10 01:02:49,022 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 01:03:59,076 (model:870) WARNING: All labels are zero
2025-02-10 01:03:59,829 (model:870) WARNING: All labels are zero
2025-02-10 01:03:59,888 (model:870) WARNING: All labels are zero
2025-02-10 01:06:08,984 (model:870) WARNING: All labels are zero
2025-02-10 01:06:26,364 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 30, batch_idx_train: 119806,  validation: loss=0.07671, DER=0.1757, ACC=0.965, MI=0.08568, FA=0.06257, CF=0.02744, over 0.00 frames. 
2025-02-10 01:06:26,365 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 01:06:26,532 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 30, batch_idx_train: 119806,  validation: loss=0.07719, DER=0.1729, ACC=0.9647, MI=0.08747, FA=0.05903, CF=0.02641, over 0.00 frames. 
2025-02-10 01:06:26,532 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 01:13:25,608 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-120000.pt
2025-02-10 01:13:27,343 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-10 01:13:27,345 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-10 01:24:39,379 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 120306, num_updates: 117000, {'loss': 0.12391654402017593, 'DER': 0.2807751461088896, 'ACC': np.float64(0.9518839285714286), 'MI': 0.14118732697631498, 'FA': 0.08883420486004306, 'CF': 0.05075361427253153}, batch size: 64, grad_norm: 0.32173067331314087, grad_scale: , lr: 0.00e+00, 
2025-02-10 01:24:39,379 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 01:24:39,380 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 120306, num_updates: 117000, {'loss': 0.09092877060174942, 'DER': 0.22164517669531997, 'ACC': np.float64(0.9608571428571429), 'MI': 0.09563037249283668, 'FA': 0.08595988538681948, 'CF': 0.0400549188156638}, batch size: 64, grad_norm: 0.32173067331314087, grad_scale: , lr: 0.00e+00, 
2025-02-10 01:24:39,380 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 01:25:48,778 (model:870) WARNING: All labels are zero
2025-02-10 01:25:48,896 (model:870) WARNING: All labels are zero
2025-02-10 01:25:49,568 (model:870) WARNING: All labels are zero
2025-02-10 01:27:54,974 (model:870) WARNING: All labels are zero
2025-02-10 01:28:11,860 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 30, batch_idx_train: 120306,  validation: loss=0.1013, DER=0.2533, ACC=0.9532, MI=0.1865, FA=0.03644, CF=0.0304, over 0.00 frames. 
2025-02-10 01:28:11,861 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 01:28:12,522 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 30, batch_idx_train: 120306,  validation: loss=0.1038, DER=0.2558, ACC=0.9516, MI=0.1935, FA=0.03206, CF=0.03023, over 0.00 frames. 
2025-02-10 01:28:12,522 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 01:46:03,735 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 120806, num_updates: 117500, {'loss': 0.10916959494352341, 'DER': 0.26694491799423903, 'ACC': np.float64(0.9547589285714285), 'MI': 0.17641526071365587, 'FA': 0.059608488625007346, 'CF': 0.030921168655575804}, batch size: 64, grad_norm: 0.3666593134403229, grad_scale: , lr: 0.00e+00, 
2025-02-10 01:46:03,735 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 01:46:03,735 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 120806, num_updates: 117500, {'loss': 0.11696895956993103, 'DER': 0.27236361528204533, 'ACC': np.float64(0.9475929475929475), 'MI': 0.1523566583570062, 'FA': 0.05478578468317004, 'CF': 0.06522117224186909}, batch size: 64, grad_norm: 0.3666593134403229, grad_scale: , lr: 0.00e+00, 
2025-02-10 01:46:03,736 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 01:47:13,430 (model:870) WARNING: All labels are zero
2025-02-10 01:47:14,200 (model:870) WARNING: All labels are zero
2025-02-10 01:47:14,234 (model:870) WARNING: All labels are zero
2025-02-10 01:49:21,591 (model:870) WARNING: All labels are zero
2025-02-10 01:49:38,606 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 30, batch_idx_train: 120806,  validation: loss=0.07685, DER=0.1755, ACC=0.9649, MI=0.09309, FA=0.05515, CF=0.02723, over 0.00 frames. 
2025-02-10 01:49:38,606 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 01:49:38,667 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 30, batch_idx_train: 120806,  validation: loss=0.07745, DER=0.1733, ACC=0.9645, MI=0.09492, FA=0.05184, CF=0.02653, over 0.00 frames. 
2025-02-10 01:49:38,667 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 02:07:32,618 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 121306, num_updates: 118000, {'loss': 0.1656889170408249, 'DER': 0.3801366318186523, 'ACC': np.float64(0.9247142857142857), 'MI': 0.2670013456163958, 'FA': 0.05687816996170169, 'CF': 0.05625711624055481}, batch size: 64, grad_norm: 0.4210543930530548, grad_scale: , lr: 0.00e+00, 
2025-02-10 02:07:32,618 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 02:07:32,618 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 121306, num_updates: 118000, {'loss': 0.09780489653348923, 'DER': 0.21928817451205512, 'ACC': np.float64(0.9584196428571429), 'MI': 0.10545350172215844, 'FA': 0.06578645235361653, 'CF': 0.04804822043628014}, batch size: 64, grad_norm: 0.4210543930530548, grad_scale: , lr: 0.00e+00, 
2025-02-10 02:07:32,618 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 02:08:41,859 (model:870) WARNING: All labels are zero
2025-02-10 02:08:42,425 (model:870) WARNING: All labels are zero
2025-02-10 02:08:42,652 (model:870) WARNING: All labels are zero
2025-02-10 02:10:47,762 (model:870) WARNING: All labels are zero
2025-02-10 02:11:04,888 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 30, batch_idx_train: 121306,  validation: loss=0.08037, DER=0.1832, ACC=0.9637, MI=0.0988, FA=0.0567, CF=0.02771, over 0.00 frames. 
2025-02-10 02:11:04,889 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 02:11:05,590 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 30, batch_idx_train: 121306,  validation: loss=0.08102, DER=0.1806, ACC=0.9634, MI=0.101, FA=0.05257, CF=0.02702, over 0.00 frames. 
2025-02-10 02:11:05,590 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 02:18:07,972 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-121500.pt
2025-02-10 02:18:09,717 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-10 02:29:06,330 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 121806, num_updates: 118500, {'loss': 0.1361129730939865, 'DER': 0.30124562309855923, 'ACC': np.float64(0.943034238488784), 'MI': 0.15108202743814936, 'FA': 0.08581596923253544, 'CF': 0.06434762642787441}, batch size: 64, grad_norm: 0.3814948499202728, grad_scale: , lr: 0.00e+00, 
2025-02-10 02:29:06,331 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 02:29:06,331 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 121806, num_updates: 118500, {'loss': 0.1273501217365265, 'DER': 0.3011636276391555, 'ACC': np.float64(0.9455357142857144), 'MI': 0.16470729366602688, 'FA': 0.07173704414587333, 'CF': 0.06471928982725528}, batch size: 64, grad_norm: 0.3814948499202728, grad_scale: , lr: 0.00e+00, 
2025-02-10 02:29:06,331 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 02:30:16,229 (model:870) WARNING: All labels are zero
2025-02-10 02:30:16,956 (model:870) WARNING: All labels are zero
2025-02-10 02:30:17,047 (model:870) WARNING: All labels are zero
2025-02-10 02:32:22,972 (model:870) WARNING: All labels are zero
2025-02-10 02:32:40,309 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 30, batch_idx_train: 121806,  validation: loss=0.07698, DER=0.175, ACC=0.9651, MI=0.08603, FA=0.06218, CF=0.02674, over 0.00 frames. 
2025-02-10 02:32:40,309 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 02:32:41,040 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 30, batch_idx_train: 121806,  validation: loss=0.07743, DER=0.1727, ACC=0.9648, MI=0.08801, FA=0.05884, CF=0.02586, over 0.00 frames. 
2025-02-10 02:32:41,041 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 02:50:28,025 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 122306, num_updates: 119000, {'loss': 0.14133548736572266, 'DER': 0.3169474617601419, 'ACC': np.float64(0.9410714285714286), 'MI': 0.20621813345156284, 'FA': 0.06190423409443582, 'CF': 0.0488250942141432}, batch size: 64, grad_norm: 0.4445993900299072, grad_scale: , lr: 0.00e+00, 
2025-02-10 02:50:28,026 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 02:50:28,027 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 122306, num_updates: 119000, {'loss': 0.13504473865032196, 'DER': 0.2971200286208336, 'ACC': np.float64(0.94551163483141), 'MI': 0.15729533122652198, 'FA': 0.07685886351439986, 'CF': 0.06296583387991175}, batch size: 64, grad_norm: 0.4445993900299072, grad_scale: , lr: 0.00e+00, 
2025-02-10 02:50:28,027 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 02:51:38,064 (model:870) WARNING: All labels are zero
2025-02-10 02:51:38,882 (model:870) WARNING: All labels are zero
2025-02-10 02:51:38,924 (model:870) WARNING: All labels are zero
2025-02-10 02:53:47,570 (model:870) WARNING: All labels are zero
2025-02-10 02:54:04,696 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 30, batch_idx_train: 122306,  validation: loss=0.07933, DER=0.1761, ACC=0.964, MI=0.09329, FA=0.05562, CF=0.0272, over 0.00 frames. 
2025-02-10 02:54:04,697 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 02:54:04,758 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 30, batch_idx_train: 122306,  validation: loss=0.07888, DER=0.1797, ACC=0.9642, MI=0.09151, FA=0.05994, CF=0.02823, over 0.00 frames. 
2025-02-10 02:54:04,759 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 03:12:23,930 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 122806, num_updates: 119500, {'loss': 0.12954607605934143, 'DER': 0.2908766451037252, 'ACC': np.float64(0.9455803571428572), 'MI': 0.17477135846531341, 'FA': 0.06708677225072496, 'CF': 0.04901851438768682}, batch size: 64, grad_norm: 0.43435096740722656, grad_scale: , lr: 0.00e+00, 
2025-02-10 03:12:23,931 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 122806, num_updates: 119500, {'loss': 0.12071379274129868, 'DER': 0.2668958284782102, 'ACC': np.float64(0.9493482142857144), 'MI': 0.142973665812165, 'FA': 0.06030062922395712, 'CF': 0.0636215334420881}, batch size: 64, grad_norm: 0.43435096740722656, grad_scale: , lr: 0.00e+00, 
2025-02-10 03:12:23,931 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 03:12:23,931 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 03:13:34,723 (model:870) WARNING: All labels are zero
2025-02-10 03:13:35,497 (model:870) WARNING: All labels are zero
2025-02-10 03:13:35,548 (model:870) WARNING: All labels are zero
2025-02-10 03:15:42,292 (model:870) WARNING: All labels are zero
2025-02-10 03:15:59,068 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 30, batch_idx_train: 122806,  validation: loss=0.07368, DER=0.1686, ACC=0.9662, MI=0.08362, FA=0.05984, CF=0.02516, over 0.00 frames. 
2025-02-10 03:15:59,068 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 03:15:59,724 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 30, batch_idx_train: 122806,  validation: loss=0.07456, DER=0.1673, ACC=0.9657, MI=0.08536, FA=0.05716, CF=0.02479, over 0.00 frames. 
2025-02-10 03:15:59,724 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 03:22:52,632 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-123000.pt
2025-02-10 03:22:54,243 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-10 03:33:51,792 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 123306, num_updates: 120000, {'loss': 0.1610138863325119, 'DER': 0.364989962078965, 'ACC': np.float64(0.9280714285714285), 'MI': 0.2302029890698193, 'FA': 0.050524202542939996, 'CF': 0.08426277046620567}, batch size: 64, grad_norm: 0.49787214398384094, grad_scale: , lr: 0.00e+00, 
2025-02-10 03:33:51,793 (train_accelerate_ddp:702) INFO: [Train] - Epoch 30, batch_idx_train: 123306, num_updates: 120000, {'loss': 0.12399915605783463, 'DER': 0.2748464144226905, 'ACC': np.float64(0.9460106311458512), 'MI': 0.15387265315496354, 'FA': 0.05000861227536315, 'CF': 0.07096514899236378}, batch size: 64, grad_norm: 0.49787214398384094, grad_scale: , lr: 0.00e+00, 
2025-02-10 03:33:51,793 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 03:33:51,793 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 03:35:02,363 (model:870) WARNING: All labels are zero
2025-02-10 03:35:03,158 (model:870) WARNING: All labels are zero
2025-02-10 03:35:03,717 (model:870) WARNING: All labels are zero
2025-02-10 03:37:10,592 (model:870) WARNING: All labels are zero
2025-02-10 03:37:27,959 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 30, batch_idx_train: 123306,  validation: loss=0.08037, DER=0.1805, ACC=0.9633, MI=0.107, FA=0.04634, CF=0.02716, over 0.00 frames. 
2025-02-10 03:37:27,959 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 03:37:27,984 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 30, batch_idx_train: 123306,  validation: loss=0.07974, DER=0.1828, ACC=0.9637, MI=0.1046, FA=0.05039, CF=0.02774, over 0.00 frames. 
2025-02-10 03:37:27,984 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 03:41:27,017 (train_accelerate_ddp:713) INFO: end of epoch 30, batch_idx: 4113 batch_idx_train: 123419, {'loss': 0.13664238154888153, 'DER': 0.3054772906570495, 'ACC': np.float64(0.9428303571428571), 'MI': 0.1700101431308464, 'FA': 0.08013073368646456, 'CF': 0.05533641383973853}, batch size: 64, grad_norm: 0.48498809337615967, grad_scale: , lr: 0.00e+00, 
2025-02-10 03:41:27,018 (train_accelerate_ddp:713) INFO: end of epoch 30, batch_idx: 4113 batch_idx_train: 123419, {'loss': 0.15346160531044006, 'DER': 0.3125958031608436, 'ACC': np.float64(0.9324196428571428), 'MI': 0.18436492415032507, 'FA': 0.04075268248850362, 'CF': 0.08747819652201491}, batch size: 64, grad_norm: 0.48498809337615967, grad_scale: , lr: 0.00e+00, 
2025-02-10 03:41:27,019 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-30.pt
2025-02-10 03:41:28,230 (train_accelerate_ddp:561) INFO:  end of epoch 30, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-30.pt 
2025-02-10 03:41:31,708 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 123420, num_updates: 120000, {'loss': 0.14773571491241455, 'DER': 0.3550518282264495, 'ACC': np.float64(0.9343236131442582), 'MI': 0.22320309830276797, 'FA': 0.07039526141929604, 'CF': 0.06145346850438547}, batch size: 64, grad_norm: 0.4840216338634491, grad_scale: , lr: 0.00e+00, 
2025-02-10 03:41:31,709 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 123420, num_updates: 120000, {'loss': 0.14616794884204865, 'DER': 0.31848961322162284, 'ACC': np.float64(0.938875), 'MI': 0.1665327671295765, 'FA': 0.07758521749110525, 'CF': 0.07437162860094113}, batch size: 64, grad_norm: 0.4840216338634491, grad_scale: , lr: 0.00e+00, 
2025-02-10 03:59:08,909 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 123920, num_updates: 120500, {'loss': 0.1379862129688263, 'DER': 0.3277857723831571, 'ACC': np.float64(0.9430538172715894), 'MI': 0.1733717074391541, 'FA': 0.08365137959081524, 'CF': 0.07076268535318776}, batch size: 64, grad_norm: 0.4426703155040741, grad_scale: , lr: 0.00e+00, 
2025-02-10 03:59:08,910 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 03:59:08,911 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 123920, num_updates: 120500, {'loss': 0.13054917752742767, 'DER': 0.3057562339780937, 'ACC': np.float64(0.9411243352747531), 'MI': 0.16901654625961315, 'FA': 0.0632137030995106, 'CF': 0.07352598461896993}, batch size: 64, grad_norm: 0.4426703155040741, grad_scale: , lr: 0.00e+00, 
2025-02-10 03:59:08,911 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 04:00:22,541 (model:870) WARNING: All labels are zero
2025-02-10 04:00:23,242 (model:870) WARNING: All labels are zero
2025-02-10 04:00:23,375 (model:870) WARNING: All labels are zero
2025-02-10 04:02:30,514 (model:870) WARNING: All labels are zero
2025-02-10 04:02:47,666 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 31, batch_idx_train: 123920,  validation: loss=0.07934, DER=0.1812, ACC=0.9639, MI=0.08289, FA=0.06896, CF=0.02938, over 0.00 frames. 
2025-02-10 04:02:47,667 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 04:02:48,324 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 31, batch_idx_train: 123920,  validation: loss=0.07989, DER=0.1779, ACC=0.9638, MI=0.08504, FA=0.06497, CF=0.02787, over 0.00 frames. 
2025-02-10 04:02:48,324 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 04:21:22,324 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 124420, num_updates: 121000, {'loss': 0.10389076918363571, 'DER': 0.23150765606595997, 'ACC': np.float64(0.9570089285714286), 'MI': 0.11442873969375736, 'FA': 0.06501766784452297, 'CF': 0.05206124852767962}, batch size: 64, grad_norm: 0.40365245938301086, grad_scale: , lr: 0.00e+00, 
2025-02-10 04:21:22,324 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 124420, num_updates: 121000, {'loss': 0.12240191549062729, 'DER': 0.2686878952122855, 'ACC': np.float64(0.9496607142857143), 'MI': 0.14826106594399277, 'FA': 0.07079945799457994, 'CF': 0.049627371273712736}, batch size: 64, grad_norm: 0.40365245938301086, grad_scale: , lr: 0.00e+00, 
2025-02-10 04:21:22,325 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 04:21:22,325 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 04:22:32,544 (model:870) WARNING: All labels are zero
2025-02-10 04:22:33,352 (model:870) WARNING: All labels are zero
2025-02-10 04:22:33,368 (model:870) WARNING: All labels are zero
2025-02-10 04:24:41,927 (model:870) WARNING: All labels are zero
2025-02-10 04:24:59,024 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 31, batch_idx_train: 124420,  validation: loss=0.07872, DER=0.1797, ACC=0.9642, MI=0.08964, FA=0.06193, CF=0.02815, over 0.00 frames. 
2025-02-10 04:24:59,025 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 04:24:59,074 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 31, batch_idx_train: 124420,  validation: loss=0.07925, DER=0.1767, ACC=0.964, MI=0.09176, FA=0.05773, CF=0.02723, over 0.00 frames. 
2025-02-10 04:24:59,075 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 04:27:45,680 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-124500.pt
2025-02-10 04:27:47,329 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-10 04:27:47,331 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-10 04:42:37,442 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 124920, num_updates: 121500, {'loss': 0.15372440218925476, 'DER': 0.3480759756965351, 'ACC': np.float64(0.9323303571428571), 'MI': 0.21260058021785538, 'FA': 0.0686956045760578, 'CF': 0.06677979090262193}, batch size: 64, grad_norm: 0.4077455997467041, grad_scale: , lr: 0.00e+00, 
2025-02-10 04:42:37,443 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 04:42:37,443 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 124920, num_updates: 121500, {'loss': 0.11225026100873947, 'DER': 0.24323588654798847, 'ACC': np.float64(0.9546339285714286), 'MI': 0.1613043714954543, 'FA': 0.048560074037781044, 'CF': 0.03337144101475312}, batch size: 64, grad_norm: 0.4077455997467041, grad_scale: , lr: 0.00e+00, 
2025-02-10 04:42:37,443 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 04:43:47,975 (model:870) WARNING: All labels are zero
2025-02-10 04:43:48,744 (model:870) WARNING: All labels are zero
2025-02-10 04:43:48,802 (model:870) WARNING: All labels are zero
2025-02-10 04:45:58,279 (model:870) WARNING: All labels are zero
2025-02-10 04:46:15,520 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 31, batch_idx_train: 124920,  validation: loss=0.07599, DER=0.1736, ACC=0.9653, MI=0.09506, FA=0.0526, CF=0.02592, over 0.00 frames. 
2025-02-10 04:46:15,521 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 04:46:15,603 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 31, batch_idx_train: 124920,  validation: loss=0.07681, DER=0.1714, ACC=0.9649, MI=0.09686, FA=0.04924, CF=0.02527, over 0.00 frames. 
2025-02-10 04:46:15,603 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 05:04:31,665 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 125420, num_updates: 122000, {'loss': 0.15276122093200684, 'DER': 0.3694301756062597, 'ACC': np.float64(0.9310446428571428), 'MI': 0.19967745789033567, 'FA': 0.07788794648190181, 'CF': 0.09186477123402222}, batch size: 64, grad_norm: 0.4111352264881134, grad_scale: , lr: 0.00e+00, 
2025-02-10 05:04:31,665 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 05:04:31,665 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 125420, num_updates: 122000, {'loss': 0.12453000247478485, 'DER': 0.2766549746673348, 'ACC': np.float64(0.9463711312339506), 'MI': 0.15333221980958744, 'FA': 0.06859306274706307, 'CF': 0.054729692110684264}, batch size: 64, grad_norm: 0.4111352264881134, grad_scale: , lr: 0.00e+00, 
2025-02-10 05:04:31,665 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 05:05:40,676 (model:870) WARNING: All labels are zero
2025-02-10 05:05:41,360 (model:870) WARNING: All labels are zero
2025-02-10 05:05:41,489 (model:870) WARNING: All labels are zero
2025-02-10 05:07:47,156 (model:870) WARNING: All labels are zero
2025-02-10 05:08:03,188 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 31, batch_idx_train: 125420,  validation: loss=0.07862, DER=0.1759, ACC=0.9641, MI=0.08823, FA=0.05985, CF=0.02781, over 0.00 frames. 
2025-02-10 05:08:03,189 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 05:08:03,520 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 31, batch_idx_train: 125420,  validation: loss=0.0783, DER=0.1794, ACC=0.9642, MI=0.08625, FA=0.06391, CF=0.0292, over 0.00 frames. 
2025-02-10 05:08:03,520 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 05:25:47,745 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 125920, num_updates: 122500, {'loss': 0.1184406504034996, 'DER': 0.29592545433499245, 'ACC': np.float64(0.94625), 'MI': 0.17947679129528882, 'FA': 0.06395416136126866, 'CF': 0.052494501678435}, batch size: 64, grad_norm: 0.3742140233516693, grad_scale: , lr: 0.00e+00, 
2025-02-10 05:25:47,745 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 125920, num_updates: 122500, {'loss': 0.10694190114736557, 'DER': 0.2663355672570608, 'ACC': np.float64(0.95025), 'MI': 0.12434179033030159, 'FA': 0.0749162278602202, 'CF': 0.06707754906653901}, batch size: 64, grad_norm: 0.3742140233516693, grad_scale: , lr: 0.00e+00, 
2025-02-10 05:25:47,746 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 05:25:47,746 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 05:26:56,375 (model:870) WARNING: All labels are zero
2025-02-10 05:26:57,164 (model:870) WARNING: All labels are zero
2025-02-10 05:26:57,182 (model:870) WARNING: All labels are zero
2025-02-10 05:29:02,197 (model:870) WARNING: All labels are zero
2025-02-10 05:29:18,698 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 31, batch_idx_train: 125920,  validation: loss=0.07492, DER=0.172, ACC=0.9654, MI=0.0862, FA=0.05883, CF=0.027, over 0.00 frames. 
2025-02-10 05:29:18,698 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 05:29:19,225 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 31, batch_idx_train: 125920,  validation: loss=0.07557, DER=0.1697, ACC=0.9651, MI=0.08784, FA=0.05556, CF=0.02627, over 0.00 frames. 
2025-02-10 05:29:19,226 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 05:32:05,004 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-126000.pt
2025-02-10 05:32:06,612 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-10 05:46:54,327 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 126420, num_updates: 123000, {'loss': 0.15172506868839264, 'DER': 0.35324513088410653, 'ACC': np.float64(0.9315803571428571), 'MI': 0.20878996081994208, 'FA': 0.06257452728408382, 'CF': 0.08188064278008063}, batch size: 64, grad_norm: 0.4699248671531677, grad_scale: , lr: 0.00e+00, 
2025-02-10 05:46:54,327 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 05:46:54,327 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 126420, num_updates: 123000, {'loss': 0.10990722477436066, 'DER': 0.23946440313228526, 'ACC': np.float64(0.9571696428571429), 'MI': 0.14023551915834778, 'FA': 0.05194572299599498, 'CF': 0.047283160977942496}, batch size: 64, grad_norm: 0.4699248671531677, grad_scale: , lr: 0.00e+00, 
2025-02-10 05:46:54,327 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 05:48:03,525 (model:870) WARNING: All labels are zero
2025-02-10 05:48:04,329 (model:870) WARNING: All labels are zero
2025-02-10 05:48:04,348 (model:870) WARNING: All labels are zero
2025-02-10 05:50:12,173 (model:870) WARNING: All labels are zero
2025-02-10 05:50:29,199 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 31, batch_idx_train: 126420,  validation: loss=0.07808, DER=0.1731, ACC=0.9646, MI=0.08846, FA=0.05808, CF=0.0266, over 0.00 frames. 
2025-02-10 05:50:29,200 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 05:50:29,247 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 31, batch_idx_train: 126420,  validation: loss=0.07743, DER=0.1756, ACC=0.9648, MI=0.0864, FA=0.06147, CF=0.02768, over 0.00 frames. 
2025-02-10 05:50:29,248 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 06:09:01,450 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 126920, num_updates: 123500, {'loss': 0.2015351802110672, 'DER': 0.4824898328061455, 'ACC': np.float64(0.9098125), 'MI': 0.31247175779484865, 'FA': 0.08195887934929959, 'CF': 0.08805919566199728}, batch size: 64, grad_norm: 0.6658050417900085, grad_scale: , lr: 0.00e+00, 
2025-02-10 06:09:01,450 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 126920, num_updates: 123500, {'loss': 0.1753230094909668, 'DER': 0.3987819874685249, 'ACC': np.float64(0.9213928571428571), 'MI': 0.19511623821514318, 'FA': 0.08690050945716461, 'CF': 0.11676523979621714}, batch size: 64, grad_norm: 0.6658050417900085, grad_scale: , lr: 0.00e+00, 
2025-02-10 06:09:01,451 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 06:09:01,451 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 06:10:10,584 (model:870) WARNING: All labels are zero
2025-02-10 06:10:11,308 (model:870) WARNING: All labels are zero
2025-02-10 06:10:11,405 (model:870) WARNING: All labels are zero
2025-02-10 06:12:15,740 (model:870) WARNING: All labels are zero
2025-02-10 06:12:32,192 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 31, batch_idx_train: 126920,  validation: loss=0.0769, DER=0.1755, ACC=0.9648, MI=0.08226, FA=0.06525, CF=0.028, over 0.00 frames. 
2025-02-10 06:12:32,192 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 06:12:32,632 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 31, batch_idx_train: 126920,  validation: loss=0.07724, DER=0.1723, ACC=0.9647, MI=0.08423, FA=0.06159, CF=0.02647, over 0.00 frames. 
2025-02-10 06:12:32,632 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 06:30:15,556 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 127420, num_updates: 124000, {'loss': 0.13131457567214966, 'DER': 0.29703028868906767, 'ACC': np.float64(0.9454910714285715), 'MI': 0.1667061050638902, 'FA': 0.06619734973970658, 'CF': 0.0641268338854709}, batch size: 64, grad_norm: 0.4081380367279053, grad_scale: , lr: 0.00e+00, 
2025-02-10 06:30:15,556 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 06:30:15,556 (train_accelerate_ddp:702) INFO: [Train] - Epoch 31, batch_idx_train: 127420, num_updates: 124000, {'loss': 0.1349698305130005, 'DER': 0.2871553094676827, 'ACC': np.float64(0.9439777679530096), 'MI': 0.1802532755879612, 'FA': 0.05367030316320377, 'CF': 0.05323173071651773}, batch size: 64, grad_norm: 0.4081380367279053, grad_scale: , lr: 0.00e+00, 
2025-02-10 06:30:15,556 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 06:31:25,446 (model:870) WARNING: All labels are zero
2025-02-10 06:31:26,263 (model:870) WARNING: All labels are zero
2025-02-10 06:31:26,271 (model:870) WARNING: All labels are zero
2025-02-10 06:33:34,436 (model:870) WARNING: All labels are zero
2025-02-10 06:33:51,568 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 31, batch_idx_train: 127420,  validation: loss=0.08048, DER=0.1849, ACC=0.9635, MI=0.1109, FA=0.04694, CF=0.02706, over 0.00 frames. 
2025-02-10 06:33:51,569 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 06:33:51,605 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 31, batch_idx_train: 127420,  validation: loss=0.08136, DER=0.1832, ACC=0.9629, MI=0.1131, FA=0.04329, CF=0.02685, over 0.00 frames. 
2025-02-10 06:33:51,605 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 06:36:39,108 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-127500.pt
2025-02-10 06:36:40,670 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-10 06:37:50,598 (train_accelerate_ddp:713) INFO: end of epoch 31, batch_idx: 4113 batch_idx_train: 127533, {'loss': 0.10778111964464188, 'DER': 0.23610397029420166, 'ACC': np.float64(0.9564522357632309), 'MI': 0.13373321908026278, 'FA': 0.06146815195658383, 'CF': 0.040902599257355045}, batch size: 64, grad_norm: 0.3707788288593292, grad_scale: , lr: 0.00e+00, 
2025-02-10 06:37:50,599 (train_accelerate_ddp:713) INFO: end of epoch 31, batch_idx: 4113 batch_idx_train: 127533, {'loss': 0.13168445229530334, 'DER': 0.2770015524506542, 'ACC': np.float64(0.9458660714285715), 'MI': 0.15236194278110446, 'FA': 0.06548015080949213, 'CF': 0.05915945886005766}, batch size: 64, grad_norm: 0.3707788288593292, grad_scale: , lr: 0.00e+00, 
2025-02-10 06:37:50,600 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-31.pt
2025-02-10 06:37:51,792 (train_accelerate_ddp:561) INFO:  end of epoch 31, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-31.pt 
2025-02-10 06:37:55,124 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 127534, num_updates: 124000, {'loss': 0.12506407499313354, 'DER': 0.2836300288529588, 'ACC': np.float64(0.9454821428571429), 'MI': 0.1749142577168055, 'FA': 0.05993793891883064, 'CF': 0.04877783221732266}, batch size: 64, grad_norm: 0.41116437315940857, grad_scale: , lr: 0.00e+00, 
2025-02-10 06:37:55,125 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 127534, num_updates: 124000, {'loss': 0.12024518847465515, 'DER': 0.2854238541153277, 'ACC': np.float64(0.9503395356377325), 'MI': 0.14754805322819123, 'FA': 0.08360029571217348, 'CF': 0.05427550517496304}, batch size: 64, grad_norm: 0.41116437315940857, grad_scale: , lr: 0.00e+00, 
2025-02-10 06:55:58,339 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 128034, num_updates: 124500, {'loss': 0.13424357771873474, 'DER': 0.31399915412965984, 'ACC': np.float64(0.9455357142857144), 'MI': 0.16409884599117877, 'FA': 0.09534167119811492, 'CF': 0.05455863694036614}, batch size: 64, grad_norm: 0.43433234095573425, grad_scale: , lr: 0.00e+00, 
2025-02-10 06:55:58,339 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 128034, num_updates: 124500, {'loss': 0.13715526461601257, 'DER': 0.2894453741333971, 'ACC': np.float64(0.9462955279346237), 'MI': 0.14857757590246234, 'FA': 0.07446808510638298, 'CF': 0.06639971312455176}, batch size: 64, grad_norm: 0.43433234095573425, grad_scale: , lr: 0.00e+00, 
2025-02-10 06:55:58,339 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 06:55:58,339 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 06:57:07,583 (model:870) WARNING: All labels are zero
2025-02-10 06:57:08,261 (model:870) WARNING: All labels are zero
2025-02-10 06:57:08,397 (model:870) WARNING: All labels are zero
2025-02-10 06:59:11,737 (model:870) WARNING: All labels are zero
2025-02-10 06:59:28,467 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 32, batch_idx_train: 128034,  validation: loss=0.09261, DER=0.2165, ACC=0.9581, MI=0.1329, FA=0.05024, CF=0.03335, over 0.00 frames. 
2025-02-10 06:59:28,468 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 06:59:29,113 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 32, batch_idx_train: 128034,  validation: loss=0.09378, DER=0.2153, ACC=0.9573, MI=0.1379, FA=0.04478, CF=0.03266, over 0.00 frames. 
2025-02-10 06:59:29,113 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 07:17:29,523 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 128534, num_updates: 125000, {'loss': 0.1213398426771164, 'DER': 0.24588850918410934, 'ACC': np.float64(0.9525178571428571), 'MI': 0.16344510892780864, 'FA': 0.04437206322084579, 'CF': 0.038071337035454934}, batch size: 64, grad_norm: 0.3451163172721863, grad_scale: , lr: 0.00e+00, 
2025-02-10 07:17:29,523 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 128534, num_updates: 125000, {'loss': 0.12411802262067795, 'DER': 0.26547965531016376, 'ACC': np.float64(0.9482678571428571), 'MI': 0.15043086229526909, 'FA': 0.04987730411459225, 'CF': 0.06517148890030246}, batch size: 64, grad_norm: 0.3451163172721863, grad_scale: , lr: 0.00e+00, 
2025-02-10 07:17:29,524 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 07:17:29,524 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 07:18:38,778 (model:870) WARNING: All labels are zero
2025-02-10 07:18:39,535 (model:870) WARNING: All labels are zero
2025-02-10 07:18:39,584 (model:870) WARNING: All labels are zero
2025-02-10 07:20:46,313 (model:870) WARNING: All labels are zero
2025-02-10 07:21:03,244 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 32, batch_idx_train: 128534,  validation: loss=0.08574, DER=0.1968, ACC=0.9612, MI=0.1137, FA=0.05164, CF=0.03146, over 0.00 frames. 
2025-02-10 07:21:03,245 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 07:21:03,341 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 32, batch_idx_train: 128534,  validation: loss=0.08656, DER=0.1947, ACC=0.9606, MI=0.1173, FA=0.0469, CF=0.03047, over 0.00 frames. 
2025-02-10 07:21:03,341 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 07:37:27,840 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-129000.pt
2025-02-10 07:37:29,429 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-10 07:37:29,431 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-10 07:38:43,613 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 129034, num_updates: 125500, {'loss': 0.16025306284427643, 'DER': 0.35123529411764703, 'ACC': np.float64(0.9286517857142856), 'MI': 0.16952941176470587, 'FA': 0.06288235294117647, 'CF': 0.1188235294117647}, batch size: 64, grad_norm: 0.4981948733329773, grad_scale: , lr: 0.00e+00, 
2025-02-10 07:38:43,614 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 07:38:43,614 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 129034, num_updates: 125500, {'loss': 0.15299242734909058, 'DER': 0.3840029174010819, 'ACC': np.float64(0.9313392857142857), 'MI': 0.2188050811402176, 'FA': 0.08180878867075914, 'CF': 0.08338904759010515}, batch size: 64, grad_norm: 0.4981948733329773, grad_scale: , lr: 0.00e+00, 
2025-02-10 07:38:43,615 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 07:39:53,314 (model:870) WARNING: All labels are zero
2025-02-10 07:39:54,021 (model:870) WARNING: All labels are zero
2025-02-10 07:39:54,128 (model:870) WARNING: All labels are zero
2025-02-10 07:42:01,480 (model:870) WARNING: All labels are zero
2025-02-10 07:42:18,465 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 32, batch_idx_train: 129034,  validation: loss=0.07841, DER=0.1791, ACC=0.9641, MI=0.09143, FA=0.05805, CF=0.02958, over 0.00 frames. 
2025-02-10 07:42:18,466 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 07:42:19,366 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 32, batch_idx_train: 129034,  validation: loss=0.07904, DER=0.1759, ACC=0.9638, MI=0.09336, FA=0.05394, CF=0.02864, over 0.00 frames. 
2025-02-10 07:42:19,367 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 08:00:50,250 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 129534, num_updates: 126000, {'loss': 0.13294655084609985, 'DER': 0.298915578358209, 'ACC': np.float64(0.944625), 'MI': 0.1640625, 'FA': 0.07217817164179105, 'CF': 0.06267490671641791}, batch size: 64, grad_norm: 0.5157508254051208, grad_scale: , lr: 0.00e+00, 
2025-02-10 08:00:50,250 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 08:00:50,251 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 129534, num_updates: 126000, {'loss': 0.14752504229545593, 'DER': 0.3340147916541399, 'ACC': np.float64(0.9368482142857143), 'MI': 0.16078407792676327, 'FA': 0.08195538452287895, 'CF': 0.09127532920449763}, batch size: 64, grad_norm: 0.5157508254051208, grad_scale: , lr: 0.00e+00, 
2025-02-10 08:00:50,251 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 08:01:59,396 (model:870) WARNING: All labels are zero
2025-02-10 08:02:00,168 (model:870) WARNING: All labels are zero
2025-02-10 08:02:00,216 (model:870) WARNING: All labels are zero
2025-02-10 08:04:07,036 (model:870) WARNING: All labels are zero
2025-02-10 08:04:23,892 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 32, batch_idx_train: 129534,  validation: loss=0.08059, DER=0.1839, ACC=0.9632, MI=0.09666, FA=0.05676, CF=0.03048, over 0.00 frames. 
2025-02-10 08:04:23,893 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 08:04:23,995 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 32, batch_idx_train: 129534,  validation: loss=0.08132, DER=0.1813, ACC=0.9628, MI=0.09957, FA=0.05215, CF=0.02959, over 0.00 frames. 
2025-02-10 08:04:23,996 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 08:22:19,511 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 130034, num_updates: 126500, {'loss': 0.17603595554828644, 'DER': 0.3822784810126582, 'ACC': np.float64(0.9227321428571429), 'MI': 0.2189323059988993, 'FA': 0.0693450742982939, 'CF': 0.09400110071546505}, batch size: 64, grad_norm: 0.5892965793609619, grad_scale: , lr: 0.00e+00, 
2025-02-10 08:22:19,512 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 130034, num_updates: 126500, {'loss': 0.11370189487934113, 'DER': 0.2449983045100034, 'ACC': np.float64(0.9524651221513794), 'MI': 0.13722165705889003, 'FA': 0.05487735955691195, 'CF': 0.052899287894201424}, batch size: 64, grad_norm: 0.5892965793609619, grad_scale: , lr: 0.00e+00, 
2025-02-10 08:22:19,512 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 08:22:19,512 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 08:23:28,834 (model:870) WARNING: All labels are zero
2025-02-10 08:23:29,614 (model:870) WARNING: All labels are zero
2025-02-10 08:23:29,640 (model:870) WARNING: All labels are zero
2025-02-10 08:25:37,184 (model:870) WARNING: All labels are zero
2025-02-10 08:25:54,149 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 32, batch_idx_train: 130034,  validation: loss=0.1384, DER=0.3478, ACC=0.9368, MI=0.2584, FA=0.04368, CF=0.04574, over 0.00 frames. 
2025-02-10 08:25:54,150 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 08:25:54,180 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 32, batch_idx_train: 130034,  validation: loss=0.1409, DER=0.3473, ACC=0.9359, MI=0.2658, FA=0.03948, CF=0.04204, over 0.00 frames. 
2025-02-10 08:25:54,180 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 08:42:10,504 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-130500.pt
2025-02-10 08:42:12,128 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-10 08:43:25,245 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 130534, num_updates: 127000, {'loss': 0.1315067559480667, 'DER': 0.3026518485915493, 'ACC': np.float64(0.9424740562220104), 'MI': 0.19014084507042253, 'FA': 0.06321522887323944, 'CF': 0.04929577464788732}, batch size: 64, grad_norm: 0.4390409588813782, grad_scale: , lr: 0.00e+00, 
2025-02-10 08:43:25,245 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 08:43:25,246 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 130534, num_updates: 127000, {'loss': 0.11050762236118317, 'DER': 0.26128599316739876, 'ACC': np.float64(0.9546607142857143), 'MI': 0.11627623230844314, 'FA': 0.09651049292337725, 'CF': 0.04849926793557833}, batch size: 64, grad_norm: 0.4390409588813782, grad_scale: , lr: 0.00e+00, 
2025-02-10 08:43:25,246 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 08:44:34,270 (model:870) WARNING: All labels are zero
2025-02-10 08:44:35,060 (model:870) WARNING: All labels are zero
2025-02-10 08:44:35,075 (model:870) WARNING: All labels are zero
2025-02-10 08:46:41,663 (model:870) WARNING: All labels are zero
2025-02-10 08:46:58,552 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 32, batch_idx_train: 130534,  validation: loss=0.08027, DER=0.1839, ACC=0.9635, MI=0.1021, FA=0.05283, CF=0.029, over 0.00 frames. 
2025-02-10 08:46:58,552 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 08:46:58,610 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 32, batch_idx_train: 130534,  validation: loss=0.08093, DER=0.1815, ACC=0.963, MI=0.1044, FA=0.04862, CF=0.02843, over 0.00 frames. 
2025-02-10 08:46:58,610 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 09:05:28,749 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 131034, num_updates: 127500, {'loss': 0.13732974231243134, 'DER': 0.3148862081830618, 'ACC': np.float64(0.9440089285714286), 'MI': 0.15986817560004973, 'FA': 0.0799651784603905, 'CF': 0.07505285412262157}, batch size: 64, grad_norm: 0.4348268508911133, grad_scale: , lr: 0.00e+00, 
2025-02-10 09:05:28,749 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 131034, num_updates: 127500, {'loss': 0.1345166265964508, 'DER': 0.3256682273454632, 'ACC': np.float64(0.9393136512742871), 'MI': 0.17696912226634268, 'FA': 0.07526817993243644, 'CF': 0.07343092514668405}, batch size: 64, grad_norm: 0.4348268508911133, grad_scale: , lr: 0.00e+00, 
2025-02-10 09:05:28,749 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 09:05:28,749 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 09:06:36,202 (model:870) WARNING: All labels are zero
2025-02-10 09:06:36,986 (model:870) WARNING: All labels are zero
2025-02-10 09:06:37,427 (model:870) WARNING: All labels are zero
2025-02-10 09:08:41,489 (model:870) WARNING: All labels are zero
2025-02-10 09:08:58,106 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 32, batch_idx_train: 131034,  validation: loss=0.09206, DER=0.2079, ACC=0.9594, MI=0.1081, FA=0.06633, CF=0.03354, over 0.00 frames. 
2025-02-10 09:08:58,106 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 09:08:58,263 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 32, batch_idx_train: 131034,  validation: loss=0.09246, DER=0.2035, ACC=0.9595, MI=0.1125, FA=0.05981, CF=0.03119, over 0.00 frames. 
2025-02-10 09:08:58,263 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 09:26:50,682 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 131534, num_updates: 128000, {'loss': 0.1296863853931427, 'DER': 0.31557665260196904, 'ACC': np.float64(0.9410089285714286), 'MI': 0.1753398968588842, 'FA': 0.06862400375058603, 'CF': 0.07161275199249882}, batch size: 64, grad_norm: 0.4874381422996521, grad_scale: , lr: 0.00e+00, 
2025-02-10 09:26:50,682 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 09:26:50,682 (train_accelerate_ddp:702) INFO: [Train] - Epoch 32, batch_idx_train: 131534, num_updates: 128000, {'loss': 0.1376619040966034, 'DER': 0.2953105196451204, 'ACC': np.float64(0.9406607142857143), 'MI': 0.19608153781157583, 'FA': 0.04356780735107731, 'CF': 0.05566117448246726}, batch size: 64, grad_norm: 0.4874381422996521, grad_scale: , lr: 0.00e+00, 
2025-02-10 09:26:50,683 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 09:28:00,250 (model:870) WARNING: All labels are zero
2025-02-10 09:28:01,025 (model:870) WARNING: All labels are zero
2025-02-10 09:28:01,058 (model:870) WARNING: All labels are zero
2025-02-10 09:30:09,875 (model:870) WARNING: All labels are zero
2025-02-10 09:30:27,153 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 32, batch_idx_train: 131534,  validation: loss=0.08183, DER=0.1814, ACC=0.963, MI=0.09064, FA=0.06138, CF=0.02938, over 0.00 frames. 
2025-02-10 09:30:27,154 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 09:30:27,155 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 32, batch_idx_train: 131534,  validation: loss=0.08169, DER=0.1855, ACC=0.9629, MI=0.08795, FA=0.06607, CF=0.03149, over 0.00 frames. 
2025-02-10 09:30:27,155 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 09:34:31,331 (train_accelerate_ddp:713) INFO: end of epoch 32, batch_idx: 4113 batch_idx_train: 131647, {'loss': 0.12375562638044357, 'DER': 0.2855938835711276, 'ACC': np.float64(0.949339841850244), 'MI': 0.14105111070977064, 'FA': 0.09150562880019264, 'CF': 0.05303714406116429}, batch size: 64, grad_norm: 0.3456557095050812, grad_scale: , lr: 0.00e+00, 
2025-02-10 09:34:31,331 (train_accelerate_ddp:713) INFO: end of epoch 32, batch_idx: 4113 batch_idx_train: 131647, {'loss': 0.1287919282913208, 'DER': 0.30518510320402853, 'ACC': np.float64(0.9416785714285715), 'MI': 0.1836644347296774, 'FA': 0.06524265397598362, 'CF': 0.05627801449836755}, batch size: 64, grad_norm: 0.3456557095050812, grad_scale: , lr: 0.00e+00, 
2025-02-10 09:34:31,332 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-32.pt
2025-02-10 09:34:32,575 (train_accelerate_ddp:561) INFO:  end of epoch 32, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-32.pt 
2025-02-10 09:34:35,820 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 131648, num_updates: 128000, {'loss': 0.11833669990301132, 'DER': 0.2526806265087296, 'ACC': np.float64(0.9527767857142857), 'MI': 0.1423117947566384, 'FA': 0.06613147701117161, 'CF': 0.044237354740919554}, batch size: 64, grad_norm: 0.4428538680076599, grad_scale: , lr: 0.00e+00, 
2025-02-10 09:34:35,820 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 131648, num_updates: 128000, {'loss': 0.11100917309522629, 'DER': 0.24902132632193982, 'ACC': np.float64(0.9547142857142856), 'MI': 0.1359626059012562, 'FA': 0.06573181419807186, 'CF': 0.04732690622261174}, batch size: 64, grad_norm: 0.4428538680076599, grad_scale: , lr: 0.00e+00, 
2025-02-10 09:47:11,563 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-132000.pt
2025-02-10 09:47:13,242 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-10 09:47:13,244 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-10 09:52:32,993 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 132148, num_updates: 128500, {'loss': 0.12729093432426453, 'DER': 0.2779725143270461, 'ACC': np.float64(0.9464375), 'MI': 0.16441328659656151, 'FA': 0.05775329661158404, 'CF': 0.05580593111890057}, batch size: 64, grad_norm: 0.40949925780296326, grad_scale: , lr: 0.00e+00, 
2025-02-10 09:52:32,994 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 09:52:32,994 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 132148, num_updates: 128500, {'loss': 0.1328629106283188, 'DER': 0.2834897390945653, 'ACC': np.float64(0.943625), 'MI': 0.19062596679385377, 'FA': 0.050788903784675675, 'CF': 0.04207486851603589}, batch size: 64, grad_norm: 0.40949925780296326, grad_scale: , lr: 0.00e+00, 
2025-02-10 09:52:32,994 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 09:53:43,311 (model:870) WARNING: All labels are zero
2025-02-10 09:53:44,126 (model:870) WARNING: All labels are zero
2025-02-10 09:53:44,204 (model:870) WARNING: All labels are zero
2025-02-10 09:55:53,163 (model:870) WARNING: All labels are zero
2025-02-10 09:56:10,242 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 33, batch_idx_train: 132148,  validation: loss=0.09544, DER=0.2212, ACC=0.9561, MI=0.1394, FA=0.0468, CF=0.03497, over 0.00 frames. 
2025-02-10 09:56:10,242 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 09:56:10,355 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 33, batch_idx_train: 132148,  validation: loss=0.09428, DER=0.2223, ACC=0.957, MI=0.1341, FA=0.05228, CF=0.03585, over 0.00 frames. 
2025-02-10 09:56:10,356 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 10:13:59,494 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 132648, num_updates: 129000, {'loss': 0.14462898671627045, 'DER': 0.27294713160854894, 'ACC': np.float64(0.9491875), 'MI': 0.16608548931383577, 'FA': 0.05973003374578178, 'CF': 0.047131608548931385}, batch size: 64, grad_norm: 0.4067559838294983, grad_scale: , lr: 0.00e+00, 
2025-02-10 10:13:59,494 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 132648, num_updates: 129000, {'loss': 0.12209621071815491, 'DER': 0.29162956366874443, 'ACC': np.float64(0.9449107142857144), 'MI': 0.1767586821015138, 'FA': 0.06311219946571683, 'CF': 0.051758682101513805}, batch size: 64, grad_norm: 0.4067559838294983, grad_scale: , lr: 0.00e+00, 
2025-02-10 10:13:59,495 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 10:13:59,495 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 10:15:10,335 (model:870) WARNING: All labels are zero
2025-02-10 10:15:11,158 (model:870) WARNING: All labels are zero
2025-02-10 10:15:11,166 (model:870) WARNING: All labels are zero
2025-02-10 10:17:20,792 (model:870) WARNING: All labels are zero
2025-02-10 10:17:37,542 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 33, batch_idx_train: 132648,  validation: loss=0.07641, DER=0.1748, ACC=0.965, MI=0.08927, FA=0.05873, CF=0.02678, over 0.00 frames. 
2025-02-10 10:17:37,543 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 10:17:37,967 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 33, batch_idx_train: 132648,  validation: loss=0.07691, DER=0.172, ACC=0.9648, MI=0.09125, FA=0.05486, CF=0.02591, over 0.00 frames. 
2025-02-10 10:17:37,968 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 10:36:14,282 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 133148, num_updates: 129500, {'loss': 0.15607373416423798, 'DER': 0.3891706971806064, 'ACC': np.float64(0.9290357142857143), 'MI': 0.19788840391647988, 'FA': 0.11165506665093783, 'CF': 0.07962722661318863}, batch size: 64, grad_norm: 0.4836762845516205, grad_scale: , lr: 0.00e+00, 
2025-02-10 10:36:14,282 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 10:36:14,283 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 133148, num_updates: 129500, {'loss': 0.12875695526599884, 'DER': 0.28353585894686684, 'ACC': np.float64(0.9470178571428571), 'MI': 0.1373600190612342, 'FA': 0.07624493685966166, 'CF': 0.06993090302597094}, batch size: 64, grad_norm: 0.4836762845516205, grad_scale: , lr: 0.00e+00, 
2025-02-10 10:36:14,283 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 10:37:24,738 (model:870) WARNING: All labels are zero
2025-02-10 10:37:25,386 (model:870) WARNING: All labels are zero
2025-02-10 10:37:25,580 (model:870) WARNING: All labels are zero
2025-02-10 10:39:34,311 (model:870) WARNING: All labels are zero
2025-02-10 10:39:51,530 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 33, batch_idx_train: 133148,  validation: loss=0.07509, DER=0.1717, ACC=0.9656, MI=0.08847, FA=0.05692, CF=0.02627, over 0.00 frames. 
2025-02-10 10:39:51,530 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 10:39:51,826 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 33, batch_idx_train: 133148,  validation: loss=0.07575, DER=0.1701, ACC=0.9652, MI=0.09034, FA=0.05404, CF=0.02573, over 0.00 frames. 
2025-02-10 10:39:51,826 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 10:52:37,711 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-133500.pt
2025-02-10 10:52:39,317 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-10 10:57:56,810 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 133648, num_updates: 130000, {'loss': 0.15927813947200775, 'DER': 0.344975095224143, 'ACC': np.float64(0.9320982142857144), 'MI': 0.17866979197187224, 'FA': 0.06563140931731615, 'CF': 0.10067389393495459}, batch size: 64, grad_norm: 0.5776299238204956, grad_scale: , lr: 0.00e+00, 
2025-02-10 10:57:56,811 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 133648, num_updates: 130000, {'loss': 0.11959812790155411, 'DER': 0.25829709945511586, 'ACC': np.float64(0.9499821428571429), 'MI': 0.1382574715174198, 'FA': 0.07000935659640047, 'CF': 0.05003027134129561}, batch size: 64, grad_norm: 0.5776299238204956, grad_scale: , lr: 0.00e+00, 
2025-02-10 10:57:56,811 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 10:57:56,811 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 10:59:05,660 (model:870) WARNING: All labels are zero
2025-02-10 10:59:06,423 (model:870) WARNING: All labels are zero
2025-02-10 10:59:06,464 (model:870) WARNING: All labels are zero
2025-02-10 11:01:12,388 (model:870) WARNING: All labels are zero
2025-02-10 11:01:29,175 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 33, batch_idx_train: 133648,  validation: loss=0.07525, DER=0.1719, ACC=0.9655, MI=0.08424, FA=0.0609, CF=0.02671, over 0.00 frames. 
2025-02-10 11:01:29,176 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 11:01:29,255 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 33, batch_idx_train: 133648,  validation: loss=0.07599, DER=0.1692, ACC=0.9652, MI=0.08615, FA=0.05733, CF=0.02576, over 0.00 frames. 
2025-02-10 11:01:29,255 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 11:19:11,353 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 134148, num_updates: 130500, {'loss': 0.1391126811504364, 'DER': 0.31221771858714537, 'ACC': np.float64(0.9431160714285715), 'MI': 0.16352055587724376, 'FA': 0.09200926462072959, 'CF': 0.056687898089171976}, batch size: 64, grad_norm: 0.41208615899086, grad_scale: , lr: 0.00e+00, 
2025-02-10 11:19:11,353 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 11:19:11,354 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 134148, num_updates: 130500, {'loss': 0.10351398587226868, 'DER': 0.24244804253262445, 'ACC': np.float64(0.9576582978761683), 'MI': 0.11364185596906719, 'FA': 0.08687771870468826, 'CF': 0.04192846785886902}, batch size: 64, grad_norm: 0.41208615899086, grad_scale: , lr: 0.00e+00, 
2025-02-10 11:19:11,354 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 11:20:22,077 (model:870) WARNING: All labels are zero
2025-02-10 11:20:22,902 (model:870) WARNING: All labels are zero
2025-02-10 11:20:22,920 (model:870) WARNING: All labels are zero
2025-02-10 11:22:33,651 (model:870) WARNING: All labels are zero
2025-02-10 11:22:51,124 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 33, batch_idx_train: 134148,  validation: loss=0.08006, DER=0.183, ACC=0.9637, MI=0.08167, FA=0.0716, CF=0.02974, over 0.00 frames. 
2025-02-10 11:22:51,124 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 11:22:51,179 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 33, batch_idx_train: 134148,  validation: loss=0.08062, DER=0.1796, ACC=0.9636, MI=0.08328, FA=0.06781, CF=0.02853, over 0.00 frames. 
2025-02-10 11:22:51,180 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 11:41:37,122 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 134648, num_updates: 131000, {'loss': 0.15883709490299225, 'DER': 0.35721349302274474, 'ACC': np.float64(0.9290535714285715), 'MI': 0.20651576749807712, 'FA': 0.07136578397978244, 'CF': 0.07933194154488518}, batch size: 64, grad_norm: 0.4502672851085663, grad_scale: , lr: 0.00e+00, 
2025-02-10 11:41:37,123 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 134648, num_updates: 131000, {'loss': 0.12801937758922577, 'DER': 0.25896370185646994, 'ACC': np.float64(0.9500267857142857), 'MI': 0.14458298697700195, 'FA': 0.06317539484621779, 'CF': 0.05120532003325021}, batch size: 64, grad_norm: 0.4502672851085663, grad_scale: , lr: 0.00e+00, 
2025-02-10 11:41:37,123 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 11:41:37,123 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 11:42:48,277 (model:870) WARNING: All labels are zero
2025-02-10 11:42:48,362 (model:870) WARNING: All labels are zero
2025-02-10 11:42:49,094 (model:870) WARNING: All labels are zero
2025-02-10 11:44:58,486 (model:870) WARNING: All labels are zero
2025-02-10 11:45:15,869 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 33, batch_idx_train: 134648,  validation: loss=0.09409, DER=0.2208, ACC=0.9574, MI=0.1359, FA=0.05054, CF=0.03428, over 0.00 frames. 
2025-02-10 11:45:15,870 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 11:45:16,552 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 33, batch_idx_train: 134648,  validation: loss=0.09517, DER=0.2193, ACC=0.9566, MI=0.1413, FA=0.04468, CF=0.0333, over 0.00 frames. 
2025-02-10 11:45:16,552 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 11:57:49,361 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-135000.pt
2025-02-10 11:57:50,980 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-10 12:03:11,374 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 135148, num_updates: 131500, {'loss': 0.1399243026971817, 'DER': 0.27821564527371184, 'ACC': np.float64(0.9434272004040914), 'MI': 0.15929440780655194, 'FA': 0.060854645863492575, 'CF': 0.05806659160366737}, batch size: 64, grad_norm: 0.3520890772342682, grad_scale: , lr: 0.00e+00, 
2025-02-10 12:03:11,375 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 135148, num_updates: 131500, {'loss': 0.11184271425008774, 'DER': 0.260855006139078, 'ACC': np.float64(0.9517142857142856), 'MI': 0.1647505301931019, 'FA': 0.055140082598504295, 'CF': 0.04096439334747182}, batch size: 64, grad_norm: 0.3520890772342682, grad_scale: , lr: 0.00e+00, 
2025-02-10 12:03:11,375 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 12:03:11,375 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 12:04:21,677 (model:870) WARNING: All labels are zero
2025-02-10 12:04:22,497 (model:870) WARNING: All labels are zero
2025-02-10 12:04:22,499 (model:870) WARNING: All labels are zero
2025-02-10 12:06:32,057 (model:870) WARNING: All labels are zero
2025-02-10 12:06:49,414 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 33, batch_idx_train: 135148,  validation: loss=0.08977, DER=0.1998, ACC=0.9601, MI=0.1163, FA=0.05339, CF=0.03007, over 0.00 frames. 
2025-02-10 12:06:49,415 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 12:06:49,423 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 33, batch_idx_train: 135148,  validation: loss=0.08917, DER=0.2033, ACC=0.9602, MI=0.112, FA=0.05951, CF=0.03175, over 0.00 frames. 
2025-02-10 12:06:49,423 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 12:24:43,306 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 135648, num_updates: 132000, {'loss': 0.14080888032913208, 'DER': 0.3129235802757654, 'ACC': np.float64(0.9395267857142857), 'MI': 0.1462958635195139, 'FA': 0.08383968216873101, 'CF': 0.08278803458752045}, batch size: 64, grad_norm: 0.5494988560676575, grad_scale: , lr: 0.00e+00, 
2025-02-10 12:24:43,307 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 12:24:43,307 (train_accelerate_ddp:702) INFO: [Train] - Epoch 33, batch_idx_train: 135648, num_updates: 132000, {'loss': 0.161881685256958, 'DER': 0.37037037037037035, 'ACC': np.float64(0.9260446428571429), 'MI': 0.24350109878329848, 'FA': 0.053277590180629254, 'CF': 0.07359168140644262}, batch size: 64, grad_norm: 0.5494988560676575, grad_scale: , lr: 0.00e+00, 
2025-02-10 12:24:43,307 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 12:25:53,663 (model:870) WARNING: All labels are zero
2025-02-10 12:25:54,462 (model:870) WARNING: All labels are zero
2025-02-10 12:25:54,478 (model:870) WARNING: All labels are zero
2025-02-10 12:28:03,738 (model:870) WARNING: All labels are zero
2025-02-10 12:28:21,073 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 33, batch_idx_train: 135648,  validation: loss=0.07374, DER=0.1682, ACC=0.9663, MI=0.08085, FA=0.06232, CF=0.02504, over 0.00 frames. 
2025-02-10 12:28:21,073 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 12:28:21,120 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 33, batch_idx_train: 135648,  validation: loss=0.07452, DER=0.167, ACC=0.9658, MI=0.08265, FA=0.0596, CF=0.02472, over 0.00 frames. 
2025-02-10 12:28:21,121 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 12:33:10,672 (train_accelerate_ddp:713) INFO: end of epoch 33, batch_idx: 4113 batch_idx_train: 135761, {'loss': 0.11765298247337341, 'DER': 0.2631852579284848, 'ACC': np.float64(0.9506964285714286), 'MI': 0.14944255097914622, 'FA': 0.05794003812604702, 'CF': 0.055802668823291546}, batch size: 64, grad_norm: 0.37115854024887085, grad_scale: , lr: 0.00e+00, 
2025-02-10 12:33:10,672 (train_accelerate_ddp:713) INFO: end of epoch 33, batch_idx: 4113 batch_idx_train: 135761, {'loss': 0.11003690958023071, 'DER': 0.2648240018899126, 'ACC': np.float64(0.9525535714285714), 'MI': 0.1393810536262698, 'FA': 0.07642334042050555, 'CF': 0.049019607843137254}, batch size: 64, grad_norm: 0.37115854024887085, grad_scale: , lr: 0.00e+00, 
2025-02-10 12:33:10,674 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-33.pt
2025-02-10 12:33:11,966 (train_accelerate_ddp:561) INFO:  end of epoch 33, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/epoch-33.pt 
2025-02-10 12:33:15,481 (train_accelerate_ddp:702) INFO: [Train] - Epoch 34, batch_idx_train: 135762, num_updates: 132000, {'loss': 0.14033685624599457, 'DER': 0.34036601002447836, 'ACC': np.float64(0.9348571428571429), 'MI': 0.1814896841123674, 'FA': 0.07401795081011774, 'CF': 0.08485837510199323}, batch size: 64, grad_norm: 0.438674658536911, grad_scale: , lr: 0.00e+00, 
2025-02-10 12:33:15,482 (train_accelerate_ddp:702) INFO: [Train] - Epoch 34, batch_idx_train: 135762, num_updates: 132000, {'loss': 0.12856657803058624, 'DER': 0.2851780292575214, 'ACC': np.float64(0.9455074540000896), 'MI': 0.17615235992271597, 'FA': 0.05823902842947833, 'CF': 0.05078664090532708}, batch size: 64, grad_norm: 0.438674658536911, grad_scale: , lr: 0.00e+00, 
2025-02-10 12:51:27,584 (train_accelerate_ddp:702) INFO: [Train] - Epoch 34, batch_idx_train: 136262, num_updates: 132500, {'loss': 0.1503077745437622, 'DER': 0.3509690937663698, 'ACC': np.float64(0.9350982142857144), 'MI': 0.19195623071998139, 'FA': 0.08689831790931843, 'CF': 0.07211454513707002}, batch size: 64, grad_norm: 0.48780545592308044, grad_scale: , lr: 0.00e+00, 
2025-02-10 12:51:27,585 (train_accelerate_ddp:702) INFO: [Train] - Epoch 34, batch_idx_train: 136262, num_updates: 132500, {'loss': 0.12435276806354523, 'DER': 0.2851492869875223, 'ACC': np.float64(0.9457589285714285), 'MI': 0.16755793226381463, 'FA': 0.06433823529411764, 'CF': 0.05325311942959002}, batch size: 64, grad_norm: 0.48780545592308044, grad_scale: , lr: 0.00e+00, 
2025-02-10 12:51:27,585 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 12:51:27,585 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 12:52:37,855 (model:870) WARNING: All labels are zero
2025-02-10 12:52:38,629 (model:870) WARNING: All labels are zero
2025-02-10 12:52:38,705 (model:870) WARNING: All labels are zero
2025-02-10 12:54:47,155 (model:870) WARNING: All labels are zero
2025-02-10 12:55:03,653 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 34, batch_idx_train: 136262,  validation: loss=0.08388, DER=0.1867, ACC=0.9621, MI=0.1045, FA=0.0524, CF=0.02978, over 0.00 frames. 
2025-02-10 12:55:03,654 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 12:55:04,259 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 34, batch_idx_train: 136262,  validation: loss=0.08338, DER=0.1901, ACC=0.9622, MI=0.1017, FA=0.05715, CF=0.03123, over 0.00 frames. 
2025-02-10 12:55:04,260 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 13:03:33,948 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-136500.pt
2025-02-10 13:03:35,753 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-10 13:03:35,755 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-10 13:13:01,156 (train_accelerate_ddp:702) INFO: [Train] - Epoch 34, batch_idx_train: 136762, num_updates: 133000, {'loss': 0.11702653020620346, 'DER': 0.2837341547210046, 'ACC': np.float64(0.9508482142857143), 'MI': 0.16176993247245586, 'FA': 0.07961142044781425, 'CF': 0.04235280180073451}, batch size: 64, grad_norm: 0.384272962808609, grad_scale: , lr: 0.00e+00, 
2025-02-10 13:13:01,156 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 13:13:01,157 (train_accelerate_ddp:702) INFO: [Train] - Epoch 34, batch_idx_train: 136762, num_updates: 133000, {'loss': 0.11871489137411118, 'DER': 0.2547164368545549, 'ACC': np.float64(0.9538125), 'MI': 0.13823342756591472, 'FA': 0.07275139906536664, 'CF': 0.04373161022327352}, batch size: 64, grad_norm: 0.384272962808609, grad_scale: , lr: 0.00e+00, 
2025-02-10 13:13:01,157 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 13:14:11,509 (model:870) WARNING: All labels are zero
2025-02-10 13:14:12,285 (model:870) WARNING: All labels are zero
2025-02-10 13:14:12,336 (model:870) WARNING: All labels are zero
2025-02-10 13:16:20,290 (model:870) WARNING: All labels are zero
2025-02-10 13:16:37,029 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 34, batch_idx_train: 136762,  validation: loss=0.08003, DER=0.1825, ACC=0.9633, MI=0.08945, FA=0.06176, CF=0.0313, over 0.00 frames. 
2025-02-10 13:16:37,030 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 13:16:37,503 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 34, batch_idx_train: 136762,  validation: loss=0.08055, DER=0.1797, ACC=0.9631, MI=0.09196, FA=0.05786, CF=0.0299, over 0.00 frames. 
2025-02-10 13:16:37,503 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 13:34:32,227 (train_accelerate_ddp:702) INFO: [Train] - Epoch 34, batch_idx_train: 137262, num_updates: 133500, {'loss': 0.1903417408466339, 'DER': 0.4199049630411827, 'ACC': np.float64(0.9119910714285715), 'MI': 0.26964097148891236, 'FA': 0.04973600844772967, 'CF': 0.10052798310454066}, batch size: 64, grad_norm: 0.4838849902153015, grad_scale: , lr: 0.00e+00, 
2025-02-10 13:34:32,227 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 13:34:32,228 (train_accelerate_ddp:702) INFO: [Train] - Epoch 34, batch_idx_train: 137262, num_updates: 133500, {'loss': 0.1142445057630539, 'DER': 0.2722908494818804, 'ACC': np.float64(0.9503839285714285), 'MI': 0.14320004683566537, 'FA': 0.07604941162695393, 'CF': 0.05304139101926117}, batch size: 64, grad_norm: 0.4838849902153015, grad_scale: , lr: 0.00e+00, 
2025-02-10 13:34:32,228 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 13:35:41,495 (model:870) WARNING: All labels are zero
2025-02-10 13:35:45,941 (model:870) WARNING: All labels are zero
2025-02-10 13:35:46,811 (model:870) WARNING: All labels are zero
2025-02-10 13:37:47,717 (model:870) WARNING: All labels are zero
2025-02-10 13:38:07,516 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 34, batch_idx_train: 137262,  validation: loss=0.0827, DER=0.189, ACC=0.9627, MI=0.09925, FA=0.06058, CF=0.02917, over 0.00 frames. 
2025-02-10 13:38:07,516 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 13:38:25,499 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 34, batch_idx_train: 137262,  validation: loss=0.08316, DER=0.1853, ACC=0.9626, MI=0.102, FA=0.05522, CF=0.02807, over 0.00 frames. 
2025-02-10 13:38:25,500 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 13:57:30,280 (train_accelerate_ddp:702) INFO: [Train] - Epoch 34, batch_idx_train: 137762, num_updates: 134000, {'loss': 0.12846338748931885, 'DER': 0.29716117216117216, 'ACC': np.float64(0.9438592388028821), 'MI': 0.16105769230769232, 'FA': 0.07606456043956043, 'CF': 0.060038919413919416}, batch size: 64, grad_norm: 0.36665821075439453, grad_scale: , lr: 0.00e+00, 
2025-02-10 13:57:30,281 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 13:57:30,281 (train_accelerate_ddp:702) INFO: [Train] - Epoch 34, batch_idx_train: 137762, num_updates: 134000, {'loss': 0.10266629606485367, 'DER': 0.24244570349386213, 'ACC': np.float64(0.9574687125132043), 'MI': 0.14984655335221908, 'FA': 0.054650613786591126, 'CF': 0.03794853635505194}, batch size: 64, grad_norm: 0.36665821075439453, grad_scale: , lr: 0.00e+00, 
2025-02-10 13:57:30,281 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 13:58:40,955 (model:870) WARNING: All labels are zero
2025-02-10 13:58:41,600 (model:870) WARNING: All labels are zero
2025-02-10 13:58:41,790 (model:870) WARNING: All labels are zero
2025-02-10 14:00:51,390 (model:870) WARNING: All labels are zero
2025-02-10 14:01:08,646 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 34, batch_idx_train: 137762,  validation: loss=0.08267, DER=0.1892, ACC=0.9626, MI=0.08869, FA=0.06952, CF=0.03098, over 0.00 frames. 
2025-02-10 14:01:08,647 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
2025-02-10 14:01:09,365 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 34, batch_idx_train: 137762,  validation: loss=0.08278, DER=0.1852, ACC=0.9628, MI=0.09094, FA=0.06524, CF=0.02906, over 0.00 frames. 
2025-02-10 14:01:09,366 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 14:09:31,288 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch40_front_fix_seed_lr2e5_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/checkpoint-138000.pt
2025-02-10 14:09:32,933 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-10 14:18:56,474 (train_accelerate_ddp:702) INFO: [Train] - Epoch 34, batch_idx_train: 138262, num_updates: 134500, {'loss': 0.1285194605588913, 'DER': 0.2758936755270394, 'ACC': np.float64(0.9463571428571429), 'MI': 0.13657195233730524, 'FA': 0.07103574702108158, 'CF': 0.06828597616865262}, batch size: 64, grad_norm: 0.40025052428245544, grad_scale: , lr: 0.00e+00, 
2025-02-10 14:18:56,474 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 14:18:56,474 (train_accelerate_ddp:702) INFO: [Train] - Epoch 34, batch_idx_train: 138262, num_updates: 134500, {'loss': 0.12751975655555725, 'DER': 0.2683732915079543, 'ACC': np.float64(0.9478866647465438), 'MI': 0.15802151019493615, 'FA': 0.054391664799462246, 'CF': 0.0559601165135559}, batch size: 64, grad_norm: 0.40025052428245544, grad_scale: , lr: 0.00e+00, 
2025-02-10 14:18:56,475 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-10 14:20:06,781 (model:870) WARNING: All labels are zero
2025-02-10 14:20:07,593 (model:870) WARNING: All labels are zero
2025-02-10 14:20:07,603 (model:870) WARNING: All labels are zero
2025-02-10 14:22:17,159 (model:870) WARNING: All labels are zero
2025-02-10 14:22:34,458 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 34, batch_idx_train: 138262,  validation: loss=0.09725, DER=0.2096, ACC=0.9581, MI=0.1087, FA=0.06504, CF=0.03584, over 0.00 frames. 
2025-02-10 14:22:34,459 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11783MB
2025-02-10 14:22:34,483 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 34, batch_idx_train: 138262,  validation: loss=0.09686, DER=0.2143, ACC=0.958, MI=0.1063, FA=0.07017, CF=0.03784, over 0.00 frames. 
2025-02-10 14:22:34,484 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 11781MB
