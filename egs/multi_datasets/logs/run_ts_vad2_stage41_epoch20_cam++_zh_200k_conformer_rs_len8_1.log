2025-02-13 08:35:57,608 (train_accelerate_ddp:857) INFO: params: {'best_train_loss': inf, 'best_valid_loss': inf, 'best_train_der': inf, 'best_valid_der': inf, 'best_train_epoch': -1, 'best_valid_epoch': -1, 'batch_idx_train': 0, 'log_interval': 500, 'reset_interval': 200, 'valid_interval': 500, 'batch_size': 64, 'verbose': 1, 'world_size': 2, 'tensorboard': True, 'num_epochs': 20, 'max_updates': 40000, 'warmup_updates': 4000, 'freeze_updates': 4000, 'start_batch': 0, 'start_epoch': 1, 'seed': 1337, 'exp_dir': PosixPath('/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8'), 'save_every_n': 1500, 'keep_last_k': 1, 'keep_last_epoch': 1, 'grad_clip': True, 'feature_grad_mult': 0.1, 'lr': 0.0002, 'average_period': 200, 'train_on_average': False, 'musan_path': '/mntcephfs/lee_dataset/asr/musan', 'rir_path': '/mntcephfs/lee_dataset/asr/RIRS_NOISES', 'spk_path': '/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4', 'speaker_embedding_name_dir': 'cam++_zh-cn_200k_feature_dir', 'data_dir': '/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4', 'dataset_name': 'alimeeting_ami_aishell_4', 'max_num_speaker': 7, 'speech_encoder_path': '/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/zh/modelscope/speech_campplus_sv_zh-cn_16k-common/campplus_cn_common.bin', 'select_encoder_layer_nums': 6, 'wavlm_fuse_feat_post_norm': False, 'speech_encoder_config': '/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/wav-bert2.0/config.json', 'num_transformer_layer': 2, 'd_state': 256, 'expand': 4, 'speech_encoder_type': 'CAM++', 'speaker_embed_dim': 192, 'rs_len': 8, 'segment_shift': 2, 'single_backend_type': 'conformer', 'multi_backend_type': 'transformer', 'do_finetune': False, 'init_modules': None, 'finetune_ckpt': None}
2025-02-13 08:35:57,608 (train_accelerate_ddp:857) INFO: params: {'best_train_loss': inf, 'best_valid_loss': inf, 'best_train_der': inf, 'best_valid_der': inf, 'best_train_epoch': -1, 'best_valid_epoch': -1, 'batch_idx_train': 0, 'log_interval': 500, 'reset_interval': 200, 'valid_interval': 500, 'batch_size': 64, 'verbose': 1, 'world_size': 2, 'tensorboard': True, 'num_epochs': 20, 'max_updates': 40000, 'warmup_updates': 4000, 'freeze_updates': 4000, 'start_batch': 0, 'start_epoch': 1, 'seed': 1337, 'exp_dir': PosixPath('/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8'), 'save_every_n': 1500, 'keep_last_k': 1, 'keep_last_epoch': 1, 'grad_clip': True, 'feature_grad_mult': 0.1, 'lr': 0.0002, 'average_period': 200, 'train_on_average': False, 'musan_path': '/mntcephfs/lee_dataset/asr/musan', 'rir_path': '/mntcephfs/lee_dataset/asr/RIRS_NOISES', 'spk_path': '/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4', 'speaker_embedding_name_dir': 'cam++_zh-cn_200k_feature_dir', 'data_dir': '/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4', 'dataset_name': 'alimeeting_ami_aishell_4', 'max_num_speaker': 7, 'speech_encoder_path': '/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/zh/modelscope/speech_campplus_sv_zh-cn_16k-common/campplus_cn_common.bin', 'select_encoder_layer_nums': 6, 'wavlm_fuse_feat_post_norm': False, 'speech_encoder_config': '/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/wav-bert2.0/config.json', 'num_transformer_layer': 2, 'd_state': 256, 'expand': 4, 'speech_encoder_type': 'CAM++', 'speaker_embed_dim': 192, 'rs_len': 8, 'segment_shift': 2, 'single_backend_type': 'conformer', 'multi_backend_type': 'transformer', 'do_finetune': False, 'init_modules': None, 'finetune_ckpt': None}
2025-02-13 08:35:57,616 (train_accelerate_ddp:873) INFO: data_cfg: TSVADDataConfig(data_dir='/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4', ts_len=6000, rs_len=8, segment_shift=2, spk_path='/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4', speech_encoder_type='CAM++', speaker_embedding_name_dir='cam++_zh-cn_200k_feature_dir', speaker_embed_dim=192, noise_ratio=0.8, zero_ratio=0.3, sample_rate=16000, max_num_speaker=7, dataset_name='alimeeting', embed_input=False, embed_len=1, embed_shift=0.4, label_rate=25, random_channel=False, random_mask_speaker_prob=0.0, random_mask_speaker_step=0, musan_path='/mntcephfs/lee_dataset/asr/musan', rir_path='/mntcephfs/lee_dataset/asr/RIRS_NOISES')
2025-02-13 08:35:57,616 (train_accelerate_ddp:873) INFO: data_cfg: TSVADDataConfig(data_dir='/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4', ts_len=6000, rs_len=8, segment_shift=2, spk_path='/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4', speech_encoder_type='CAM++', speaker_embedding_name_dir='cam++_zh-cn_200k_feature_dir', speaker_embed_dim=192, noise_ratio=0.8, zero_ratio=0.3, sample_rate=16000, max_num_speaker=7, dataset_name='alimeeting', embed_input=False, embed_len=1, embed_shift=0.4, label_rate=25, random_channel=False, random_mask_speaker_prob=0.0, random_mask_speaker_step=0, musan_path='/mntcephfs/lee_dataset/asr/musan', rir_path='/mntcephfs/lee_dataset/asr/RIRS_NOISES')
  0%|          | 0/145 [00:00<?, ?it/s]  0%|          | 0/145 [00:00<?, ?it/s] 11%|█         | 16/145 [00:00<00:00, 156.88it/s] 25%|██▍       | 36/145 [00:00<00:00, 341.32it/s] 28%|██▊       | 41/145 [00:00<00:00, 210.39it/s] 50%|█████     | 73/145 [00:00<00:00, 354.10it/s] 53%|█████▎    | 77/145 [00:00<00:00, 277.92it/s] 82%|████████▏ | 119/145 [00:00<00:00, 401.01it/s] 86%|████████▌ | 125/145 [00:00<00:00, 354.66it/s]100%|██████████| 145/145 [00:00<00:00, 402.32it/s]
2025-02-13 08:35:58,124 (ts_vad_dataset:152) INFO: model expect fbank as input , fbank_input should be True !!!
2025-02-13 08:35:58,125 (ts_vad_dataset:160) INFO: loaded sentence=35332, shortest sent=640.0, longest sent=128000.0, rs_len=8, segment_shift=2,  rir=False, musan=False, noise_ratio=0.8, zero_ratio=0.3 
100%|██████████| 145/145 [00:00<00:00, 323.37it/s]
2025-02-13 08:35:58,129 (ts_vad_dataset:152) INFO: model expect fbank as input , fbank_input should be True !!!
2025-02-13 08:35:58,130 (ts_vad_dataset:160) INFO: loaded sentence=35332, shortest sent=640.0, longest sent=128000.0, rs_len=8, segment_shift=2,  rir=False, musan=False, noise_ratio=0.8, zero_ratio=0.3 
  0%|          | 0/2080 [00:00<?, ?it/s]  0%|          | 0/2080 [00:00<?, ?it/s]  1%|          | 12/2080 [00:00<00:17, 119.83it/s]  1%|          | 23/2080 [00:00<00:09, 221.45it/s]  1%|▏         | 28/2080 [00:00<00:24, 84.93it/s]   2%|▏         | 46/2080 [00:00<00:15, 134.89it/s]  2%|▏         | 51/2080 [00:00<00:15, 131.02it/s]  3%|▎         | 67/2080 [00:00<00:12, 157.45it/s]  4%|▎         | 73/2080 [00:00<00:12, 158.18it/s]  4%|▍         | 89/2080 [00:00<00:11, 177.07it/s]  5%|▍         | 97/2080 [00:00<00:11, 179.23it/s]  5%|▌         | 111/2080 [00:00<00:10, 189.02it/s]  6%|▌         | 122/2080 [00:00<00:09, 200.58it/s]  6%|▋         | 134/2080 [00:00<00:09, 200.37it/s]  7%|▋         | 144/2080 [00:01<00:14, 134.17it/s]  7%|▋         | 155/2080 [00:00<00:14, 136.84it/s]  8%|▊         | 170/2080 [00:01<00:11, 160.66it/s]  9%|▊         | 181/2080 [00:01<00:11, 163.27it/s]  9%|▉         | 194/2080 [00:01<00:10, 179.30it/s] 10%|▉         | 206/2080 [00:01<00:10, 182.97it/s] 10%|█         | 218/2080 [00:01<00:09, 193.29it/s] 11%|█         | 230/2080 [00:01<00:09, 196.23it/s] 12%|█▏        | 242/2080 [00:01<00:09, 203.30it/s] 12%|█▏        | 255/2080 [00:01<00:08, 209.76it/s] 13%|█▎        | 269/2080 [00:01<00:08, 220.53it/s] 14%|█▎        | 282/2080 [00:01<00:08, 224.22it/s] 14%|█▍        | 294/2080 [00:01<00:11, 150.47it/s] 15%|█▍        | 306/2080 [00:01<00:11, 149.57it/s] 15%|█▌        | 321/2080 [00:01<00:10, 172.21it/s] 16%|█▌        | 333/2080 [00:01<00:10, 170.15it/s] 17%|█▋        | 348/2080 [00:02<00:08, 192.85it/s] 18%|█▊        | 364/2080 [00:02<00:08, 199.98it/s] 18%|█▊        | 374/2080 [00:02<00:08, 207.50it/s] 19%|█▊        | 388/2080 [00:02<00:08, 199.15it/s] 19%|█▉        | 398/2080 [00:02<00:07, 211.52it/s] 20%|██        | 416/2080 [00:02<00:07, 217.76it/s] 21%|██        | 427/2080 [00:02<00:07, 228.65it/s] 21%|██▏       | 446/2080 [00:02<00:06, 237.27it/s] 22%|██▏       | 459/2080 [00:02<00:06, 252.64it/s] 23%|██▎       | 478/2080 [00:02<00:06, 256.33it/s] 24%|██▎       | 491/2080 [00:02<00:05, 267.11it/s] 24%|██▍       | 509/2080 [00:02<00:05, 268.49it/s] 25%|██▌       | 520/2080 [00:02<00:05, 271.70it/s] 26%|██▌       | 538/2080 [00:02<00:05, 274.14it/s] 26%|██▋       | 548/2080 [00:02<00:05, 271.86it/s] 27%|██▋       | 567/2080 [00:02<00:05, 271.82it/s] 28%|██▊       | 579/2080 [00:03<00:09, 160.47it/s] 29%|██▊       | 595/2080 [00:03<00:09, 163.40it/s] 30%|██▉       | 614/2080 [00:03<00:07, 195.61it/s] 30%|███       | 628/2080 [00:03<00:07, 195.75it/s] 31%|███       | 646/2080 [00:03<00:06, 219.87it/s] 32%|███▏      | 658/2080 [00:03<00:06, 216.93it/s] 33%|███▎      | 678/2080 [00:03<00:05, 242.46it/s] 33%|███▎      | 691/2080 [00:03<00:05, 243.33it/s] 34%|███▍      | 712/2080 [00:03<00:05, 265.89it/s] 35%|███▍      | 726/2080 [00:03<00:05, 269.14it/s] 36%|███▌      | 750/2080 [00:03<00:04, 294.48it/s] 37%|███▋      | 762/2080 [00:03<00:04, 291.62it/s] 38%|███▊      | 784/2080 [00:03<00:04, 305.28it/s] 39%|███▊      | 801/2080 [00:03<00:04, 310.79it/s] 39%|███▉      | 817/2080 [00:03<00:04, 311.72it/s] 40%|████      | 834/2080 [00:03<00:04, 308.93it/s] 41%|████      | 850/2080 [00:03<00:04, 307.15it/s] 42%|████▏     | 867/2080 [00:03<00:03, 310.05it/s] 43%|████▎     | 886/2080 [00:04<00:03, 320.03it/s] 44%|████▎     | 905/2080 [00:04<00:03, 327.91it/s] 44%|████▍     | 920/2080 [00:04<00:03, 324.71it/s] 45%|████▌     | 939/2080 [00:04<00:03, 330.33it/s] 46%|████▌     | 956/2080 [00:04<00:03, 334.88it/s] 47%|████▋     | 979/2080 [00:04<00:03, 348.12it/s] 48%|████▊     | 995/2080 [00:04<00:03, 350.49it/s] 49%|████▉     | 1016/2080 [00:04<00:03, 342.78it/s] 50%|████▉     | 1032/2080 [00:04<00:02, 354.31it/s] 51%|█████     | 1057/2080 [00:04<00:02, 358.48it/s] 52%|█████▏    | 1072/2080 [00:04<00:02, 366.21it/s] 53%|█████▎    | 1097/2080 [00:04<00:02, 368.25it/s] 54%|█████▎    | 1114/2080 [00:04<00:02, 379.68it/s] 55%|█████▍    | 1135/2080 [00:04<00:02, 364.41it/s] 55%|█████▌    | 1153/2080 [00:04<00:02, 355.83it/s] 56%|█████▋    | 1172/2080 [00:04<00:02, 358.06it/s] 57%|█████▋    | 1191/2080 [00:04<00:02, 361.68it/s] 58%|█████▊    | 1214/2080 [00:04<00:02, 373.36it/s] 59%|█████▉    | 1234/2080 [00:04<00:02, 380.09it/s] 60%|██████    | 1252/2080 [00:04<00:02, 373.67it/s] 61%|██████    | 1273/2080 [00:05<00:02, 372.33it/s] 62%|██████▏   | 1294/2080 [00:05<00:02, 385.97it/s] 63%|██████▎   | 1311/2080 [00:05<00:02, 372.99it/s] 64%|██████▍   | 1333/2080 [00:05<00:01, 381.26it/s] 65%|██████▌   | 1357/2080 [00:05<00:01, 396.79it/s] 66%|██████▌   | 1374/2080 [00:05<00:01, 386.81it/s] 67%|██████▋   | 1398/2080 [00:05<00:01, 398.13it/s] 68%|██████▊   | 1415/2080 [00:05<00:01, 393.52it/s] 69%|██████▉   | 1441/2080 [00:05<00:01, 405.23it/s] 70%|██████▉   | 1455/2080 [00:05<00:01, 370.58it/s] 71%|███████▏  | 1482/2080 [00:05<00:01, 369.89it/s] 72%|███████▏  | 1493/2080 [00:05<00:01, 370.50it/s] 73%|███████▎  | 1522/2080 [00:05<00:01, 376.90it/s] 74%|███████▍  | 1535/2080 [00:05<00:01, 382.86it/s] 75%|███████▌  | 1569/2080 [00:05<00:01, 402.51it/s] 76%|███████▌  | 1579/2080 [00:05<00:01, 398.14it/s] 77%|███████▋  | 1610/2080 [00:05<00:01, 394.05it/s] 78%|███████▊  | 1619/2080 [00:05<00:01, 394.28it/s] 80%|███████▉  | 1656/2080 [00:06<00:01, 412.70it/s] 80%|███████▉  | 1663/2080 [00:06<00:01, 407.12it/s] 82%|████████▏ | 1699/2080 [00:06<00:01, 374.33it/s] 82%|████████▏ | 1704/2080 [00:06<00:00, 378.63it/s] 84%|████████▍ | 1748/2080 [00:06<00:00, 403.65it/s] 84%|████████▍ | 1749/2080 [00:06<00:00, 396.92it/s] 86%|████████▋ | 1796/2080 [00:06<00:00, 422.78it/s] 86%|████████▋ | 1794/2080 [00:06<00:00, 411.62it/s] 88%|████████▊ | 1840/2080 [00:06<00:00, 426.58it/s] 88%|████████▊ | 1836/2080 [00:06<00:00, 411.91it/s] 91%|█████████ | 1884/2080 [00:06<00:00, 427.07it/s] 90%|█████████ | 1878/2080 [00:06<00:00, 412.19it/s] 93%|█████████▎| 1928/2080 [00:06<00:00, 427.97it/s] 92%|█████████▏| 1920/2080 [00:06<00:00, 404.97it/s] 95%|█████████▍| 1975/2080 [00:06<00:00, 438.79it/s] 95%|█████████▍| 1966/2080 [00:06<00:00, 420.50it/s] 97%|█████████▋| 2025/2080 [00:06<00:00, 454.03it/s] 97%|█████████▋| 2011/2080 [00:06<00:00, 428.51it/s]100%|█████████▉| 2073/2080 [00:06<00:00, 460.61it/s]100%|██████████| 2080/2080 [00:07<00:00, 296.89it/s]
 99%|█████████▉| 2054/2080 [00:06<00:00, 425.45it/s]100%|██████████| 2080/2080 [00:07<00:00, 296.84it/s]
2025-02-13 08:36:05,775 (ts_vad_dataset:152) INFO: model expect fbank as input , fbank_input should be True !!!
2025-02-13 08:36:05,775 (ts_vad_dataset:152) INFO: model expect fbank as input , fbank_input should be True !!!
2025-02-13 08:36:05,786 (ts_vad_dataset:160) INFO: loaded sentence=526485, shortest sent=48640.0, longest sent=128000.0, rs_len=8, segment_shift=2,  rir=True, musan=True, noise_ratio=0.8, zero_ratio=0.3 
2025-02-13 08:36:05,786 (train_accelerate_ddp:908) INFO: The scale window is set to 8192.
2025-02-13 08:36:05,789 (ts_vad_dataset:160) INFO: loaded sentence=526485, shortest sent=48640.0, longest sent=128000.0, rs_len=8, segment_shift=2,  rir=True, musan=True, noise_ratio=0.8, zero_ratio=0.3 
2025-02-13 08:36:05,790 (train_accelerate_ddp:908) INFO: The scale window is set to 8192.
/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler(**kwargs)
2025-02-13 08:36:05,981 (other:349) WARNING: Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-02-13 08:36:05,981 (train_accelerate_ddp:946) INFO: model_cfg: TSVADConfig(speech_encoder_path='/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/zh/modelscope/speech_campplus_sv_zh-cn_16k-common/campplus_cn_common.bin', speech_encoder_type='CAM++', freeze_speech_encoder_updates=4000, num_attention_head=4, num_transformer_layer=2, transformer_embed_dim=384, transformer_ffn_embed_dim=1536, speaker_embed_dim=192, dropout=0.1, use_spk_embed=True, feature_grad_mult=0.1, whisper_n_mels=80, select_encoder_layer_nums=6, wavlm_fuse_feat_post_norm=False, speech_encoder_config='/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/wav-bert2.0/config.json', single_backend_type='conformer', multi_backend_type='transformer', d_state=256, expand=4)
/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.scaler = torch.cuda.amp.GradScaler(**kwargs)
self.wavlm_fuse_feat_post_norm: False
2025-02-13 08:36:05,982 (train_accelerate_ddp:946) INFO: model_cfg: TSVADConfig(speech_encoder_path='/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/zh/modelscope/speech_campplus_sv_zh-cn_16k-common/campplus_cn_common.bin', speech_encoder_type='CAM++', freeze_speech_encoder_updates=4000, num_attention_head=4, num_transformer_layer=2, transformer_embed_dim=384, transformer_ffn_embed_dim=1536, speaker_embed_dim=192, dropout=0.1, use_spk_embed=True, feature_grad_mult=0.1, whisper_n_mels=80, select_encoder_layer_nums=6, wavlm_fuse_feat_post_norm=False, speech_encoder_config='/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/wav-bert2.0/config.json', single_backend_type='conformer', multi_backend_type='transformer', d_state=256, expand=4)
self.wavlm_fuse_feat_post_norm: False
/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/model.py:953: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loadedState = torch.load(model_path, map_location=device)
/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/model.py:953: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  loadedState = torch.load(model_path, map_location=device)
/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
2025-02-13 08:36:06,442 (train_accelerate_ddp:949) INFO: model: TSVADModel(
  (rs_dropout): Dropout(p=0.1, inplace=False)
  (speech_encoder): CAMPPlus(
    (head): FCM(
      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (layer1): Sequential(
        (0): BasicResBlock(
          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (shortcut): Sequential(
            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicResBlock(
          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (shortcut): Sequential()
        )
      )
      (layer2): Sequential(
        (0): BasicResBlock(
          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (shortcut): Sequential(
            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicResBlock(
          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (shortcut): Sequential()
        )
      )
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (xvector): Sequential(
      (tdnn): TDNNLayer(
        (linear): Conv1d(320, 128, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)
        (nonlinear): Sequential(
          (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (block1): CAMDenseTDNNBlock(
        (0): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (1): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(160, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (2): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(192, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (3): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(224, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (4): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (5): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(288, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (6): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(320, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (7): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(352, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (8): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(384, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (9): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(416, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (10): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(448, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (11): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(480, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
      )
      (transit1): TransitLayer(
        (nonlinear): Sequential(
          (batchnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (linear): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      )
      (block2): CAMDenseTDNNBlock(
        (0): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (1): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(288, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (2): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(320, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (3): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(352, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (4): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(384, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (5): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(416, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (6): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(448, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (7): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(480, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (8): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (9): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(544, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (10): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(576, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (11): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(608, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (12): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(640, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (13): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(672, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (14): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(704, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (15): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(736, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (16): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(768, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (17): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(800, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (18): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(832, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (19): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(864, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (20): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(896, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (21): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(928, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (22): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(960, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (23): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(992, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
      )
      (transit2): TransitLayer(
        (nonlinear): Sequential(
          (batchnorm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (linear): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)
      )
      (block3): CAMDenseTDNNBlock(
        (0): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (1): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(544, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (2): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(576, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (3): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(608, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (4): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(640, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (5): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(672, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (6): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(704, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (7): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(736, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (8): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(768, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (9): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(800, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (10): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(832, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (11): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(864, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (12): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(896, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (13): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(928, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (14): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(960, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (15): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(992, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
      )
      (transit3): TransitLayer(
        (nonlinear): Sequential(
          (batchnorm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (linear): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)
      )
      (out_nonlinear): Sequential(
        (batchnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (stats): StatsPool()
      (dense): DenseLayer(
        (linear): Conv1d(1024, 192, kernel_size=(1,), stride=(1,), bias=False)
        (nonlinear): Sequential(
          (batchnorm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
        )
      )
    )
  )
  (speech_down_or_up): Sequential(
    (0): Conv1d(512, 192, kernel_size=(5,), stride=(2,), padding=(2,))
    (1): BatchNorm1D(
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ReLU()
  )
  (pos_encoder): PositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (single_backend): Conformer(
    (conformer_layers): ModuleList(
      (0-1): 2 x ConformerLayer(
        (ffn1): _FeedForwardModule(
          (sequential): Sequential(
            (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=384, out_features=1536, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.0, inplace=False)
            (4): Linear(in_features=1536, out_features=384, bias=True)
            (5): Dropout(p=0.0, inplace=False)
          )
        )
        (self_attn_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (self_attn_dropout): Dropout(p=0.0, inplace=False)
        (conv_module): _ConvolutionModule(
          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (sequential): Sequential(
            (0): Conv1d(384, 768, kernel_size=(1,), stride=(1,))
            (1): GLU(dim=1)
            (2): Conv1d(384, 384, kernel_size=(31,), stride=(1,), padding=(15,), groups=384)
            (3): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): SiLU()
            (5): Conv1d(384, 384, kernel_size=(1,), stride=(1,))
            (6): Dropout(p=0.0, inplace=False)
          )
        )
        (ffn2): _FeedForwardModule(
          (sequential): Sequential(
            (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=384, out_features=1536, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.0, inplace=False)
            (4): Linear(in_features=1536, out_features=384, bias=True)
            (5): Dropout(p=0.0, inplace=False)
          )
        )
        (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (backend_down): Sequential(
    (0): Conv1d(2688, 384, kernel_size=(5,), stride=(1,), padding=(2,))
    (1): BatchNorm1D(
      (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ReLU()
  )
  (multi_backend): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (linear1): Linear(in_features=384, out_features=1536, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=1536, out_features=384, bias=True)
        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc): Linear(in_features=384, out_features=7, bias=True)
)
2025-02-13 08:36:06,443 (train_accelerate_ddp:949) INFO: model: TSVADModel(
  (rs_dropout): Dropout(p=0.1, inplace=False)
  (speech_encoder): CAMPPlus(
    (head): FCM(
      (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (layer1): Sequential(
        (0): BasicResBlock(
          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (shortcut): Sequential(
            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicResBlock(
          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (shortcut): Sequential()
        )
      )
      (layer2): Sequential(
        (0): BasicResBlock(
          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (shortcut): Sequential(
            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(2, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BasicResBlock(
          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (shortcut): Sequential()
        )
      )
      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (xvector): Sequential(
      (tdnn): TDNNLayer(
        (linear): Conv1d(320, 128, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)
        (nonlinear): Sequential(
          (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (block1): CAMDenseTDNNBlock(
        (0): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (1): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(160, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (2): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(192, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (3): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(224, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (4): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (5): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(288, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (6): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(320, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (7): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(352, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (8): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(384, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (9): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(416, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (10): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(448, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (11): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(480, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
      )
      (transit1): TransitLayer(
        (nonlinear): Sequential(
          (batchnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (linear): Conv1d(512, 256, kernel_size=(1,), stride=(1,), bias=False)
      )
      (block2): CAMDenseTDNNBlock(
        (0): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (1): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(288, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (2): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(320, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (3): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(352, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (4): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(384, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (5): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(416, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (6): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(448, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (7): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(480, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (8): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (9): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(544, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (10): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(576, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (11): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(608, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (12): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(640, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (13): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(672, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (14): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(704, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (15): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(736, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (16): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(768, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (17): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(800, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (18): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(832, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (19): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(864, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (20): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(896, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (21): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(928, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (22): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(960, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (23): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(992, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
      )
      (transit2): TransitLayer(
        (nonlinear): Sequential(
          (batchnorm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (linear): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)
      )
      (block3): CAMDenseTDNNBlock(
        (0): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (1): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(544, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (2): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(576, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (3): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(608, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (4): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(640, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (5): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(672, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (6): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(704, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (7): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(736, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (8): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(768, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (9): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(800, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (10): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(832, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (11): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(864, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (12): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(896, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (13): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(928, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (14): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(960, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
        (15): CAMDenseTDNNLayer(
          (nonlinear1): Sequential(
            (batchnorm): BatchNorm1d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (linear1): Conv1d(992, 128, kernel_size=(1,), stride=(1,), bias=False)
          (nonlinear2): Sequential(
            (batchnorm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (cam_layer): CAMLayer(
            (linear_local): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(2,), dilation=(2,), bias=False)
            (linear1): Conv1d(128, 64, kernel_size=(1,), stride=(1,))
            (relu): ReLU(inplace=True)
            (linear2): Conv1d(64, 32, kernel_size=(1,), stride=(1,))
            (sigmoid): Sigmoid()
          )
        )
      )
      (transit3): TransitLayer(
        (nonlinear): Sequential(
          (batchnorm): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (linear): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)
      )
      (out_nonlinear): Sequential(
        (batchnorm): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (stats): StatsPool()
      (dense): DenseLayer(
        (linear): Conv1d(1024, 192, kernel_size=(1,), stride=(1,), bias=False)
        (nonlinear): Sequential(
          (batchnorm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
        )
      )
    )
  )
  (speech_down_or_up): Sequential(
    (0): Conv1d(512, 192, kernel_size=(5,), stride=(2,), padding=(2,))
    (1): BatchNorm1D(
      (bn): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ReLU()
  )
  (pos_encoder): PositionalEncoding(
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (single_backend): Conformer(
    (conformer_layers): ModuleList(
      (0-1): 2 x ConformerLayer(
        (ffn1): _FeedForwardModule(
          (sequential): Sequential(
            (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=384, out_features=1536, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.0, inplace=False)
            (4): Linear(in_features=1536, out_features=384, bias=True)
            (5): Dropout(p=0.0, inplace=False)
          )
        )
        (self_attn_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (self_attn_dropout): Dropout(p=0.0, inplace=False)
        (conv_module): _ConvolutionModule(
          (layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (sequential): Sequential(
            (0): Conv1d(384, 768, kernel_size=(1,), stride=(1,))
            (1): GLU(dim=1)
            (2): Conv1d(384, 384, kernel_size=(31,), stride=(1,), padding=(15,), groups=384)
            (3): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): SiLU()
            (5): Conv1d(384, 384, kernel_size=(1,), stride=(1,))
            (6): Dropout(p=0.0, inplace=False)
          )
        )
        (ffn2): _FeedForwardModule(
          (sequential): Sequential(
            (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
            (1): Linear(in_features=384, out_features=1536, bias=True)
            (2): SiLU()
            (3): Dropout(p=0.0, inplace=False)
            (4): Linear(in_features=1536, out_features=384, bias=True)
            (5): Dropout(p=0.0, inplace=False)
          )
        )
        (final_layer_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (backend_down): Sequential(
    (0): Conv1d(2688, 384, kernel_size=(5,), stride=(1,), padding=(2,))
    (1): BatchNorm1D(
      (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): ReLU()
  )
  (multi_backend): TransformerEncoder(
    (layers): ModuleList(
      (0-1): 2 x TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
        )
        (linear1): Linear(in_features=384, out_features=1536, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=1536, out_features=384, bias=True)
        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (fc): Linear(in_features=384, out_features=7, bias=True)
)
2025-02-13 08:36:06,444 (train_accelerate_ddp:951) INFO: Number of model parameters: 22884199
2025-02-13 08:36:06,444 (train_accelerate_ddp:951) INFO: Number of model parameters: 22884199
pgpu27:1899001:1899001 [0] NCCL INFO Bootstrap : Using ib1:20.20.20.27<0>
pgpu27:1899001:1899001 [0] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
pgpu27:1899001:1899001 [0] NCCL INFO cudaDriverVersion 12000
NCCL version 2.20.5+cuda11.0
pgpu27:1899002:1899002 [1] NCCL INFO cudaDriverVersion 12000
pgpu27:1899002:1899002 [1] NCCL INFO Bootstrap : Using ib1:20.20.20.27<0>
pgpu27:1899002:1899002 [1] NCCL INFO NET/Plugin : dlerror=libnccl-net.so: cannot open shared object file: No such file or directory No plugin found (libnccl-net.so), using internal implementation
pgpu27:1899001:1899339 [0] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/IB [2]mlx5_3:1/IB [RO]; OOB ib1:20.20.20.27<0>
pgpu27:1899001:1899339 [0] NCCL INFO Using non-device net plugin version 0
pgpu27:1899001:1899339 [0] NCCL INFO Using network IB
pgpu27:1899002:1899340 [1] NCCL INFO NET/IB : Using [0]mlx5_0:1/RoCE [1]mlx5_1:1/IB [2]mlx5_3:1/IB [RO]; OOB ib1:20.20.20.27<0>
pgpu27:1899002:1899340 [1] NCCL INFO Using non-device net plugin version 0
pgpu27:1899002:1899340 [1] NCCL INFO Using network IB
pgpu27:1899001:1899339 [0] NCCL INFO comm 0x555560ff7980 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 2b000 commId 0x46c0759e0a0ff140 - Init START
pgpu27:1899002:1899340 [1] NCCL INFO comm 0x55557b0f3e80 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId e2000 commId 0x46c0759e0a0ff140 - Init START
pgpu27:1899001:1899339 [0] NCCL INFO Setting affinity for GPU 0 to 0fc0,00000000,00000000,00000000,00001f80
pgpu27:1899002:1899340 [1] NCCL INFO comm 0x55557b0f3e80 rank 1 nRanks 2 nNodes 1 localRanks 2 localRank 1 MNNVL 0
pgpu27:1899001:1899339 [0] NCCL INFO comm 0x555560ff7980 rank 0 nRanks 2 nNodes 1 localRanks 2 localRank 0 MNNVL 0
pgpu27:1899001:1899339 [0] NCCL INFO Channel 00/16 :    0   1
pgpu27:1899001:1899339 [0] NCCL INFO Channel 01/16 :    0   1
pgpu27:1899001:1899339 [0] NCCL INFO Channel 02/16 :    0   1
pgpu27:1899001:1899339 [0] NCCL INFO Channel 03/16 :    0   1
pgpu27:1899001:1899339 [0] NCCL INFO Channel 04/16 :    0   1
pgpu27:1899002:1899340 [1] NCCL INFO Trees [0] -1/-1/-1->1->0 [1] -1/-1/-1->1->0 [2] -1/-1/-1->1->0 [3] -1/-1/-1->1->0 [4] 0/-1/-1->1->-1 [5] 0/-1/-1->1->-1 [6] 0/-1/-1->1->-1 [7] 0/-1/-1->1->-1 [8] -1/-1/-1->1->0 [9] -1/-1/-1->1->0 [10] -1/-1/-1->1->0 [11] -1/-1/-1->1->0 [12] 0/-1/-1->1->-1 [13] 0/-1/-1->1->-1 [14] 0/-1/-1->1->-1 [15] 0/-1/-1->1->-1
pgpu27:1899001:1899339 [0] NCCL INFO Channel 05/16 :    0   1
pgpu27:1899002:1899340 [1] NCCL INFO P2P Chunksize set to 524288
pgpu27:1899001:1899339 [0] NCCL INFO Channel 06/16 :    0   1
pgpu27:1899001:1899339 [0] NCCL INFO Channel 07/16 :    0   1
pgpu27:1899001:1899339 [0] NCCL INFO Channel 08/16 :    0   1
pgpu27:1899001:1899339 [0] NCCL INFO Channel 09/16 :    0   1
pgpu27:1899001:1899339 [0] NCCL INFO Channel 10/16 :    0   1
pgpu27:1899001:1899339 [0] NCCL INFO Channel 11/16 :    0   1
pgpu27:1899001:1899339 [0] NCCL INFO Channel 12/16 :    0   1
pgpu27:1899001:1899339 [0] NCCL INFO Channel 13/16 :    0   1
pgpu27:1899001:1899339 [0] NCCL INFO Channel 14/16 :    0   1
pgpu27:1899001:1899339 [0] NCCL INFO Channel 15/16 :    0   1
pgpu27:1899001:1899339 [0] NCCL INFO Trees [0] 1/-1/-1->0->-1 [1] 1/-1/-1->0->-1 [2] 1/-1/-1->0->-1 [3] 1/-1/-1->0->-1 [4] -1/-1/-1->0->1 [5] -1/-1/-1->0->1 [6] -1/-1/-1->0->1 [7] -1/-1/-1->0->1 [8] 1/-1/-1->0->-1 [9] 1/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 1/-1/-1->0->-1 [12] -1/-1/-1->0->1 [13] -1/-1/-1->0->1 [14] -1/-1/-1->0->1 [15] -1/-1/-1->0->1
pgpu27:1899001:1899339 [0] NCCL INFO P2P Chunksize set to 524288
pgpu27:1899002:1899340 [1] NCCL INFO Channel 00/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu27:1899001:1899339 [0] NCCL INFO Channel 00/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu27:1899002:1899340 [1] NCCL INFO Channel 01/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu27:1899001:1899339 [0] NCCL INFO Channel 01/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu27:1899002:1899340 [1] NCCL INFO Channel 02/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu27:1899001:1899339 [0] NCCL INFO Channel 02/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu27:1899002:1899340 [1] NCCL INFO Channel 03/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu27:1899001:1899339 [0] NCCL INFO Channel 03/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu27:1899002:1899340 [1] NCCL INFO Channel 04/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu27:1899001:1899339 [0] NCCL INFO Channel 04/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu27:1899002:1899340 [1] NCCL INFO Channel 05/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu27:1899001:1899339 [0] NCCL INFO Channel 05/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu27:1899002:1899340 [1] NCCL INFO Channel 06/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu27:1899001:1899339 [0] NCCL INFO Channel 06/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu27:1899002:1899340 [1] NCCL INFO Channel 07/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu27:1899001:1899339 [0] NCCL INFO Channel 07/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu27:1899002:1899340 [1] NCCL INFO Channel 08/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu27:1899001:1899339 [0] NCCL INFO Channel 08/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu27:1899002:1899340 [1] NCCL INFO Channel 09/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu27:1899001:1899339 [0] NCCL INFO Channel 09/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu27:1899002:1899340 [1] NCCL INFO Channel 10/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu27:1899001:1899339 [0] NCCL INFO Channel 10/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu27:1899002:1899340 [1] NCCL INFO Channel 11/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu27:1899001:1899339 [0] NCCL INFO Channel 11/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu27:1899002:1899340 [1] NCCL INFO Channel 12/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu27:1899001:1899339 [0] NCCL INFO Channel 12/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu27:1899002:1899340 [1] NCCL INFO Channel 13/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu27:1899001:1899339 [0] NCCL INFO Channel 13/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu27:1899002:1899340 [1] NCCL INFO Channel 14/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu27:1899001:1899339 [0] NCCL INFO Channel 14/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu27:1899002:1899340 [1] NCCL INFO Channel 15/0 : 1[1] -> 0[0] via P2P/IPC/read
pgpu27:1899001:1899339 [0] NCCL INFO Channel 15/0 : 0[0] -> 1[1] via P2P/IPC/read
pgpu27:1899002:1899340 [1] NCCL INFO Connected all rings
pgpu27:1899002:1899340 [1] NCCL INFO Connected all trees
pgpu27:1899002:1899340 [1] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
pgpu27:1899001:1899339 [0] NCCL INFO Connected all rings
pgpu27:1899002:1899340 [1] NCCL INFO 16 coll channels, 0 collnet channels, 0 nvls channels, 16 p2p channels, 16 p2p channels per peer
pgpu27:1899001:1899339 [0] NCCL INFO Connected all trees
pgpu27:1899001:1899339 [0] NCCL INFO threadThresholds 8/8/64 | 16/8/64 | 512 | 512
pgpu27:1899001:1899339 [0] NCCL INFO 16 coll channels, 0 collnet channels, 0 nvls channels, 16 p2p channels, 16 p2p channels per peer
pgpu27:1899001:1899339 [0] NCCL INFO comm 0x555560ff7980 rank 0 nranks 2 cudaDev 0 nvmlDev 0 busId 2b000 commId 0x46c0759e0a0ff140 - Init COMPLETE
pgpu27:1899002:1899340 [1] NCCL INFO comm 0x55557b0f3e80 rank 1 nranks 2 cudaDev 1 nvmlDev 1 busId e2000 commId 0x46c0759e0a0ff140 - Init COMPLETE
2025-02-13 08:36:13,911 (train_accelerate_ddp:1032) INFO: start training from epoch 1
2025-02-13 08:36:13,911 (train_accelerate_ddp:1032) INFO: start training from epoch 1
2025-02-13 08:36:13,911 (train_accelerate_ddp:1033) INFO: Train set grouped total_num_itrs = 4114
2025-02-13 08:36:13,911 (train_accelerate_ddp:1033) INFO: Train set grouped total_num_itrs = 4114
/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/ts_vad_dataset.py:398: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  feature = torch.load(path, map_location="cpu")
/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/ts_vad_dataset.py:398: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  feature = torch.load(path, map_location="cpu")
/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/ts_vad_dataset.py:392: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  feature = torch.load(path, map_location="cpu")
/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/ts_vad_dataset.py:392: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  feature = torch.load(path, map_location="cpu")
2025-02-13 08:36:29,229 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 0, num_updates: 0, {'loss': 0.7255326509475708, 'DER': 2.6724272257242014, 'ACC': np.float64(0.4945870535714285), 'MI': 0.0191231673631277, 'FA': 2.1183511580140237, 'CF': 0.5349529003470501}, batch size: 64, grad_norm: 2.3564975261688232, grad_scale: , lr: 1.00e-07, 
2025-02-13 08:36:29,229 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 0, num_updates: 0, {'loss': 0.7191768288612366, 'DER': 2.5515534781413254, 'ACC': np.float64(0.5061049107142856), 'MI': 0.023164696178168822, 'FA': 2.0380808358537257, 'CF': 0.49030794610943085}, batch size: 64, grad_norm: 2.3564975261688232, grad_scale: , lr: 1.00e-07, 
2025-02-13 08:47:54,616 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 500, num_updates: 500, {'loss': 0.31163346767425537, 'DER': 0.7878239903556359, 'ACC': np.float64(0.8674107142857143), 'MI': 0.6467751657625075, 'FA': 0.03375527426160337, 'CF': 0.10729355033152502}, batch size: 64, grad_norm: 0.40969371795654297, grad_scale: , lr: 5.01e-05, 
2025-02-13 08:47:54,616 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 08:47:54,616 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 500, num_updates: 500, {'loss': 0.3251288831233978, 'DER': 0.7764499358584835, 'ACC': np.float64(0.8551897321428571), 'MI': 0.6626156235230571, 'FA': 0.014246168388360002, 'CF': 0.09958814394706637}, batch size: 64, grad_norm: 0.40969371795654297, grad_scale: , lr: 5.01e-05, 
2025-02-13 08:47:54,617 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 08:48:43,082 (model:925) WARNING: All labels are zero
2025-02-13 08:48:43,288 (model:925) WARNING: All labels are zero
2025-02-13 08:48:43,666 (model:925) WARNING: All labels are zero
2025-02-13 08:50:14,637 (model:925) WARNING: All labels are zero
2025-02-13 08:50:26,361 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 500,  validation: loss=0.3257, DER=0.9641, ACC=0.8497, MI=0.932, FA=0.0005853, CF=0.03153, over 0.00 frames. 
2025-02-13 08:50:26,362 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 6824MB
2025-02-13 08:50:26,554 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 500,  validation: loss=0.3235, DER=0.9611, ACC=0.8485, MI=0.9314, FA=0.0004653, CF=0.02927, over 0.00 frames. 
2025-02-13 08:50:26,554 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 6824MB
2025-02-13 09:00:44,003 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 1000, num_updates: 1000, {'loss': 0.23091427981853485, 'DER': 0.5890036900369003, 'ACC': np.float64(0.8953794642857144), 'MI': 0.3847232472324723, 'FA': 0.1014760147601476, 'CF': 0.10280442804428044}, batch size: 64, grad_norm: 0.7042917609214783, grad_scale: , lr: 1.00e-04, 
2025-02-13 09:00:44,004 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 09:00:44,004 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 1000, num_updates: 1000, {'loss': 0.252215176820755, 'DER': 0.641090208857947, 'ACC': np.float64(0.8814955357142857), 'MI': 0.4103095837653681, 'FA': 0.0854688194341579, 'CF': 0.14531180565842097}, batch size: 64, grad_norm: 0.7042917609214783, grad_scale: , lr: 1.00e-04, 
2025-02-13 09:00:44,005 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 09:01:29,936 (model:925) WARNING: All labels are zero
2025-02-13 09:01:30,547 (model:925) WARNING: All labels are zero
2025-02-13 09:01:31,106 (model:925) WARNING: All labels are zero
2025-02-13 09:02:53,906 (model:925) WARNING: All labels are zero
2025-02-13 09:03:04,954 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 1000,  validation: loss=0.3535, DER=0.9835, ACC=0.8512, MI=0.9833, FA=1.783e-05, CF=0.0002642, over 0.00 frames. 
2025-02-13 09:03:04,955 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 6824MB
2025-02-13 09:03:08,441 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 1000,  validation: loss=0.3559, DER=0.9849, ACC=0.8492, MI=0.9846, FA=2.22e-06, CF=0.000284, over 0.00 frames. 
2025-02-13 09:03:08,441 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 6824MB
2025-02-13 09:13:40,543 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/checkpoint-1500.pt
2025-02-13 09:13:40,871 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-13 09:13:41,931 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 1500, num_updates: 1500, {'loss': 0.20325595140457153, 'DER': 0.4866813386962131, 'ACC': np.float64(0.9103236607142857), 'MI': 0.28101995901950366, 'FA': 0.0825681111026789, 'CF': 0.12309326857403051}, batch size: 64, grad_norm: 0.8215035200119019, grad_scale: , lr: 1.50e-04, 
2025-02-13 09:13:41,932 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 09:13:41,932 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 1500, num_updates: 1500, {'loss': 0.19970785081386566, 'DER': 0.42538373115153155, 'ACC': np.float64(0.909330357142857), 'MI': 0.25045642031239435, 'FA': 0.05098383934005004, 'CF': 0.12394347149908716}, batch size: 64, grad_norm: 0.8215035200119019, grad_scale: , lr: 1.50e-04, 
2025-02-13 09:13:41,932 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 09:14:29,786 (model:925) WARNING: All labels are zero
2025-02-13 09:14:30,356 (model:925) WARNING: All labels are zero
2025-02-13 09:14:30,594 (model:925) WARNING: All labels are zero
2025-02-13 09:15:59,841 (model:925) WARNING: All labels are zero
2025-02-13 09:16:10,635 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 1500,  validation: loss=0.4107, DER=0.8754, ACC=0.8506, MI=0.7203, FA=0.04982, CF=0.1053, over 0.00 frames. 
2025-02-13 09:16:10,635 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 6824MB
2025-02-13 09:16:11,493 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 1500,  validation: loss=0.3969, DER=0.8676, ACC=0.8536, MI=0.7135, FA=0.04837, CF=0.1057, over 0.00 frames. 
2025-02-13 09:16:11,493 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 6824MB
2025-02-13 09:26:45,858 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 2000, num_updates: 2000, {'loss': 0.1975773125886917, 'DER': 0.4177500181567289, 'ACC': np.float64(0.9195982142857143), 'MI': 0.2620379112499092, 'FA': 0.050257825550148884, 'CF': 0.10545428135667079}, batch size: 64, grad_norm: 0.42078715562820435, grad_scale: , lr: 2.00e-04, 
2025-02-13 09:26:45,858 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 2000, num_updates: 2000, {'loss': 0.20681846141815186, 'DER': 0.5099475632325725, 'ACC': np.float64(0.9141183035714286), 'MI': 0.33590376310919184, 'FA': 0.09060764959901295, 'CF': 0.08343615052436767}, batch size: 64, grad_norm: 0.42078715562820435, grad_scale: , lr: 2.00e-04, 
2025-02-13 09:26:45,859 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 09:26:45,859 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 09:27:33,860 (model:925) WARNING: All labels are zero
2025-02-13 09:27:34,429 (model:925) WARNING: All labels are zero
2025-02-13 09:27:34,927 (model:925) WARNING: All labels are zero
2025-02-13 09:29:04,766 (model:925) WARNING: All labels are zero
2025-02-13 09:29:14,695 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 2000,  validation: loss=0.3094, DER=0.7195, ACC=0.8843, MI=0.6913, FA=0.002617, CF=0.02557, over 0.00 frames. 
2025-02-13 09:29:14,696 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 6824MB
2025-02-13 09:29:16,557 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 2000,  validation: loss=0.3107, DER=0.7317, ACC=0.8841, MI=0.703, FA=0.003273, CF=0.02539, over 0.00 frames. 
2025-02-13 09:29:16,558 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 6824MB
2025-02-13 09:40:27,005 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 2500, num_updates: 2500, {'loss': 0.19147346913814545, 'DER': 0.4260215053763441, 'ACC': np.float64(0.9175284355666341), 'MI': 0.26057347670250897, 'FA': 0.06494623655913978, 'CF': 0.10050179211469534}, batch size: 64, grad_norm: 0.3378654420375824, grad_scale: , lr: 1.94e-04, 
2025-02-13 09:40:27,006 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 09:40:27,007 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 2500, num_updates: 2500, {'loss': 0.18193182349205017, 'DER': 0.39505007983742196, 'ACC': np.float64(0.9257589285714286), 'MI': 0.23806067644070256, 'FA': 0.06924081869647264, 'CF': 0.08774858470024677}, batch size: 64, grad_norm: 0.3378654420375824, grad_scale: , lr: 1.94e-04, 
2025-02-13 09:40:27,007 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 09:41:13,758 (model:925) WARNING: All labels are zero
2025-02-13 09:41:13,873 (model:925) WARNING: All labels are zero
2025-02-13 09:41:14,432 (model:925) WARNING: All labels are zero
2025-02-13 09:42:39,368 (model:925) WARNING: All labels are zero
2025-02-13 09:42:50,636 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 2500,  validation: loss=0.1652, DER=0.385, ACC=0.925, MI=0.1791, FA=0.107, CF=0.09889, over 0.00 frames. 
2025-02-13 09:42:50,637 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 6824MB
2025-02-13 09:42:52,069 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 2500,  validation: loss=0.1692, DER=0.3927, ACC=0.9222, MI=0.1791, FA=0.1076, CF=0.1059, over 0.00 frames. 
2025-02-13 09:42:52,069 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 6824MB
2025-02-13 09:53:24,484 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/checkpoint-3000.pt
2025-02-13 09:53:24,819 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-13 09:53:26,278 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 3000, num_updates: 3000, {'loss': 0.16925936937332153, 'DER': 0.3796355385378997, 'ACC': np.float64(0.9296725769118407), 'MI': 0.24767779904984755, 'FA': 0.06778699567467915, 'CF': 0.06417074381337304}, batch size: 64, grad_norm: 0.34693655371665955, grad_scale: , lr: 1.89e-04, 
2025-02-13 09:53:26,278 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 09:53:26,278 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 3000, num_updates: 3000, {'loss': 0.171647846698761, 'DER': 0.4115076474872542, 'ACC': np.float64(0.9214955357142857), 'MI': 0.24209759650400584, 'FA': 0.06860888565185724, 'CF': 0.10080116533139112}, batch size: 64, grad_norm: 0.34693655371665955, grad_scale: , lr: 1.89e-04, 
2025-02-13 09:53:26,278 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 09:54:13,532 (model:925) WARNING: All labels are zero
2025-02-13 09:54:14,095 (model:925) WARNING: All labels are zero
2025-02-13 09:54:14,809 (model:925) WARNING: All labels are zero
2025-02-13 09:55:43,597 (model:925) WARNING: All labels are zero
2025-02-13 09:55:52,706 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 3000,  validation: loss=0.1402, DER=0.3141, ACC=0.9391, MI=0.1821, FA=0.07067, CF=0.06135, over 0.00 frames. 
2025-02-13 09:55:52,706 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 6824MB
2025-02-13 09:55:55,317 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 3000,  validation: loss=0.1383, DER=0.3111, ACC=0.9406, MI=0.1804, FA=0.07114, CF=0.05961, over 0.00 frames. 
2025-02-13 09:55:55,318 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 6824MB
2025-02-13 10:06:38,748 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 3500, num_updates: 3500, {'loss': 0.19611570239067078, 'DER': 0.4358852325265162, 'ACC': np.float64(0.9141517857142857), 'MI': 0.2909301060647267, 'FA': 0.05785966820777808, 'CF': 0.08709545825401142}, batch size: 64, grad_norm: 0.3611780107021332, grad_scale: , lr: 1.83e-04, 
2025-02-13 10:06:38,748 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 3500, num_updates: 3500, {'loss': 0.1828344762325287, 'DER': 0.4412798086267474, 'ACC': np.float64(0.9193268077186136), 'MI': 0.2640352844434477, 'FA': 0.08066083576287658, 'CF': 0.09658368842042311}, batch size: 64, grad_norm: 0.3611780107021332, grad_scale: , lr: 1.83e-04, 
2025-02-13 10:06:38,748 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 10:06:38,748 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 10:07:26,608 (model:925) WARNING: All labels are zero
2025-02-13 10:07:27,173 (model:925) WARNING: All labels are zero
2025-02-13 10:07:27,497 (model:925) WARNING: All labels are zero
2025-02-13 10:08:56,491 (model:925) WARNING: All labels are zero
2025-02-13 10:09:06,866 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 3500,  validation: loss=0.1312, DER=0.308, ACC=0.9415, MI=0.2189, FA=0.03455, CF=0.05455, over 0.00 frames. 
2025-02-13 10:09:06,866 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 6824MB
2025-02-13 10:09:08,250 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 3500,  validation: loss=0.1284, DER=0.3039, ACC=0.9431, MI=0.2164, FA=0.03451, CF=0.05305, over 0.00 frames. 
2025-02-13 10:09:08,251 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 6824MB
/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.
  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]
2025-02-13 10:19:46,190 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 4000, num_updates: 4000, {'loss': 0.1839129626750946, 'DER': 0.4180889861415025, 'ACC': np.float64(0.9251004464285714), 'MI': 0.28081692195477753, 'FA': 0.06586433260393873, 'CF': 0.0714077315827863}, batch size: 64, grad_norm: 0.3833117187023163, grad_scale: , lr: 1.78e-04, 
2025-02-13 10:19:46,191 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 10:19:46,192 (train_accelerate_ddp:702) INFO: [Train] - Epoch 1, batch_idx_train: 4000, num_updates: 4000, {'loss': 0.1602434664964676, 'DER': 0.365491270112975, 'ACC': np.float64(0.92890625), 'MI': 0.2388223211229031, 'FA': 0.05600821636425882, 'CF': 0.07066073262581307}, batch size: 64, grad_norm: 0.3833117187023163, grad_scale: , lr: 1.78e-04, 
2025-02-13 10:19:46,192 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 10:20:34,946 (model:925) WARNING: All labels are zero
2025-02-13 10:20:35,513 (model:925) WARNING: All labels are zero
2025-02-13 10:20:35,566 (model:925) WARNING: All labels are zero
2025-02-13 10:22:05,618 (model:925) WARNING: All labels are zero
2025-02-13 10:22:16,743 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 4000,  validation: loss=0.1308, DER=0.3036, ACC=0.9405, MI=0.1947, FA=0.0465, CF=0.06242, over 0.00 frames. 
2025-02-13 10:22:16,743 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 10:22:17,442 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 1, batch_idx_train: 4000,  validation: loss=0.1298, DER=0.3021, ACC=0.9414, MI=0.1936, FA=0.04497, CF=0.06358, over 0.00 frames. 
2025-02-13 10:22:17,443 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 10:24:54,999 (train_accelerate_ddp:713) INFO: end of epoch 1, batch_idx: 4113 batch_idx_train: 4113, {'loss': 0.15038882195949554, 'DER': 0.35604871852349995, 'ACC': np.float64(0.9321316964285714), 'MI': 0.17664200851826944, 'FA': 0.08107300306358814, 'CF': 0.09833370694164238}, batch size: 64, grad_norm: 0.34602421522140503, grad_scale: , lr: 1.77e-04, 
2025-02-13 10:24:55,000 (train_accelerate_ddp:713) INFO: end of epoch 1, batch_idx: 4113 batch_idx_train: 4113, {'loss': 0.17765288054943085, 'DER': 0.3613335173937051, 'ACC': np.float64(0.9245535714285714), 'MI': 0.2032716731087797, 'FA': 0.0528023191606847, 'CF': 0.10525952512424075}, batch size: 64, grad_norm: 0.34602421522140503, grad_scale: , lr: 1.77e-04, 
2025-02-13 10:24:55,001 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/epoch-1.pt
2025-02-13 10:24:55,319 (train_accelerate_ddp:561) INFO:  end of epoch 1, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/epoch-1.pt 
2025-02-13 10:24:57,997 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 4114, num_updates: 4000, {'loss': 0.12910987436771393, 'DER': 0.30485040797824114, 'ACC': np.float64(0.9448325892857143), 'MI': 0.14944091870655787, 'FA': 0.08680870353581142, 'CF': 0.06860078573587186}, batch size: 64, grad_norm: 0.2700190246105194, grad_scale: , lr: 1.77e-04, 
2025-02-13 10:24:57,999 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 4114, num_updates: 4000, {'loss': 0.14488379657268524, 'DER': 0.32867438305306834, 'ACC': np.float64(0.9396218355141869), 'MI': 0.19152653417776808, 'FA': 0.07483438887675621, 'CF': 0.062313459998544075}, batch size: 64, grad_norm: 0.2700190246105194, grad_scale: , lr: 1.77e-04, 
2025-02-13 10:34:01,796 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/checkpoint-4500.pt
2025-02-13 10:34:02,211 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-13 10:34:02,213 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-13 10:36:50,792 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 4614, num_updates: 4500, {'loss': 0.1296001821756363, 'DER': 0.3010215838390045, 'ACC': np.float64(0.9449776785714286), 'MI': 0.1296566556571165, 'FA': 0.09370919425455104, 'CF': 0.07765573392733698}, batch size: 64, grad_norm: 0.25174275040626526, grad_scale: , lr: 1.71e-04, 
2025-02-13 10:36:50,793 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 10:36:50,796 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 4614, num_updates: 4500, {'loss': 0.1302706003189087, 'DER': 0.3438843298163345, 'ACC': np.float64(0.9427120535714286), 'MI': 0.1968737788198515, 'FA': 0.08972254787026182, 'CF': 0.05728800312622118}, batch size: 64, grad_norm: 0.25174275040626526, grad_scale: , lr: 1.71e-04, 
2025-02-13 10:36:50,796 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 10:37:37,358 (model:925) WARNING: All labels are zero
2025-02-13 10:37:38,320 (model:925) WARNING: All labels are zero
2025-02-13 10:37:38,883 (model:925) WARNING: All labels are zero
2025-02-13 10:39:05,726 (model:925) WARNING: All labels are zero
2025-02-13 10:39:17,815 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 4614,  validation: loss=0.1093, DER=0.2561, ACC=0.9493, MI=0.1426, FA=0.05622, CF=0.05733, over 0.00 frames. 
2025-02-13 10:39:17,816 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 10:39:19,912 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 4614,  validation: loss=0.1108, DER=0.2576, ACC=0.9484, MI=0.1422, FA=0.0558, CF=0.05956, over 0.00 frames. 
2025-02-13 10:39:19,912 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 10:51:45,167 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 5114, num_updates: 5000, {'loss': 0.15613014996051788, 'DER': 0.3591015169194866, 'ACC': np.float64(0.9278459821428571), 'MI': 0.17378938156359394, 'FA': 0.07292882147024504, 'CF': 0.11238331388564761}, batch size: 64, grad_norm: 0.2742801904678345, grad_scale: , lr: 1.65e-04, 
2025-02-13 10:51:45,168 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 10:51:45,170 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 5114, num_updates: 5000, {'loss': 0.14992265403270721, 'DER': 0.3244650900900901, 'ACC': np.float64(0.9359933035714286), 'MI': 0.17004504504504506, 'FA': 0.0752393018018018, 'CF': 0.07918074324324324}, batch size: 64, grad_norm: 0.2742801904678345, grad_scale: , lr: 1.65e-04, 
2025-02-13 10:51:45,170 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 10:52:34,053 (model:925) WARNING: All labels are zero
2025-02-13 10:52:34,629 (model:925) WARNING: All labels are zero
2025-02-13 10:52:34,634 (model:925) WARNING: All labels are zero
2025-02-13 10:54:05,246 (model:925) WARNING: All labels are zero
2025-02-13 10:54:17,155 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 5114,  validation: loss=0.1162, DER=0.266, ACC=0.9478, MI=0.1523, FA=0.05473, CF=0.05901, over 0.00 frames. 
2025-02-13 10:54:17,156 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 10:54:17,169 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 5114,  validation: loss=0.1175, DER=0.2625, ACC=0.9472, MI=0.1473, FA=0.05363, CF=0.06156, over 0.00 frames. 
2025-02-13 10:54:17,169 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 11:06:06,485 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 5614, num_updates: 5500, {'loss': 0.13233782351016998, 'DER': 0.28751280925193967, 'ACC': np.float64(0.9469419642857143), 'MI': 0.12889767237593325, 'FA': 0.0981554677206851, 'CF': 0.060459669155321326}, batch size: 64, grad_norm: 0.2221386879682541, grad_scale: , lr: 1.60e-04, 
2025-02-13 11:06:06,486 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 11:06:06,487 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 5614, num_updates: 5500, {'loss': 0.15861687064170837, 'DER': 0.34391423165860835, 'ACC': np.float64(0.930859375), 'MI': 0.17174689930628548, 'FA': 0.08198444397729661, 'CF': 0.09018288837502628}, batch size: 64, grad_norm: 0.2221386879682541, grad_scale: , lr: 1.60e-04, 
2025-02-13 11:06:06,488 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 11:06:56,700 (model:925) WARNING: All labels are zero
2025-02-13 11:06:57,307 (model:925) WARNING: All labels are zero
2025-02-13 11:06:57,530 (model:925) WARNING: All labels are zero
2025-02-13 11:08:33,075 (model:925) WARNING: All labels are zero
2025-02-13 11:08:44,237 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 5614,  validation: loss=0.1103, DER=0.2483, ACC=0.9486, MI=0.1153, FA=0.06806, CF=0.06491, over 0.00 frames. 
2025-02-13 11:08:44,237 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 11:08:45,665 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 5614,  validation: loss=0.1089, DER=0.2508, ACC=0.9497, MI=0.1159, FA=0.0703, CF=0.06463, over 0.00 frames. 
2025-02-13 11:08:45,665 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 11:17:58,636 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/checkpoint-6000.pt
2025-02-13 11:17:59,068 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-13 11:20:54,720 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 6114, num_updates: 6000, {'loss': 0.13652311265468597, 'DER': 0.3217462199822117, 'ACC': np.float64(0.9404352678571429), 'MI': 0.16172546694337386, 'FA': 0.08619922917284317, 'CF': 0.07382152386599466}, batch size: 64, grad_norm: 0.25446617603302, grad_scale: , lr: 1.54e-04, 
2025-02-13 11:20:54,720 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 11:20:54,722 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 6114, num_updates: 6000, {'loss': 0.16853241622447968, 'DER': 0.37522709576953023, 'ACC': np.float64(0.919888392857143), 'MI': 0.22248896963405138, 'FA': 0.062224240851284716, 'CF': 0.09051388528419413}, batch size: 64, grad_norm: 0.25446617603302, grad_scale: , lr: 1.54e-04, 
2025-02-13 11:20:54,723 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 11:21:42,268 (model:925) WARNING: All labels are zero
2025-02-13 11:21:42,837 (model:925) WARNING: All labels are zero
2025-02-13 11:21:43,075 (model:925) WARNING: All labels are zero
2025-02-13 11:23:14,140 (model:925) WARNING: All labels are zero
2025-02-13 11:23:26,390 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 6114,  validation: loss=0.09492, DER=0.2226, ACC=0.9562, MI=0.1311, FA=0.04864, CF=0.0429, over 0.00 frames. 
2025-02-13 11:23:26,390 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 11:23:26,396 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 6114,  validation: loss=0.09554, DER=0.218, ACC=0.9557, MI=0.1291, FA=0.04451, CF=0.04443, over 0.00 frames. 
2025-02-13 11:23:26,396 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 11:35:05,520 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 6614, num_updates: 6500, {'loss': 0.1497933268547058, 'DER': 0.3632771731027285, 'ACC': np.float64(0.93140625), 'MI': 0.17280453257790368, 'FA': 0.09557179066646787, 'CF': 0.09490084985835694}, batch size: 64, grad_norm: 0.17412056028842926, grad_scale: , lr: 1.49e-04, 
2025-02-13 11:35:05,521 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 11:35:05,523 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 6614, num_updates: 6500, {'loss': 0.12679290771484375, 'DER': 0.299653932279297, 'ACC': np.float64(0.9428794642857143), 'MI': 0.19529076474180634, 'FA': 0.05672796362896112, 'CF': 0.04763520390852955}, batch size: 64, grad_norm: 0.17412056028842926, grad_scale: , lr: 1.49e-04, 
2025-02-13 11:35:05,523 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 11:35:54,137 (model:925) WARNING: All labels are zero
2025-02-13 11:35:54,693 (model:925) WARNING: All labels are zero
2025-02-13 11:35:54,720 (model:925) WARNING: All labels are zero
2025-02-13 11:37:24,311 (model:925) WARNING: All labels are zero
2025-02-13 11:37:36,096 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 6614,  validation: loss=0.09039, DER=0.2103, ACC=0.9588, MI=0.12, FA=0.05349, CF=0.03676, over 0.00 frames. 
2025-02-13 11:37:36,096 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 11:37:36,171 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 6614,  validation: loss=0.0929, DER=0.2124, ACC=0.9574, MI=0.1217, FA=0.05208, CF=0.03868, over 0.00 frames. 
2025-02-13 11:37:36,171 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 11:49:18,868 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 7114, num_updates: 7000, {'loss': 0.13463443517684937, 'DER': 0.3344601884485363, 'ACC': np.float64(0.9366183035714286), 'MI': 0.19377112853341005, 'FA': 0.06667625692296626, 'CF': 0.07401280299215997}, batch size: 64, grad_norm: 0.20318955183029175, grad_scale: , lr: 1.43e-04, 
2025-02-13 11:49:18,868 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 11:49:18,870 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 7114, num_updates: 7000, {'loss': 0.17737524211406708, 'DER': 0.39822050290135397, 'ACC': np.float64(0.9278013392857143), 'MI': 0.19837524177949709, 'FA': 0.09756286266924565, 'CF': 0.10228239845261122}, batch size: 64, grad_norm: 0.20318955183029175, grad_scale: , lr: 1.43e-04, 
2025-02-13 11:49:18,871 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 11:50:07,598 (model:925) WARNING: All labels are zero
2025-02-13 11:50:08,128 (model:925) WARNING: All labels are zero
2025-02-13 11:50:08,169 (model:925) WARNING: All labels are zero
2025-02-13 11:51:37,227 (model:925) WARNING: All labels are zero
2025-02-13 11:51:48,864 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 7114,  validation: loss=0.08649, DER=0.2038, ACC=0.9603, MI=0.1225, FA=0.04948, CF=0.0318, over 0.00 frames. 
2025-02-13 11:51:48,864 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 11:51:49,151 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 7114,  validation: loss=0.08903, DER=0.2106, ACC=0.9586, MI=0.1264, FA=0.04992, CF=0.03427, over 0.00 frames. 
2025-02-13 11:51:49,151 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 12:01:45,602 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/checkpoint-7500.pt
2025-02-13 12:01:46,020 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-13 12:04:27,547 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 7614, num_updates: 7500, {'loss': 0.13653609156608582, 'DER': 0.3126569913480324, 'ACC': np.float64(0.9385411008509867), 'MI': 0.19048283561261511, 'FA': 0.05588891989952554, 'CF': 0.06628523583589171}, batch size: 64, grad_norm: 0.18222619593143463, grad_scale: , lr: 1.38e-04, 
2025-02-13 12:04:27,547 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 12:04:27,549 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 7614, num_updates: 7500, {'loss': 0.12585705518722534, 'DER': 0.297704719339444, 'ACC': np.float64(0.9471547450822062), 'MI': 0.15620028785698054, 'FA': 0.08226649496250284, 'CF': 0.05923793651996061}, batch size: 64, grad_norm: 0.18222619593143463, grad_scale: , lr: 1.38e-04, 
2025-02-13 12:04:27,549 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 12:05:15,391 (model:925) WARNING: All labels are zero
2025-02-13 12:05:15,708 (model:925) WARNING: All labels are zero
2025-02-13 12:05:15,958 (model:925) WARNING: All labels are zero
2025-02-13 12:06:43,477 (model:925) WARNING: All labels are zero
2025-02-13 12:06:55,004 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 7614,  validation: loss=0.08855, DER=0.2045, ACC=0.9599, MI=0.1314, FA=0.04042, CF=0.03268, over 0.00 frames. 
2025-02-13 12:06:55,005 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 12:06:55,460 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 7614,  validation: loss=0.09007, DER=0.2051, ACC=0.9591, MI=0.1335, FA=0.03874, CF=0.03286, over 0.00 frames. 
2025-02-13 12:06:55,460 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 12:18:41,268 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 8114, num_updates: 8000, {'loss': 0.14218616485595703, 'DER': 0.33073220536756126, 'ACC': np.float64(0.936171875), 'MI': 0.15475495915985998, 'FA': 0.08962952158693116, 'CF': 0.08634772462077013}, batch size: 64, grad_norm: 0.14851711690425873, grad_scale: , lr: 1.32e-04, 
2025-02-13 12:18:41,268 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 12:18:41,269 (train_accelerate_ddp:702) INFO: [Train] - Epoch 2, batch_idx_train: 8114, num_updates: 8000, {'loss': 0.11315605044364929, 'DER': 0.2487217202493521, 'ACC': np.float64(0.9515401785714286), 'MI': 0.1287385305036072, 'FA': 0.06457939342999229, 'CF': 0.05540379631575261}, batch size: 64, grad_norm: 0.14851711690425873, grad_scale: , lr: 1.32e-04, 
2025-02-13 12:18:41,269 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 12:19:29,474 (model:925) WARNING: All labels are zero
2025-02-13 12:19:30,028 (model:925) WARNING: All labels are zero
2025-02-13 12:19:30,052 (model:925) WARNING: All labels are zero
2025-02-13 12:20:58,075 (model:925) WARNING: All labels are zero
2025-02-13 12:21:09,573 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 8114,  validation: loss=0.09458, DER=0.207, ACC=0.9595, MI=0.1011, FA=0.0713, CF=0.03454, over 0.00 frames. 
2025-02-13 12:21:09,573 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 12:21:09,859 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 2, batch_idx_train: 8114,  validation: loss=0.09588, DER=0.208, ACC=0.9588, MI=0.1021, FA=0.07105, CF=0.03486, over 0.00 frames. 
2025-02-13 12:21:09,859 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 12:23:49,828 (train_accelerate_ddp:713) INFO: end of epoch 2, batch_idx: 4113 batch_idx_train: 8227, {'loss': 0.1271832287311554, 'DER': 0.30414746543778803, 'ACC': np.float64(0.9433202931786502), 'MI': 0.17734735023041476, 'FA': 0.06790034562211981, 'CF': 0.058899769585253454}, batch size: 64, grad_norm: 0.2416108399629593, grad_scale: , lr: 1.31e-04, 
2025-02-13 12:23:49,830 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/epoch-2.pt
2025-02-13 12:23:49,830 (train_accelerate_ddp:713) INFO: end of epoch 2, batch_idx: 4113 batch_idx_train: 8227, {'loss': 0.11791250109672546, 'DER': 0.2855963371613, 'ACC': np.float64(0.9452678571428571), 'MI': 0.13120168130300983, 'FA': 0.07190572693837724, 'CF': 0.08248892891991293}, batch size: 64, grad_norm: 0.2416108399629593, grad_scale: , lr: 1.31e-04, 
2025-02-13 12:23:50,122 (train_accelerate_ddp:561) INFO:  end of epoch 2, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/epoch-2.pt 
2025-02-13 12:23:52,709 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 8228, num_updates: 8000, {'loss': 0.12919701635837555, 'DER': 0.27831159917638987, 'ACC': np.float64(0.9428125), 'MI': 0.14495538778311598, 'FA': 0.05998627316403569, 'CF': 0.07336993822923817}, batch size: 64, grad_norm: 0.2001752108335495, grad_scale: , lr: 1.31e-04, 
2025-02-13 12:23:52,709 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 8228, num_updates: 8000, {'loss': 0.1284549981355667, 'DER': 0.2752339098383896, 'ACC': np.float64(0.9461495535714286), 'MI': 0.14573291749362063, 'FA': 0.06273036574992912, 'CF': 0.0667706265948398}, batch size: 64, grad_norm: 0.2001752108335495, grad_scale: , lr: 1.31e-04, 
2025-02-13 12:35:35,010 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 8728, num_updates: 8500, {'loss': 0.12634427845478058, 'DER': 0.3060752575152407, 'ACC': np.float64(0.942466517857143), 'MI': 0.19697288206853059, 'FA': 0.05395557424146871, 'CF': 0.055146801205241396}, batch size: 64, grad_norm: 0.19427217543125153, grad_scale: , lr: 1.25e-04, 
2025-02-13 12:35:35,011 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 12:35:35,013 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 8728, num_updates: 8500, {'loss': 0.12247449159622192, 'DER': 0.31941342861396455, 'ACC': np.float64(0.9443002572994742), 'MI': 0.18587166889980647, 'FA': 0.08232842042578532, 'CF': 0.05121333928837279}, batch size: 64, grad_norm: 0.19427217543125153, grad_scale: , lr: 1.25e-04, 
2025-02-13 12:35:35,013 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 12:36:23,658 (model:925) WARNING: All labels are zero
2025-02-13 12:36:23,728 (model:925) WARNING: All labels are zero
2025-02-13 12:36:24,297 (model:925) WARNING: All labels are zero
2025-02-13 12:37:51,325 (model:925) WARNING: All labels are zero
2025-02-13 12:38:02,949 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 8728,  validation: loss=0.08486, DER=0.1929, ACC=0.9618, MI=0.1029, FA=0.05892, CF=0.03101, over 0.00 frames. 
2025-02-13 12:38:02,949 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 12:38:03,720 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 8728,  validation: loss=0.08667, DER=0.1938, ACC=0.9609, MI=0.1035, FA=0.0574, CF=0.03289, over 0.00 frames. 
2025-02-13 12:38:03,720 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 12:44:23,580 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/checkpoint-9000.pt
2025-02-13 12:44:24,005 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-13 12:44:24,007 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-13 12:49:43,967 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 9228, num_updates: 9000, {'loss': 0.1238158792257309, 'DER': 0.3000450856627592, 'ACC': np.float64(0.9433977015088735), 'MI': 0.13112413585813046, 'FA': 0.0881424706943192, 'CF': 0.0807784791103096}, batch size: 64, grad_norm: 0.21436801552772522, grad_scale: , lr: 1.20e-04, 
2025-02-13 12:49:43,968 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 12:49:43,970 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 9228, num_updates: 9000, {'loss': 0.1370987892150879, 'DER': 0.2873232226275037, 'ACC': np.float64(0.9438727678571429), 'MI': 0.2034299609649965, 'FA': 0.04940167658539707, 'CF': 0.03449158507711013}, batch size: 64, grad_norm: 0.21436801552772522, grad_scale: , lr: 1.20e-04, 
2025-02-13 12:49:43,970 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 12:50:32,300 (model:925) WARNING: All labels are zero
2025-02-13 12:50:32,860 (model:925) WARNING: All labels are zero
2025-02-13 12:50:32,886 (model:925) WARNING: All labels are zero
2025-02-13 12:52:02,221 (model:925) WARNING: All labels are zero
2025-02-13 12:52:13,956 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 9228,  validation: loss=0.08565, DER=0.1973, ACC=0.9603, MI=0.08556, FA=0.07267, CF=0.03911, over 0.00 frames. 
2025-02-13 12:52:13,956 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 12:52:13,981 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 9228,  validation: loss=0.08635, DER=0.1965, ACC=0.96, MI=0.08716, FA=0.07069, CF=0.03866, over 0.00 frames. 
2025-02-13 12:52:13,981 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 13:04:32,489 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 9728, num_updates: 9500, {'loss': 0.1307966560125351, 'DER': 0.3051478974982891, 'ACC': np.float64(0.9454464285714286), 'MI': 0.14455174511443997, 'FA': 0.09406128811497225, 'CF': 0.06653486426887689}, batch size: 64, grad_norm: 0.16554956138134003, grad_scale: , lr: 1.14e-04, 
2025-02-13 13:04:32,490 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 13:04:32,490 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 9728, num_updates: 9500, {'loss': 0.10021907836198807, 'DER': 0.24557554482960361, 'ACC': np.float64(0.9550669642857144), 'MI': 0.10918531519672371, 'FA': 0.08753839403247038, 'CF': 0.04885183560040954}, batch size: 64, grad_norm: 0.16554956138134003, grad_scale: , lr: 1.14e-04, 
2025-02-13 13:04:32,490 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 13:05:20,706 (model:925) WARNING: All labels are zero
2025-02-13 13:05:21,069 (model:925) WARNING: All labels are zero
2025-02-13 13:05:21,272 (model:925) WARNING: All labels are zero
2025-02-13 13:06:49,844 (model:925) WARNING: All labels are zero
2025-02-13 13:07:01,328 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 9728,  validation: loss=0.08421, DER=0.1912, ACC=0.9609, MI=0.09998, FA=0.05518, CF=0.03606, over 0.00 frames. 
2025-02-13 13:07:01,328 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 13:07:01,442 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 9728,  validation: loss=0.0826, DER=0.1891, ACC=0.9622, MI=0.09947, FA=0.05716, CF=0.0325, over 0.00 frames. 
2025-02-13 13:07:01,443 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 13:18:44,574 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 10228, num_updates: 10000, {'loss': 0.1303057223558426, 'DER': 0.3035494831200752, 'ACC': np.float64(0.9417857142857143), 'MI': 0.1700281934504446, 'FA': 0.06000144581797152, 'CF': 0.07351984385165908}, batch size: 64, grad_norm: 0.22072544693946838, grad_scale: , lr: 1.09e-04, 
2025-02-13 13:18:44,574 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 13:18:44,576 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 10228, num_updates: 10000, {'loss': 0.15624548494815826, 'DER': 0.37035979440319816, 'ACC': np.float64(0.9311272321428571), 'MI': 0.21202170188463734, 'FA': 0.08816390633923472, 'CF': 0.0701741861793261}, batch size: 64, grad_norm: 0.22072544693946838, grad_scale: , lr: 1.09e-04, 
2025-02-13 13:18:44,576 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 13:19:32,804 (model:925) WARNING: All labels are zero
2025-02-13 13:19:32,839 (model:925) WARNING: All labels are zero
2025-02-13 13:19:33,416 (model:925) WARNING: All labels are zero
2025-02-13 13:21:00,950 (model:925) WARNING: All labels are zero
2025-02-13 13:21:12,488 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 10228,  validation: loss=0.08001, DER=0.1894, ACC=0.9623, MI=0.09145, FA=0.06446, CF=0.03347, over 0.00 frames. 
2025-02-13 13:21:12,489 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 13:21:13,127 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 10228,  validation: loss=0.08094, DER=0.1856, ACC=0.9622, MI=0.09198, FA=0.06097, CF=0.03262, over 0.00 frames. 
2025-02-13 13:21:13,127 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 13:27:35,838 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/checkpoint-10500.pt
2025-02-13 13:27:36,262 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-13 13:32:58,524 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 10728, num_updates: 10500, {'loss': 0.1123105138540268, 'DER': 0.2751019175600181, 'ACC': np.float64(0.9498325892857143), 'MI': 0.13377623433489355, 'FA': 0.07707987316925864, 'CF': 0.06424581005586592}, batch size: 64, grad_norm: 0.16410593688488007, grad_scale: , lr: 1.03e-04, 
2025-02-13 13:32:58,524 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 13:32:58,526 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 10728, num_updates: 10500, {'loss': 0.10517594963312149, 'DER': 0.23979160799774712, 'ACC': np.float64(0.9536607142857143), 'MI': 0.138552520416784, 'FA': 0.0487186707969586, 'CF': 0.05252041678400451}, batch size: 64, grad_norm: 0.16410593688488007, grad_scale: , lr: 1.03e-04, 
2025-02-13 13:32:58,527 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 13:33:46,255 (model:925) WARNING: All labels are zero
2025-02-13 13:33:46,580 (model:925) WARNING: All labels are zero
2025-02-13 13:33:46,822 (model:925) WARNING: All labels are zero
2025-02-13 13:35:14,606 (model:925) WARNING: All labels are zero
2025-02-13 13:35:26,159 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 10728,  validation: loss=0.08154, DER=0.1889, ACC=0.9621, MI=0.08816, FA=0.06615, CF=0.03461, over 0.00 frames. 
2025-02-13 13:35:26,160 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 13:35:26,839 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 10728,  validation: loss=0.08361, DER=0.1922, ACC=0.9606, MI=0.08964, FA=0.06537, CF=0.0372, over 0.00 frames. 
2025-02-13 13:35:26,840 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 13:47:16,676 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 11228, num_updates: 11000, {'loss': 0.11265724152326584, 'DER': 0.25365918272733295, 'ACC': np.float64(0.9509933035714286), 'MI': 0.17365388436320287, 'FA': 0.042850519901980265, 'CF': 0.03715477846214981}, batch size: 64, grad_norm: 0.20354551076889038, grad_scale: , lr: 9.75e-05, 
2025-02-13 13:47:16,676 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 13:47:16,678 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 11228, num_updates: 11000, {'loss': 0.13106609880924225, 'DER': 0.3069627074800604, 'ACC': np.float64(0.943002232142857), 'MI': 0.17791190630164547, 'FA': 0.06905223826974204, 'CF': 0.059998562908672844}, batch size: 64, grad_norm: 0.20354551076889038, grad_scale: , lr: 9.75e-05, 
2025-02-13 13:47:16,678 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 13:48:04,635 (model:925) WARNING: All labels are zero
2025-02-13 13:48:05,200 (model:925) WARNING: All labels are zero
2025-02-13 13:48:05,463 (model:925) WARNING: All labels are zero
2025-02-13 13:49:34,653 (model:925) WARNING: All labels are zero
2025-02-13 13:49:45,623 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 11228,  validation: loss=0.07795, DER=0.1793, ACC=0.9633, MI=0.1076, FA=0.04134, CF=0.03045, over 0.00 frames. 
2025-02-13 13:49:45,623 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 13:49:46,288 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 11228,  validation: loss=0.07612, DER=0.1783, ACC=0.9643, MI=0.1063, FA=0.04415, CF=0.02782, over 0.00 frames. 
2025-02-13 13:49:46,289 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 14:01:31,983 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 11728, num_updates: 11500, {'loss': 0.09800887852907181, 'DER': 0.23515527034004574, 'ACC': np.float64(0.9563882547429741), 'MI': 0.13682968208305674, 'FA': 0.04742937228000295, 'CF': 0.050896215976986056}, batch size: 64, grad_norm: 0.15413586795330048, grad_scale: , lr: 9.19e-05, 
2025-02-13 14:01:31,983 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 14:01:31,984 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 11728, num_updates: 11500, {'loss': 0.11871093511581421, 'DER': 0.26871794871794874, 'ACC': np.float64(0.9484709821428571), 'MI': 0.127985347985348, 'FA': 0.07120879120879121, 'CF': 0.06952380952380953}, batch size: 64, grad_norm: 0.15413586795330048, grad_scale: , lr: 9.19e-05, 
2025-02-13 14:01:31,984 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 14:02:19,891 (model:925) WARNING: All labels are zero
2025-02-13 14:02:20,412 (model:925) WARNING: All labels are zero
2025-02-13 14:02:20,446 (model:925) WARNING: All labels are zero
2025-02-13 14:03:49,208 (model:925) WARNING: All labels are zero
2025-02-13 14:04:00,916 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 11728,  validation: loss=0.07743, DER=0.1771, ACC=0.9644, MI=0.09477, FA=0.05387, CF=0.02846, over 0.00 frames. 
2025-02-13 14:04:00,917 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 14:04:00,919 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 11728,  validation: loss=0.07921, DER=0.1793, ACC=0.9633, MI=0.09618, FA=0.05212, CF=0.03104, over 0.00 frames. 
2025-02-13 14:04:00,920 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 14:10:22,342 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/checkpoint-12000.pt
2025-02-13 14:10:22,742 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-13 14:15:36,243 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 12228, num_updates: 12000, {'loss': 0.10860363394021988, 'DER': 0.2633388133313406, 'ACC': np.float64(0.9527790178571429), 'MI': 0.13181886115677777, 'FA': 0.07868778956807652, 'CF': 0.05283216260648632}, batch size: 64, grad_norm: 0.2124992311000824, grad_scale: , lr: 8.63e-05, 
2025-02-13 14:15:36,244 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 14:15:36,246 (train_accelerate_ddp:702) INFO: [Train] - Epoch 3, batch_idx_train: 12228, num_updates: 12000, {'loss': 0.15015137195587158, 'DER': 0.3338412522510043, 'ACC': np.float64(0.9319642857142857), 'MI': 0.1793184651613797, 'FA': 0.0661448954148774, 'CF': 0.08837789167474719}, batch size: 64, grad_norm: 0.2124992311000824, grad_scale: , lr: 8.63e-05, 
2025-02-13 14:15:36,247 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 14:16:21,795 (model:925) WARNING: All labels are zero
2025-02-13 14:16:22,541 (model:925) WARNING: All labels are zero
2025-02-13 14:16:23,100 (model:925) WARNING: All labels are zero
2025-02-13 14:17:45,571 (model:925) WARNING: All labels are zero
2025-02-13 14:17:56,521 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 12228,  validation: loss=0.08433, DER=0.191, ACC=0.9607, MI=0.09964, FA=0.05311, CF=0.03821, over 0.00 frames. 
2025-02-13 14:17:56,521 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 14:17:59,991 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 3, batch_idx_train: 12228,  validation: loss=0.08444, DER=0.1891, ACC=0.9606, MI=0.1019, FA=0.05025, CF=0.03697, over 0.00 frames. 
2025-02-13 14:17:59,991 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 14:20:33,197 (train_accelerate_ddp:713) INFO: end of epoch 3, batch_idx: 4113 batch_idx_train: 12341, {'loss': 0.10250173509120941, 'DER': 0.21615645083269988, 'ACC': np.float64(0.9584040178571429), 'MI': 0.13730910096054177, 'FA': 0.03745421878239237, 'CF': 0.041393131089765736}, batch size: 64, grad_norm: 0.15071417391300201, grad_scale: , lr: 8.51e-05, 
2025-02-13 14:20:33,199 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/epoch-3.pt
2025-02-13 14:20:33,201 (train_accelerate_ddp:713) INFO: end of epoch 3, batch_idx: 4113 batch_idx_train: 12341, {'loss': 0.1161850169301033, 'DER': 0.24790530655672297, 'ACC': np.float64(0.9508370535714286), 'MI': 0.15254688123420668, 'FA': 0.05033914084319723, 'CF': 0.045019284479319056}, batch size: 64, grad_norm: 0.15071417391300201, grad_scale: , lr: 8.51e-05, 
2025-02-13 14:20:33,493 (train_accelerate_ddp:561) INFO:  end of epoch 3, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/epoch-3.pt 
2025-02-13 14:20:36,015 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 12342, num_updates: 12000, {'loss': 0.09712615609169006, 'DER': 0.21278052491441612, 'ACC': np.float64(0.9631361607142856), 'MI': 0.1107645492582731, 'FA': 0.06352225180677064, 'CF': 0.038493723849372385}, batch size: 64, grad_norm: 0.13502375781536102, grad_scale: , lr: 8.51e-05, 
2025-02-13 14:20:36,019 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 12342, num_updates: 12000, {'loss': 0.12150046974420547, 'DER': 0.28521690690063367, 'ACC': np.float64(0.9462165178571429), 'MI': 0.16259313418285634, 'FA': 0.07227908919991644, 'CF': 0.05034468351786087}, batch size: 64, grad_norm: 0.13502375781536102, grad_scale: , lr: 8.51e-05, 
2025-02-13 14:32:10,950 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 12842, num_updates: 12500, {'loss': 0.10305227339267731, 'DER': 0.23022629702393946, 'ACC': np.float64(0.9565625), 'MI': 0.12246234446627374, 'FA': 0.05479153023357346, 'CF': 0.052972422324092265}, batch size: 64, grad_norm: 0.17781169712543488, grad_scale: , lr: 7.95e-05, 
2025-02-13 14:32:10,950 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 12842, num_updates: 12500, {'loss': 0.1283034086227417, 'DER': 0.29546844214960255, 'ACC': np.float64(0.9408258928571429), 'MI': 0.1938990420544874, 'FA': 0.0368231537468578, 'CF': 0.06474624634825736}, batch size: 64, grad_norm: 0.17781169712543488, grad_scale: , lr: 7.95e-05, 
2025-02-13 14:32:10,951 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 14:32:10,951 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 14:32:59,260 (model:925) WARNING: All labels are zero
2025-02-13 14:32:59,792 (model:925) WARNING: All labels are zero
2025-02-13 14:32:59,835 (model:925) WARNING: All labels are zero
2025-02-13 14:34:28,315 (model:925) WARNING: All labels are zero
2025-02-13 14:34:39,971 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 12842,  validation: loss=0.0773, DER=0.1763, ACC=0.9643, MI=0.08679, FA=0.05979, CF=0.02968, over 0.00 frames. 
2025-02-13 14:34:39,972 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 14:34:40,026 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 12842,  validation: loss=0.07867, DER=0.1785, ACC=0.9634, MI=0.08929, FA=0.05913, CF=0.03004, over 0.00 frames. 
2025-02-13 14:34:40,026 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 14:46:15,764 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 13342, num_updates: 13000, {'loss': 0.11300496011972427, 'DER': 0.260236643958408, 'ACC': np.float64(0.9513950892857143), 'MI': 0.13166009322337754, 'FA': 0.07651487988526354, 'CF': 0.05206167084976694}, batch size: 64, grad_norm: 0.1632942408323288, grad_scale: , lr: 7.40e-05, 
2025-02-13 14:46:15,764 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 14:46:15,765 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 13342, num_updates: 13000, {'loss': 0.10310418158769608, 'DER': 0.24045773882813065, 'ACC': np.float64(0.9558963772424858), 'MI': 0.13348301586151953, 'FA': 0.062721807778663, 'CF': 0.04425291518794814}, batch size: 64, grad_norm: 0.1632942408323288, grad_scale: , lr: 7.40e-05, 
2025-02-13 14:46:15,765 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 14:47:03,858 (model:925) WARNING: All labels are zero
2025-02-13 14:47:04,417 (model:925) WARNING: All labels are zero
2025-02-13 14:47:04,433 (model:925) WARNING: All labels are zero
2025-02-13 14:48:33,394 (model:925) WARNING: All labels are zero
2025-02-13 14:48:45,133 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 13342,  validation: loss=0.07808, DER=0.1772, ACC=0.9638, MI=0.09791, FA=0.05016, CF=0.02909, over 0.00 frames. 
2025-02-13 14:48:45,133 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 14:48:45,140 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 13342,  validation: loss=0.07616, DER=0.1735, ACC=0.9651, MI=0.09579, FA=0.0507, CF=0.02704, over 0.00 frames. 
2025-02-13 14:48:45,140 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 14:52:26,748 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/checkpoint-13500.pt
2025-02-13 14:52:27,929 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-13 14:52:27,931 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-13 15:00:31,740 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 13842, num_updates: 13500, {'loss': 0.12010371685028076, 'DER': 0.24994729815192185, 'ACC': np.float64(0.9516964285714287), 'MI': 0.14911109549574872, 'FA': 0.04665870283184597, 'CF': 0.05417749982432717}, batch size: 64, grad_norm: 0.17905962467193604, grad_scale: , lr: 6.84e-05, 
2025-02-13 15:00:31,740 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 15:00:31,741 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 13842, num_updates: 13500, {'loss': 0.1032017320394516, 'DER': 0.2687336570788196, 'ACC': np.float64(0.9543449715497795), 'MI': 0.1612252521479268, 'FA': 0.07231976092641015, 'CF': 0.03518864400448263}, batch size: 64, grad_norm: 0.17905962467193604, grad_scale: , lr: 6.84e-05, 
2025-02-13 15:00:31,741 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 15:01:20,832 (model:925) WARNING: All labels are zero
2025-02-13 15:01:21,416 (model:925) WARNING: All labels are zero
2025-02-13 15:01:21,421 (model:925) WARNING: All labels are zero
2025-02-13 15:02:52,445 (model:925) WARNING: All labels are zero
2025-02-13 15:03:04,429 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 13842,  validation: loss=0.07575, DER=0.1731, ACC=0.9647, MI=0.1028, FA=0.04407, CF=0.02623, over 0.00 frames. 
2025-02-13 15:03:04,429 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 15:03:04,448 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 13842,  validation: loss=0.07423, DER=0.1722, ACC=0.9656, MI=0.1013, FA=0.04646, CF=0.02438, over 0.00 frames. 
2025-02-13 15:03:04,449 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 15:14:39,154 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 14342, num_updates: 14000, {'loss': 0.0991741195321083, 'DER': 0.23811902383330955, 'ACC': np.float64(0.9567299107142857), 'MI': 0.14742400456686172, 'FA': 0.05216212359069502, 'CF': 0.03853289567575282}, batch size: 64, grad_norm: 0.1666269153356552, grad_scale: , lr: 6.29e-05, 
2025-02-13 15:14:39,154 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 15:14:39,156 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 14342, num_updates: 14000, {'loss': 0.1130414679646492, 'DER': 0.25803476410074494, 'ACC': np.float64(0.9496875), 'MI': 0.14395175594182333, 'FA': 0.0522880454061724, 'CF': 0.061794962752749205}, batch size: 64, grad_norm: 0.1666269153356552, grad_scale: , lr: 6.29e-05, 
2025-02-13 15:14:39,156 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 15:15:24,661 (model:925) WARNING: All labels are zero
2025-02-13 15:15:25,473 (model:925) WARNING: All labels are zero
2025-02-13 15:15:26,024 (model:925) WARNING: All labels are zero
2025-02-13 15:16:47,639 (model:925) WARNING: All labels are zero
2025-02-13 15:16:58,602 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 14342,  validation: loss=0.07748, DER=0.1796, ACC=0.9637, MI=0.09368, FA=0.05356, CF=0.03234, over 0.00 frames. 
2025-02-13 15:16:58,602 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 15:17:02,817 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 14342,  validation: loss=0.07828, DER=0.1776, ACC=0.9632, MI=0.09377, FA=0.05079, CF=0.033, over 0.00 frames. 
2025-02-13 15:17:02,817 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 15:28:35,238 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 14842, num_updates: 14500, {'loss': 0.12441329658031464, 'DER': 0.26423916123547747, 'ACC': np.float64(0.94921875), 'MI': 0.16690280532728818, 'FA': 0.03924624539529612, 'CF': 0.05809011051289317}, batch size: 64, grad_norm: 0.19290806353092194, grad_scale: , lr: 5.73e-05, 
2025-02-13 15:28:35,239 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 15:28:35,243 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 14842, num_updates: 14500, {'loss': 0.10735467821359634, 'DER': 0.2588139241445855, 'ACC': np.float64(0.9516977307280815), 'MI': 0.13248719661545313, 'FA': 0.06680026720106881, 'CF': 0.05952646032806354}, batch size: 64, grad_norm: 0.19290806353092194, grad_scale: , lr: 5.73e-05, 
2025-02-13 15:28:35,243 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 15:29:20,664 (model:925) WARNING: All labels are zero
2025-02-13 15:29:21,469 (model:925) WARNING: All labels are zero
2025-02-13 15:29:22,019 (model:925) WARNING: All labels are zero
2025-02-13 15:30:44,283 (model:925) WARNING: All labels are zero
2025-02-13 15:30:58,181 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 14842,  validation: loss=0.07665, DER=0.1775, ACC=0.9643, MI=0.09245, FA=0.05556, CF=0.02951, over 0.00 frames. 
2025-02-13 15:30:58,181 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 15:31:01,530 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 14842,  validation: loss=0.07746, DER=0.1769, ACC=0.9636, MI=0.09319, FA=0.05301, CF=0.0307, over 0.00 frames. 
2025-02-13 15:31:01,530 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 15:35:35,563 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/checkpoint-15000.pt
2025-02-13 15:35:35,969 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-13 15:43:56,455 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 15342, num_updates: 15000, {'loss': 0.10717907547950745, 'DER': 0.24556295063782585, 'ACC': np.float64(0.9529129464285714), 'MI': 0.14371880199667222, 'FA': 0.05490848585690516, 'CF': 0.046935662784248475}, batch size: 64, grad_norm: 0.16856563091278076, grad_scale: , lr: 5.17e-05, 
2025-02-13 15:43:56,456 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 15:43:56,458 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 15342, num_updates: 15000, {'loss': 0.104720838367939, 'DER': 0.2398069442443452, 'ACC': np.float64(0.9554799107142857), 'MI': 0.12130816885175047, 'FA': 0.07095519377611295, 'CF': 0.04754358161648178}, batch size: 64, grad_norm: 0.16856563091278076, grad_scale: , lr: 5.17e-05, 
2025-02-13 15:43:56,458 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 15:44:44,357 (model:925) WARNING: All labels are zero
2025-02-13 15:44:44,566 (model:925) WARNING: All labels are zero
2025-02-13 15:44:44,930 (model:925) WARNING: All labels are zero
2025-02-13 15:46:12,860 (model:925) WARNING: All labels are zero
2025-02-13 15:46:24,776 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 15342,  validation: loss=0.07669, DER=0.1757, ACC=0.9646, MI=0.0903, FA=0.05637, CF=0.02899, over 0.00 frames. 
2025-02-13 15:46:24,776 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 15:46:25,375 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 15342,  validation: loss=0.07833, DER=0.1776, ACC=0.9634, MI=0.09204, FA=0.05513, CF=0.03046, over 0.00 frames. 
2025-02-13 15:46:25,375 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 15:58:17,045 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 15842, num_updates: 15500, {'loss': 0.10704169422388077, 'DER': 0.24511740179942945, 'ACC': np.float64(0.9564174107142857), 'MI': 0.13312852022529442, 'FA': 0.0714651451978641, 'CF': 0.040523736376270936}, batch size: 64, grad_norm: 0.16931301355361938, grad_scale: , lr: 4.62e-05, 
2025-02-13 15:58:17,046 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 15:58:17,046 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 15842, num_updates: 15500, {'loss': 0.09558865427970886, 'DER': 0.26579131380623106, 'ACC': np.float64(0.9563727678571429), 'MI': 0.13270142180094788, 'FA': 0.09517520006215523, 'CF': 0.037914691943127965}, batch size: 64, grad_norm: 0.16931301355361938, grad_scale: , lr: 4.62e-05, 
2025-02-13 15:58:17,046 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 15:59:05,533 (model:925) WARNING: All labels are zero
2025-02-13 15:59:06,031 (model:925) WARNING: All labels are zero
2025-02-13 15:59:06,108 (model:925) WARNING: All labels are zero
2025-02-13 16:00:35,721 (model:925) WARNING: All labels are zero
2025-02-13 16:00:47,812 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 15842,  validation: loss=0.07744, DER=0.1757, ACC=0.9648, MI=0.09146, FA=0.05698, CF=0.02721, over 0.00 frames. 
2025-02-13 16:00:47,812 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 16:00:47,816 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 15842,  validation: loss=0.07888, DER=0.1766, ACC=0.9637, MI=0.09276, FA=0.05431, CF=0.02952, over 0.00 frames. 
2025-02-13 16:00:47,817 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 16:12:36,497 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 16342, num_updates: 16000, {'loss': 0.11947968602180481, 'DER': 0.244426483464673, 'ACC': np.float64(0.9506361607142857), 'MI': 0.1495925102714353, 'FA': 0.04135515592375564, 'CF': 0.05347881726948205}, batch size: 64, grad_norm: 0.1592191606760025, grad_scale: , lr: 4.06e-05, 
2025-02-13 16:12:36,498 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 16:12:36,500 (train_accelerate_ddp:702) INFO: [Train] - Epoch 4, batch_idx_train: 16342, num_updates: 16000, {'loss': 0.10639102011919022, 'DER': 0.24187698911997632, 'ACC': np.float64(0.9558482142857143), 'MI': 0.13714750943675524, 'FA': 0.05380800828954185, 'CF': 0.050921471393679224}, batch size: 64, grad_norm: 0.1592191606760025, grad_scale: , lr: 4.06e-05, 
2025-02-13 16:12:36,500 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 16:13:24,837 (model:925) WARNING: All labels are zero
2025-02-13 16:13:25,328 (model:925) WARNING: All labels are zero
2025-02-13 16:13:25,410 (model:925) WARNING: All labels are zero
2025-02-13 16:14:53,498 (model:925) WARNING: All labels are zero
2025-02-13 16:15:05,146 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 16342,  validation: loss=0.07456, DER=0.1726, ACC=0.9652, MI=0.09412, FA=0.05117, CF=0.02732, over 0.00 frames. 
2025-02-13 16:15:05,146 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 16:15:05,928 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 4, batch_idx_train: 16342,  validation: loss=0.07618, DER=0.1729, ACC=0.9643, MI=0.09531, FA=0.04876, CF=0.02888, over 0.00 frames. 
2025-02-13 16:15:05,928 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 16:17:47,008 (train_accelerate_ddp:713) INFO: end of epoch 4, batch_idx: 4113 batch_idx_train: 16455, {'loss': 0.10953649878501892, 'DER': 0.26983655274888557, 'ACC': np.float64(0.9517857142857143), 'MI': 0.17652303120356613, 'FA': 0.04219910846953938, 'CF': 0.05111441307578009}, batch size: 64, grad_norm: 0.18554744124412537, grad_scale: , lr: 3.94e-05, 
2025-02-13 16:17:47,010 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/epoch-4.pt
2025-02-13 16:17:47,011 (train_accelerate_ddp:713) INFO: end of epoch 4, batch_idx: 4113 batch_idx_train: 16455, {'loss': 0.11180341243743896, 'DER': 0.2753433616742969, 'ACC': np.float64(0.9482142857142857), 'MI': 0.15158782065256884, 'FA': 0.06191410507957271, 'CF': 0.06184143594215537}, batch size: 64, grad_norm: 0.18554744124412537, grad_scale: , lr: 3.94e-05, 
2025-02-13 16:17:47,300 (train_accelerate_ddp:561) INFO:  end of epoch 4, Saved checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/epoch-4.pt 
2025-02-13 16:17:49,998 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 16456, num_updates: 16000, {'loss': 0.10184343159198761, 'DER': 0.25442086648983203, 'ACC': np.float64(0.9543303571428571), 'MI': 0.13807839669908636, 'FA': 0.06926024167403477, 'CF': 0.047082228116710874}, batch size: 64, grad_norm: 0.12275785207748413, grad_scale: , lr: 3.94e-05, 
2025-02-13 16:17:49,998 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 16456, num_updates: 16000, {'loss': 0.09257842600345612, 'DER': 0.20756370008030955, 'ACC': np.float64(0.9628683035714286), 'MI': 0.11206833613199971, 'FA': 0.06015915893991385, 'CF': 0.035336205008396}, batch size: 64, grad_norm: 0.12275785207748413, grad_scale: , lr: 3.94e-05, 
2025-02-13 16:18:50,514 (checkpoint:75) INFO: Saving checkpoint to /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_cam++_200k_zh_cn_epoch20_front_fix_seed_lr2e4_single_backend_2layer_conformer_multi_backend_transformer_rs_len8/checkpoint-16500.pt
2025-02-13 16:18:50,912 (checkpoint:473) INFO: currently, remove unused checkpoint-*.pt
2025-02-13 16:18:50,914 (checkpoint:362) INFO: currently, remove unused epoch-*.pt
2025-02-13 16:29:52,639 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 16956, num_updates: 16500, {'loss': 0.11016184836626053, 'DER': 0.24541017894492215, 'ACC': np.float64(0.954486607142857), 'MI': 0.1116275466728639, 'FA': 0.06328917809280347, 'CF': 0.07049345417925479}, batch size: 64, grad_norm: 0.2311488837003708, grad_scale: , lr: 3.38e-05, 
2025-02-13 16:29:52,640 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 16:29:52,641 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 16956, num_updates: 16500, {'loss': 0.1273977905511856, 'DER': 0.30253164556962026, 'ACC': np.float64(0.9412702153687305), 'MI': 0.16969057665260198, 'FA': 0.06736990154711674, 'CF': 0.06547116736990155}, batch size: 64, grad_norm: 0.2311488837003708, grad_scale: , lr: 3.38e-05, 
2025-02-13 16:29:52,641 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 16:30:42,233 (model:925) WARNING: All labels are zero
2025-02-13 16:30:42,785 (model:925) WARNING: All labels are zero
2025-02-13 16:30:42,827 (model:925) WARNING: All labels are zero
2025-02-13 16:32:14,976 (model:925) WARNING: All labels are zero
2025-02-13 16:32:27,084 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 16956,  validation: loss=0.07372, DER=0.1686, ACC=0.9653, MI=0.0943, FA=0.04728, CF=0.02704, over 0.00 frames. 
2025-02-13 16:32:27,085 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 16:32:27,233 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 16956,  validation: loss=0.07201, DER=0.1663, ACC=0.9665, MI=0.09222, FA=0.04929, CF=0.02477, over 0.00 frames. 
2025-02-13 16:32:27,233 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 16:44:31,769 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 17456, num_updates: 17000, {'loss': 0.10866890102624893, 'DER': 0.26689306258229956, 'ACC': np.float64(0.9499665178571429), 'MI': 0.1591932912883776, 'FA': 0.06389909210617506, 'CF': 0.043800679187746897}, batch size: 64, grad_norm: 0.14578230679035187, grad_scale: , lr: 2.83e-05, 
2025-02-13 16:44:31,769 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 16:44:31,771 (train_accelerate_ddp:702) INFO: [Train] - Epoch 5, batch_idx_train: 17456, num_updates: 17000, {'loss': 0.0875832661986351, 'DER': 0.2071044602644196, 'ACC': np.float64(0.9626674107142857), 'MI': 0.10845561528403312, 'FA': 0.06276332994333866, 'CF': 0.0358855150370478}, batch size: 64, grad_norm: 0.14578230679035187, grad_scale: , lr: 2.83e-05, 
2025-02-13 16:44:31,771 (train_accelerate_ddp:720) INFO: Computing validation loss
2025-02-13 16:45:20,558 (model:925) WARNING: All labels are zero
2025-02-13 16:45:21,106 (model:925) WARNING: All labels are zero
2025-02-13 16:45:21,128 (model:925) WARNING: All labels are zero
2025-02-13 16:46:51,182 (model:925) WARNING: All labels are zero
2025-02-13 16:47:03,252 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 17456,  validation: loss=0.07715, DER=0.1755, ACC=0.9636, MI=0.09731, FA=0.04751, CF=0.03068, over 0.00 frames. 
2025-02-13 16:47:03,252 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
2025-02-13 16:47:03,255 (train_accelerate_ddp:728) INFO: [Eval] - Epoch 5, batch_idx_train: 17456,  validation: loss=0.07564, DER=0.1757, ACC=0.9645, MI=0.09625, FA=0.05092, CF=0.02855, over 0.00 frames. 
2025-02-13 16:47:03,256 (train_accelerate_ddp:732) INFO: Maximum memory allocated so far is 12491MB
[rank0]: Traceback (most recent call last):
[rank0]:   File "/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/train_accelerate_ddp.py", line 1075, in <module>
[rank0]:   File "/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/train_accelerate_ddp.py", line 1039, in main
[rank0]:   File "/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/train_accelerate_ddp.py", line 634, in train_one_epoch
[rank0]:   File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/accelerate/data_loader.py", line 561, in __iter__
[rank0]:   File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
[rank0]:   File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 673, in _next_data
[rank0]:   File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
[rank0]:   File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
[rank0]:   File "/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/ts_vad_dataset.py", line 599, in __getitem__
[rank0]:   File "/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/ts_vad_dataset.py", line 414, in load_ts_embed
[rank0]:   File "/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/ts_vad_dataset.py", line 398, in load_alimeeting_ts_embed
[rank0]:   File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/serialization.py", line 1065, in load
[rank0]:   File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/serialization.py", line 468, in _open_file_like
[rank0]:   File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/serialization.py", line 449, in __init__
[rank0]: OSError: [Errno 23] Too many open files in system: '/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4/train/cam++_zh-cn_200k_feature_dir/R0008_M0063_MS006/4.pt'
Exception ignored in atexit callback: <function dump_compile_times at 0x155443ce3420>
Traceback (most recent call last):
  File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/_dynamo/utils.py", line 335, in dump_compile_times
  File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/_dynamo/utils.py", line 322, in compile_times
  File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/_dynamo/utils.py", line 127, in tabulate
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1073, in get_code
  File "<frozen importlib._bootstrap_external>", line 1130, in get_data
OSError: [Errno 23] Too many open files in system: '/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/tabulate/__init__.py'
[rank1]: Traceback (most recent call last):
[rank1]:   File "/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/train_accelerate_ddp.py", line 1075, in <module>
[rank1]:   File "/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/train_accelerate_ddp.py", line 1039, in main
[rank1]:   File "/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/train_accelerate_ddp.py", line 634, in train_one_epoch
[rank1]:   File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/accelerate/data_loader.py", line 561, in __iter__
[rank1]:   File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
[rank1]:   File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 673, in _next_data
[rank1]:   File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
[rank1]:   File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
[rank1]:   File "/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/ts_vad_dataset.py", line 599, in __getitem__
[rank1]:   File "/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/ts_vad_dataset.py", line 414, in load_ts_embed
[rank1]:   File "/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/ts_vad_dataset.py", line 392, in load_alimeeting_ts_embed
[rank1]:   File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/serialization.py", line 1065, in load
[rank1]:   File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/serialization.py", line 468, in _open_file_like
[rank1]:   File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/serialization.py", line 449, in __init__
[rank1]: OSError: [Errno 23] Too many open files in system: '/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/data/alimeeting_ami_aishell_4/train/cam++_zh-cn_200k_feature_dir/R0020_M0185_MS005/3.pt'
Exception ignored in atexit callback: <function dump_compile_times at 0x155443fe36a0>
Traceback (most recent call last):
  File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/_dynamo/utils.py", line 335, in dump_compile_times
  File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/_dynamo/utils.py", line 322, in compile_times
  File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/_dynamo/utils.py", line 127, in tabulate
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1073, in get_code
  File "<frozen importlib._bootstrap_external>", line 1130, in get_data
OSError: [Errno 23] Too many open files in system: '/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/tabulate/__init__.py'
pgpu27:1899002:1899347 [1] NCCL INFO [Service thread] Connection closed by localRank 1
[rank0]:[W213 16:53:35.104015983 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
pgpu27:1899001:1899348 [0] NCCL INFO [Service thread] Connection closed by localRank 0
pgpu27:1899002:2000241 [1] NCCL INFO comm 0x55557b0f3e80 rank 1 nranks 2 cudaDev 1 busId e2000 - Abort COMPLETE
pgpu27:1899001:2000242 [0] NCCL INFO comm 0x555560ff7980 rank 0 nranks 2 cudaDev 0 busId 2b000 - Abort COMPLETE
W0213 16:53:37.215000 23456247940928 torch/distributed/elastic/multiprocessing/api.py:858] Sending process 1899001 closing signal SIGTERM
E0213 16:53:37.629000 23456247940928 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 1 (pid: 1899002) of binary: /mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/bin/python3.11
Traceback (most recent call last):
  File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/bin/accelerate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/accelerate/commands/accelerate_cli.py", line 48, in main
    args.func(args)
  File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/accelerate/commands/launch.py", line 1165, in launch_command
    multi_gpu_launcher(args)
  File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/accelerate/commands/launch.py", line 799, in multi_gpu_launcher
    distrib_run.run(args)
  File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
ts_vad2/train_accelerate_ddp.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-02-13_16:53:37
  host      : pgpu27.cm.cluster
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 1899002)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
