2025-02-06 10:15:31,191 (infer:256) INFO: infer data_cfg: TSVADDataConfig(data_dir='/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/datasets/aishell-4/data_processed', ts_len=6000, rs_len=10, segment_shift=1, spk_path='/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/model_hub/ts_vad/spk_embed/aishell_4/SpeakerEmbedding/', speech_encoder_type='w2v-bert2', speaker_embedding_name_dir='cam++_zh-cn_200k_feature_dir', speaker_embed_dim=192, noise_ratio=0.8, zero_ratio=0.3, sample_rate=16000, max_num_speaker=7, dataset_name='alimeeting', embed_input=False, embed_len=1, embed_shift=0.4, label_rate=25, random_channel=False, random_mask_speaker_prob=0.0, random_mask_speaker_step=0, musan_path='/mntcephfs/lee_dataset/asr/musan', rir_path='/mntcephfs/lee_dataset/asr/RIRS_NOISES')
2025-02-06 10:15:31,191 (infer:257) INFO: currently, it will infer test set.
  0%|          | 0/116 [00:00<?, ?it/s] 33%|███▎      | 38/116 [00:00<00:00, 369.27it/s] 65%|██████▍   | 75/116 [00:00<00:00, 369.20it/s] 97%|█████████▋| 112/116 [00:00<00:00, 357.56it/s]100%|██████████| 116/116 [00:00<00:00, 362.53it/s]
2025-02-06 10:15:31,537 (ts_vad_dataset:152) INFO: model expect fbank as input , fbank_input should be True !!!
2025-02-06 10:15:31,538 (ts_vad_dataset:160) INFO: loaded sentence=45820, shortest sent=1280.0, longest sent=160000.0, rs_len=10, segment_shift=1,  rir=False, musan=False, noise_ratio=0.8, zero_ratio=0.3 
2025-02-06 10:15:31,614 (infer:279) INFO: Device: cuda:0
2025-02-06 10:15:31,614 (infer:297) INFO: infer model_cfg: TSVADConfig(speech_encoder_path='/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/w2v-bert2.0/model.safetensors', speech_encoder_type='w2v-bert2', freeze_speech_encoder_updates=4000, num_attention_head=4, num_transformer_layer=2, transformer_embed_dim=384, transformer_ffn_embed_dim=1536, speaker_embed_dim=192, dropout=0.1, use_spk_embed=True, feature_grad_mult=0.1, whisper_n_mels=80, select_encoder_layer_nums=6, wavlm_fuse_feat_post_norm=False, speech_encoder_config='/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/w2v-bert2.0/config.json', single_backend_type='mamba2', multi_backend_type='transformer', d_state=256, expand=4)
Some weights of the model checkpoint at /mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/w2v-bert2.0/model.safetensors were not used when initializing Wav2Vec2BertModel: ['encoder.layers.10.conv_module.depthwise_conv.weight', 'encoder.layers.10.conv_module.depthwise_layer_norm.bias', 'encoder.layers.10.conv_module.depthwise_layer_norm.weight', 'encoder.layers.10.conv_module.layer_norm.bias', 'encoder.layers.10.conv_module.layer_norm.weight', 'encoder.layers.10.conv_module.pointwise_conv1.weight', 'encoder.layers.10.conv_module.pointwise_conv2.weight', 'encoder.layers.10.ffn1.intermediate_dense.bias', 'encoder.layers.10.ffn1.intermediate_dense.weight', 'encoder.layers.10.ffn1.output_dense.bias', 'encoder.layers.10.ffn1.output_dense.weight', 'encoder.layers.10.ffn1_layer_norm.bias', 'encoder.layers.10.ffn1_layer_norm.weight', 'encoder.layers.10.ffn2.intermediate_dense.bias', 'encoder.layers.10.ffn2.intermediate_dense.weight', 'encoder.layers.10.ffn2.output_dense.bias', 'encoder.layers.10.ffn2.output_dense.weight', 'encoder.layers.10.ffn2_layer_norm.bias', 'encoder.layers.10.ffn2_layer_norm.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.self_attn.distance_embedding.weight', 'encoder.layers.10.self_attn.linear_k.bias', 'encoder.layers.10.self_attn.linear_k.weight', 'encoder.layers.10.self_attn.linear_out.bias', 'encoder.layers.10.self_attn.linear_out.weight', 'encoder.layers.10.self_attn.linear_q.bias', 'encoder.layers.10.self_attn.linear_q.weight', 'encoder.layers.10.self_attn.linear_v.bias', 'encoder.layers.10.self_attn.linear_v.weight', 'encoder.layers.10.self_attn_layer_norm.bias', 'encoder.layers.10.self_attn_layer_norm.weight', 'encoder.layers.11.conv_module.depthwise_conv.weight', 'encoder.layers.11.conv_module.depthwise_layer_norm.bias', 'encoder.layers.11.conv_module.depthwise_layer_norm.weight', 'encoder.layers.11.conv_module.layer_norm.bias', 'encoder.layers.11.conv_module.layer_norm.weight', 'encoder.layers.11.conv_module.pointwise_conv1.weight', 'encoder.layers.11.conv_module.pointwise_conv2.weight', 'encoder.layers.11.ffn1.intermediate_dense.bias', 'encoder.layers.11.ffn1.intermediate_dense.weight', 'encoder.layers.11.ffn1.output_dense.bias', 'encoder.layers.11.ffn1.output_dense.weight', 'encoder.layers.11.ffn1_layer_norm.bias', 'encoder.layers.11.ffn1_layer_norm.weight', 'encoder.layers.11.ffn2.intermediate_dense.bias', 'encoder.layers.11.ffn2.intermediate_dense.weight', 'encoder.layers.11.ffn2.output_dense.bias', 'encoder.layers.11.ffn2.output_dense.weight', 'encoder.layers.11.ffn2_layer_norm.bias', 'encoder.layers.11.ffn2_layer_norm.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.self_attn.distance_embedding.weight', 'encoder.layers.11.self_attn.linear_k.bias', 'encoder.layers.11.self_attn.linear_k.weight', 'encoder.layers.11.self_attn.linear_out.bias', 'encoder.layers.11.self_attn.linear_out.weight', 'encoder.layers.11.self_attn.linear_q.bias', 'encoder.layers.11.self_attn.linear_q.weight', 'encoder.layers.11.self_attn.linear_v.bias', 'encoder.layers.11.self_attn.linear_v.weight', 'encoder.layers.11.self_attn_layer_norm.bias', 'encoder.layers.11.self_attn_layer_norm.weight', 'encoder.layers.12.conv_module.depthwise_conv.weight', 'encoder.layers.12.conv_module.depthwise_layer_norm.bias', 'encoder.layers.12.conv_module.depthwise_layer_norm.weight', 'encoder.layers.12.conv_module.layer_norm.bias', 'encoder.layers.12.conv_module.layer_norm.weight', 'encoder.layers.12.conv_module.pointwise_conv1.weight', 'encoder.layers.12.conv_module.pointwise_conv2.weight', 'encoder.layers.12.ffn1.intermediate_dense.bias', 'encoder.layers.12.ffn1.intermediate_dense.weight', 'encoder.layers.12.ffn1.output_dense.bias', 'encoder.layers.12.ffn1.output_dense.weight', 'encoder.layers.12.ffn1_layer_norm.bias', 'encoder.layers.12.ffn1_layer_norm.weight', 'encoder.layers.12.ffn2.intermediate_dense.bias', 'encoder.layers.12.ffn2.intermediate_dense.weight', 'encoder.layers.12.ffn2.output_dense.bias', 'encoder.layers.12.ffn2.output_dense.weight', 'encoder.layers.12.ffn2_layer_norm.bias', 'encoder.layers.12.ffn2_layer_norm.weight', 'encoder.layers.12.final_layer_norm.bias', 'encoder.layers.12.final_layer_norm.weight', 'encoder.layers.12.self_attn.distance_embedding.weight', 'encoder.layers.12.self_attn.linear_k.bias', 'encoder.layers.12.self_attn.linear_k.weight', 'encoder.layers.12.self_attn.linear_out.bias', 'encoder.layers.12.self_attn.linear_out.weight', 'encoder.layers.12.self_attn.linear_q.bias', 'encoder.layers.12.self_attn.linear_q.weight', 'encoder.layers.12.self_attn.linear_v.bias', 'encoder.layers.12.self_attn.linear_v.weight', 'encoder.layers.12.self_attn_layer_norm.bias', 'encoder.layers.12.self_attn_layer_norm.weight', 'encoder.layers.13.conv_module.depthwise_conv.weight', 'encoder.layers.13.conv_module.depthwise_layer_norm.bias', 'encoder.layers.13.conv_module.depthwise_layer_norm.weight', 'encoder.layers.13.conv_module.layer_norm.bias', 'encoder.layers.13.conv_module.layer_norm.weight', 'encoder.layers.13.conv_module.pointwise_conv1.weight', 'encoder.layers.13.conv_module.pointwise_conv2.weight', 'encoder.layers.13.ffn1.intermediate_dense.bias', 'encoder.layers.13.ffn1.intermediate_dense.weight', 'encoder.layers.13.ffn1.output_dense.bias', 'encoder.layers.13.ffn1.output_dense.weight', 'encoder.layers.13.ffn1_layer_norm.bias', 'encoder.layers.13.ffn1_layer_norm.weight', 'encoder.layers.13.ffn2.intermediate_dense.bias', 'encoder.layers.13.ffn2.intermediate_dense.weight', 'encoder.layers.13.ffn2.output_dense.bias', 'encoder.layers.13.ffn2.output_dense.weight', 'encoder.layers.13.ffn2_layer_norm.bias', 'encoder.layers.13.ffn2_layer_norm.weight', 'encoder.layers.13.final_layer_norm.bias', 'encoder.layers.13.final_layer_norm.weight', 'encoder.layers.13.self_attn.distance_embedding.weight', 'encoder.layers.13.self_attn.linear_k.bias', 'encoder.layers.13.self_attn.linear_k.weight', 'encoder.layers.13.self_attn.linear_out.bias', 'encoder.layers.13.self_attn.linear_out.weight', 'encoder.layers.13.self_attn.linear_q.bias', 'encoder.layers.13.self_attn.linear_q.weight', 'encoder.layers.13.self_attn.linear_v.bias', 'encoder.layers.13.self_attn.linear_v.weight', 'encoder.layers.13.self_attn_layer_norm.bias', 'encoder.layers.13.self_attn_layer_norm.weight', 'encoder.layers.14.conv_module.depthwise_conv.weight', 'encoder.layers.14.conv_module.depthwise_layer_norm.bias', 'encoder.layers.14.conv_module.depthwise_layer_norm.weight', 'encoder.layers.14.conv_module.layer_norm.bias', 'encoder.layers.14.conv_module.layer_norm.weight', 'encoder.layers.14.conv_module.pointwise_conv1.weight', 'encoder.layers.14.conv_module.pointwise_conv2.weight', 'encoder.layers.14.ffn1.intermediate_dense.bias', 'encoder.layers.14.ffn1.intermediate_dense.weight', 'encoder.layers.14.ffn1.output_dense.bias', 'encoder.layers.14.ffn1.output_dense.weight', 'encoder.layers.14.ffn1_layer_norm.bias', 'encoder.layers.14.ffn1_layer_norm.weight', 'encoder.layers.14.ffn2.intermediate_dense.bias', 'encoder.layers.14.ffn2.intermediate_dense.weight', 'encoder.layers.14.ffn2.output_dense.bias', 'encoder.layers.14.ffn2.output_dense.weight', 'encoder.layers.14.ffn2_layer_norm.bias', 'encoder.layers.14.ffn2_layer_norm.weight', 'encoder.layers.14.final_layer_norm.bias', 'encoder.layers.14.final_layer_norm.weight', 'encoder.layers.14.self_attn.distance_embedding.weight', 'encoder.layers.14.self_attn.linear_k.bias', 'encoder.layers.14.self_attn.linear_k.weight', 'encoder.layers.14.self_attn.linear_out.bias', 'encoder.layers.14.self_attn.linear_out.weight', 'encoder.layers.14.self_attn.linear_q.bias', 'encoder.layers.14.self_attn.linear_q.weight', 'encoder.layers.14.self_attn.linear_v.bias', 'encoder.layers.14.self_attn.linear_v.weight', 'encoder.layers.14.self_attn_layer_norm.bias', 'encoder.layers.14.self_attn_layer_norm.weight', 'encoder.layers.15.conv_module.depthwise_conv.weight', 'encoder.layers.15.conv_module.depthwise_layer_norm.bias', 'encoder.layers.15.conv_module.depthwise_layer_norm.weight', 'encoder.layers.15.conv_module.layer_norm.bias', 'encoder.layers.15.conv_module.layer_norm.weight', 'encoder.layers.15.conv_module.pointwise_conv1.weight', 'encoder.layers.15.conv_module.pointwise_conv2.weight', 'encoder.layers.15.ffn1.intermediate_dense.bias', 'encoder.layers.15.ffn1.intermediate_dense.weight', 'encoder.layers.15.ffn1.output_dense.bias', 'encoder.layers.15.ffn1.output_dense.weight', 'encoder.layers.15.ffn1_layer_norm.bias', 'encoder.layers.15.ffn1_layer_norm.weight', 'encoder.layers.15.ffn2.intermediate_dense.bias', 'encoder.layers.15.ffn2.intermediate_dense.weight', 'encoder.layers.15.ffn2.output_dense.bias', 'encoder.layers.15.ffn2.output_dense.weight', 'encoder.layers.15.ffn2_layer_norm.bias', 'encoder.layers.15.ffn2_layer_norm.weight', 'encoder.layers.15.final_layer_norm.bias', 'encoder.layers.15.final_layer_norm.weight', 'encoder.layers.15.self_attn.distance_embedding.weight', 'encoder.layers.15.self_attn.linear_k.bias', 'encoder.layers.15.self_attn.linear_k.weight', 'encoder.layers.15.self_attn.linear_out.bias', 'encoder.layers.15.self_attn.linear_out.weight', 'encoder.layers.15.self_attn.linear_q.bias', 'encoder.layers.15.self_attn.linear_q.weight', 'encoder.layers.15.self_attn.linear_v.bias', 'encoder.layers.15.self_attn.linear_v.weight', 'encoder.layers.15.self_attn_layer_norm.bias', 'encoder.layers.15.self_attn_layer_norm.weight', 'encoder.layers.16.conv_module.depthwise_conv.weight', 'encoder.layers.16.conv_module.depthwise_layer_norm.bias', 'encoder.layers.16.conv_module.depthwise_layer_norm.weight', 'encoder.layers.16.conv_module.layer_norm.bias', 'encoder.layers.16.conv_module.layer_norm.weight', 'encoder.layers.16.conv_module.pointwise_conv1.weight', 'encoder.layers.16.conv_module.pointwise_conv2.weight', 'encoder.layers.16.ffn1.intermediate_dense.bias', 'encoder.layers.16.ffn1.intermediate_dense.weight', 'encoder.layers.16.ffn1.output_dense.bias', 'encoder.layers.16.ffn1.output_dense.weight', 'encoder.layers.16.ffn1_layer_norm.bias', 'encoder.layers.16.ffn1_layer_norm.weight', 'encoder.layers.16.ffn2.intermediate_dense.bias', 'encoder.layers.16.ffn2.intermediate_dense.weight', 'encoder.layers.16.ffn2.output_dense.bias', 'encoder.layers.16.ffn2.output_dense.weight', 'encoder.layers.16.ffn2_layer_norm.bias', 'encoder.layers.16.ffn2_layer_norm.weight', 'encoder.layers.16.final_layer_norm.bias', 'encoder.layers.16.final_layer_norm.weight', 'encoder.layers.16.self_attn.distance_embedding.weight', 'encoder.layers.16.self_attn.linear_k.bias', 'encoder.layers.16.self_attn.linear_k.weight', 'encoder.layers.16.self_attn.linear_out.bias', 'encoder.layers.16.self_attn.linear_out.weight', 'encoder.layers.16.self_attn.linear_q.bias', 'encoder.layers.16.self_attn.linear_q.weight', 'encoder.layers.16.self_attn.linear_v.bias', 'encoder.layers.16.self_attn.linear_v.weight', 'encoder.layers.16.self_attn_layer_norm.bias', 'encoder.layers.16.self_attn_layer_norm.weight', 'encoder.layers.17.conv_module.depthwise_conv.weight', 'encoder.layers.17.conv_module.depthwise_layer_norm.bias', 'encoder.layers.17.conv_module.depthwise_layer_norm.weight', 'encoder.layers.17.conv_module.layer_norm.bias', 'encoder.layers.17.conv_module.layer_norm.weight', 'encoder.layers.17.conv_module.pointwise_conv1.weight', 'encoder.layers.17.conv_module.pointwise_conv2.weight', 'encoder.layers.17.ffn1.intermediate_dense.bias', 'encoder.layers.17.ffn1.intermediate_dense.weight', 'encoder.layers.17.ffn1.output_dense.bias', 'encoder.layers.17.ffn1.output_dense.weight', 'encoder.layers.17.ffn1_layer_norm.bias', 'encoder.layers.17.ffn1_layer_norm.weight', 'encoder.layers.17.ffn2.intermediate_dense.bias', 'encoder.layers.17.ffn2.intermediate_dense.weight', 'encoder.layers.17.ffn2.output_dense.bias', 'encoder.layers.17.ffn2.output_dense.weight', 'encoder.layers.17.ffn2_layer_norm.bias', 'encoder.layers.17.ffn2_layer_norm.weight', 'encoder.layers.17.final_layer_norm.bias', 'encoder.layers.17.final_layer_norm.weight', 'encoder.layers.17.self_attn.distance_embedding.weight', 'encoder.layers.17.self_attn.linear_k.bias', 'encoder.layers.17.self_attn.linear_k.weight', 'encoder.layers.17.self_attn.linear_out.bias', 'encoder.layers.17.self_attn.linear_out.weight', 'encoder.layers.17.self_attn.linear_q.bias', 'encoder.layers.17.self_attn.linear_q.weight', 'encoder.layers.17.self_attn.linear_v.bias', 'encoder.layers.17.self_attn.linear_v.weight', 'encoder.layers.17.self_attn_layer_norm.bias', 'encoder.layers.17.self_attn_layer_norm.weight', 'encoder.layers.18.conv_module.depthwise_conv.weight', 'encoder.layers.18.conv_module.depthwise_layer_norm.bias', 'encoder.layers.18.conv_module.depthwise_layer_norm.weight', 'encoder.layers.18.conv_module.layer_norm.bias', 'encoder.layers.18.conv_module.layer_norm.weight', 'encoder.layers.18.conv_module.pointwise_conv1.weight', 'encoder.layers.18.conv_module.pointwise_conv2.weight', 'encoder.layers.18.ffn1.intermediate_dense.bias', 'encoder.layers.18.ffn1.intermediate_dense.weight', 'encoder.layers.18.ffn1.output_dense.bias', 'encoder.layers.18.ffn1.output_dense.weight', 'encoder.layers.18.ffn1_layer_norm.bias', 'encoder.layers.18.ffn1_layer_norm.weight', 'encoder.layers.18.ffn2.intermediate_dense.bias', 'encoder.layers.18.ffn2.intermediate_dense.weight', 'encoder.layers.18.ffn2.output_dense.bias', 'encoder.layers.18.ffn2.output_dense.weight', 'encoder.layers.18.ffn2_layer_norm.bias', 'encoder.layers.18.ffn2_layer_norm.weight', 'encoder.layers.18.final_layer_norm.bias', 'encoder.layers.18.final_layer_norm.weight', 'encoder.layers.18.self_attn.distance_embedding.weight', 'encoder.layers.18.self_attn.linear_k.bias', 'encoder.layers.18.self_attn.linear_k.weight', 'encoder.layers.18.self_attn.linear_out.bias', 'encoder.layers.18.self_attn.linear_out.weight', 'encoder.layers.18.self_attn.linear_q.bias', 'encoder.layers.18.self_attn.linear_q.weight', 'encoder.layers.18.self_attn.linear_v.bias', 'encoder.layers.18.self_attn.linear_v.weight', 'encoder.layers.18.self_attn_layer_norm.bias', 'encoder.layers.18.self_attn_layer_norm.weight', 'encoder.layers.19.conv_module.depthwise_conv.weight', 'encoder.layers.19.conv_module.depthwise_layer_norm.bias', 'encoder.layers.19.conv_module.depthwise_layer_norm.weight', 'encoder.layers.19.conv_module.layer_norm.bias', 'encoder.layers.19.conv_module.layer_norm.weight', 'encoder.layers.19.conv_module.pointwise_conv1.weight', 'encoder.layers.19.conv_module.pointwise_conv2.weight', 'encoder.layers.19.ffn1.intermediate_dense.bias', 'encoder.layers.19.ffn1.intermediate_dense.weight', 'encoder.layers.19.ffn1.output_dense.bias', 'encoder.layers.19.ffn1.output_dense.weight', 'encoder.layers.19.ffn1_layer_norm.bias', 'encoder.layers.19.ffn1_layer_norm.weight', 'encoder.layers.19.ffn2.intermediate_dense.bias', 'encoder.layers.19.ffn2.intermediate_dense.weight', 'encoder.layers.19.ffn2.output_dense.bias', 'encoder.layers.19.ffn2.output_dense.weight', 'encoder.layers.19.ffn2_layer_norm.bias', 'encoder.layers.19.ffn2_layer_norm.weight', 'encoder.layers.19.final_layer_norm.bias', 'encoder.layers.19.final_layer_norm.weight', 'encoder.layers.19.self_attn.distance_embedding.weight', 'encoder.layers.19.self_attn.linear_k.bias', 'encoder.layers.19.self_attn.linear_k.weight', 'encoder.layers.19.self_attn.linear_out.bias', 'encoder.layers.19.self_attn.linear_out.weight', 'encoder.layers.19.self_attn.linear_q.bias', 'encoder.layers.19.self_attn.linear_q.weight', 'encoder.layers.19.self_attn.linear_v.bias', 'encoder.layers.19.self_attn.linear_v.weight', 'encoder.layers.19.self_attn_layer_norm.bias', 'encoder.layers.19.self_attn_layer_norm.weight', 'encoder.layers.20.conv_module.depthwise_conv.weight', 'encoder.layers.20.conv_module.depthwise_layer_norm.bias', 'encoder.layers.20.conv_module.depthwise_layer_norm.weight', 'encoder.layers.20.conv_module.layer_norm.bias', 'encoder.layers.20.conv_module.layer_norm.weight', 'encoder.layers.20.conv_module.pointwise_conv1.weight', 'encoder.layers.20.conv_module.pointwise_conv2.weight', 'encoder.layers.20.ffn1.intermediate_dense.bias', 'encoder.layers.20.ffn1.intermediate_dense.weight', 'encoder.layers.20.ffn1.output_dense.bias', 'encoder.layers.20.ffn1.output_dense.weight', 'encoder.layers.20.ffn1_layer_norm.bias', 'encoder.layers.20.ffn1_layer_norm.weight', 'encoder.layers.20.ffn2.intermediate_dense.bias', 'encoder.layers.20.ffn2.intermediate_dense.weight', 'encoder.layers.20.ffn2.output_dense.bias', 'encoder.layers.20.ffn2.output_dense.weight', 'encoder.layers.20.ffn2_layer_norm.bias', 'encoder.layers.20.ffn2_layer_norm.weight', 'encoder.layers.20.final_layer_norm.bias', 'encoder.layers.20.final_layer_norm.weight', 'encoder.layers.20.self_attn.distance_embedding.weight', 'encoder.layers.20.self_attn.linear_k.bias', 'encoder.layers.20.self_attn.linear_k.weight', 'encoder.layers.20.self_attn.linear_out.bias', 'encoder.layers.20.self_attn.linear_out.weight', 'encoder.layers.20.self_attn.linear_q.bias', 'encoder.layers.20.self_attn.linear_q.weight', 'encoder.layers.20.self_attn.linear_v.bias', 'encoder.layers.20.self_attn.linear_v.weight', 'encoder.layers.20.self_attn_layer_norm.bias', 'encoder.layers.20.self_attn_layer_norm.weight', 'encoder.layers.21.conv_module.depthwise_conv.weight', 'encoder.layers.21.conv_module.depthwise_layer_norm.bias', 'encoder.layers.21.conv_module.depthwise_layer_norm.weight', 'encoder.layers.21.conv_module.layer_norm.bias', 'encoder.layers.21.conv_module.layer_norm.weight', 'encoder.layers.21.conv_module.pointwise_conv1.weight', 'encoder.layers.21.conv_module.pointwise_conv2.weight', 'encoder.layers.21.ffn1.intermediate_dense.bias', 'encoder.layers.21.ffn1.intermediate_dense.weight', 'encoder.layers.21.ffn1.output_dense.bias', 'encoder.layers.21.ffn1.output_dense.weight', 'encoder.layers.21.ffn1_layer_norm.bias', 'encoder.layers.21.ffn1_layer_norm.weight', 'encoder.layers.21.ffn2.intermediate_dense.bias', 'encoder.layers.21.ffn2.intermediate_dense.weight', 'encoder.layers.21.ffn2.output_dense.bias', 'encoder.layers.21.ffn2.output_dense.weight', 'encoder.layers.21.ffn2_layer_norm.bias', 'encoder.layers.21.ffn2_layer_norm.weight', 'encoder.layers.21.final_layer_norm.bias', 'encoder.layers.21.final_layer_norm.weight', 'encoder.layers.21.self_attn.distance_embedding.weight', 'encoder.layers.21.self_attn.linear_k.bias', 'encoder.layers.21.self_attn.linear_k.weight', 'encoder.layers.21.self_attn.linear_out.bias', 'encoder.layers.21.self_attn.linear_out.weight', 'encoder.layers.21.self_attn.linear_q.bias', 'encoder.layers.21.self_attn.linear_q.weight', 'encoder.layers.21.self_attn.linear_v.bias', 'encoder.layers.21.self_attn.linear_v.weight', 'encoder.layers.21.self_attn_layer_norm.bias', 'encoder.layers.21.self_attn_layer_norm.weight', 'encoder.layers.22.conv_module.depthwise_conv.weight', 'encoder.layers.22.conv_module.depthwise_layer_norm.bias', 'encoder.layers.22.conv_module.depthwise_layer_norm.weight', 'encoder.layers.22.conv_module.layer_norm.bias', 'encoder.layers.22.conv_module.layer_norm.weight', 'encoder.layers.22.conv_module.pointwise_conv1.weight', 'encoder.layers.22.conv_module.pointwise_conv2.weight', 'encoder.layers.22.ffn1.intermediate_dense.bias', 'encoder.layers.22.ffn1.intermediate_dense.weight', 'encoder.layers.22.ffn1.output_dense.bias', 'encoder.layers.22.ffn1.output_dense.weight', 'encoder.layers.22.ffn1_layer_norm.bias', 'encoder.layers.22.ffn1_layer_norm.weight', 'encoder.layers.22.ffn2.intermediate_dense.bias', 'encoder.layers.22.ffn2.intermediate_dense.weight', 'encoder.layers.22.ffn2.output_dense.bias', 'encoder.layers.22.ffn2.output_dense.weight', 'encoder.layers.22.ffn2_layer_norm.bias', 'encoder.layers.22.ffn2_layer_norm.weight', 'encoder.layers.22.final_layer_norm.bias', 'encoder.layers.22.final_layer_norm.weight', 'encoder.layers.22.self_attn.distance_embedding.weight', 'encoder.layers.22.self_attn.linear_k.bias', 'encoder.layers.22.self_attn.linear_k.weight', 'encoder.layers.22.self_attn.linear_out.bias', 'encoder.layers.22.self_attn.linear_out.weight', 'encoder.layers.22.self_attn.linear_q.bias', 'encoder.layers.22.self_attn.linear_q.weight', 'encoder.layers.22.self_attn.linear_v.bias', 'encoder.layers.22.self_attn.linear_v.weight', 'encoder.layers.22.self_attn_layer_norm.bias', 'encoder.layers.22.self_attn_layer_norm.weight', 'encoder.layers.23.conv_module.depthwise_conv.weight', 'encoder.layers.23.conv_module.depthwise_layer_norm.bias', 'encoder.layers.23.conv_module.depthwise_layer_norm.weight', 'encoder.layers.23.conv_module.layer_norm.bias', 'encoder.layers.23.conv_module.layer_norm.weight', 'encoder.layers.23.conv_module.pointwise_conv1.weight', 'encoder.layers.23.conv_module.pointwise_conv2.weight', 'encoder.layers.23.ffn1.intermediate_dense.bias', 'encoder.layers.23.ffn1.intermediate_dense.weight', 'encoder.layers.23.ffn1.output_dense.bias', 'encoder.layers.23.ffn1.output_dense.weight', 'encoder.layers.23.ffn1_layer_norm.bias', 'encoder.layers.23.ffn1_layer_norm.weight', 'encoder.layers.23.ffn2.intermediate_dense.bias', 'encoder.layers.23.ffn2.intermediate_dense.weight', 'encoder.layers.23.ffn2.output_dense.bias', 'encoder.layers.23.ffn2.output_dense.weight', 'encoder.layers.23.ffn2_layer_norm.bias', 'encoder.layers.23.ffn2_layer_norm.weight', 'encoder.layers.23.final_layer_norm.bias', 'encoder.layers.23.final_layer_norm.weight', 'encoder.layers.23.self_attn.distance_embedding.weight', 'encoder.layers.23.self_attn.linear_k.bias', 'encoder.layers.23.self_attn.linear_k.weight', 'encoder.layers.23.self_attn.linear_out.bias', 'encoder.layers.23.self_attn.linear_out.weight', 'encoder.layers.23.self_attn.linear_q.bias', 'encoder.layers.23.self_attn.linear_q.weight', 'encoder.layers.23.self_attn.linear_v.bias', 'encoder.layers.23.self_attn.linear_v.weight', 'encoder.layers.23.self_attn_layer_norm.bias', 'encoder.layers.23.self_attn_layer_norm.weight', 'encoder.layers.6.conv_module.depthwise_conv.weight', 'encoder.layers.6.conv_module.depthwise_layer_norm.bias', 'encoder.layers.6.conv_module.depthwise_layer_norm.weight', 'encoder.layers.6.conv_module.layer_norm.bias', 'encoder.layers.6.conv_module.layer_norm.weight', 'encoder.layers.6.conv_module.pointwise_conv1.weight', 'encoder.layers.6.conv_module.pointwise_conv2.weight', 'encoder.layers.6.ffn1.intermediate_dense.bias', 'encoder.layers.6.ffn1.intermediate_dense.weight', 'encoder.layers.6.ffn1.output_dense.bias', 'encoder.layers.6.ffn1.output_dense.weight', 'encoder.layers.6.ffn1_layer_norm.bias', 'encoder.layers.6.ffn1_layer_norm.weight', 'encoder.layers.6.ffn2.intermediate_dense.bias', 'encoder.layers.6.ffn2.intermediate_dense.weight', 'encoder.layers.6.ffn2.output_dense.bias', 'encoder.layers.6.ffn2.output_dense.weight', 'encoder.layers.6.ffn2_layer_norm.bias', 'encoder.layers.6.ffn2_layer_norm.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.self_attn.distance_embedding.weight', 'encoder.layers.6.self_attn.linear_k.bias', 'encoder.layers.6.self_attn.linear_k.weight', 'encoder.layers.6.self_attn.linear_out.bias', 'encoder.layers.6.self_attn.linear_out.weight', 'encoder.layers.6.self_attn.linear_q.bias', 'encoder.layers.6.self_attn.linear_q.weight', 'encoder.layers.6.self_attn.linear_v.bias', 'encoder.layers.6.self_attn.linear_v.weight', 'encoder.layers.6.self_attn_layer_norm.bias', 'encoder.layers.6.self_attn_layer_norm.weight', 'encoder.layers.7.conv_module.depthwise_conv.weight', 'encoder.layers.7.conv_module.depthwise_layer_norm.bias', 'encoder.layers.7.conv_module.depthwise_layer_norm.weight', 'encoder.layers.7.conv_module.layer_norm.bias', 'encoder.layers.7.conv_module.layer_norm.weight', 'encoder.layers.7.conv_module.pointwise_conv1.weight', 'encoder.layers.7.conv_module.pointwise_conv2.weight', 'encoder.layers.7.ffn1.intermediate_dense.bias', 'encoder.layers.7.ffn1.intermediate_dense.weight', 'encoder.layers.7.ffn1.output_dense.bias', 'encoder.layers.7.ffn1.output_dense.weight', 'encoder.layers.7.ffn1_layer_norm.bias', 'encoder.layers.7.ffn1_layer_norm.weight', 'encoder.layers.7.ffn2.intermediate_dense.bias', 'encoder.layers.7.ffn2.intermediate_dense.weight', 'encoder.layers.7.ffn2.output_dense.bias', 'encoder.layers.7.ffn2.output_dense.weight', 'encoder.layers.7.ffn2_layer_norm.bias', 'encoder.layers.7.ffn2_layer_norm.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.self_attn.distance_embedding.weight', 'encoder.layers.7.self_attn.linear_k.bias', 'encoder.layers.7.self_attn.linear_k.weight', 'encoder.layers.7.self_attn.linear_out.bias', 'encoder.layers.7.self_attn.linear_out.weight', 'encoder.layers.7.self_attn.linear_q.bias', 'encoder.layers.7.self_attn.linear_q.weight', 'encoder.layers.7.self_attn.linear_v.bias', 'encoder.layers.7.self_attn.linear_v.weight', 'encoder.layers.7.self_attn_layer_norm.bias', 'encoder.layers.7.self_attn_layer_norm.weight', 'encoder.layers.8.conv_module.depthwise_conv.weight', 'encoder.layers.8.conv_module.depthwise_layer_norm.bias', 'encoder.layers.8.conv_module.depthwise_layer_norm.weight', 'encoder.layers.8.conv_module.layer_norm.bias', 'encoder.layers.8.conv_module.layer_norm.weight', 'encoder.layers.8.conv_module.pointwise_conv1.weight', 'encoder.layers.8.conv_module.pointwise_conv2.weight', 'encoder.layers.8.ffn1.intermediate_dense.bias', 'encoder.layers.8.ffn1.intermediate_dense.weight', 'encoder.layers.8.ffn1.output_dense.bias', 'encoder.layers.8.ffn1.output_dense.weight', 'encoder.layers.8.ffn1_layer_norm.bias', 'encoder.layers.8.ffn1_layer_norm.weight', 'encoder.layers.8.ffn2.intermediate_dense.bias', 'encoder.layers.8.ffn2.intermediate_dense.weight', 'encoder.layers.8.ffn2.output_dense.bias', 'encoder.layers.8.ffn2.output_dense.weight', 'encoder.layers.8.ffn2_layer_norm.bias', 'encoder.layers.8.ffn2_layer_norm.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.self_attn.distance_embedding.weight', 'encoder.layers.8.self_attn.linear_k.bias', 'encoder.layers.8.self_attn.linear_k.weight', 'encoder.layers.8.self_attn.linear_out.bias', 'encoder.layers.8.self_attn.linear_out.weight', 'encoder.layers.8.self_attn.linear_q.bias', 'encoder.layers.8.self_attn.linear_q.weight', 'encoder.layers.8.self_attn.linear_v.bias', 'encoder.layers.8.self_attn.linear_v.weight', 'encoder.layers.8.self_attn_layer_norm.bias', 'encoder.layers.8.self_attn_layer_norm.weight', 'encoder.layers.9.conv_module.depthwise_conv.weight', 'encoder.layers.9.conv_module.depthwise_layer_norm.bias', 'encoder.layers.9.conv_module.depthwise_layer_norm.weight', 'encoder.layers.9.conv_module.layer_norm.bias', 'encoder.layers.9.conv_module.layer_norm.weight', 'encoder.layers.9.conv_module.pointwise_conv1.weight', 'encoder.layers.9.conv_module.pointwise_conv2.weight', 'encoder.layers.9.ffn1.intermediate_dense.bias', 'encoder.layers.9.ffn1.intermediate_dense.weight', 'encoder.layers.9.ffn1.output_dense.bias', 'encoder.layers.9.ffn1.output_dense.weight', 'encoder.layers.9.ffn1_layer_norm.bias', 'encoder.layers.9.ffn1_layer_norm.weight', 'encoder.layers.9.ffn2.intermediate_dense.bias', 'encoder.layers.9.ffn2.intermediate_dense.weight', 'encoder.layers.9.ffn2.output_dense.bias', 'encoder.layers.9.ffn2.output_dense.weight', 'encoder.layers.9.ffn2_layer_norm.bias', 'encoder.layers.9.ffn2_layer_norm.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.self_attn.distance_embedding.weight', 'encoder.layers.9.self_attn.linear_k.bias', 'encoder.layers.9.self_attn.linear_k.weight', 'encoder.layers.9.self_attn.linear_out.bias', 'encoder.layers.9.self_attn.linear_out.weight', 'encoder.layers.9.self_attn.linear_q.bias', 'encoder.layers.9.self_attn.linear_q.weight', 'encoder.layers.9.self_attn.linear_v.bias', 'encoder.layers.9.self_attn.linear_v.weight', 'encoder.layers.9.self_attn_layer_norm.bias', 'encoder.layers.9.self_attn_layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
2025-02-06 10:15:32,594 (infer:201) INFO: params.model_file: /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch20_front_fix_seed_lr1e4_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/best-valid-der.pt
/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/infer.py:203: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  torch.load(params.model_file, map_location=device)["model"]
/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/ts_vad_dataset.py:398: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  feature = torch.load(path, map_location="cpu")
2025-02-06 10:20:13,225 (model:870) WARNING: All labels are zero
2025-02-06 10:33:44,179 (infer:89) INFO: frame_len: 0.04!!
self.wavlm_fuse_feat_post_norm: False
Model DER:  0.9986033519553073
Model ACC:  0.861419223000053
  0%|          | 0/116 [00:00<?, ?it/s]  1%|          | 1/116 [00:00<01:13,  1.56it/s]  2%|▏         | 2/116 [00:01<01:12,  1.58it/s]  3%|▎         | 3/116 [00:01<01:10,  1.60it/s]  3%|▎         | 4/116 [00:02<01:09,  1.61it/s]  4%|▍         | 5/116 [00:05<02:40,  1.44s/it]  5%|▌         | 6/116 [00:06<02:07,  1.16s/it]  6%|▌         | 7/116 [00:06<01:48,  1.01it/s]  7%|▋         | 8/116 [00:07<01:35,  1.14it/s]  8%|▊         | 9/116 [00:07<01:25,  1.25it/s]  9%|▊         | 10/116 [00:08<01:19,  1.33it/s]  9%|▉         | 11/116 [00:09<01:15,  1.40it/s] 10%|█         | 12/116 [00:09<01:12,  1.43it/s] 11%|█         | 13/116 [00:10<01:10,  1.47it/s] 12%|█▏        | 14/116 [00:11<01:07,  1.52it/s] 13%|█▎        | 15/116 [00:11<01:05,  1.55it/s] 14%|█▍        | 16/116 [00:12<01:03,  1.58it/s] 15%|█▍        | 17/116 [00:12<01:02,  1.59it/s] 16%|█▌        | 18/116 [00:13<01:01,  1.60it/s] 16%|█▋        | 19/116 [00:14<01:00,  1.60it/s] 17%|█▋        | 20/116 [00:14<01:00,  1.60it/s] 18%|█▊        | 21/116 [00:15<00:59,  1.60it/s] 19%|█▉        | 22/116 [00:16<00:58,  1.61it/s] 20%|█▉        | 23/116 [00:16<00:57,  1.61it/s] 21%|██        | 24/116 [00:17<00:56,  1.61it/s] 22%|██▏       | 25/116 [00:17<00:56,  1.60it/s] 22%|██▏       | 26/116 [00:18<00:56,  1.59it/s] 23%|██▎       | 27/116 [00:19<00:55,  1.59it/s] 24%|██▍       | 28/116 [00:19<00:55,  1.59it/s] 25%|██▌       | 29/116 [00:20<00:54,  1.58it/s] 26%|██▌       | 30/116 [00:21<00:54,  1.59it/s] 27%|██▋       | 31/116 [00:21<00:52,  1.61it/s] 28%|██▊       | 32/116 [00:22<00:51,  1.63it/s] 28%|██▊       | 33/116 [00:22<00:50,  1.64it/s] 29%|██▉       | 34/116 [00:23<00:49,  1.65it/s] 30%|███       | 35/116 [00:24<00:48,  1.66it/s] 31%|███       | 36/116 [00:24<00:47,  1.67it/s] 32%|███▏      | 37/116 [00:25<00:47,  1.67it/s] 33%|███▎      | 38/116 [00:27<01:26,  1.11s/it] 34%|███▎      | 39/116 [00:28<01:13,  1.04it/s] 34%|███▍      | 40/116 [00:28<01:04,  1.17it/s] 35%|███▌      | 41/116 [00:29<00:58,  1.28it/s] 36%|███▌      | 42/116 [00:29<00:53,  1.38it/s] 37%|███▋      | 43/116 [00:30<00:50,  1.45it/s] 38%|███▊      | 44/116 [00:31<00:47,  1.51it/s] 39%|███▉      | 45/116 [00:31<00:45,  1.54it/s] 40%|███▉      | 46/116 [00:32<00:44,  1.57it/s] 41%|████      | 47/116 [00:33<00:43,  1.60it/s] 41%|████▏     | 48/116 [00:33<00:42,  1.61it/s] 42%|████▏     | 49/116 [00:34<00:41,  1.62it/s] 43%|████▎     | 50/116 [00:34<00:40,  1.63it/s] 44%|████▍     | 51/116 [00:35<00:39,  1.63it/s] 45%|████▍     | 52/116 [00:36<00:39,  1.64it/s] 46%|████▌     | 53/116 [00:36<00:38,  1.64it/s] 47%|████▋     | 54/116 [00:37<00:37,  1.65it/s] 47%|████▋     | 55/116 [00:37<00:36,  1.66it/s] 48%|████▊     | 56/116 [00:38<00:36,  1.66it/s] 49%|████▉     | 57/116 [00:39<00:35,  1.65it/s] 50%|█████     | 58/116 [00:39<00:34,  1.66it/s] 51%|█████     | 59/116 [00:40<00:34,  1.63it/s] 52%|█████▏    | 60/116 [00:40<00:34,  1.61it/s] 53%|█████▎    | 61/116 [00:41<00:34,  1.61it/s] 53%|█████▎    | 62/116 [00:42<00:33,  1.60it/s] 54%|█████▍    | 63/116 [00:42<00:33,  1.60it/s] 55%|█████▌    | 64/116 [00:43<00:32,  1.60it/s] 56%|█████▌    | 65/116 [00:44<00:31,  1.60it/s] 57%|█████▋    | 66/116 [00:44<00:31,  1.61it/s] 58%|█████▊    | 67/116 [00:45<00:30,  1.62it/s] 59%|█████▊    | 68/116 [00:45<00:29,  1.62it/s] 59%|█████▉    | 69/116 [00:46<00:28,  1.62it/s] 60%|██████    | 70/116 [00:47<00:28,  1.62it/s] 61%|██████    | 71/116 [00:47<00:28,  1.59it/s] 62%|██████▏   | 72/116 [00:48<00:27,  1.58it/s] 63%|██████▎   | 73/116 [00:50<00:51,  1.20s/it] 64%|██████▍   | 74/116 [00:51<00:43,  1.03s/it] 65%|██████▍   | 75/116 [00:52<00:37,  1.10it/s] 66%|██████▌   | 76/116 [00:52<00:33,  1.21it/s] 66%|██████▋   | 77/116 [00:53<00:29,  1.32it/s] 67%|██████▋   | 78/116 [00:54<00:27,  1.41it/s] 68%|██████▊   | 79/116 [00:54<00:25,  1.48it/s] 69%|██████▉   | 80/116 [00:55<00:23,  1.53it/s] 70%|██████▉   | 81/116 [00:55<00:22,  1.57it/s] 71%|███████   | 82/116 [00:56<00:21,  1.57it/s] 72%|███████▏  | 83/116 [00:57<00:21,  1.57it/s] 72%|███████▏  | 84/116 [00:57<00:20,  1.57it/s] 73%|███████▎  | 85/116 [00:58<00:19,  1.57it/s] 74%|███████▍  | 86/116 [00:59<00:19,  1.56it/s] 75%|███████▌  | 87/116 [00:59<00:18,  1.58it/s] 76%|███████▌  | 88/116 [01:00<00:17,  1.59it/s] 77%|███████▋  | 89/116 [01:00<00:16,  1.60it/s] 78%|███████▊  | 90/116 [01:01<00:16,  1.61it/s] 78%|███████▊  | 91/116 [01:02<00:15,  1.61it/s] 79%|███████▉  | 92/116 [01:02<00:15,  1.58it/s] 80%|████████  | 93/116 [01:03<00:14,  1.57it/s] 81%|████████  | 94/116 [01:04<00:14,  1.56it/s] 82%|████████▏ | 95/116 [01:04<00:13,  1.56it/s] 83%|████████▎ | 96/116 [01:05<00:12,  1.55it/s] 84%|████████▎ | 97/116 [01:06<00:12,  1.56it/s] 84%|████████▍ | 98/116 [01:06<00:11,  1.56it/s] 85%|████████▌ | 99/116 [01:07<00:10,  1.57it/s] 86%|████████▌ | 100/116 [01:07<00:10,  1.56it/s] 87%|████████▋ | 101/116 [01:08<00:09,  1.57it/s] 88%|████████▊ | 102/116 [01:09<00:08,  1.58it/s] 89%|████████▉ | 103/116 [01:09<00:08,  1.58it/s] 90%|████████▉ | 104/116 [01:10<00:07,  1.59it/s] 91%|█████████ | 105/116 [01:11<00:06,  1.59it/s] 91%|█████████▏| 106/116 [01:11<00:06,  1.59it/s] 92%|█████████▏| 107/116 [01:14<00:10,  1.21s/it] 93%|█████████▎| 108/116 [01:14<00:08,  1.04s/it] 94%|█████████▍| 109/116 [01:15<00:06,  1.10it/s] 95%|█████████▍| 110/116 [01:16<00:04,  1.21it/s] 96%|█████████▌| 111/116 [01:16<00:03,  1.30it/s] 97%|█████████▋| 112/116 [01:17<00:02,  1.38it/s] 97%|█████████▋| 113/116 [01:18<00:02,  1.44it/s] 98%|█████████▊| 114/116 [01:18<00:01,  1.49it/s] 99%|█████████▉| 115/116 [01:19<00:00,  1.52it/s]100%|██████████| 116/116 [01:19<00:00,  1.55it/s]100%|██████████| 116/116 [01:19<00:00,  1.45it/s]
Eval for threshold 0.2 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.3 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.35 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.4 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.45 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.5 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.55 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.6 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.7 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.8 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


2025-02-06 10:35:17,882 (infer:256) INFO: infer data_cfg: TSVADDataConfig(data_dir='/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/datasets/aishell-4/data_processed', ts_len=6000, rs_len=10, segment_shift=1, spk_path='/mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/model_hub/ts_vad/spk_embed/aishell_4/SpeakerEmbedding/', speech_encoder_type='w2v-bert2', speaker_embedding_name_dir='cam++_zh-cn_200k_feature_dir', speaker_embed_dim=192, noise_ratio=0.8, zero_ratio=0.3, sample_rate=16000, max_num_speaker=7, dataset_name='alimeeting', embed_input=False, embed_len=1, embed_shift=0.4, label_rate=25, random_channel=False, random_mask_speaker_prob=0.0, random_mask_speaker_step=0, musan_path='/mntcephfs/lee_dataset/asr/musan', rir_path='/mntcephfs/lee_dataset/asr/RIRS_NOISES')
2025-02-06 10:35:17,882 (infer:257) INFO: currently, it will infer test set.
  0%|          | 0/116 [00:00<?, ?it/s] 33%|███▎      | 38/116 [00:00<00:00, 367.76it/s] 66%|██████▌   | 76/116 [00:00<00:00, 370.31it/s] 98%|█████████▊| 114/116 [00:00<00:00, 358.91it/s]100%|██████████| 116/116 [00:00<00:00, 362.46it/s]
2025-02-06 10:35:18,232 (ts_vad_dataset:152) INFO: model expect fbank as input , fbank_input should be True !!!
2025-02-06 10:35:18,233 (ts_vad_dataset:160) INFO: loaded sentence=45820, shortest sent=1280.0, longest sent=160000.0, rs_len=10, segment_shift=1,  rir=False, musan=False, noise_ratio=0.8, zero_ratio=0.3 
2025-02-06 10:35:18,303 (infer:279) INFO: Device: cuda:0
2025-02-06 10:35:18,304 (infer:297) INFO: infer model_cfg: TSVADConfig(speech_encoder_path='/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/w2v-bert2.0/model.safetensors', speech_encoder_type='w2v-bert2', freeze_speech_encoder_updates=4000, num_attention_head=4, num_transformer_layer=2, transformer_embed_dim=384, transformer_ffn_embed_dim=1536, speaker_embed_dim=192, dropout=0.1, use_spk_embed=True, feature_grad_mult=0.1, whisper_n_mels=80, select_encoder_layer_nums=6, wavlm_fuse_feat_post_norm=False, speech_encoder_config='/mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/w2v-bert2.0/config.json', single_backend_type='mamba2', multi_backend_type='transformer', d_state=256, expand=4)
Some weights of the model checkpoint at /mntcephfs/lab_data/maduo/model_hub/speaker_pretrain_model/w2v-bert2.0/model.safetensors were not used when initializing Wav2Vec2BertModel: ['encoder.layers.10.conv_module.depthwise_conv.weight', 'encoder.layers.10.conv_module.depthwise_layer_norm.bias', 'encoder.layers.10.conv_module.depthwise_layer_norm.weight', 'encoder.layers.10.conv_module.layer_norm.bias', 'encoder.layers.10.conv_module.layer_norm.weight', 'encoder.layers.10.conv_module.pointwise_conv1.weight', 'encoder.layers.10.conv_module.pointwise_conv2.weight', 'encoder.layers.10.ffn1.intermediate_dense.bias', 'encoder.layers.10.ffn1.intermediate_dense.weight', 'encoder.layers.10.ffn1.output_dense.bias', 'encoder.layers.10.ffn1.output_dense.weight', 'encoder.layers.10.ffn1_layer_norm.bias', 'encoder.layers.10.ffn1_layer_norm.weight', 'encoder.layers.10.ffn2.intermediate_dense.bias', 'encoder.layers.10.ffn2.intermediate_dense.weight', 'encoder.layers.10.ffn2.output_dense.bias', 'encoder.layers.10.ffn2.output_dense.weight', 'encoder.layers.10.ffn2_layer_norm.bias', 'encoder.layers.10.ffn2_layer_norm.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.self_attn.distance_embedding.weight', 'encoder.layers.10.self_attn.linear_k.bias', 'encoder.layers.10.self_attn.linear_k.weight', 'encoder.layers.10.self_attn.linear_out.bias', 'encoder.layers.10.self_attn.linear_out.weight', 'encoder.layers.10.self_attn.linear_q.bias', 'encoder.layers.10.self_attn.linear_q.weight', 'encoder.layers.10.self_attn.linear_v.bias', 'encoder.layers.10.self_attn.linear_v.weight', 'encoder.layers.10.self_attn_layer_norm.bias', 'encoder.layers.10.self_attn_layer_norm.weight', 'encoder.layers.11.conv_module.depthwise_conv.weight', 'encoder.layers.11.conv_module.depthwise_layer_norm.bias', 'encoder.layers.11.conv_module.depthwise_layer_norm.weight', 'encoder.layers.11.conv_module.layer_norm.bias', 'encoder.layers.11.conv_module.layer_norm.weight', 'encoder.layers.11.conv_module.pointwise_conv1.weight', 'encoder.layers.11.conv_module.pointwise_conv2.weight', 'encoder.layers.11.ffn1.intermediate_dense.bias', 'encoder.layers.11.ffn1.intermediate_dense.weight', 'encoder.layers.11.ffn1.output_dense.bias', 'encoder.layers.11.ffn1.output_dense.weight', 'encoder.layers.11.ffn1_layer_norm.bias', 'encoder.layers.11.ffn1_layer_norm.weight', 'encoder.layers.11.ffn2.intermediate_dense.bias', 'encoder.layers.11.ffn2.intermediate_dense.weight', 'encoder.layers.11.ffn2.output_dense.bias', 'encoder.layers.11.ffn2.output_dense.weight', 'encoder.layers.11.ffn2_layer_norm.bias', 'encoder.layers.11.ffn2_layer_norm.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.self_attn.distance_embedding.weight', 'encoder.layers.11.self_attn.linear_k.bias', 'encoder.layers.11.self_attn.linear_k.weight', 'encoder.layers.11.self_attn.linear_out.bias', 'encoder.layers.11.self_attn.linear_out.weight', 'encoder.layers.11.self_attn.linear_q.bias', 'encoder.layers.11.self_attn.linear_q.weight', 'encoder.layers.11.self_attn.linear_v.bias', 'encoder.layers.11.self_attn.linear_v.weight', 'encoder.layers.11.self_attn_layer_norm.bias', 'encoder.layers.11.self_attn_layer_norm.weight', 'encoder.layers.12.conv_module.depthwise_conv.weight', 'encoder.layers.12.conv_module.depthwise_layer_norm.bias', 'encoder.layers.12.conv_module.depthwise_layer_norm.weight', 'encoder.layers.12.conv_module.layer_norm.bias', 'encoder.layers.12.conv_module.layer_norm.weight', 'encoder.layers.12.conv_module.pointwise_conv1.weight', 'encoder.layers.12.conv_module.pointwise_conv2.weight', 'encoder.layers.12.ffn1.intermediate_dense.bias', 'encoder.layers.12.ffn1.intermediate_dense.weight', 'encoder.layers.12.ffn1.output_dense.bias', 'encoder.layers.12.ffn1.output_dense.weight', 'encoder.layers.12.ffn1_layer_norm.bias', 'encoder.layers.12.ffn1_layer_norm.weight', 'encoder.layers.12.ffn2.intermediate_dense.bias', 'encoder.layers.12.ffn2.intermediate_dense.weight', 'encoder.layers.12.ffn2.output_dense.bias', 'encoder.layers.12.ffn2.output_dense.weight', 'encoder.layers.12.ffn2_layer_norm.bias', 'encoder.layers.12.ffn2_layer_norm.weight', 'encoder.layers.12.final_layer_norm.bias', 'encoder.layers.12.final_layer_norm.weight', 'encoder.layers.12.self_attn.distance_embedding.weight', 'encoder.layers.12.self_attn.linear_k.bias', 'encoder.layers.12.self_attn.linear_k.weight', 'encoder.layers.12.self_attn.linear_out.bias', 'encoder.layers.12.self_attn.linear_out.weight', 'encoder.layers.12.self_attn.linear_q.bias', 'encoder.layers.12.self_attn.linear_q.weight', 'encoder.layers.12.self_attn.linear_v.bias', 'encoder.layers.12.self_attn.linear_v.weight', 'encoder.layers.12.self_attn_layer_norm.bias', 'encoder.layers.12.self_attn_layer_norm.weight', 'encoder.layers.13.conv_module.depthwise_conv.weight', 'encoder.layers.13.conv_module.depthwise_layer_norm.bias', 'encoder.layers.13.conv_module.depthwise_layer_norm.weight', 'encoder.layers.13.conv_module.layer_norm.bias', 'encoder.layers.13.conv_module.layer_norm.weight', 'encoder.layers.13.conv_module.pointwise_conv1.weight', 'encoder.layers.13.conv_module.pointwise_conv2.weight', 'encoder.layers.13.ffn1.intermediate_dense.bias', 'encoder.layers.13.ffn1.intermediate_dense.weight', 'encoder.layers.13.ffn1.output_dense.bias', 'encoder.layers.13.ffn1.output_dense.weight', 'encoder.layers.13.ffn1_layer_norm.bias', 'encoder.layers.13.ffn1_layer_norm.weight', 'encoder.layers.13.ffn2.intermediate_dense.bias', 'encoder.layers.13.ffn2.intermediate_dense.weight', 'encoder.layers.13.ffn2.output_dense.bias', 'encoder.layers.13.ffn2.output_dense.weight', 'encoder.layers.13.ffn2_layer_norm.bias', 'encoder.layers.13.ffn2_layer_norm.weight', 'encoder.layers.13.final_layer_norm.bias', 'encoder.layers.13.final_layer_norm.weight', 'encoder.layers.13.self_attn.distance_embedding.weight', 'encoder.layers.13.self_attn.linear_k.bias', 'encoder.layers.13.self_attn.linear_k.weight', 'encoder.layers.13.self_attn.linear_out.bias', 'encoder.layers.13.self_attn.linear_out.weight', 'encoder.layers.13.self_attn.linear_q.bias', 'encoder.layers.13.self_attn.linear_q.weight', 'encoder.layers.13.self_attn.linear_v.bias', 'encoder.layers.13.self_attn.linear_v.weight', 'encoder.layers.13.self_attn_layer_norm.bias', 'encoder.layers.13.self_attn_layer_norm.weight', 'encoder.layers.14.conv_module.depthwise_conv.weight', 'encoder.layers.14.conv_module.depthwise_layer_norm.bias', 'encoder.layers.14.conv_module.depthwise_layer_norm.weight', 'encoder.layers.14.conv_module.layer_norm.bias', 'encoder.layers.14.conv_module.layer_norm.weight', 'encoder.layers.14.conv_module.pointwise_conv1.weight', 'encoder.layers.14.conv_module.pointwise_conv2.weight', 'encoder.layers.14.ffn1.intermediate_dense.bias', 'encoder.layers.14.ffn1.intermediate_dense.weight', 'encoder.layers.14.ffn1.output_dense.bias', 'encoder.layers.14.ffn1.output_dense.weight', 'encoder.layers.14.ffn1_layer_norm.bias', 'encoder.layers.14.ffn1_layer_norm.weight', 'encoder.layers.14.ffn2.intermediate_dense.bias', 'encoder.layers.14.ffn2.intermediate_dense.weight', 'encoder.layers.14.ffn2.output_dense.bias', 'encoder.layers.14.ffn2.output_dense.weight', 'encoder.layers.14.ffn2_layer_norm.bias', 'encoder.layers.14.ffn2_layer_norm.weight', 'encoder.layers.14.final_layer_norm.bias', 'encoder.layers.14.final_layer_norm.weight', 'encoder.layers.14.self_attn.distance_embedding.weight', 'encoder.layers.14.self_attn.linear_k.bias', 'encoder.layers.14.self_attn.linear_k.weight', 'encoder.layers.14.self_attn.linear_out.bias', 'encoder.layers.14.self_attn.linear_out.weight', 'encoder.layers.14.self_attn.linear_q.bias', 'encoder.layers.14.self_attn.linear_q.weight', 'encoder.layers.14.self_attn.linear_v.bias', 'encoder.layers.14.self_attn.linear_v.weight', 'encoder.layers.14.self_attn_layer_norm.bias', 'encoder.layers.14.self_attn_layer_norm.weight', 'encoder.layers.15.conv_module.depthwise_conv.weight', 'encoder.layers.15.conv_module.depthwise_layer_norm.bias', 'encoder.layers.15.conv_module.depthwise_layer_norm.weight', 'encoder.layers.15.conv_module.layer_norm.bias', 'encoder.layers.15.conv_module.layer_norm.weight', 'encoder.layers.15.conv_module.pointwise_conv1.weight', 'encoder.layers.15.conv_module.pointwise_conv2.weight', 'encoder.layers.15.ffn1.intermediate_dense.bias', 'encoder.layers.15.ffn1.intermediate_dense.weight', 'encoder.layers.15.ffn1.output_dense.bias', 'encoder.layers.15.ffn1.output_dense.weight', 'encoder.layers.15.ffn1_layer_norm.bias', 'encoder.layers.15.ffn1_layer_norm.weight', 'encoder.layers.15.ffn2.intermediate_dense.bias', 'encoder.layers.15.ffn2.intermediate_dense.weight', 'encoder.layers.15.ffn2.output_dense.bias', 'encoder.layers.15.ffn2.output_dense.weight', 'encoder.layers.15.ffn2_layer_norm.bias', 'encoder.layers.15.ffn2_layer_norm.weight', 'encoder.layers.15.final_layer_norm.bias', 'encoder.layers.15.final_layer_norm.weight', 'encoder.layers.15.self_attn.distance_embedding.weight', 'encoder.layers.15.self_attn.linear_k.bias', 'encoder.layers.15.self_attn.linear_k.weight', 'encoder.layers.15.self_attn.linear_out.bias', 'encoder.layers.15.self_attn.linear_out.weight', 'encoder.layers.15.self_attn.linear_q.bias', 'encoder.layers.15.self_attn.linear_q.weight', 'encoder.layers.15.self_attn.linear_v.bias', 'encoder.layers.15.self_attn.linear_v.weight', 'encoder.layers.15.self_attn_layer_norm.bias', 'encoder.layers.15.self_attn_layer_norm.weight', 'encoder.layers.16.conv_module.depthwise_conv.weight', 'encoder.layers.16.conv_module.depthwise_layer_norm.bias', 'encoder.layers.16.conv_module.depthwise_layer_norm.weight', 'encoder.layers.16.conv_module.layer_norm.bias', 'encoder.layers.16.conv_module.layer_norm.weight', 'encoder.layers.16.conv_module.pointwise_conv1.weight', 'encoder.layers.16.conv_module.pointwise_conv2.weight', 'encoder.layers.16.ffn1.intermediate_dense.bias', 'encoder.layers.16.ffn1.intermediate_dense.weight', 'encoder.layers.16.ffn1.output_dense.bias', 'encoder.layers.16.ffn1.output_dense.weight', 'encoder.layers.16.ffn1_layer_norm.bias', 'encoder.layers.16.ffn1_layer_norm.weight', 'encoder.layers.16.ffn2.intermediate_dense.bias', 'encoder.layers.16.ffn2.intermediate_dense.weight', 'encoder.layers.16.ffn2.output_dense.bias', 'encoder.layers.16.ffn2.output_dense.weight', 'encoder.layers.16.ffn2_layer_norm.bias', 'encoder.layers.16.ffn2_layer_norm.weight', 'encoder.layers.16.final_layer_norm.bias', 'encoder.layers.16.final_layer_norm.weight', 'encoder.layers.16.self_attn.distance_embedding.weight', 'encoder.layers.16.self_attn.linear_k.bias', 'encoder.layers.16.self_attn.linear_k.weight', 'encoder.layers.16.self_attn.linear_out.bias', 'encoder.layers.16.self_attn.linear_out.weight', 'encoder.layers.16.self_attn.linear_q.bias', 'encoder.layers.16.self_attn.linear_q.weight', 'encoder.layers.16.self_attn.linear_v.bias', 'encoder.layers.16.self_attn.linear_v.weight', 'encoder.layers.16.self_attn_layer_norm.bias', 'encoder.layers.16.self_attn_layer_norm.weight', 'encoder.layers.17.conv_module.depthwise_conv.weight', 'encoder.layers.17.conv_module.depthwise_layer_norm.bias', 'encoder.layers.17.conv_module.depthwise_layer_norm.weight', 'encoder.layers.17.conv_module.layer_norm.bias', 'encoder.layers.17.conv_module.layer_norm.weight', 'encoder.layers.17.conv_module.pointwise_conv1.weight', 'encoder.layers.17.conv_module.pointwise_conv2.weight', 'encoder.layers.17.ffn1.intermediate_dense.bias', 'encoder.layers.17.ffn1.intermediate_dense.weight', 'encoder.layers.17.ffn1.output_dense.bias', 'encoder.layers.17.ffn1.output_dense.weight', 'encoder.layers.17.ffn1_layer_norm.bias', 'encoder.layers.17.ffn1_layer_norm.weight', 'encoder.layers.17.ffn2.intermediate_dense.bias', 'encoder.layers.17.ffn2.intermediate_dense.weight', 'encoder.layers.17.ffn2.output_dense.bias', 'encoder.layers.17.ffn2.output_dense.weight', 'encoder.layers.17.ffn2_layer_norm.bias', 'encoder.layers.17.ffn2_layer_norm.weight', 'encoder.layers.17.final_layer_norm.bias', 'encoder.layers.17.final_layer_norm.weight', 'encoder.layers.17.self_attn.distance_embedding.weight', 'encoder.layers.17.self_attn.linear_k.bias', 'encoder.layers.17.self_attn.linear_k.weight', 'encoder.layers.17.self_attn.linear_out.bias', 'encoder.layers.17.self_attn.linear_out.weight', 'encoder.layers.17.self_attn.linear_q.bias', 'encoder.layers.17.self_attn.linear_q.weight', 'encoder.layers.17.self_attn.linear_v.bias', 'encoder.layers.17.self_attn.linear_v.weight', 'encoder.layers.17.self_attn_layer_norm.bias', 'encoder.layers.17.self_attn_layer_norm.weight', 'encoder.layers.18.conv_module.depthwise_conv.weight', 'encoder.layers.18.conv_module.depthwise_layer_norm.bias', 'encoder.layers.18.conv_module.depthwise_layer_norm.weight', 'encoder.layers.18.conv_module.layer_norm.bias', 'encoder.layers.18.conv_module.layer_norm.weight', 'encoder.layers.18.conv_module.pointwise_conv1.weight', 'encoder.layers.18.conv_module.pointwise_conv2.weight', 'encoder.layers.18.ffn1.intermediate_dense.bias', 'encoder.layers.18.ffn1.intermediate_dense.weight', 'encoder.layers.18.ffn1.output_dense.bias', 'encoder.layers.18.ffn1.output_dense.weight', 'encoder.layers.18.ffn1_layer_norm.bias', 'encoder.layers.18.ffn1_layer_norm.weight', 'encoder.layers.18.ffn2.intermediate_dense.bias', 'encoder.layers.18.ffn2.intermediate_dense.weight', 'encoder.layers.18.ffn2.output_dense.bias', 'encoder.layers.18.ffn2.output_dense.weight', 'encoder.layers.18.ffn2_layer_norm.bias', 'encoder.layers.18.ffn2_layer_norm.weight', 'encoder.layers.18.final_layer_norm.bias', 'encoder.layers.18.final_layer_norm.weight', 'encoder.layers.18.self_attn.distance_embedding.weight', 'encoder.layers.18.self_attn.linear_k.bias', 'encoder.layers.18.self_attn.linear_k.weight', 'encoder.layers.18.self_attn.linear_out.bias', 'encoder.layers.18.self_attn.linear_out.weight', 'encoder.layers.18.self_attn.linear_q.bias', 'encoder.layers.18.self_attn.linear_q.weight', 'encoder.layers.18.self_attn.linear_v.bias', 'encoder.layers.18.self_attn.linear_v.weight', 'encoder.layers.18.self_attn_layer_norm.bias', 'encoder.layers.18.self_attn_layer_norm.weight', 'encoder.layers.19.conv_module.depthwise_conv.weight', 'encoder.layers.19.conv_module.depthwise_layer_norm.bias', 'encoder.layers.19.conv_module.depthwise_layer_norm.weight', 'encoder.layers.19.conv_module.layer_norm.bias', 'encoder.layers.19.conv_module.layer_norm.weight', 'encoder.layers.19.conv_module.pointwise_conv1.weight', 'encoder.layers.19.conv_module.pointwise_conv2.weight', 'encoder.layers.19.ffn1.intermediate_dense.bias', 'encoder.layers.19.ffn1.intermediate_dense.weight', 'encoder.layers.19.ffn1.output_dense.bias', 'encoder.layers.19.ffn1.output_dense.weight', 'encoder.layers.19.ffn1_layer_norm.bias', 'encoder.layers.19.ffn1_layer_norm.weight', 'encoder.layers.19.ffn2.intermediate_dense.bias', 'encoder.layers.19.ffn2.intermediate_dense.weight', 'encoder.layers.19.ffn2.output_dense.bias', 'encoder.layers.19.ffn2.output_dense.weight', 'encoder.layers.19.ffn2_layer_norm.bias', 'encoder.layers.19.ffn2_layer_norm.weight', 'encoder.layers.19.final_layer_norm.bias', 'encoder.layers.19.final_layer_norm.weight', 'encoder.layers.19.self_attn.distance_embedding.weight', 'encoder.layers.19.self_attn.linear_k.bias', 'encoder.layers.19.self_attn.linear_k.weight', 'encoder.layers.19.self_attn.linear_out.bias', 'encoder.layers.19.self_attn.linear_out.weight', 'encoder.layers.19.self_attn.linear_q.bias', 'encoder.layers.19.self_attn.linear_q.weight', 'encoder.layers.19.self_attn.linear_v.bias', 'encoder.layers.19.self_attn.linear_v.weight', 'encoder.layers.19.self_attn_layer_norm.bias', 'encoder.layers.19.self_attn_layer_norm.weight', 'encoder.layers.20.conv_module.depthwise_conv.weight', 'encoder.layers.20.conv_module.depthwise_layer_norm.bias', 'encoder.layers.20.conv_module.depthwise_layer_norm.weight', 'encoder.layers.20.conv_module.layer_norm.bias', 'encoder.layers.20.conv_module.layer_norm.weight', 'encoder.layers.20.conv_module.pointwise_conv1.weight', 'encoder.layers.20.conv_module.pointwise_conv2.weight', 'encoder.layers.20.ffn1.intermediate_dense.bias', 'encoder.layers.20.ffn1.intermediate_dense.weight', 'encoder.layers.20.ffn1.output_dense.bias', 'encoder.layers.20.ffn1.output_dense.weight', 'encoder.layers.20.ffn1_layer_norm.bias', 'encoder.layers.20.ffn1_layer_norm.weight', 'encoder.layers.20.ffn2.intermediate_dense.bias', 'encoder.layers.20.ffn2.intermediate_dense.weight', 'encoder.layers.20.ffn2.output_dense.bias', 'encoder.layers.20.ffn2.output_dense.weight', 'encoder.layers.20.ffn2_layer_norm.bias', 'encoder.layers.20.ffn2_layer_norm.weight', 'encoder.layers.20.final_layer_norm.bias', 'encoder.layers.20.final_layer_norm.weight', 'encoder.layers.20.self_attn.distance_embedding.weight', 'encoder.layers.20.self_attn.linear_k.bias', 'encoder.layers.20.self_attn.linear_k.weight', 'encoder.layers.20.self_attn.linear_out.bias', 'encoder.layers.20.self_attn.linear_out.weight', 'encoder.layers.20.self_attn.linear_q.bias', 'encoder.layers.20.self_attn.linear_q.weight', 'encoder.layers.20.self_attn.linear_v.bias', 'encoder.layers.20.self_attn.linear_v.weight', 'encoder.layers.20.self_attn_layer_norm.bias', 'encoder.layers.20.self_attn_layer_norm.weight', 'encoder.layers.21.conv_module.depthwise_conv.weight', 'encoder.layers.21.conv_module.depthwise_layer_norm.bias', 'encoder.layers.21.conv_module.depthwise_layer_norm.weight', 'encoder.layers.21.conv_module.layer_norm.bias', 'encoder.layers.21.conv_module.layer_norm.weight', 'encoder.layers.21.conv_module.pointwise_conv1.weight', 'encoder.layers.21.conv_module.pointwise_conv2.weight', 'encoder.layers.21.ffn1.intermediate_dense.bias', 'encoder.layers.21.ffn1.intermediate_dense.weight', 'encoder.layers.21.ffn1.output_dense.bias', 'encoder.layers.21.ffn1.output_dense.weight', 'encoder.layers.21.ffn1_layer_norm.bias', 'encoder.layers.21.ffn1_layer_norm.weight', 'encoder.layers.21.ffn2.intermediate_dense.bias', 'encoder.layers.21.ffn2.intermediate_dense.weight', 'encoder.layers.21.ffn2.output_dense.bias', 'encoder.layers.21.ffn2.output_dense.weight', 'encoder.layers.21.ffn2_layer_norm.bias', 'encoder.layers.21.ffn2_layer_norm.weight', 'encoder.layers.21.final_layer_norm.bias', 'encoder.layers.21.final_layer_norm.weight', 'encoder.layers.21.self_attn.distance_embedding.weight', 'encoder.layers.21.self_attn.linear_k.bias', 'encoder.layers.21.self_attn.linear_k.weight', 'encoder.layers.21.self_attn.linear_out.bias', 'encoder.layers.21.self_attn.linear_out.weight', 'encoder.layers.21.self_attn.linear_q.bias', 'encoder.layers.21.self_attn.linear_q.weight', 'encoder.layers.21.self_attn.linear_v.bias', 'encoder.layers.21.self_attn.linear_v.weight', 'encoder.layers.21.self_attn_layer_norm.bias', 'encoder.layers.21.self_attn_layer_norm.weight', 'encoder.layers.22.conv_module.depthwise_conv.weight', 'encoder.layers.22.conv_module.depthwise_layer_norm.bias', 'encoder.layers.22.conv_module.depthwise_layer_norm.weight', 'encoder.layers.22.conv_module.layer_norm.bias', 'encoder.layers.22.conv_module.layer_norm.weight', 'encoder.layers.22.conv_module.pointwise_conv1.weight', 'encoder.layers.22.conv_module.pointwise_conv2.weight', 'encoder.layers.22.ffn1.intermediate_dense.bias', 'encoder.layers.22.ffn1.intermediate_dense.weight', 'encoder.layers.22.ffn1.output_dense.bias', 'encoder.layers.22.ffn1.output_dense.weight', 'encoder.layers.22.ffn1_layer_norm.bias', 'encoder.layers.22.ffn1_layer_norm.weight', 'encoder.layers.22.ffn2.intermediate_dense.bias', 'encoder.layers.22.ffn2.intermediate_dense.weight', 'encoder.layers.22.ffn2.output_dense.bias', 'encoder.layers.22.ffn2.output_dense.weight', 'encoder.layers.22.ffn2_layer_norm.bias', 'encoder.layers.22.ffn2_layer_norm.weight', 'encoder.layers.22.final_layer_norm.bias', 'encoder.layers.22.final_layer_norm.weight', 'encoder.layers.22.self_attn.distance_embedding.weight', 'encoder.layers.22.self_attn.linear_k.bias', 'encoder.layers.22.self_attn.linear_k.weight', 'encoder.layers.22.self_attn.linear_out.bias', 'encoder.layers.22.self_attn.linear_out.weight', 'encoder.layers.22.self_attn.linear_q.bias', 'encoder.layers.22.self_attn.linear_q.weight', 'encoder.layers.22.self_attn.linear_v.bias', 'encoder.layers.22.self_attn.linear_v.weight', 'encoder.layers.22.self_attn_layer_norm.bias', 'encoder.layers.22.self_attn_layer_norm.weight', 'encoder.layers.23.conv_module.depthwise_conv.weight', 'encoder.layers.23.conv_module.depthwise_layer_norm.bias', 'encoder.layers.23.conv_module.depthwise_layer_norm.weight', 'encoder.layers.23.conv_module.layer_norm.bias', 'encoder.layers.23.conv_module.layer_norm.weight', 'encoder.layers.23.conv_module.pointwise_conv1.weight', 'encoder.layers.23.conv_module.pointwise_conv2.weight', 'encoder.layers.23.ffn1.intermediate_dense.bias', 'encoder.layers.23.ffn1.intermediate_dense.weight', 'encoder.layers.23.ffn1.output_dense.bias', 'encoder.layers.23.ffn1.output_dense.weight', 'encoder.layers.23.ffn1_layer_norm.bias', 'encoder.layers.23.ffn1_layer_norm.weight', 'encoder.layers.23.ffn2.intermediate_dense.bias', 'encoder.layers.23.ffn2.intermediate_dense.weight', 'encoder.layers.23.ffn2.output_dense.bias', 'encoder.layers.23.ffn2.output_dense.weight', 'encoder.layers.23.ffn2_layer_norm.bias', 'encoder.layers.23.ffn2_layer_norm.weight', 'encoder.layers.23.final_layer_norm.bias', 'encoder.layers.23.final_layer_norm.weight', 'encoder.layers.23.self_attn.distance_embedding.weight', 'encoder.layers.23.self_attn.linear_k.bias', 'encoder.layers.23.self_attn.linear_k.weight', 'encoder.layers.23.self_attn.linear_out.bias', 'encoder.layers.23.self_attn.linear_out.weight', 'encoder.layers.23.self_attn.linear_q.bias', 'encoder.layers.23.self_attn.linear_q.weight', 'encoder.layers.23.self_attn.linear_v.bias', 'encoder.layers.23.self_attn.linear_v.weight', 'encoder.layers.23.self_attn_layer_norm.bias', 'encoder.layers.23.self_attn_layer_norm.weight', 'encoder.layers.6.conv_module.depthwise_conv.weight', 'encoder.layers.6.conv_module.depthwise_layer_norm.bias', 'encoder.layers.6.conv_module.depthwise_layer_norm.weight', 'encoder.layers.6.conv_module.layer_norm.bias', 'encoder.layers.6.conv_module.layer_norm.weight', 'encoder.layers.6.conv_module.pointwise_conv1.weight', 'encoder.layers.6.conv_module.pointwise_conv2.weight', 'encoder.layers.6.ffn1.intermediate_dense.bias', 'encoder.layers.6.ffn1.intermediate_dense.weight', 'encoder.layers.6.ffn1.output_dense.bias', 'encoder.layers.6.ffn1.output_dense.weight', 'encoder.layers.6.ffn1_layer_norm.bias', 'encoder.layers.6.ffn1_layer_norm.weight', 'encoder.layers.6.ffn2.intermediate_dense.bias', 'encoder.layers.6.ffn2.intermediate_dense.weight', 'encoder.layers.6.ffn2.output_dense.bias', 'encoder.layers.6.ffn2.output_dense.weight', 'encoder.layers.6.ffn2_layer_norm.bias', 'encoder.layers.6.ffn2_layer_norm.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.self_attn.distance_embedding.weight', 'encoder.layers.6.self_attn.linear_k.bias', 'encoder.layers.6.self_attn.linear_k.weight', 'encoder.layers.6.self_attn.linear_out.bias', 'encoder.layers.6.self_attn.linear_out.weight', 'encoder.layers.6.self_attn.linear_q.bias', 'encoder.layers.6.self_attn.linear_q.weight', 'encoder.layers.6.self_attn.linear_v.bias', 'encoder.layers.6.self_attn.linear_v.weight', 'encoder.layers.6.self_attn_layer_norm.bias', 'encoder.layers.6.self_attn_layer_norm.weight', 'encoder.layers.7.conv_module.depthwise_conv.weight', 'encoder.layers.7.conv_module.depthwise_layer_norm.bias', 'encoder.layers.7.conv_module.depthwise_layer_norm.weight', 'encoder.layers.7.conv_module.layer_norm.bias', 'encoder.layers.7.conv_module.layer_norm.weight', 'encoder.layers.7.conv_module.pointwise_conv1.weight', 'encoder.layers.7.conv_module.pointwise_conv2.weight', 'encoder.layers.7.ffn1.intermediate_dense.bias', 'encoder.layers.7.ffn1.intermediate_dense.weight', 'encoder.layers.7.ffn1.output_dense.bias', 'encoder.layers.7.ffn1.output_dense.weight', 'encoder.layers.7.ffn1_layer_norm.bias', 'encoder.layers.7.ffn1_layer_norm.weight', 'encoder.layers.7.ffn2.intermediate_dense.bias', 'encoder.layers.7.ffn2.intermediate_dense.weight', 'encoder.layers.7.ffn2.output_dense.bias', 'encoder.layers.7.ffn2.output_dense.weight', 'encoder.layers.7.ffn2_layer_norm.bias', 'encoder.layers.7.ffn2_layer_norm.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.self_attn.distance_embedding.weight', 'encoder.layers.7.self_attn.linear_k.bias', 'encoder.layers.7.self_attn.linear_k.weight', 'encoder.layers.7.self_attn.linear_out.bias', 'encoder.layers.7.self_attn.linear_out.weight', 'encoder.layers.7.self_attn.linear_q.bias', 'encoder.layers.7.self_attn.linear_q.weight', 'encoder.layers.7.self_attn.linear_v.bias', 'encoder.layers.7.self_attn.linear_v.weight', 'encoder.layers.7.self_attn_layer_norm.bias', 'encoder.layers.7.self_attn_layer_norm.weight', 'encoder.layers.8.conv_module.depthwise_conv.weight', 'encoder.layers.8.conv_module.depthwise_layer_norm.bias', 'encoder.layers.8.conv_module.depthwise_layer_norm.weight', 'encoder.layers.8.conv_module.layer_norm.bias', 'encoder.layers.8.conv_module.layer_norm.weight', 'encoder.layers.8.conv_module.pointwise_conv1.weight', 'encoder.layers.8.conv_module.pointwise_conv2.weight', 'encoder.layers.8.ffn1.intermediate_dense.bias', 'encoder.layers.8.ffn1.intermediate_dense.weight', 'encoder.layers.8.ffn1.output_dense.bias', 'encoder.layers.8.ffn1.output_dense.weight', 'encoder.layers.8.ffn1_layer_norm.bias', 'encoder.layers.8.ffn1_layer_norm.weight', 'encoder.layers.8.ffn2.intermediate_dense.bias', 'encoder.layers.8.ffn2.intermediate_dense.weight', 'encoder.layers.8.ffn2.output_dense.bias', 'encoder.layers.8.ffn2.output_dense.weight', 'encoder.layers.8.ffn2_layer_norm.bias', 'encoder.layers.8.ffn2_layer_norm.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.self_attn.distance_embedding.weight', 'encoder.layers.8.self_attn.linear_k.bias', 'encoder.layers.8.self_attn.linear_k.weight', 'encoder.layers.8.self_attn.linear_out.bias', 'encoder.layers.8.self_attn.linear_out.weight', 'encoder.layers.8.self_attn.linear_q.bias', 'encoder.layers.8.self_attn.linear_q.weight', 'encoder.layers.8.self_attn.linear_v.bias', 'encoder.layers.8.self_attn.linear_v.weight', 'encoder.layers.8.self_attn_layer_norm.bias', 'encoder.layers.8.self_attn_layer_norm.weight', 'encoder.layers.9.conv_module.depthwise_conv.weight', 'encoder.layers.9.conv_module.depthwise_layer_norm.bias', 'encoder.layers.9.conv_module.depthwise_layer_norm.weight', 'encoder.layers.9.conv_module.layer_norm.bias', 'encoder.layers.9.conv_module.layer_norm.weight', 'encoder.layers.9.conv_module.pointwise_conv1.weight', 'encoder.layers.9.conv_module.pointwise_conv2.weight', 'encoder.layers.9.ffn1.intermediate_dense.bias', 'encoder.layers.9.ffn1.intermediate_dense.weight', 'encoder.layers.9.ffn1.output_dense.bias', 'encoder.layers.9.ffn1.output_dense.weight', 'encoder.layers.9.ffn1_layer_norm.bias', 'encoder.layers.9.ffn1_layer_norm.weight', 'encoder.layers.9.ffn2.intermediate_dense.bias', 'encoder.layers.9.ffn2.intermediate_dense.weight', 'encoder.layers.9.ffn2.output_dense.bias', 'encoder.layers.9.ffn2.output_dense.weight', 'encoder.layers.9.ffn2_layer_norm.bias', 'encoder.layers.9.ffn2_layer_norm.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.self_attn.distance_embedding.weight', 'encoder.layers.9.self_attn.linear_k.bias', 'encoder.layers.9.self_attn.linear_k.weight', 'encoder.layers.9.self_attn.linear_out.bias', 'encoder.layers.9.self_attn.linear_out.weight', 'encoder.layers.9.self_attn.linear_q.bias', 'encoder.layers.9.self_attn.linear_q.weight', 'encoder.layers.9.self_attn.linear_v.bias', 'encoder.layers.9.self_attn.linear_v.weight', 'encoder.layers.9.self_attn_layer_norm.bias', 'encoder.layers.9.self_attn_layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
/mntnfs/lee_data1/maduo/anaconda3/envs/dia_pt2.4/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(f"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}")
2025-02-06 10:35:19,644 (infer:201) INFO: params.model_file: /mntcephfs/data/haizhouli/Lab-projects/maduo/huawei_diarization/exp/speaker_diarization/ts_vad2/alimeeting_ami_aishell_4_ts_vad2_two_gpus_freeze_with_musan_rirs_w2v-bert2_cam++_200k_zh_cn_epoch20_front_fix_seed_lr1e4_single_backend_2layer_mamba2_multi_backend_transformer_d_state256_rs_len10/best-valid-der.pt
/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/infer.py:203: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  torch.load(params.model_file, map_location=device)["model"]
/mntnfs/lee_data1/maduo/codebase/speaker_diarization/egs/multi_datasets/ts_vad2/ts_vad_dataset.py:398: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  feature = torch.load(path, map_location="cpu")
2025-02-06 10:40:02,372 (model:870) WARNING: All labels are zero
2025-02-06 10:53:30,399 (infer:89) INFO: frame_len: 0.04!!
self.wavlm_fuse_feat_post_norm: False
Model DER:  0.9986033519553073
Model ACC:  0.861419223000053
  0%|          | 0/116 [00:00<?, ?it/s]  1%|          | 1/116 [00:00<01:10,  1.64it/s]  2%|▏         | 2/116 [00:01<01:09,  1.64it/s]  3%|▎         | 3/116 [00:01<01:08,  1.65it/s]  3%|▎         | 4/116 [00:02<01:08,  1.64it/s]  4%|▍         | 5/116 [00:03<01:07,  1.64it/s]  5%|▌         | 6/116 [00:03<01:06,  1.65it/s]  6%|▌         | 7/116 [00:04<01:07,  1.63it/s]  7%|▋         | 8/116 [00:04<01:07,  1.61it/s]  8%|▊         | 9/116 [00:05<01:06,  1.60it/s]  9%|▊         | 10/116 [00:06<01:06,  1.59it/s]  9%|▉         | 11/116 [00:06<01:06,  1.58it/s] 10%|█         | 12/116 [00:07<01:05,  1.58it/s] 11%|█         | 13/116 [00:08<01:04,  1.60it/s] 12%|█▏        | 14/116 [00:08<01:03,  1.61it/s] 13%|█▎        | 15/116 [00:09<01:02,  1.62it/s] 14%|█▍        | 16/116 [00:09<01:01,  1.62it/s] 15%|█▍        | 17/116 [00:10<01:00,  1.63it/s] 16%|█▌        | 18/116 [00:11<00:59,  1.64it/s] 16%|█▋        | 19/116 [00:11<00:59,  1.64it/s] 17%|█▋        | 20/116 [00:12<00:58,  1.63it/s] 18%|█▊        | 21/116 [00:12<00:58,  1.63it/s] 19%|█▉        | 22/116 [00:13<00:57,  1.63it/s] 20%|█▉        | 23/116 [00:14<00:56,  1.63it/s] 21%|██        | 24/116 [00:14<00:56,  1.64it/s] 22%|██▏       | 25/116 [00:15<00:56,  1.62it/s] 22%|██▏       | 26/116 [00:16<00:55,  1.61it/s] 23%|██▎       | 27/116 [00:16<00:55,  1.60it/s] 24%|██▍       | 28/116 [00:17<00:54,  1.60it/s] 25%|██▌       | 29/116 [00:17<00:54,  1.60it/s] 26%|██▌       | 30/116 [00:18<00:53,  1.60it/s] 27%|██▋       | 31/116 [00:20<01:36,  1.14s/it] 28%|██▊       | 32/116 [00:21<01:21,  1.03it/s] 28%|██▊       | 33/116 [00:22<01:11,  1.16it/s] 29%|██▉       | 34/116 [00:22<01:03,  1.28it/s] 30%|███       | 35/116 [00:23<00:58,  1.38it/s] 31%|███       | 36/116 [00:23<00:54,  1.46it/s] 32%|███▏      | 37/116 [00:24<00:51,  1.52it/s] 33%|███▎      | 38/116 [00:25<00:49,  1.56it/s] 34%|███▎      | 39/116 [00:25<00:48,  1.59it/s] 34%|███▍      | 40/116 [00:26<00:47,  1.61it/s] 35%|███▌      | 41/116 [00:26<00:46,  1.63it/s] 36%|███▌      | 42/116 [00:27<00:45,  1.63it/s] 37%|███▋      | 43/116 [00:28<00:44,  1.64it/s] 38%|███▊      | 44/116 [00:28<00:43,  1.65it/s] 39%|███▉      | 45/116 [00:29<00:43,  1.63it/s] 40%|███▉      | 46/116 [00:29<00:42,  1.64it/s] 41%|████      | 47/116 [00:30<00:42,  1.64it/s] 41%|████▏     | 48/116 [00:31<00:41,  1.65it/s] 42%|████▏     | 49/116 [00:31<00:40,  1.65it/s] 43%|████▎     | 50/116 [00:32<00:39,  1.66it/s] 44%|████▍     | 51/116 [00:32<00:39,  1.66it/s] 45%|████▍     | 52/116 [00:33<00:39,  1.64it/s] 46%|████▌     | 53/116 [00:34<00:38,  1.65it/s] 47%|████▋     | 54/116 [00:34<00:37,  1.65it/s] 47%|████▋     | 55/116 [00:35<00:36,  1.66it/s] 48%|████▊     | 56/116 [00:35<00:35,  1.67it/s] 49%|████▉     | 57/116 [00:36<00:35,  1.67it/s] 50%|█████     | 58/116 [00:37<00:34,  1.67it/s] 51%|█████     | 59/116 [00:37<00:34,  1.63it/s] 52%|█████▏    | 60/116 [00:38<00:34,  1.62it/s] 53%|█████▎    | 61/116 [00:39<00:34,  1.61it/s] 53%|█████▎    | 62/116 [00:39<00:33,  1.60it/s] 54%|█████▍    | 63/116 [00:40<00:33,  1.59it/s] 55%|█████▌    | 64/116 [00:40<00:32,  1.60it/s] 56%|█████▌    | 65/116 [00:41<00:32,  1.59it/s] 57%|█████▋    | 66/116 [00:43<00:57,  1.14s/it] 58%|█████▊    | 67/116 [00:44<00:48,  1.02it/s] 59%|█████▊    | 68/116 [00:45<00:41,  1.15it/s] 59%|█████▉    | 69/116 [00:45<00:37,  1.27it/s] 60%|██████    | 70/116 [00:46<00:33,  1.36it/s] 61%|██████    | 71/116 [00:46<00:31,  1.43it/s] 62%|██████▏   | 72/116 [00:47<00:29,  1.47it/s] 63%|██████▎   | 73/116 [00:48<00:28,  1.51it/s] 64%|██████▍   | 74/116 [00:48<00:27,  1.53it/s] 65%|██████▍   | 75/116 [00:49<00:26,  1.55it/s] 66%|██████▌   | 76/116 [00:50<00:25,  1.57it/s] 66%|██████▋   | 77/116 [00:50<00:24,  1.60it/s] 67%|██████▋   | 78/116 [00:51<00:23,  1.62it/s] 68%|██████▊   | 79/116 [00:51<00:22,  1.63it/s] 69%|██████▉   | 80/116 [00:52<00:21,  1.65it/s] 70%|██████▉   | 81/116 [00:53<00:21,  1.66it/s] 71%|███████   | 82/116 [00:53<00:20,  1.63it/s] 72%|███████▏  | 83/116 [00:54<00:20,  1.62it/s] 72%|███████▏  | 84/116 [00:54<00:19,  1.60it/s] 73%|███████▎  | 85/116 [00:55<00:19,  1.60it/s] 74%|███████▍  | 86/116 [00:56<00:18,  1.59it/s] 75%|███████▌  | 87/116 [00:56<00:18,  1.60it/s] 76%|███████▌  | 88/116 [00:57<00:17,  1.61it/s] 77%|███████▋  | 89/116 [00:58<00:16,  1.62it/s] 78%|███████▊  | 90/116 [00:58<00:16,  1.62it/s] 78%|███████▊  | 91/116 [00:59<00:15,  1.62it/s] 79%|███████▉  | 92/116 [00:59<00:14,  1.60it/s] 80%|████████  | 93/116 [01:00<00:14,  1.59it/s] 81%|████████  | 94/116 [01:01<00:13,  1.58it/s] 82%|████████▏ | 95/116 [01:01<00:13,  1.57it/s] 83%|████████▎ | 96/116 [01:02<00:12,  1.56it/s] 84%|████████▎ | 97/116 [01:03<00:12,  1.57it/s] 84%|████████▍ | 98/116 [01:03<00:11,  1.57it/s] 85%|████████▌ | 99/116 [01:06<00:19,  1.14s/it] 86%|████████▌ | 100/116 [01:06<00:15,  1.01it/s] 87%|████████▋ | 101/116 [01:07<00:13,  1.14it/s] 88%|████████▊ | 102/116 [01:07<00:11,  1.24it/s] 89%|████████▉ | 103/116 [01:08<00:09,  1.33it/s] 90%|████████▉ | 104/116 [01:09<00:08,  1.40it/s] 91%|█████████ | 105/116 [01:09<00:07,  1.45it/s] 91%|█████████▏| 106/116 [01:10<00:06,  1.50it/s] 92%|█████████▏| 107/116 [01:11<00:05,  1.53it/s] 93%|█████████▎| 108/116 [01:11<00:05,  1.55it/s] 94%|█████████▍| 109/116 [01:12<00:04,  1.56it/s] 95%|█████████▍| 110/116 [01:12<00:03,  1.57it/s] 96%|█████████▌| 111/116 [01:13<00:03,  1.57it/s] 97%|█████████▋| 112/116 [01:14<00:02,  1.58it/s] 97%|█████████▋| 113/116 [01:14<00:01,  1.58it/s] 98%|█████████▊| 114/116 [01:15<00:01,  1.59it/s] 99%|█████████▉| 115/116 [01:16<00:00,  1.59it/s]100%|██████████| 116/116 [01:16<00:00,  1.59it/s]100%|██████████| 116/116 [01:16<00:00,  1.51it/s]
Eval for threshold 0.2 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.3 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.35 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.4 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.45 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.5 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.55 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.6 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.7 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


Eval for threshold 0.8 DER=100.00, miss=100.00, falarm=0.00, confusion=0.00


